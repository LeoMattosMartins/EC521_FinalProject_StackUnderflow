[
  {
    "url": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator",
    "title": "Does Python have a ternary conditional operator?",
    "question_id": 394809,
    "posted_date": "2008-12-27T03:32:18",
    "answers": [
      {
        "answer_id": 394814,
        "body": ">>> pass if False else pass\n  File \"<stdin>\", line 1\n    pass if False else pass\n         ^\nSyntaxError: invalid syntax\n>>> # Python parses this as `x = (1 if False else y) = 2`\n>>> # The `(1 if False else x)` part is actually valid, but\n>>> # it can't be on the left-hand side of `=`.\n>>> x = 1 if False else y = 2\n  File \"<stdin>\", line 1\nSyntaxError: cannot assign to conditional expression\n>>> # If we parenthesize it instead...\n>>> (x = 1) if False else (y = 2)\n  File \"<stdin>\", line 1\n    (x = 1) if False else (y = 2)\n       ^\nSyntaxError: invalid syntax",
        "score": 9290,
        "is_accepted": true,
        "creation_date": "2008-12-27T03:44:19",
        "author": "Vinko Vrsalovic"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42950/get-the-last-day-of-the-month",
    "title": "Get the last day of the month",
    "question_id": 42950,
    "posted_date": "2008-09-03T20:54:44",
    "answers": [
      {
        "answer_id": 43663,
        "body": ">>> import calendar\n>>> calendar.monthrange(2002, 1)\n(calendar.TUESDAY, 31)\n>>> calendar.monthrange(2008, 2)  # leap years are handled correctly\n(calendar.FRIDAY, 29)\n>>> calendar.monthrange(2100, 2)  # years divisible by 100 but not 400 aren't leap years\n(calendar.MONDAY, 28)\n# the module uses the Georgian calendar extended into the past and\n# future, so leap days in the distant past will differ from Julian:\n>>> calendar.monthrange(1100, 2)\n(calendar.THURSDAY, 28)\n# note also that pre-Python 3.12, the REPL renders the weekday\n# as a bare integer:\n>>> calendar.monthrange(2002, 1)\n(1, 31)",
        "score": 1510,
        "is_accepted": true,
        "creation_date": "2008-09-04T08:44:12",
        "author": "Blair Conrad"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29530232/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe",
    "title": "How to check if any value is NaN in a Pandas DataFrame",
    "question_id": 29530232,
    "posted_date": "2015-04-09T01:09:39",
    "answers": [
      {
        "answer_id": 29530601,
        "body": "import numpy as np\nimport pandas as pd\nimport perfplot\ndef setup(n):\n    df = pd.DataFrame(np.random.randn(n))\n    df[df > 0.9] = np.nan\n    return df\ndef isnull_any(df):\n    return df.isnull().any()\ndef isnull_values_sum(df):\n    return df.isnull().values.sum() > 0\ndef isnull_sum(df):\n    return df.isnull().sum() > 0\ndef isnull_values_any(df):\n    return df.isnull().values.any()\nperfplot.save(\n    \"out.png\",\n    setup=setup,\n    kernels=[isnull_any, isnull_values_sum, isnull_sum, isnull_values_any],\n    n_range=[2 ** k for k in range(25)],\n)",
        "score": 881,
        "is_accepted": true,
        "creation_date": "2015-04-09T01:39:54",
        "author": "S Anand"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2627002/whats-the-pythonic-way-to-use-getters-and-setters",
    "title": "What&#39;s the pythonic way to use getters and setters?",
    "question_id": 2627002,
    "posted_date": "2010-04-13T00:38:23",
    "answers": [
      {
        "answer_id": 36943813,
        "body": "class Obj:\n    \"\"\"property demo\"\"\"\n    #\n    @property            # first decorate the getter method\n    def attribute(self): # This getter method name is *the* name\n        return self._attribute\n    #\n    @attribute.setter    # the property decorates with `.setter` now\n    def attribute(self, value):   # name, e.g. \"attribute\", is the same\n        self._attribute = value   # the \"value\" name isn't special\n    #\n    @attribute.deleter     # decorate with `.deleter`\n    def attribute(self):   # again, the method name is the same\n        del self._attribute",
        "score": 618,
        "is_accepted": false,
        "creation_date": "2016-04-29T12:58:35",
        "author": "Aaron Hall"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/34439/finding-what-methods-a-python-object-has",
    "title": "Finding what methods a Python object has",
    "question_id": 34439,
    "posted_date": "2008-08-29T11:05:17",
    "answers": [
      {
        "answer_id": 34452,
        "body": "import pandas as pd\ndf = pd.DataFrame([[10, 20, 30], [100, 200, 300]],\n                  columns=['foo', 'bar', 'baz'])\ndef get_methods(object, spacing=20):\n  methodList = []\n  for method_name in dir(object):\n    try:\n        if callable(getattr(object, method_name)):\n            methodList.append(str(method_name))\n    except Exception:\n        methodList.append(str(method_name))\n  processFunc = (lambda s: ' '.join(s.split())) or (lambda s: s)\n  for method in methodList:\n    try:\n        print(str(method.ljust(spacing)) + ' ' +\n              processFunc(str(getattr(object, method).__doc__)[0:90]))\n    except Exception:\n        print(method.ljust(spacing) + ' ' + ' getattr() failed')\nget_methods(df['foo'])",
        "score": 767,
        "is_accepted": true,
        "creation_date": "2008-08-29T11:09:05",
        "author": "ljs"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/35215161/most-efficient-way-to-map-function-over-numpy-array",
    "title": "Most efficient way to map function over numpy array",
    "question_id": 35215161,
    "posted_date": "2016-02-04T21:08:10",
    "answers": [
      {
        "answer_id": 46470401,
        "body": "import numpy as np\nimport perfplot\nimport math\ndef f(x):\n    # return math.sqrt(x)\n    return np.sqrt(x)\nvf = np.vectorize(f)\ndef array_for(x):\n    return np.array([f(xi) for xi in x])\ndef array_map(x):\n    return np.array(list(map(f, x)))\ndef fromiter(x):\n    return np.fromiter((f(xi) for xi in x), x.dtype)\ndef vectorize(x):\n    return np.vectorize(f)(x)\ndef vectorize_without_init(x):\n    return vf(x)\nb = perfplot.bench(\n    setup=np.random.rand,\n    n_range=[2 ** k for k in range(20)],\n    kernels=[\n        f,\n        array_for,\n        array_map,\n        fromiter,\n        vectorize,\n        vectorize_without_init,\n    ],\n    xlabel=\"len(x)\",\n)\nb.save(\"out1.svg\")\nb.show()",
        "score": 587,
        "is_accepted": false,
        "creation_date": "2017-09-28T09:28:35",
        "author": "Nico Schl&#246;mer"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/32899/how-do-you-generate-dynamic-parameterized-unit-tests-in-python",
    "title": "How do you generate dynamic (parameterized) unit tests in Python?",
    "question_id": 32899,
    "posted_date": "2008-08-28T13:49:02",
    "answers": [
      {
        "answer_id": 32939,
        "body": "test_sequence_0_foo (__main__.TestSequence) ... ok\ntest_sequence_1_bar (__main__.TestSequence) ... FAIL\ntest_sequence_2_lee (__main__.TestSequence) ... ok\n======================================================================\nFAIL: test_sequence_1_bar (__main__.TestSequence)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/site-packages/parameterized/parameterized.py\", line 233, in <lambda>\n    standalone_func = lambda *a: func(*(a + p.args), **p.kwargs)\n  File \"x.py\", line 12, in test_sequence\n    self.assertEqual(a,b)\nAssertionError: 'a' != 'b'",
        "score": 319,
        "is_accepted": true,
        "creation_date": "2008-08-28T14:02:33",
        "author": "Dmitry Mukhin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6824681/get-a-random-boolean-in-python",
    "title": "Get a random boolean in python?",
    "question_id": 6824681,
    "posted_date": "2011-07-25T22:46:02",
    "answers": [
      {
        "answer_id": 6824868,
        "body": "$ python3 --version\nPython 3.9.7\n$ python3 -m timeit -s \"from random import choice\" \"choice([True, False])\"\n1000000 loops, best of 5: 376 nsec per loop\n$ python3 -m timeit -s \"from random import choice\" \"choice((True, False))\"\n1000000 loops, best of 5: 352 nsec per loop\n$ python3 -m timeit -s \"from random import getrandbits\" \"getrandbits(1)\"\n10000000 loops, best of 5: 33.7 nsec per loop\n$ python3 -m timeit -s \"from random import getrandbits\" \"bool(getrandbits(1))\"\n5000000 loops, best of 5: 89.5 nsec per loop\n$ python3 -m timeit -s \"from random import getrandbits\" \"not getrandbits(1)\"\n5000000 loops, best of 5: 46.3 nsec per loop\n$ python3 -m timeit -s \"from random import random\" \"random() < 0.5\"\n5000000 loops, best of 5: 46.4 nsec per loop",
        "score": 524,
        "is_accepted": true,
        "creation_date": "2011-07-25T23:18:45",
        "author": "John La Rooy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18072759/how-can-i-use-list-comprehensions-to-process-a-nested-list",
    "title": "How can I use list comprehensions to process a nested list?",
    "question_id": 18072759,
    "posted_date": "2013-08-06T02:02:43",
    "answers": [
      {
        "answer_id": 45079294,
        "body": "school_data = [\n    {\n        \"students\": [\n            {\"name\": \"John\", \"age\": 18, \"friends\": [\"Alice\", \"Bob\"]},\n            {\"name\": \"Alice\", \"age\": 19, \"friends\": [\"John\", \"Bob\"]},\n        ],\n        \"teacher\": \"Mr. Smith\",\n    },\n    {\n        \"students\": [\n            {\"name\": \"Sponge\", \"age\": 20, \"friends\": [\"Bob\"]},\n        ],\n        \"teacher\": \"Mr. tom\",\n    },\n]\nresult = []\nfor class_dict in school_data:\n    for student_dict in class_dict[\"students\"]:\n        if student_dict[\"name\"] == \"John\" and student_dict[\"age\"] == 18:\n            for friend_name in student_dict[\"friends\"]:\n                if friend_name.startswith(\"A\"):\n                    result.append(friend_name)",
        "score": 402,
        "is_accepted": false,
        "creation_date": "2017-07-13T07:27:35",
        "author": "Rahul"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/328356/extracting-text-from-html-file-using-python",
    "title": "Extracting text from HTML file using Python",
    "question_id": 328356,
    "posted_date": "2008-11-29T21:28:04",
    "answers": [
      {
        "answer_id": 24618186,
        "body": "from urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nurl = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\nhtml = urlopen(url).read()\nsoup = BeautifulSoup(html, features=\"html.parser\")\n# kill all script and style elements\nfor script in soup([\"script\", \"style\"]):\n    script.extract()    # rip it out\n# get text\ntext = soup.get_text()\n# break into lines and remove leading and trailing space on each\nlines = (line.strip() for line in text.splitlines())\n# break multi-headlines into a line each\nchunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n# drop blank lines\ntext = '\\n'.join(chunk for chunk in chunks if chunk)\nprint(text)",
        "score": 274,
        "is_accepted": false,
        "creation_date": "2014-07-07T15:18:20",
        "author": "PeYoTlL"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53835198/integrating-python-poetry-with-docker",
    "title": "Integrating Python Poetry with Docker",
    "question_id": 53835198,
    "posted_date": "2018-12-18T09:28:18",
    "answers": [
      {
        "answer_id": 54763270,
        "body": "FROM python:3.11.5-slim-bookworm\nARG YOUR_ENV\nENV YOUR_ENV=${YOUR_ENV} \\\n  PYTHONFAULTHANDLER=1 \\\n  PYTHONUNBUFFERED=1 \\\n  PYTHONHASHSEED=random \\\n  PIP_NO_CACHE_DIR=off \\\n  PIP_DISABLE_PIP_VERSION_CHECK=on \\\n  PIP_DEFAULT_TIMEOUT=100 \\\n  # Poetry's configuration:\n  POETRY_NO_INTERACTION=1 \\\n  POETRY_VIRTUALENVS_CREATE=false \\\n  POETRY_CACHE_DIR='/var/cache/pypoetry' \\\n  POETRY_HOME='/usr/local' \\\n  POETRY_VERSION=1.7.1\n  # ^^^\n  # Make sure to update it!\n# System deps:\nRUN curl -sSL https://install.python-poetry.org | python3 -\n# Copy only requirements to cache them in docker layer\nWORKDIR /code\nCOPY poetry.lock pyproject.toml /code/\n# Project initialization:\nRUN poetry install $(test \"$YOUR_ENV\" == production && echo \"--only=main\") --no-interaction --no-ansi\n# Creating folders, and files for a project:\nCOPY . /code",
        "score": 487,
        "is_accepted": false,
        "creation_date": "2019-02-19T04:50:53",
        "author": "sobolevn"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15085348/what-is-the-use-of-join-in-threading",
    "title": "What is the use of join() in threading?",
    "question_id": 15085348,
    "posted_date": "2013-02-26T04:21:55",
    "answers": [
      {
        "answer_id": 15086113,
        "body": "    without join:\n    +---+---+------------------                     main-thread\n        |   |\n        |   +...........                            child-thread(short)\n        +..................................         child-thread(long)\n\n    with join\n    +---+---+------------------***********+###      main-thread\n        |   |                             |\n        |   +...........join()            |         child-thread(short)\n        +......................join()......         child-thread(long)\n    with join and daemon thread\n    +-+--+---+------------------***********+###     parent-thread\n      |  |   |                             |\n      |  |   +...........join()            |        child-thread(short)\n      |  +......................join()......        child-thread(long)\n      +,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,     child-thread(long + daemonized)\n    '-' main-thread/parent-thread/main-program execution\n    '.' child-thread execution\n    '#' optional parent-thread execution after join()-blocked parent-thread could\n        continue\n    '*' main-thread 'sleeping' in join-method, waiting for child-thread to finish\n    ',' daemonized thread - 'ignores' lifetime of other threads;\n        terminates when main-programs exits; is normally meant for\n        join-independent tasks",
        "score": 420,
        "is_accepted": true,
        "creation_date": "2013-02-26T05:00:20",
        "author": "Don Question"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7016056/python-logging-not-outputting-anything",
    "title": "Python logging not outputting anything",
    "question_id": 7016056,
    "posted_date": "2011-08-10T14:45:29",
    "answers": [
      {
        "answer_id": 56144390,
        "body": "import logging\n# This sets the root logger to write to stdout (your console).\n# Your script/app needs to call this somewhere at least once.\nlogging.basicConfig()\n# By default the root logger is set to WARNING and all loggers you define\n# inherit that value. Here we set the root logger to NOTSET. This logging\n# level is automatically inherited by all existing and new sub-loggers\n# that do not set a less verbose level.\nlogging.root.setLevel(logging.NOTSET)\n# The following line sets the root logger level as well.\n# It's equivalent to both previous statements combined:\nlogging.basicConfig(level=logging.NOTSET)\n# You can either share the `logger` object between all your files or the\n# name handle (here `my-app`) and call `logging.getLogger` with it.\n# The result is the same.\nhandle = \"my-app\"\nlogger1 = logging.getLogger(handle)\nlogger2 = logging.getLogger(handle)\n# logger1 and logger2 point to the same object:\n# (logger1 is logger2) == True\nlogger = logging.getLogger(\"my-app\")\n# Convenient methods in order of verbosity from highest to lowest\nlogger.debug(\"this will get printed\")\nlogger.info(\"this will get printed\")\nlogger.warning(\"this will get printed\")\nlogger.error(\"this will get printed\")\nlogger.critical(\"this will get printed\")\n# In large applications where you would like more control over the logging,\n# create sub-loggers from your main application logger.\ncomponent_logger = logger.getChild(\"component-a\")\ncomponent_logger.info(\"this will get printed with the prefix `my-app.component-a`\")\n# If you wish to control the logging levels, you can set the level anywhere\n# in the hierarchy:\n#\n# - root\n#   - my-app\n#     - component-a\n#\n# Example for development:\nlogger.setLevel(logging.DEBUG)\n# If that prints too much, enable debug printing only for your component:\ncomponent_logger.setLevel(logging.DEBUG)\n# For production you rather want:\nlogger.setLevel(logging.WARNING)",
        "score": 390,
        "is_accepted": false,
        "creation_date": "2019-05-15T04:06:06",
        "author": "Hugo G"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2161752/how-to-count-the-frequency-of-the-elements-in-an-unordered-list",
    "title": "How to count the frequency of the elements in an unordered list?",
    "question_id": 2161752,
    "posted_date": "2010-01-29T07:08:20",
    "answers": [
      {
        "answer_id": 2162045,
        "body": ">>> import collections\n>>> a = [5, 1, 2, 2, 4, 3, 1, 2, 3, 1, 1, 5, 2]\n>>> counter = collections.Counter(a)\n>>> counter\nCounter({1: 4, 2: 4, 5: 2, 3: 2, 4: 1})\n>>> counter.values()\ndict_values([2, 4, 4, 1, 2])\n>>> counter.keys()\ndict_keys([5, 1, 2, 4, 3])\n>>> counter.most_common(3)\n[(1, 4), (2, 4), (5, 2)]\n>>> dict(counter)\n{5: 2, 1: 4, 2: 4, 4: 1, 3: 2}\n>>> # Get the counts in order matching the original specification,\n>>> # by iterating over keys in sorted order\n>>> [counter[x] for x in sorted(counter.keys())]\n[4, 4, 2, 1, 2]",
        "score": 652,
        "is_accepted": true,
        "creation_date": "2010-01-29T08:02:41",
        "author": "unutbu"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/28885132/why-is-x-in-x-faster-than-x-x",
    "title": "Why is &#39;x&#39; in (&#39;x&#39;,) faster than &#39;x&#39; == &#39;x&#39;?",
    "question_id": 28885132,
    "posted_date": "2015-03-05T13:29:58",
    "answers": [
      {
        "answer_id": 28889838,
        "body": "PyObject *\nPyUnicode_RichCompare(PyObject *left, PyObject *right, int op)\n{\n    int result;\n    PyObject *v;\n    if (!PyUnicode_Check(left) || !PyUnicode_Check(right))\n        Py_RETURN_NOTIMPLEMENTED;\n    if (PyUnicode_READY(left) == -1 ||\n        PyUnicode_READY(right) == -1)\n        return NULL;\n    if (left == right) {\n        switch (op) {\n        case Py_EQ:\n        case Py_LE:\n        case Py_GE:\n            /* a string is equal to itself */\n            v = Py_True;\n            break;\n        case Py_NE:\n        case Py_LT:\n        case Py_GT:\n            v = Py_False;\n            break;\n        default:\n            ...\n        }\n    }\n    else if (...) { ... }\n    else { ...}\n    Py_INCREF(v);\n    return v;\n}",
        "score": 266,
        "is_accepted": true,
        "creation_date": "2015-03-05T18:29:11",
        "author": "Veedrac"
      },
      {
        "answer_id": 28889838,
        "body": "POP()                           // Stack stuff\nTOP()                           //\n                                //\ncase PyCmp_IN:                  // Dispatch on operation\n                                //\nsqm != NULL                     // Dispatch to builtin op\nsqm->sq_contains != NULL        //\n*sqm->sq_contains               //\n                                //\ncmp == 0                        // Do comparison in loop\ni < Py_SIZE(a)                  //\nv == w                          //\nop == Py_EQ                     //\n++i                             //\ncmp == 0                        //\n                                //\nres < 0                         // Convert to Python-space\nres ? Py_True : Py_False        //\nPy_INCREF(v)                    //\n                                //\nPy_DECREF(left)                 // Stack stuff\nPy_DECREF(right)                //\nSET_TOP(res)                    //\nres == NULL                     //\nDISPATCH()                      //",
        "score": 266,
        "is_accepted": true,
        "creation_date": "2015-03-05T18:29:11",
        "author": "Veedrac"
      },
      {
        "answer_id": 28889838,
        "body": "POP()                           // Stack stuff\nTOP()                           //\n                                //\ndefault:                        // Dispatch on operation\n                                //\nPy_LT <= op                     // Checking operation\nop <= Py_GE                     //\nv == NULL                       //\nw == NULL                       //\nPy_EnterRecursiveCall(...)      // Recursive check\n                                //\nv->ob_type != w->ob_type        // More operation checks\nf = v->ob_type->tp_richcompare  // Dispatch to builtin op\nf != NULL                       //\n                                //\n!PyUnicode_Check(left)          // ...More checks\n!PyUnicode_Check(right))        //\nPyUnicode_READY(left) == -1     //\nPyUnicode_READY(right) == -1    //\nleft == right                   // Finally, doing comparison\ncase Py_EQ:                     // Immediately short circuit\nPy_INCREF(v);                   //\n                                //\nres != Py_NotImplemented        //\n                                //\nPy_LeaveRecursiveCall()         // Recursive check\n                                //\nPy_DECREF(left)                 // Stack stuff\nPy_DECREF(right)                //\nSET_TOP(res)                    //\nres == NULL                     //\nDISPATCH()                      //",
        "score": 266,
        "is_accepted": true,
        "creation_date": "2015-03-05T18:29:11",
        "author": "Veedrac"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9215658/plot-a-circle-with-matplotlib-pyplot",
    "title": "plot a circle with Matplotlib.pyplot",
    "question_id": 9215658,
    "posted_date": "2012-02-09T12:23:25",
    "answers": [
      {
        "answer_id": 9216646,
        "body": "circle1 = plt.Circle((0, 0), 2, color='r')\n# now make a circle with no fill, which is good for hi-lighting key results\ncircle2 = plt.Circle((5, 5), 0.5, color='b', fill=False)\ncircle3 = plt.Circle((10, 10), 2, color='g', clip_on=False)\n\nax = plt.gca()\nax.cla() # clear things for fresh plot\n# change default range so that new circles will work\nax.set_xlim((0, 10))\nax.set_ylim((0, 10))\n# some data\nax.plot(range(11), 'o', color='black')\n# key data point that we are encircling\nax.plot((5), (5), 'o', color='y')\n\nax.add_patch(circle1)\nax.add_patch(circle2)\nax.add_patch(circle3)\nfig.savefig('plotcircles2.png')",
        "score": 348,
        "is_accepted": true,
        "creation_date": "2012-02-09T13:32:25",
        "author": "Yann"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6028000/how-to-read-a-static-file-from-inside-a-python-package",
    "title": "How to read a (static) file from inside a Python package?",
    "question_id": 6028000,
    "posted_date": "2011-05-17T04:09:45",
    "answers": [
      {
        "answer_id": 20885799,
        "body": "try:\n    from importlib import resources as impresources\nexcept ImportError:\n    # Try backported to PY<37 `importlib_resources`.\n    import importlib_resources as impresources\nfrom . import templates  # relative-import the *package* containing the templates\ntry:\n    inp_file = (impresources.files(templates) / 'temp_file')\n    with inp_file.open(\"rb\") as f:  # or \"rt\" as text file with universal newlines\n        template = f.read()\nexcept AttributeError:\n    # Python < PY3.9, fall back to method deprecated in PY3.11.\n    template = impresources.read_text(templates, 'temp_file')\n    # or for a file-like stream:\n    template = impresources.open_text(templates, 'temp_file')",
        "score": 315,
        "is_accepted": false,
        "creation_date": "2014-01-02T10:07:18",
        "author": "ankostis"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/13905741/accessing-class-variables-from-a-list-comprehension-in-the-class-definition",
    "title": "Accessing class variables from a list comprehension in the class definition",
    "question_id": 13905741,
    "posted_date": "2012-12-16T16:42:22",
    "answers": [
      {
        "answer_id": 13913933,
        "body": "# creating `def foo()` and its bytecode elided\nDisassembly of <code object Foo at 0x104e97000, file \"<stdin>\", line 2>:\n  2           0 RESUME                   0\n              2 LOAD_NAME                0 (__name__)\n              4 STORE_NAME               1 (__module__)\n              6 LOAD_CONST               0 ('foo.<locals>.Foo')\n              8 STORE_NAME               2 (__qualname__)\n  3          10 LOAD_CONST               1 (5)\n             12 STORE_NAME               3 (x)\n  4          14 PUSH_NULL\n             16 LOAD_NAME                4 (range)\n             18 LOAD_CONST               2 (1)\n             20 CALL                     1\n             28 GET_ITER\n             30 LOAD_FAST_AND_CLEAR      0 (.0)\n             32 LOAD_FAST_AND_CLEAR      1 (i)\n             34 LOAD_FAST_AND_CLEAR      2 (x)\n             36 SWAP                     4\n             38 BUILD_LIST               0\n             40 SWAP                     2\n        >>   42 FOR_ITER                 8 (to 62)\n             46 STORE_FAST               1 (i)\n             48 LOAD_GLOBAL              6 (x)\n             58 LIST_APPEND              2\n             60 JUMP_BACKWARD           10 (to 42)\n        >>   62 END_FOR\n             64 SWAP                     4\n             66 STORE_FAST               2 (x)\n             68 STORE_FAST               1 (i)\n             70 STORE_FAST               0 (.0)\n             72 STORE_NAME               5 (y)\n             74 RETURN_CONST             3 (None)",
        "score": 365,
        "is_accepted": true,
        "creation_date": "2012-12-17T07:11:56",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/23327293/flask-raises-templatenotfound-error-even-though-template-file-exists",
    "title": "Flask raises TemplateNotFound error even though template file exists",
    "question_id": 23327293,
    "posted_date": "2014-04-27T14:30:28",
    "answers": [
      {
        "answer_id": 23327352,
        "body": "[2019-06-15 16:03:39,197] INFO in debughelpers: Locating template \"foo/bar.html\":\n    1: trying loader of application \"flaskpackagename\"\n       class: jinja2.loaders.FileSystemLoader\n       encoding: 'utf-8'\n       followlinks: False\n       searchpath:\n         - /.../project/flaskpackagename/templates\n       -> found ('/.../project/flaskpackagename/templates/foo/bar.html')\n[2019-06-15 16:03:39,203] INFO in debughelpers: Locating template \"base.html\":\n    1: trying loader of application \"flaskpackagename\"\n       class: jinja2.loaders.FileSystemLoader\n       encoding: 'utf-8'\n       followlinks: False\n       searchpath:\n         - /.../project/flaskpackagename/templates\n       -> found ('/.../project/flaskpackagename/templates/base.html')",
        "score": 443,
        "is_accepted": true,
        "creation_date": "2014-04-27T14:36:01",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41171791/how-to-suppress-or-capture-the-output-of-subprocess-run",
    "title": "How to suppress or capture the output of subprocess.run()?",
    "question_id": 41171791,
    "posted_date": "2016-12-15T14:21:10",
    "answers": [
      {
        "answer_id": 41172862,
        "body": "import subprocess\nresult = subprocess.run(\n    ['ls', '-l'],\n    stdout = subprocess.PIPE,\n    universal_newlines = True # Python >= 3.7 also accepts \"text=True\"\n)\nprint(result.stdout)\n# To also capture stderr...\nresult = subprocess.run(\n    ['ls', '-l'],\n    stdout = subprocess.PIPE,\n    stderr = subprocess.PIPE,\n    universal_newlines = True # Python >= 3.7 also accepts \"text=True\"\n)\nprint(result.stdout)\nprint(result.stderr)\n# To mix stdout and stderr into a single string\nresult = subprocess.run(\n    ['ls', '-l'],\n    stdout = subprocess.PIPE,\n    stderr = subprocess.STDOUT,\n    universal_newlines = True # Python >= 3.7 also accepts \"text=True\"\n)\nprint(result.stdout)",
        "score": 421,
        "is_accepted": true,
        "creation_date": "2016-12-15T15:32:12",
        "author": "SethMMorton"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6062576/adding-information-to-an-exception",
    "title": "Adding information to an exception?",
    "question_id": 6062576,
    "posted_date": "2011-05-19T13:34:35",
    "answers": [
      {
        "answer_id": 46091127,
        "body": "2017-09-06 16:50:14,797 [ERROR] django.request: Internal Server Error: /v1/sendEmail/\nTraceback (most recent call last):\nFile \"venv/lib/python3.4/site-packages/rest_framework/views.py\", line 275, in get_permissions\n\treturn [permission() for permission in self.permission_classes]\nTypeError: 'type' object is not iterable\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n\t# Traceback removed...\nTypeError: Make sure your view's Permission_classes are iterable. If\n     you use parens () to generate a set with a single element make\n     sure that there is a (comma,) behind the one element.",
        "score": 275,
        "is_accepted": false,
        "creation_date": "2017-09-07T04:06:06",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7204805/deep-merge-dictionaries-of-dictionaries-in-python",
    "title": "Deep merge dictionaries of dictionaries in Python",
    "question_id": 7204805,
    "posted_date": "2011-08-26T08:44:30",
    "answers": [
      {
        "answer_id": 7205107,
        "body": "def merge(a: dict, b: dict, path=[]):\n    for key in b:\n        if key in a:\n            if isinstance(a[key], dict) and isinstance(b[key], dict):\n                merge(a[key], b[key], path + [str(key)])\n            elif a[key] != b[key]:\n                raise Exception('Conflict at ' + '.'.join(path + [str(key)]))\n        else:\n            a[key] = b[key]\n    return a\n# works\nprint(merge({1:{\"a\":\"A\"},2:{\"b\":\"B\"}}, {2:{\"c\":\"C\"},3:{\"d\":\"D\"}}))\n# has conflict\nmerge({1:{\"a\":\"A\"},2:{\"b\":\"B\"}}, {1:{\"a\":\"A\"},2:{\"b\":\"C\"}})",
        "score": 221,
        "is_accepted": true,
        "creation_date": "2011-08-26T09:08:48",
        "author": "andrew cooke"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3949226/calculating-pearson-correlation-and-significance-in-python",
    "title": "Calculating Pearson correlation and significance in Python",
    "question_id": 3949226,
    "posted_date": "2010-10-16T10:15:27",
    "answers": [
      {
        "answer_id": 3949282,
        "body": ">>>\nHelp on function pearsonr in module scipy.stats.stats:\npearsonr(x, y)\n Calculates a Pearson correlation coefficient and the p-value for testing\n non-correlation.\n The Pearson correlation coefficient measures the linear relationship\n between two datasets. Strictly speaking, Pearson's correlation requires\n that each dataset be normally distributed. Like other correlation\n coefficients, this one varies between -1 and +1 with 0 implying no\n correlation. Correlations of -1 or +1 imply an exact linear\n relationship. Positive correlations imply that as x increases, so does\n y. Negative correlations imply that as x increases, y decreases.\n The p-value roughly indicates the probability of an uncorrelated system\n producing datasets that have a Pearson correlation at least as extreme\n as the one computed from these datasets. The p-values are not entirely\n reliable but are probably reasonable for datasets larger than 500 or so.\n Parameters\n ----------\n x : 1D array\n y : 1D array the same length as x\n Returns\n -------\n (Pearson's correlation coefficient,\n  2-tailed p-value)\n References\n ----------\n http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation",
        "score": 218,
        "is_accepted": false,
        "creation_date": "2010-10-16T10:29:57",
        "author": "Sacha"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3041986/apt-command-line-interface-like-yes-no-input",
    "title": "APT command line interface-like yes/no input?",
    "question_id": 3041986,
    "posted_date": "2010-06-14T21:13:54",
    "answers": [
      {
        "answer_id": 3041990,
        "body": "import sys\ndef query_yes_no(question, default=\"yes\"):\n    \"\"\"Ask a yes/no question via raw_input() and return their answer.\n    \"question\" is a string that is presented to the user.\n    \"default\" is the presumed answer if the user just hits <Enter>.\n            It must be \"yes\" (the default), \"no\" or None (meaning\n            an answer is required of the user).\n    The \"answer\" return value is True for \"yes\" or False for \"no\".\n    \"\"\"\n    valid = {\"yes\": True, \"y\": True, \"ye\": True, \"no\": False, \"n\": False}\n    if default is None:\n        prompt = \" [y/n] \"\n    elif default == \"yes\":\n        prompt = \" [Y/n] \"\n    elif default == \"no\":\n        prompt = \" [y/N] \"\n    else:\n        raise ValueError(\"invalid default answer: '%s'\" % default)\n    while True:\n        sys.stdout.write(question + prompt)\n        choice = input().lower()\n        if default is not None and choice == \"\":\n            return valid[default]\n        elif choice in valid:\n            return valid[choice]\n        else:\n            sys.stdout.write(\"Please respond with 'yes' or 'no' \" \"(or 'y' or 'n').\\n\")",
        "score": 286,
        "is_accepted": true,
        "creation_date": "2010-06-14T21:16:00",
        "author": "fmark"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15511349/select-50-items-from-list-at-random",
    "title": "Select 50 items from list at random",
    "question_id": 15511349,
    "posted_date": "2013-03-19T18:01:11",
    "answers": [
      {
        "answer_id": 15511372,
        "body": "sample(self, population, k) method of random.Random instance\n    Chooses k unique random elements from a population sequence.\n\n    Returns a new list containing elements from the population while\n    leaving the original population unchanged.  The resulting list is\n    in selection order so that all sub-slices will also be valid random\n    samples.  This allows raffle winners (the sample) to be partitioned\n    into grand prize and second place winners (the subslices).\n\n    Members of the population need not be hashable or unique.  If the\n    population contains repeats, then each occurrence is a possible\n    selection in the sample.\n\n    To choose a sample in a range of integers, use xrange as an argument.\n    This is especially fast and space efficient for sampling from a\n    large population:   sample(xrange(10000000), 60)",
        "score": 415,
        "is_accepted": true,
        "creation_date": "2013-03-19T18:03:19",
        "author": "John La Rooy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/8463008/multiprocessing-pipe-vs-queue",
    "title": "Multiprocessing - Pipe vs Queue",
    "question_id": 8463008,
    "posted_date": "2011-12-11T04:28:37",
    "answers": [
      {
        "answer_id": 8463046,
        "body": "import concurrent.futures\nimport time\ndef do_slow_thing(input_str: str) -> str:\n    \"\"\"Return modified input string after a 1-second delay\"\"\"\n    if isinstance(input_str, str):\n        time.sleep(1)\n        return \"1-SECOND-DELAY \" + input_str\n    else:\n        return \"INPUT ERROR\"\nif __name__==\"__main__\":\n    # Define some inputs for process pool\n    all_inputs = [\n        \"do\",\n        \"foo\",\n        \"moo\",\n        \"chew\",\n    ]\n    # Spawn a process pool with the default number of workers...\n    with concurrent.futures.ProcessPoolExecutor(max_workers=None) as executor:\n        # For each string in all_inputs, call do_slow_thing()\n        #    in parallel across the process worker pool\n        these_futures = [executor.submit(do_slow_thing, ii) for ii in all_inputs]\n        # Wait for all processes to finish\n        concurrent.futures.wait(these_futures)\n    # Get the results from the process pool execution... each\n    # future.result() call is the return value from do_slow_thing()\n    string_outputs = [future.result() for future in these_futures]\n    for tmp in string_outputs:\n        print(tmp)",
        "score": 381,
        "is_accepted": true,
        "creation_date": "2011-12-11T04:36:37",
        "author": "Mike Pennington"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5218895/python-nested-functions-variable-scoping",
    "title": "Python nested functions variable scoping",
    "question_id": 5218895,
    "posted_date": "2011-03-07T06:05:45",
    "answers": [
      {
        "answer_id": 8178808,
        "body": "def sum_list_items(_list):\n    total = 0\n    def do_the_sum(_list):\n        # The nonlocal total binds to this variable.\n        total = 0\n        def do_core_computations(_list):\n            # Define the total variable as non-local, causing it to bind\n            # to the nearest non-global variable also called total.\n            nonlocal total\n            for i in _list:\n                total += i\n        do_core_computations(_list)\n    do_the_sum(_list)\n    return total\nsum_list_items([1, 2, 3])",
        "score": 412,
        "is_accepted": false,
        "creation_date": "2011-11-18T01:54:17",
        "author": "Michael Hoffman"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29177498/replace-nan-in-one-column-with-value-from-corresponding-row-of-second-column",
    "title": "Replace NaN in one column with value from corresponding row of second column",
    "question_id": 29177498,
    "posted_date": "2015-03-20T19:43:01",
    "answers": [
      {
        "answer_id": 29177664,
        "body": "File  heat  Observations\n0      1  YesQ            75\n1      1   NoR           115\n2      1  YesA            63\n3      1   NoT            41\n4      1   NoY            80\n5      1  YesZ            12\n6      2  YesQ           111\n7      2   NoR            60\n8      2  YesA            19\n9      2   NoT            77\n10     2   NoY            21\n11     2  YesZ            54\n12     3  YesQ            84\n13     3   NoR            67\n14     3  YesA            94\n15     3   NoT            39\n16     3   NoY            46\n17     3  YesZ            81",
        "score": 278,
        "is_accepted": true,
        "creation_date": "2015-03-20T20:03:59",
        "author": "Jonathan Eunice"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry",
    "title": "Does it make sense to use Conda + Poetry?",
    "question_id": 70851048,
    "posted_date": "2022-01-25T10:09:43",
    "answers": [
      {
        "answer_id": 71110028,
        "body": "name: my_project_env\nchannels:\n  - pytorch\n  - conda-forge\n  # We want to have a reproducible setup, so we don't want default channels,\n  # which may be different for different users. All required channels should\n  # be listed explicitly here.\n  - nodefaults\ndependencies:\n  - python=3.10.*  # or don't specify the version and use the latest stable Python\n  - mamba\n  - pip  # pip must be mentioned explicitly, or conda-lock will fail\n  - poetry=1.*  # or 1.1.*, or no version at all -- as you want\n  - tensorflow=2.8.0\n  - pytorch::pytorch=1.11.0\n  - pytorch::torchaudio=0.11.0\n  - pytorch::torchvision=0.12.0\n# Non-standard section listing target platforms for conda-lock:\nplatforms:\n  - linux-64",
        "score": 243,
        "is_accepted": true,
        "creation_date": "2022-02-14T05:04:35",
        "author": "kxmh42"
      },
      {
        "answer_id": 71110028,
        "body": "# Create a bootstrap env\nconda create -p /tmp/bootstrap -c conda-forge mamba conda-lock poetry='1.*'\nconda activate /tmp/bootstrap\n# Create Conda lock file(s) from environment.yml\nconda-lock -k explicit --conda mamba\n# Set up Poetry\npoetry init --python=~3.10  # version spec should match the one from environment.yml\n# Fix package versions installed by Conda to prevent upgrades\npoetry add --lock tensorflow=2.8.0 torch=1.11.0 torchaudio=0.11.0 torchvision=0.12.0\n# Add conda-lock (and other packages, as needed) to pyproject.toml and poetry.lock\npoetry add --lock conda-lock\n# Remove the bootstrap env\nconda deactivate\nrm -rf /tmp/bootstrap\n# Add Conda spec and lock files\ngit add environment.yml virtual-packages.yml conda-linux-64.lock\n# Add Poetry spec and lock files\ngit add pyproject.toml poetry.lock\ngit commit",
        "score": 243,
        "is_accepted": true,
        "creation_date": "2022-02-14T05:04:35",
        "author": "kxmh42"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/1323455/python-unit-test-with-base-and-sub-class",
    "title": "Python unit test with base and sub class",
    "question_id": 1323455,
    "posted_date": "2009-08-24T12:39:41",
    "answers": [
      {
        "answer_id": 25695512,
        "body": "class BaseTestCases:\n    class BaseTest(unittest.TestCase):\n        def testCommon(self):\n            print('Calling BaseTest:testCommon')\n            value = 5\n            self.assertEqual(value, 5)\nclass SubTest1(BaseTestCases.BaseTest):\n    def testSub1(self):\n        print('Calling SubTest1:testSub1')\n        sub = 3\n        self.assertEqual(sub, 3)\nclass SubTest2(BaseTestCases.BaseTest):\n    def testSub2(self):\n        print('Calling SubTest2:testSub2')\n        sub = 4\n        self.assertEqual(sub, 4)\n\nif __name__ == '__main__':\n    unittest.main()",
        "score": 207,
        "is_accepted": false,
        "creation_date": "2014-09-05T19:58:24",
        "author": "Vadim P."
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55266154/pytorch-preferred-way-to-copy-a-tensor",
    "title": "PyTorch preferred way to copy a tensor",
    "question_id": 55266154,
    "posted_date": "2019-03-20T12:51:41",
    "answers": [
      {
        "answer_id": 62496418,
        "body": "import torch\nimport perfplot\nperfplot.show(\n    setup=lambda n: torch.randn(n),\n    kernels=[\n        lambda a: a.new_tensor(a),\n        lambda a: a.clone().detach(),\n        lambda a: torch.empty_like(a).copy_(a),\n        lambda a: torch.tensor(a),\n        lambda a: a.detach().clone(),\n    ],\n    labels=[\"new_tensor()\", \"clone().detach()\", \"empty_like().copy()\", \"tensor()\", \"detach().clone()\"],\n    n_range=[2 ** k for k in range(15)],\n    xlabel=\"len(a)\",\n    logx=False,\n    logy=False,\n    title='Timing comparison for copying a pytorch tensor',\n)",
        "score": 210,
        "is_accepted": true,
        "creation_date": "2020-06-21T04:53:42",
        "author": "Harshit Kumar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39356413/how-to-add-a-custom-ca-root-certificate-to-the-ca-store-used-by-pip-in-windows",
    "title": "How to add a custom CA Root certificate to the CA Store used by pip in Windows?",
    "question_id": 39356413,
    "posted_date": "2016-09-06T15:24:30",
    "answers": [
      {
        "answer_id": 52961564,
        "body": "pip config list\nconda config --show ssl_verify\n# Hot tip: use -v to show where your pip config file is...\npip config list -v\n# Example output for macOS and homebrew installed python\nFor variant 'global', will try loading '/Library/Application Support/pip/pip.conf'\nFor variant 'user', will try loading '/Users/jpeak/.pip/pip.conf'\nFor variant 'user', will try loading '/Users/jpeak/.config/pip/pip.conf'\nFor variant 'site', will try loading '/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/pip.conf'",
        "score": 243,
        "is_accepted": false,
        "creation_date": "2018-10-24T01:22:18",
        "author": "Josh Peak"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3927628/how-can-i-profile-python-code-line-by-line",
    "title": "How can I profile Python code line-by-line?",
    "question_id": 3927628,
    "posted_date": "2010-10-13T16:12:36",
    "answers": [
      {
        "answer_id": 3927671,
        "body": "File: pystone.py\nFunction: Proc2 at line 149\nTotal time: 0.606656 s\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n   149                                           @profile\n   150                                           def Proc2(IntParIO):\n   151     50000        82003      1.6     13.5      IntLoc = IntParIO + 10\n   152     50000        63162      1.3     10.4      while 1:\n   153     50000        69065      1.4     11.4          if Char1Glob == 'A':\n   154     50000        66354      1.3     10.9              IntLoc = IntLoc - 1\n   155     50000        67263      1.3     11.1              IntParIO = IntLoc - IntGlob\n   156     50000        65494      1.3     10.8              EnumLoc = Ident1\n   157     50000        68001      1.4     11.2          if EnumLoc == Ident1:\n   158     50000        63739      1.3     10.5              break\n   159     50000        61575      1.2     10.1      return IntParIO",
        "score": 165,
        "is_accepted": true,
        "creation_date": "2010-10-13T16:19:45",
        "author": "Joe Kington"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/28931224/how-to-add-value-labels-on-a-bar-chart",
    "title": "How to add value labels on a bar chart",
    "question_id": 28931224,
    "posted_date": "2015-03-08T16:00:53",
    "answers": [
      {
        "answer_id": 28931750,
        "body": "import pandas as pd\nimport matplotlib.pyplot as plt\n# Bring some raw data.\nfrequencies = [6, 16, 75, 160, 244, 260, 145, 73, 16, 4, 1]\n# In my original code I create a series and run on that,\n# so for consistency I create a series from the list.\nfreq_series = pd.Series(frequencies)\nx_labels = [\n    108300.0,\n    110540.0,\n    112780.0,\n    115020.0,\n    117260.0,\n    119500.0,\n    121740.0,\n    123980.0,\n    126220.0,\n    128460.0,\n    130700.0,\n]\n# Plot the figure.\nplt.figure(figsize=(12, 8))\nax = freq_series.plot(kind=\"bar\")\nax.set_title(\"Amount Frequency\")\nax.set_xlabel(\"Amount ($)\")\nax.set_ylabel(\"Frequency\")\nax.set_xticklabels(x_labels)\nrects = ax.patches\n# Make some labels.\nlabels = [f\"label{i}\" for i in range(len(rects))]\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(\n        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n    )\nplt.show()",
        "score": 164,
        "is_accepted": false,
        "creation_date": "2015-03-08T16:52:34",
        "author": "Simon Gibbons"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/22231592/pandas-change-data-type-of-series-to-string",
    "title": "Pandas: change data type of Series to String",
    "question_id": 22231592,
    "posted_date": "2014-03-06T12:24:23",
    "answers": [
      {
        "answer_id": 60553529,
        "body": "import pandas as pd\n# Create a sample DataFrame\ndata = {\n    'Name': ['John', 'Alice', 'Bob', 'John', 'Alice'],\n    'Age': [25, 30, 35, 25, 30],\n    'City': ['New York', 'London', 'Paris', 'New York', 'London'],\n    'Salary': [50000, 60000, 70000, 50000, 60000],\n    'Category': ['A', 'B', 'C', 'A', 'B']\n}\ndf = pd.DataFrame(data)\n# Print the DataFrame\nprint(\"Original DataFrame:\")\nprint(df)\nprint(\"\\nData types:\")\nprint(df.dtypes)\ncat_cols_ = None\n# Apply the code to change data types\nif not cat_cols_:\n    # Get the columns with object data type\n    object_columns = df.select_dtypes(include=['object']).columns.tolist()\n\n    if len(object_columns) > 0:\n        print(f\"\\nObject columns found, converting to string: {object_columns}\")\n\n        # Convert object columns to string type\n        df[object_columns] = df[object_columns].astype('string')\n\n    # Get the categorical columns (including string and category data types)\n    cat_cols_ = df.select_dtypes(include=['category', 'string']).columns.tolist()\n# Print the updated DataFrame and data types\nprint(\"\\nUpdated DataFrame:\")\nprint(df)\nprint(\"\\nUpdated data types:\")\nprint(df.dtypes)\nprint(f\"\\nCategorical columns (cat_cols_): {cat_cols_}\")",
        "score": 249,
        "is_accepted": true,
        "creation_date": "2020-03-05T15:34:55",
        "author": "rocksNwaves"
      },
      {
        "answer_id": 60553529,
        "body": "Original DataFrame:\n    Name  Age      City  Salary Category\n0   John   25  New York   50000        A\n1  Alice   30    London   60000        B\n2    Bob   35     Paris   70000        C\n3   John   25  New York   50000        A\n4  Alice   30    London   60000        B\nData types:\nName        object\nAge          int64\nCity        object\nSalary       int64\nCategory    object\ndtype: object\nObject columns found, converting to string: ['Name', 'City', 'Category']\nUpdated DataFrame:\n    Name  Age      City  Salary Category\n0   John   25  New York   50000        A\n1  Alice   30    London   60000        B\n2    Bob   35     Paris   70000        C\n3   John   25  New York   50000        A\n4  Alice   30    London   60000        B\nUpdated data types:\nName        string[python]\nAge                  int64\nCity        string[python]\nSalary               int64\nCategory    string[python]\ndtype: object\nCategorical columns (cat_cols_): ['Name', 'City', 'Category']",
        "score": 249,
        "is_accepted": true,
        "creation_date": "2020-03-05T15:34:55",
        "author": "rocksNwaves"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16337511/log-all-requests-from-the-python-requests-module",
    "title": "Log all requests from the python-requests module",
    "question_id": 16337511,
    "posted_date": "2013-05-02T07:57:58",
    "answers": [
      {
        "answer_id": 16337639,
        "body": ">>> httpclient_logging_patch()\n>>> r = requests.get('http://httpbin.org/get?foo=bar&baz=python')\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (1): httpbin.org:80\nDEBUG:http.client:send: b'GET /get?foo=bar&baz=python HTTP/1.1\\r\\nHost: httpbin.org\\r\\nUser-Agent: python-requests/2.22.0\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept: */*\\r\\nConnection: keep-alive\\r\\n\\r\\n'\nDEBUG:http.client:reply: 'HTTP/1.1 200 OK\\r\\n'\nDEBUG:http.client:header: Date: Tue, 04 Feb 2020 13:36:53 GMT\nDEBUG:http.client:header: Content-Type: application/json\nDEBUG:http.client:header: Content-Length: 366\nDEBUG:http.client:header: Connection: keep-alive\nDEBUG:http.client:header: Server: gunicorn/19.9.0\nDEBUG:http.client:header: Access-Control-Allow-Origin: *\nDEBUG:http.client:header: Access-Control-Allow-Credentials: true\nDEBUG:urllib3.connectionpool:http://httpbin.org:80 \"GET /get?foo=bar&baz=python HTTP/1.1\" 200 366",
        "score": 171,
        "is_accepted": true,
        "creation_date": "2013-05-02T08:05:35",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/8991506/iterate-an-iterator-by-chunks-of-n-in-python",
    "title": "Iterate an iterator by chunks (of n) in Python?",
    "question_id": 8991506,
    "posted_date": "2012-01-24T12:44:02",
    "answers": [
      {
        "answer_id": 8991553,
        "body": "def grouper(iterable, n, *, incomplete='fill', fillvalue=None):\n    \"Collect data into non-overlapping fixed-length chunks or blocks\"\n    # grouper('ABCDEFG', 3, fillvalue='x') --> ABC DEF Gxx\n    # grouper('ABCDEFG', 3, incomplete='strict') --> ABC DEF ValueError\n    # grouper('ABCDEFG', 3, incomplete='ignore') --> ABC DEF\n    args = [iter(iterable)] * n\n    if incomplete == 'fill':\n        return zip_longest(*args, fillvalue=fillvalue)\n    if incomplete == 'strict':\n        return zip(*args, strict=True)\n    if incomplete == 'ignore':\n        return zip(*args)\n    else:\n        raise ValueError('Expected fill, strict, or ignore')",
        "score": 191,
        "is_accepted": true,
        "creation_date": "2012-01-24T12:48:03",
        "author": "Sven Marnach"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/12439588/how-to-maximize-a-plt-show-window",
    "title": "How to maximize a plt.show() window",
    "question_id": 12439588,
    "posted_date": "2012-09-15T13:31:02",
    "answers": [
      {
        "answer_id": 22418354,
        "body": "from matplotlib import pyplot as plt\n### for 'TkAgg' backend\nplt.figure(1)\nplt.switch_backend('TkAgg') #TkAgg (instead Qt4Agg)\nprint '#1 Backend:',plt.get_backend()\nplt.plot([1,2,6,4])\nmng = plt.get_current_fig_manager()\n### works on Ubuntu??? >> did NOT working on windows\n# mng.resize(*mng.window.maxsize())\nmng.window.state('zoomed') #works fine on Windows!\nplt.show() #close the figure to run the next section\n### for 'wxAgg' backend\nplt.figure(2)\nplt.switch_backend('wxAgg')\nprint '#2 Backend:',plt.get_backend()\nplt.plot([1,2,6,4])\nmng = plt.get_current_fig_manager()\nmng.frame.Maximize(True)\nplt.show() #close the figure to run the next section\n### for 'Qt4Agg' backend\nplt.figure(3)\nplt.switch_backend('QT4Agg') #default on my system\nprint '#3 Backend:',plt.get_backend()\nplt.plot([1,2,6,4])\nfigManager = plt.get_current_fig_manager()\nfigManager.window.showMaximized()\nplt.show()",
        "score": 212,
        "is_accepted": false,
        "creation_date": "2014-03-14T21:12:12",
        "author": "Pythonio"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6282042/assignment-inside-lambda-expression-in-python",
    "title": "Assignment inside lambda expression in Python",
    "question_id": 6282042,
    "posted_date": "2011-06-08T12:23:36",
    "answers": [
      {
        "answer_id": 14617232,
        "body": "(lambda: [\n    ['def'\n        for sys in [__import__('sys')]\n        for math in [__import__('math')]\n        for sub in [lambda *vals: None]\n        for fun in [lambda *vals: vals[-1]]\n        for echo in [lambda *vals: sub(\n            sys.stdout.write(u\" \".join(map(unicode, vals)) + u\"\\n\"))]\n        for Cylinder in [type('Cylinder', (object,), dict(\n            __init__ = lambda self, radius, height: sub(\n                setattr(self, 'radius', radius),\n                setattr(self, 'height', height)),\n            volume = property(lambda self: fun(\n                ['def' for top_area in [math.pi * self.radius ** 2]],\n                self.height * top_area))))]\n        for main in [lambda: sub(\n            ['loop' for factor in [1, 2, 3] if sub(\n                ['def'\n                    for my_radius, my_height in [[10 * factor, 20 * factor]]\n                    for my_cylinder in [Cylinder(my_radius, my_height)]],\n                echo(u\"A cylinder with a radius of %.1fcm and a height \"\n                     u\"of %.1fcm has a volume of %.1fcm\u00b3.\"\n                     % (my_radius, my_height, my_cylinder.volume)))])]],\n    main()])()",
        "score": 283,
        "is_accepted": false,
        "creation_date": "2013-01-30T20:58:29",
        "author": "Jeremy Banks"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/26139423/plot-different-color-for-different-categorical-levels",
    "title": "plot different color for different categorical levels",
    "question_id": 26139423,
    "posted_date": "2014-10-01T06:37:29",
    "answers": [
      {
        "answer_id": 26139658,
        "body": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns  # for sample data\nfrom matplotlib.lines import Line2D  # for legend handle\n# DataFrame used for all options\ndf = sns.load_dataset('diamonds')\n   carat      cut color clarity  depth  table  price     x     y     z\n0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31",
        "score": 227,
        "is_accepted": true,
        "creation_date": "2014-10-01T06:50:55",
        "author": "Ffisegydd"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58755948/what-is-the-difference-between-typevar-and-newtype",
    "title": "What is the difference between TypeVar and NewType?",
    "question_id": 58755948,
    "posted_date": "2019-11-07T14:46:52",
    "answers": [
      {
        "answer_id": 58775376,
        "body": "# (This code will type check, but it won't run.)\nfrom typing import TypeVar, Generic\n# Two type variables, named T and R\nT = TypeVar('T')\nR = TypeVar('R')\n# Put in a list of Ts and get out one T\ndef get_one(x: list[T]) -> T: ...\n# Put in a T and an R, get back an R and a T\ndef swap(x: T, y: R) -> tuple[R, T]:\n    return y, x\n# A simple generic class that holds a value of type T\nclass ValueHolder(Generic[T]):\n    def __init__(self, value: T):\n        self.value = value\n    def get(self) -> T:\n        return self.value\nx: ValueHolder[int] = ValueHolder(123)\ny: ValueHolder[str] = ValueHolder('abc')",
        "score": 215,
        "is_accepted": true,
        "creation_date": "2019-11-08T19:38:38",
        "author": "jirassimok"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/1985856/how-to-make-a-3d-scatter-plot",
    "title": "How to make a 3D scatter plot",
    "question_id": 1985856,
    "posted_date": "2009-12-31T10:37:06",
    "answers": [
      {
        "answer_id": 1986020,
        "body": "import matplotlib.pyplot as plt\nimport random\nfig = plt.figure(figsize=(12, 12))\nax = fig.add_subplot(projection='3d')\nsequence_containing_x_vals = list(range(0, 100))\nsequence_containing_y_vals = list(range(0, 100))\nsequence_containing_z_vals = list(range(0, 100))\nrandom.shuffle(sequence_containing_x_vals)\nrandom.shuffle(sequence_containing_y_vals)\nrandom.shuffle(sequence_containing_z_vals)\nax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)\nplt.show()",
        "score": 230,
        "is_accepted": true,
        "creation_date": "2009-12-31T11:29:09",
        "author": "Chinmay Kanchi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6999565/python-https-get-with-basic-authentication",
    "title": "Python, HTTPS GET with basic authentication",
    "question_id": 6999565,
    "posted_date": "2011-08-09T12:31:22",
    "answers": [
      {
        "answer_id": 7000784,
        "body": "from http.client import HTTPSConnection\nfrom base64 import b64encode\n# Authorization token: we need to base 64 encode it\n# and then decode it to acsii as python 3 stores it as a byte string\ndef basic_auth(username, password):\n    token = b64encode(f\"{username}:{password}\".encode('utf-8')).decode(\"ascii\")\n    return f'Basic {token}'\nusername = \"user_name\"\npassword = \"password\"\n#This sets up the https connection\nc = HTTPSConnection(\"www.google.com\")\n#then connect\nheaders = { 'Authorization' : basic_auth(username, password) }\nc.request('GET', '/', headers=headers)\n#get the response back\nres = c.getresponse()\n# at this point you could check the status etc\n# this gets the page text\ndata = res.read()",
        "score": 199,
        "is_accepted": true,
        "creation_date": "2011-08-09T14:12:57",
        "author": "Andrew Cox"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29596350/how-to-uninstall-miniconda",
    "title": "How to uninstall miniconda?",
    "question_id": 29596350,
    "posted_date": "2015-04-12T20:43:47",
    "answers": [
      {
        "answer_id": 29616442,
        "body": "$ wget https://repo.continuum.io/miniconda/Miniconda3-3.7.0-Linux-x86_64.sh -O ~/miniconda.sh\n$ bash miniconda\n$ conda env remove --yes -n new_env    # remove the environement new_env if it exists (optional)\n$ conda create --yes -n new_env pip numpy pandas scipy matplotlib scikit-learn nltk ipython-notebook seaborn python=2\n$ activate new_env\n$ # pip install modules if needed, run python scripts, etc\n  # everything will be installed in the new_env\n  # located in ~/miniconda/envs/new_env\n$ deactivate",
        "score": 147,
        "is_accepted": true,
        "creation_date": "2015-04-13T18:58:15",
        "author": "rth"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50016862/grouping-tests-in-pytest-classes-vs-plain-functions",
    "title": "Grouping tests in pytest: Classes vs plain functions",
    "question_id": 50016862,
    "posted_date": "2018-04-25T03:54:39",
    "answers": [
      {
        "answer_id": 62176555,
        "body": "# in file `test_class_parametrization.py`\nimport pytest\n@pytest.mark.parametrize(\n    (\"param1\", \"param2\"),\n    [\n        (\"a\", \"b\"),\n        (\"c\", \"d\"),\n    ],\n)\nclass TestGroup:\n    \"\"\"A class with common parameters, `param1` and `param2`.\"\"\"\n    @pytest.fixture\n    def fixt(self) -> int:\n        \"\"\"This fixture will only be available within the scope of TestGroup\"\"\"\n        return 123\n    def test_one(self, param1: str, param2: str, fixt: int) -> None:\n        print(\"\\ntest_one\", param1, param2, fixt)\n    def test_two(self, param1: str, param2: str) -> None:\n        print(\"\\ntest_two\", param1, param2)",
        "score": 147,
        "is_accepted": false,
        "creation_date": "2020-06-03T11:22:09",
        "author": "Jasha"
      },
      {
        "answer_id": 62176555,
        "body": "$ pytest -s test_class_parametrization.py\n================================================================== test session starts ==================================================================\nplatform linux -- Python 3.8.6, pytest-6.2.1, py-1.10.0, pluggy-0.13.1\nrootdir: /home/jbss\nplugins: pylint-0.18.0\ncollected 4 items\ntest_class_parametrization.py\ntest_one a b 123\n.\ntest_one c d 123\n.\ntest_two a b\n.\ntest_two c d\n.\n=================================================================== 4 passed in 0.01s ===================================================================",
        "score": 147,
        "is_accepted": false,
        "creation_date": "2020-06-03T11:22:09",
        "author": "Jasha"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39581893/find-percentile-stats-of-a-given-column",
    "title": "Find percentile stats of a given column",
    "question_id": 39581893,
    "posted_date": "2016-09-19T16:50:57",
    "answers": [
      {
        "answer_id": 45495773,
        "body": "import pandas as pd\nimport numpy as np\n# sample data\nnp.random.seed(2023)  # for reproducibility\ndata = {'Category': np.random.choice(['hot', 'cold'], size=(10,)),\n        'field_A': np.random.randint(0, 100, size=(10,)),\n        'field_B': np.random.randint(0, 100, size=(10,))}\ndf = pd.DataFrame(data)\ndf.field_A.mean()  # Same as df['field_A'].mean()\n# 51.1\ndf.field_A.median()\n# 50.0\n# You can call `quantile(i)` to get the i'th quantile,\n# where `i` should be a fractional number.\ndf.field_A.quantile(0.1)  # 10th percentile\n# 15.6\ndf.field_A.quantile(0.5)  # same as median\n# 50.0\ndf.field_A.quantile(0.9)  # 90th percentile\n# 88.8\ndf.groupby('Category').field_A.quantile(0.1)\n#Category\n#cold    28.8\n#hot      8.6\n#Name: field_A, dtype: float64",
        "score": 183,
        "is_accepted": true,
        "creation_date": "2017-08-03T18:52:45",
        "author": "stackoverflowuser2010"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/17182656/how-do-i-iterate-through-the-alphabet",
    "title": "How do I iterate through the alphabet?",
    "question_id": 17182656,
    "posted_date": "2013-06-18T23:59:17",
    "answers": [
      {
        "answer_id": 17182670,
        "body": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nfor i in alc:\n    print(f\"www.website.com/term/{i}\")\n    for j in alc:\n        print(f\"www.website.com/term/{i}{j}\")\n# Result\n# www.website.com/term/a\n# www.website.com/term/aa\n# www.website.com/term/ab\n# www.website.com/term/ac\n# ...\n# www.website.com/term/ax\n# www.website.com/term/ay\n# www.website.com/term/az\n# www.website.com/term/b\n# www.website.com/term/ba\n# www.website.com/term/bb\n# www.website.com/term/bc\n# ...\n# www.website.com/term/bx\n# www.website.com/term/by\n# www.website.com/term/bz\n# www.website.com/term/c\n# www.website.com/term/ca\n# www.website.com/term/cb\n# www.website.com/term/cc\n# ...\n# ...\n# ...\n# www.website.com/term/z\n# www.website.com/term/za\n# www.website.com/term/zb\n# www.website.com/term/zc\n# www.website.com/term/zd\n# ...\n# www.website.com/term/zx\n# www.website.com/term/zy\n# www.website.com/term/zz",
        "score": 216,
        "is_accepted": true,
        "creation_date": "2013-06-19T00:00:45",
        "author": "Jared"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9878020/how-do-i-get-the-user-agent-with-flask",
    "title": "How do I get the user agent with Flask?",
    "question_id": 9878020,
    "posted_date": "2012-03-26T14:57:01",
    "answers": [
      {
        "answer_id": 9878404,
        "body": "from ua_parser import user_agent_parser\nfrom werkzeug.user_agent import UserAgent\nfrom werkzeug.utils import cached_property\nclass ParsedUserAgent(UserAgent):\n    @cached_property\n    def _details(self):\n        return user_agent_parser.Parse(self.string)\n    @property\n    def platform(self):\n        return self._details['os']['family']\n    @property\n    def browser(self):\n        return self._details['user_agent']['family']\n    @property\n    def version(self):\n        return '.'.join(\n            part\n            for key in ('major', 'minor', 'patch')\n            if (part := self._details['user_agent'][key]) is not None\n        )",
        "score": 225,
        "is_accepted": true,
        "creation_date": "2012-03-26T15:25:48",
        "author": "ThiefMaster"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4352244/should-ne-be-implemented-as-the-negation-of-eq",
    "title": "Should __ne__ be implemented as the negation of __eq__?",
    "question_id": 4352244,
    "posted_date": "2010-12-04T01:18:35",
    "answers": [
      {
        "answer_id": 30676267,
        "body": "class BaseEquatable(object):\n    def __init__(self, x):\n        self.x = x\n    def __eq__(self, other):\n        return isinstance(other, BaseEquatable) and self.x == other.x\nclass ComparableWrong(BaseEquatable):\n    def __ne__(self, other):\n        return not self.__eq__(other)\nclass ComparableRight(BaseEquatable):\n    def __ne__(self, other):\n        return not self == other\nclass EqMixin(object):\n    def __eq__(self, other):\n        \"\"\"override Base __eq__ & bounce to other for __eq__, e.g.\n        if issubclass(type(self), type(other)): # True in this example\n        \"\"\"\n        return NotImplemented\nclass ChildComparableWrong(EqMixin, ComparableWrong):\n    \"\"\"__ne__ the wrong way (__eq__ directly)\"\"\"\nclass ChildComparableRight(EqMixin, ComparableRight):\n    \"\"\"__ne__ the right way (uses ==)\"\"\"\nclass ChildComparablePy3(EqMixin, BaseEquatable):\n    \"\"\"No __ne__, only right in Python 3.\"\"\"",
        "score": 187,
        "is_accepted": false,
        "creation_date": "2015-06-05T17:41:16",
        "author": "Aaron Hall"
      },
      {
        "answer_id": 30676267,
        "body": "case Py_NE:\n    /* By default, __ne__() delegates to __eq__() and inverts the result,\n       unless the latter returns NotImplemented. */\n    if (Py_TYPE(self)->tp_richcompare == NULL) {\n        res = Py_NotImplemented;\n        Py_INCREF(res);\n        break;\n    }\n    res = (*Py_TYPE(self)->tp_richcompare)(self, other, Py_EQ);\n    if (res != NULL && res != Py_NotImplemented) {\n        int ok = PyObject_IsTrue(res);\n        Py_DECREF(res);\n        if (ok < 0)\n            res = NULL;\n        else {\n            if (ok)\n                res = Py_False;\n            else\n                res = Py_True;\n            Py_INCREF(res);\n        }\n    }\n    break;",
        "score": 187,
        "is_accepted": false,
        "creation_date": "2015-06-05T17:41:16",
        "author": "Aaron Hall"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37872171/how-can-i-perform-two-dimensional-interpolation-using-scipy",
    "title": "How can I perform two-dimensional interpolation using scipy?",
    "question_id": 37872171,
    "posted_date": "2016-06-16T22:27:48",
    "answers": [
      {
        "answer_id": 37872172,
        "body": "import scipy.interpolate as interp\nsparse_points = np.stack([x_sparse.ravel(), y_sparse.ravel()], -1)  # shape (N, 2) in 2d\ndense_points = np.stack([x_dense.ravel(), y_dense.ravel()], -1)  # shape (N, 2) in 2d\nzfun_smooth_rbf = interp.RBFInterpolator(sparse_points, z_sparse_smooth.ravel(),\n                                         smoothing=0, kernel='cubic')  # explicit default smoothing=0 for interpolation\nz_dense_smooth_rbf = zfun_smooth_rbf(dense_points).reshape(x_dense.shape)  # not really a function, but a callable class instance\nzfun_evil_rbf = interp.RBFInterpolator(sparse_points, z_sparse_evil.ravel(),\n                                       smoothing=0, kernel='cubic')  # explicit default smoothing=0 for interpolation\nz_dense_evil_rbf = zfun_evil_rbf(dense_points).reshape(x_dense.shape)  # not really a function, but a callable class instance",
        "score": 218,
        "is_accepted": true,
        "creation_date": "2016-06-16T22:27:48",
        "author": "Andras Deak -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4714136/how-to-implement-virtual-methods-in-python",
    "title": "How to implement virtual methods in Python?",
    "question_id": 4714136,
    "posted_date": "2011-01-17T09:14:53",
    "answers": [
      {
        "answer_id": 38717503,
        "body": "from typing import Protocol\nclass Bird(Protocol):\n    def fly(self) -> str:\n        pass\n    def peck(self) -> str:\n        return 'Bird.peck'\nclass Pigeon(Bird):\n    def fly(self):\n        return 'Pigeon.fly'\n    def peck(self):\n        return 'Pigeon.peck'\nclass Parrot(Bird):\n    def fly(self):\n        return 'Parrot.fly'\nclass Dog(Bird):\n    pass\npigeon = Pigeon()\nassert pigeon.fly() == 'Pigeon.fly'\nassert pigeon.peck() == 'Pigeon.peck'\nparrot = Parrot()\nassert parrot.fly() == 'Parrot.fly'\nassert parrot.peck() == 'Bird.peck'\n# mypy error\ndog = Dog()\nassert dog.fly() is None\nassert dog.peck() == 'Bird.peck'",
        "score": 123,
        "is_accepted": false,
        "creation_date": "2016-08-02T06:07:22",
        "author": "Ciro Santilli OurBigBook.com"
      },
      {
        "answer_id": 38717503,
        "body": "#!/usr/bin/env python\nimport abc\nclass CanFly(metaclass=abc.ABCMeta):\n    '''\n    doc\n    '''\n    @abc.abstractmethod\n    def fly(self) -> str:\n        '''\n        doc\n        '''\n        pass\nclass Bird(CanFly):\n    '''\n    doc\n    '''\n    def fly(self):\n        '''\n        doc\n        '''\n        return 'Bird.fly'\nclass Dog(CanFly):\n    '''\n    doc\n    '''\n    pass\ndef send_mail(flyer: CanFly) -> str:\n    '''\n    doc\n    '''\n    return flyer.fly()\nassert send_mail(Bird()) == 'Bird.fly'\nassert send_mail(Dog()) == 'Dog.fly'",
        "score": 123,
        "is_accepted": false,
        "creation_date": "2016-08-02T06:07:22",
        "author": "Ciro Santilli OurBigBook.com"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/1728376/get-a-list-of-all-the-encodings-python-can-encode-to",
    "title": "Get a list of all the encodings Python can encode to",
    "question_id": 1728376,
    "posted_date": "2009-11-13T05:24:29",
    "answers": [
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_11',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'cp65001',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp273',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1125',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'cp65001',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_11',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_u',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp273',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1125',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'cp65001',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_11',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_t',\n 'koi8_u',\n 'kz1048',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "['ascii',\n 'big5',\n 'big5hkscs',\n 'cp037',\n 'cp273',\n 'cp424',\n 'cp437',\n 'cp500',\n 'cp720',\n 'cp737',\n 'cp775',\n 'cp850',\n 'cp852',\n 'cp855',\n 'cp856',\n 'cp857',\n 'cp858',\n 'cp860',\n 'cp861',\n 'cp862',\n 'cp863',\n 'cp864',\n 'cp865',\n 'cp866',\n 'cp869',\n 'cp874',\n 'cp875',\n 'cp932',\n 'cp949',\n 'cp950',\n 'cp1006',\n 'cp1026',\n 'cp1125',\n 'cp1140',\n 'cp1250',\n 'cp1251',\n 'cp1252',\n 'cp1253',\n 'cp1254',\n 'cp1255',\n 'cp1256',\n 'cp1257',\n 'cp1258',\n 'euc_jp',\n 'euc_jis_2004',\n 'euc_jisx0213',\n 'euc_kr',\n 'gb2312',\n 'gbk',\n 'gb18030',\n 'hz',\n 'iso2022_jp',\n 'iso2022_jp_1',\n 'iso2022_jp_2',\n 'iso2022_jp_2004',\n 'iso2022_jp_3',\n 'iso2022_jp_ext',\n 'iso2022_kr',\n 'latin_1',\n 'iso8859_2',\n 'iso8859_3',\n 'iso8859_4',\n 'iso8859_5',\n 'iso8859_6',\n 'iso8859_7',\n 'iso8859_8',\n 'iso8859_9',\n 'iso8859_10',\n 'iso8859_11',\n 'iso8859_13',\n 'iso8859_14',\n 'iso8859_15',\n 'iso8859_16',\n 'johab',\n 'koi8_r',\n 'koi8_t',\n 'koi8_u',\n 'kz1048',\n 'mac_cyrillic',\n 'mac_greek',\n 'mac_iceland',\n 'mac_latin2',\n 'mac_roman',\n 'mac_turkish',\n 'ptcp154',\n 'shift_jis',\n 'shift_jis_2004',\n 'shift_jisx0213',\n 'utf_32',\n 'utf_32_be',\n 'utf_32_le',\n 'utf_16',\n 'utf_16_be',\n 'utf_16_le',\n 'utf_7',\n 'utf_8',\n 'utf_8_sig']",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      },
      {
        "answer_id": 25584253,
        "body": "import re\nimport requests\nimport lxml.html\nimport pprint\nprevious = None\nfor version, url in [\n    ('2.3', 'https://docs.python.org/2.3/lib/node130.html'),\n    ('2.4', 'https://docs.python.org/2.4/lib/standard-encodings.html'),\n    ('2.5', 'https://docs.python.org/2.5/lib/standard-encodings.html'),\n    ('2.6', 'https://docs.python.org/2.6/library/codecs.html#standard-encodings'),\n    ('2.7', 'https://docs.python.org/2.7/library/codecs.html#standard-encodings'),\n    ('3.0', 'https://docs.python.org/3.0/library/codecs.html#standard-encodings'),\n    ('3.1', 'https://docs.python.org/3.1/library/codecs.html#standard-encodings'),\n    ('3.2', 'https://docs.python.org/3.2/library/codecs.html#standard-encodings'),\n    ('3.3', 'https://docs.python.org/3.3/library/codecs.html#standard-encodings'),\n    ('3.4', 'https://docs.python.org/3.4/library/codecs.html#standard-encodings'),\n    ('3.5', 'https://docs.python.org/3.5/library/codecs.html#standard-encodings'),\n    ('3.6', 'https://docs.python.org/3.6/library/codecs.html#standard-encodings'),\n    ('3.7', 'https://docs.python.org/3.7/library/codecs.html#standard-encodings'),\n    ('3.8', 'https://docs.python.org/3.8/library/codecs.html#standard-encodings'),\n    ('3.9', 'https://docs.python.org/3.9/library/codecs.html#standard-encodings'),\n    ('3.10', 'https://docs.python.org/3.10/library/codecs.html#standard-encodings'),\n    ('3.11', 'https://docs.python.org/3.11/library/codecs.html#standard-encodings'),\n    ('3.12', 'https://docs.python.org/3.12/library/codecs.html#standard-encodings'),\n    ('3.13', 'https://docs.python.org/3.13/library/codecs.html#standard-encodings'),\n]:\n    html = requests.get(url).text\n    # Work-around for weird HTML markup in recent versions of Python documentation:\n    html = re.sub('<[/]?p>', '', html)\n    doc = lxml.html.fromstring(html)\n    standard_encodings_table = doc.xpath(\n        '//table[preceding::h2[.//text()[contains(., \"Standard Encodings\")]]][//th/text()=\"Codec\"]'\n    )[0]\n    codecs = standard_encodings_table.xpath('.//td[1]/text()')\n    print(\"## Python %s (%i encodings)\\n\" % (version, len(codecs)))\n    if codecs == previous:\n        print('_Same as previous version._\\n')\n    else:\n        print('",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2014-08-30T11:59:40",
        "author": "Mark Amery"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55873174/how-do-i-return-an-image-in-fastapi",
    "title": "How do I return an image in FastAPI?",
    "question_id": 55873174,
    "posted_date": "2019-04-26T14:29:35",
    "answers": [
      {
        "answer_id": 67497103,
        "body": "@app.get(\n    \"/image\",\n    # Set what the media type will be in the autogenerated OpenAPI specification.\n    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response\n    responses = {\n        200: {\n            \"content\": {\"image/png\": {}}\n        }\n    },\n    # Prevent FastAPI from adding \"application/json\" as an additional\n    # response media type in the autogenerated OpenAPI specification.\n    # https://github.com/tiangolo/fastapi/issues/3258\n    response_class=Response\n)\ndef get_image()\n    image_bytes: bytes = generate_cat_picture()\n    # media_type here sets the media type of the actual response sent to the client.\n    return Response(content=image_bytes, media_type=\"image/png\")",
        "score": 143,
        "is_accepted": true,
        "creation_date": "2021-05-11T23:49:28",
        "author": "Maxpm"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-when-piping-prog-py-othercmd",
    "title": "IOError: [Errno 32] Broken pipe when piping: `prog.py | othercmd`",
    "question_id": 14207708,
    "posted_date": "2013-01-07T22:18:28",
    "answers": [
      {
        "answer_id": 30091579,
        "body": "import sys, os, errno\ntry:\n  # Start printing many lines.\n  for x in range(10000): print(x)\n  # IMPORTANT: Flush stdout here, to ensure that the\n  # SIGPIPE-triggered exception can be caught.\n  sys.stdout.flush()\nexcept IOError as e:\n  # Note: Python 3 has the more specific BrokenPipeError,\n  #       but this way the code works in Python 2 too.\n  if e.errno != errno.EPIPE: raise e # Unrelated error, re-throw.\n  # Python flushes standard streams on exit; redirect remaining output\n  # to devnull to avoid another BrokenPipeError at shutdown\n  devnull = os.open(os.devnull, os.O_WRONLY)\n  os.dup2(devnull, sys.stdout.fileno())\n  # ... perform other handling.\n  # Note: You can't write to stdout here.\n  #       (print() and sys.stdout.write won't work)\n  #       However, sys.stderr.write() can be used.\n  sys.stderr.write(\"SIGPIPE received, terminating.\\n\")\n  # Finally, exit with an exit code of choice.\n  sys.exit(141)",
        "score": 125,
        "is_accepted": false,
        "creation_date": "2015-05-06T23:50:10",
        "author": "mklement0"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7222382/get-lat-long-given-current-point-distance-and-bearing",
    "title": "Get lat/long given current point, distance and bearing",
    "question_id": 7222382,
    "posted_date": "2011-08-28T12:56:14",
    "answers": [
      {
        "answer_id": 7835325,
        "body": "from math import asin, atan2, cos, degrees, radians, sin\ndef get_point_at_distance(lat1, lon1, d, bearing, R=6371):\n    \"\"\"\n    lat: initial latitude, in degrees\n    lon: initial longitude, in degrees\n    d: target distance from initial\n    bearing: (true) heading in degrees\n    R: optional radius of sphere, defaults to mean radius of earth\n    Returns new lat/lon coordinate {d}km from initial, in degrees\n    \"\"\"\n    lat1 = radians(lat1)\n    lon1 = radians(lon1)\n    a = radians(bearing)\n    lat2 = asin(sin(lat1) * cos(d/R) + cos(lat1) * sin(d/R) * cos(a))\n    lon2 = lon1 + atan2(\n        sin(a) * sin(d/R) * cos(lat1),\n        cos(d/R) - sin(lat1) * sin(lat2)\n    )\n    return (degrees(lat2), degrees(lon2),)\nlat = 52.20472\nlon = 0.14056\ndistance = 15\nbearing = 90\nlat2, lon2 = get_point_at_distance(lat, lon, distance, bearing)\n# lat2  52.20444 - the lat result I'm hoping for\n# lon2  0.36056 - the long result I'm hoping for.\nprint(lat2, lon2)\n# prints \"52.20451523755824 0.36067845713550956\"",
        "score": 136,
        "is_accepted": true,
        "creation_date": "2011-10-20T07:34:51",
        "author": "David M"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25862026/turn-off-axes-in-subplots",
    "title": "Turn off axes in subplots",
    "question_id": 25862026,
    "posted_date": "2014-09-16T02:32:07",
    "answers": [
      {
        "answer_id": 25864515,
        "body": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.cm as cm\nimport matplotlib.cbook as cbook  # used for matplotlib sample image\n# load readily available sample image\nwith cbook.get_sample_data('grace_hopper.jpg') as image_file:\n    img = plt.imread(image_file)\n# read a local file\n# img = mpimg.imread(\"file.jpg\")\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 8), tight_layout=True)\naxs[0, 0].imshow(img, cmap=cm.Greys_r)\naxs[0, 0].set_title(\"Rank = 512\")\naxs[0, 0].axis(\"off\")\naxs[0, 1].imshow(img, cmap=cm.Greys_r)\naxs[0, 1].set_title(\"Rank = %s\" % 128)\naxs[0, 1].axis(\"off\")\naxs[1, 0].imshow(img, cmap=cm.Greys_r)\naxs[1, 0].set_title(\"Rank = %s\" % 32)\naxs[1, 0].axis(\"off\")\naxs[1, 1].imshow(img, cmap=cm.Greys_r)\naxs[1, 1].set_title(\"Rank = %s\" % 16)\naxs[1, 1].axis(\"off\")\nplt.show()",
        "score": 200,
        "is_accepted": true,
        "creation_date": "2014-09-16T04:56:04",
        "author": "Ffisegydd"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18084554/why-do-i-get-a-syntaxerror-for-a-unicode-escape-in-my-file-path",
    "title": "Why do I get a SyntaxError for a Unicode escape in my file path?",
    "question_id": 18084554,
    "posted_date": "2013-08-06T11:37:38",
    "answers": [
      {
        "answer_id": 18084594,
        "body": "Python 3.10.0 (default, Oct 15 2021, 22:25:32) [Clang 13.0.0 (clang-1300.0.29.3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import warnings\n>>> '\\expoperialed'\n'\\\\expoperialed'\n>>> warnings.filterwarnings('default', '^invalid escape sequence .*', DeprecationWarning)\n>>> '\\expoperialed'\n<stdin>:1: DeprecationWarning: invalid escape sequence '\\e'\n'\\\\expoperialed'\n>>> warnings.filterwarnings('error', '^invalid escape sequence .*', DeprecationWarning)\n>>> '\\expoperialed'\n  File \"<stdin>\", line 1\n    '\\expoperialed'\n    ^^^^^^^^^^^^^^^\nSyntaxError: invalid escape sequence '\\e'",
        "score": 188,
        "is_accepted": false,
        "creation_date": "2013-08-06T11:39:30",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/26646191/pandas-groupby-month-and-year",
    "title": "Pandas groupby month and year",
    "question_id": 26646191,
    "posted_date": "2014-10-30T02:10:51",
    "answers": [
      {
        "answer_id": 26649199,
        "body": "In [11]: df1\nOut[11]:\n            abc  xyz\nDate\n2013-06-01  100  200\n2013-06-03  -20   50\n2013-08-15   40   -5\n2014-01-20   25   15\n2014-02-21   60   80\nIn [12]: g = df1.groupby(pd.Grouper(freq=\"M\"))  # DataFrameGroupBy (grouped by Month)\nIn [13]: g.sum()\nOut[13]:\n            abc  xyz\nDate\n2013-06-30   80  250\n2013-07-31  NaN  NaN\n2013-08-31   40   -5\n2013-09-30  NaN  NaN\n2013-10-31  NaN  NaN\n2013-11-30  NaN  NaN\n2013-12-31  NaN  NaN\n2014-01-31   25   15\n2014-02-28   60   80\nIn [14]: df1.resample(\"M\", how='sum')  # the same\nOut[14]:\n            abc  xyz\nDate\n2013-06-30   40  125\n2013-07-31  NaN  NaN\n2013-08-31   40   -5\n2013-09-30  NaN  NaN\n2013-10-31  NaN  NaN\n2013-11-30  NaN  NaN\n2013-12-31  NaN  NaN\n2014-01-31   25   15\n2014-02-28   60   80",
        "score": 168,
        "is_accepted": true,
        "creation_date": "2014-10-30T05:24:40",
        "author": "Andy Hayden"
      },
      {
        "answer_id": 26649199,
        "body": "In [21]: df\nOut[21]:\n        Date  abc  xyz\n0 2013-06-01  100  200\n1 2013-06-03  -20   50\n2 2013-08-15   40   -5\n3 2014-01-20   25   15\n4 2014-02-21   60   80\nIn [22]: pd.DatetimeIndex(df.Date).to_period(\"M\")  # old way\nOut[22]:\n<class 'pandas.tseries.period.PeriodIndex'>\n[2013-06, ..., 2014-02]\nLength: 5, Freq: M\nIn [23]: per = df.Date.dt.to_period(\"M\")  # new way to get the same\nIn [24]: g = df.groupby(per)\nIn [25]: g.sum()  # dang not quite what we want (doesn't fill in the gaps)\nOut[25]:\n         abc  xyz\n2013-06   80  250\n2013-08   40   -5\n2014-01   25   15\n2014-02   60   80",
        "score": 168,
        "is_accepted": true,
        "creation_date": "2014-10-30T05:24:40",
        "author": "Andy Hayden"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape",
    "title": "Automatic contrast and brightness adjustment of a color photo of a sheet of paper with OpenCV",
    "question_id": 56905592,
    "posted_date": "2019-07-05T11:10:32",
    "answers": [
      {
        "answer_id": 56909036,
        "body": "import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n# Automatic brightness and contrast optimization with optional histogram clipping\ndef automatic_brightness_and_contrast(image, clip_hist_percent=1):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Calculate grayscale histogram\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n    hist_size = len(hist)\n\n    # Calculate cumulative distribution from the histogram\n    accumulator = []\n    accumulator.append(float(hist[0]))\n    for index in range(1, hist_size):\n        accumulator.append(accumulator[index -1] + float(hist[index]))\n\n    # Locate points to clip\n    maximum = accumulator[-1]\n    clip_hist_percent *= (maximum/100.0)\n    clip_hist_percent /= 2.0\n\n    # Locate left cut\n    minimum_gray = 0\n    while accumulator[minimum_gray] < clip_hist_percent:\n        minimum_gray += 1\n\n    # Locate right cut\n    maximum_gray = hist_size -1\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n        maximum_gray -= 1\n\n    # Calculate alpha and beta values\n    alpha = 255 / (maximum_gray - minimum_gray)\n    beta = -minimum_gray * alpha\n\n    '''\n    # Calculate new histogram with desired range and show histogram\n    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n    plt.plot(hist)\n    plt.plot(new_hist)\n    plt.xlim([0,256])\n    plt.show()\n    '''\n    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n    return (auto_result, alpha, beta)\nimage = cv2.imread('1.jpg')\nauto_result, alpha, beta = automatic_brightness_and_contrast(image)\nprint('alpha', alpha)\nprint('beta', beta)\ncv2.imshow('auto_result', auto_result)\ncv2.waitKey()",
        "score": 96,
        "is_accepted": false,
        "creation_date": "2019-07-05T16:40:58",
        "author": "nathancy"
      },
      {
        "answer_id": 56909036,
        "body": "import cv2\nimport numpy as np\n# from matplotlib import pyplot as plt\ndef convertScale(img, alpha, beta):\n    \"\"\"Add bias and gain to an image with saturation arithmetics. Unlike\n    cv2.convertScaleAbs, it does not take an absolute value, which would lead to\n    nonsensical results (e.g., a pixel at 44 with alpha = 3 and beta = -210\n    becomes 78 with OpenCV, when in fact it should become 0).\n    \"\"\"\n    new_img = img * alpha + beta\n    new_img[new_img < 0] = 0\n    new_img[new_img > 255] = 255\n    return new_img.astype(np.uint8)\n# Automatic brightness and contrast optimization with optional histogram clipping\ndef automatic_brightness_and_contrast(image, clip_hist_percent=25):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # Calculate grayscale histogram\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n    hist_size = len(hist)\n    # Calculate cumulative distribution from the histogram\n    accumulator = []\n    accumulator.append(float(hist[0]))\n    for index in range(1, hist_size):\n        accumulator.append(accumulator[index -1] + float(hist[index]))\n    # Locate points to clip\n    maximum = accumulator[-1]\n    clip_hist_percent *= (maximum/100.0)\n    clip_hist_percent /= 2.0\n    # Locate left cut\n    minimum_gray = 0\n    while accumulator[minimum_gray] < clip_hist_percent:\n        minimum_gray += 1\n    # Locate right cut\n    maximum_gray = hist_size -1\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n        maximum_gray -= 1\n    # Calculate alpha and beta values\n    alpha = 255 / (maximum_gray - minimum_gray)\n    beta = -minimum_gray * alpha\n    '''\n    # Calculate new histogram with desired range and show histogram\n    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n    plt.plot(hist)\n    plt.plot(new_hist)\n    plt.xlim([0,256])\n    plt.show()\n    '''\n    auto_result = convertScale(image, alpha=alpha, beta=beta)\n    return (auto_result, alpha, beta)\nimage = cv2.imread('1.jpg')\nauto_result, alpha, beta = automatic_brightness_and_contrast(image)\nprint('alpha', alpha)\nprint('beta', beta)\ncv2.imshow('auto_result', auto_result)\ncv2.imwrite('auto_result.png', auto_result)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 96,
        "is_accepted": false,
        "creation_date": "2019-07-05T16:40:58",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58108488/what-is-qualname-in-python",
    "title": "What is __qualname__ in python?",
    "question_id": 58108488,
    "posted_date": "2019-09-25T21:44:25",
    "answers": [
      {
        "answer_id": 58110139,
        "body": ">>> def f(): pass\n... class A:\n...    def f(self): pass\n...    class A:\n...        def f(self): pass\n...\n>>> # __name__ is not showing the path, so these functions look equal\n>>> f.__name__\n'f'\n>>> A.f.__name__\n'f'\n>>> A.A.f.__name__\n'f'\n>>> # And these classes looks equal\n>>> A.__name__\n'A'\n>>> A.A.__name__\n'A'\n>>>\n>>> # __qualname__ shows the path, so these functions are distinguishable\n>>> f.__qualname__\n'f'\n>>> A.f.__qualname__\n'A.f'\n>>> A.A.f.__qualname__\n'A.A.f'\n>>> # And these classes are distinguishable\n>>> A.__qualname__\n'A'\n>>> A.A.__qualname__\n'A.A'",
        "score": 140,
        "is_accepted": true,
        "creation_date": "2019-09-26T01:31:33",
        "author": "Mattias Wallin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9103166/multiple-axis-in-matplotlib-with-different-scales",
    "title": "multiple axis in matplotlib with different scales",
    "question_id": 9103166,
    "posted_date": "2012-02-01T15:50:14",
    "answers": [
      {
        "answer_id": 45925049,
        "body": "import matplotlib.pyplot as plt\n# Create figure and subplot manually\n# fig = plt.figure()\n# host = fig.add_subplot(111)\n# More versatile wrapper\nfig, host = plt.subplots(figsize=(8,5), layout='constrained') # (width, height) in inches\n# (see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html and\n# .. https://matplotlib.org/stable/tutorials/intermediate/constrainedlayout_guide.html)\n\nax2 = host.twinx()\nax3 = host.twinx()\n\nhost.set_xlim(0, 2)\nhost.set_ylim(0, 2)\nax2.set_ylim(0, 4)\nax3.set_ylim(1, 65)\n\nhost.set_xlabel(\"Distance\")\nhost.set_ylabel(\"Density\")\nax2.set_ylabel(\"Temperature\")\nax3.set_ylabel(\"Velocity\")\ncolor1, color2, color3 = plt.cm.viridis([0, .5, .9])\np1 = host.plot([0, 1, 2], [0, 1, 2],    color=color1, label=\"Density\")\np2 = ax2.plot( [0, 1, 2], [0, 3, 2],    color=color2, label=\"Temperature\")\np3 = ax3.plot( [0, 1, 2], [50, 30, 15], color=color3, label=\"Velocity\")\nhost.legend(handles=p1+p2+p3, loc='best')\n# right, left, top, bottom\nax3.spines['right'].set_position(('outward', 60))\n# no x-ticks\nhost.xaxis.set_ticks([])\n# Alternatively (more verbose):\n# host.tick_params(\n#     axis='x',          # changes apply to the x-axis\n#     which='both',      # both major and minor ticks are affected\n#     bottom=False,      # ticks along the bottom edge are off)\n#     labelbottom=False) # labels along the bottom edge are off\n# sometimes handy:  direction='in'\n# Move \"Velocity\"-axis to the left\n# ax3.spines['left'].set_position(('outward', 60))\n# ax3.spines['left'].set_visible(True)\n# ax3.spines['right'].set_visible(False)\n# ax3.yaxis.set_label_position('left')\n# ax3.yaxis.set_ticks_position('left')\nhost.yaxis.label.set_color(p1[0].get_color())\nax2.yaxis.label.set_color(p2[0].get_color())\nax3.yaxis.label.set_color(p3[0].get_color())\n# For professional typesetting, e.g. LaTeX, use .pgf or .pdf\n# For raster graphics use the dpi argument. E.g. '[...].png\", dpi=300)'\nplt.savefig(\"pyplot_multiple_y-axis.pdf\", bbox_inches='tight')\n# bbox_inches='tight': Try to strip excess whitespace\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html",
        "score": 139,
        "is_accepted": false,
        "creation_date": "2017-08-28T14:11:08",
        "author": "Suuuehgi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5854515/interactive-large-plot-with-20-million-sample-points-and-gigabytes-of-data",
    "title": "Interactive large plot with ~20 million sample points and gigabytes of data",
    "question_id": 5854515,
    "posted_date": "2011-05-02T03:25:39",
    "answers": [
      {
        "answer_id": 55967461,
        "body": "from bokeh.io import output_notebook, show\nfrom bokeh.models import HoverTool\nfrom bokeh.transform import linear_cmap\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource\nimport numpy as np\noutput_notebook()\nN = 1000000\nsource = ColumnDataSource(data=dict(\n    x=np.random.random(size=N) * N,\n    y=np.random.random(size=N) * N,\n    z=np.random.random(size=N)\n))\nhover = HoverTool(tooltips=[(\"z\", \"@z\")])\np = figure()\np.add_tools(hover)\np.circle(\n    'x',\n    'y',\n    source=source,\n    color=linear_cmap('z', 'Viridis256', 0, 1.0),\n    size=5\n)\nshow(p)",
        "score": 109,
        "is_accepted": false,
        "creation_date": "2019-05-03T05:57:54",
        "author": "Ciro Santilli OurBigBook.com"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix",
    "title": "How to write a confusion matrix",
    "question_id": 2148543,
    "posted_date": "2010-01-27T11:27:19",
    "answers": [
      {
        "answer_id": 29877565,
        "body": "Confusion Matrix:\nPredicted  0  1  2  __all__\nActual\n0          3  0  0        3\n1          0  1  2        3\n2          2  1  3        6\n__all__    5  2  5       12\nOverall Statistics:\nAccuracy: 0.583333333333\n95% CI: (0.27666968568210581, 0.84834777019156982)\nNo Information Rate: ToDo\nP-Value [Acc > NIR]: 0.189264302376\nKappa: 0.354838709677\nMcnemar's Test P-Value: ToDo\nClass Statistics:\nClasses                                        0          1          2\nPopulation                                    12         12         12\nP: Condition positive                          3          3          6\nN: Condition negative                          9          9          6\nTest outcome positive                          5          2          5\nTest outcome negative                          7         10          7\nTP: True Positive                              3          1          3\nTN: True Negative                              7          8          4\nFP: False Positive                             2          1          2\nFN: False Negative                             0          2          3\nTPR: (Sensitivity, hit rate, recall)           1  0.3333333        0.5\nTNR=SPC: (Specificity)                 0.7777778  0.8888889  0.6666667\nPPV: Pos Pred Value (Precision)              0.6        0.5        0.6\nNPV: Neg Pred Value                            1        0.8  0.5714286\nFPR: False-out                         0.2222222  0.1111111  0.3333333\nFDR: False Discovery Rate                    0.4        0.5        0.4\nFNR: Miss Rate                                 0  0.6666667        0.5\nACC: Accuracy                          0.8333333       0.75  0.5833333\nF1 score                                    0.75        0.4  0.5454545\nMCC: Matthews correlation coefficient  0.6831301  0.2581989  0.1690309\nInformedness                           0.7777778  0.2222222  0.1666667\nMarkedness                                   0.6        0.3  0.1714286\nPrevalence                                  0.25       0.25        0.5\nLR+: Positive likelihood ratio               4.5          3        1.5\nLR-: Negative likelihood ratio                 0       0.75       0.75\nDOR: Diagnostic odds ratio                   inf          4          2\nFOR: False omission rate                       0        0.2  0.4285714",
        "score": 250,
        "is_accepted": false,
        "creation_date": "2015-04-26T08:22:11",
        "author": "scls"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69437526/what-is-this-odd-sorting-algorithm",
    "title": "What is this odd sorting algorithm?",
    "question_id": 69437526,
    "posted_date": "2021-10-04T10:14:22",
    "answers": [
      {
        "answer_id": 69439123,
        "body": "before: [1, 12, 13, 8, 15, 18, 19, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [19, 1, 12, 8, 13, 15, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 19, 12, 8, 13, 15, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 12, 19, 8, 13, 15, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 8, 12, 19, 13, 15, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 8, 12, 13, 19, 15, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 8, 12, 13, 15, 19, 18, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 8, 12, 13, 15, 18, 19, 16, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 8, 12, 13, 15, 16, 18, 19, 7, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 7, 8, 12, 13, 15, 16, 18, 19, 11, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 7, 8, 11, 12, 13, 15, 16, 18, 19, 6, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 14, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 3, 2, 9, 5, 4, 0, 10, 17]\n        [1, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 2, 9, 5, 4, 0, 10, 17]\n        [1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 9, 5, 4, 0, 10, 17]\n        [1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 5, 4, 0, 10, 17]\n        [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 4, 0, 10, 17]\n        [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 0, 10, 17]\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 10, 17]\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 17]\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nafter:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]",
        "score": 91,
        "is_accepted": false,
        "creation_date": "2021-10-04T12:07:50",
        "author": "no comment"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18727347/how-to-extract-a-filename-from-a-url-and-append-a-word-to-it",
    "title": "How to extract a filename from a URL and append a word to it?",
    "question_id": 18727347,
    "posted_date": "2013-09-10T15:32:23",
    "answers": [
      {
        "answer_id": 18727481,
        "body": "from pathlib import Path, PurePosixPath\nfrom urllib.parse import urlparse, unquote\nurl = \"http://photographs.500px.com/kyle/09-09-2013%20-%2015-47-571378756077.jpg\"\nurlparse(url).path\nurl_parsed = urlparse(url)\nprint(unquote(url_parsed.path))  # Output: /kyle/09-09-2013 - 15-47-571378756077.jpg\nfile_path = Path(\"/home/ubuntu/Desktop/\") / unquote(PurePosixPath(url_parsed.path).name)\nprint(file_path)        # Output: /home/ubuntu/Desktop/09-09-2013 - 15-47-571378756077.jpg\nnew_file = file_path.with_stem(file_path.stem + \"_small\")\nprint(new_file)         # Output: /home/ubuntu/Desktop/09-09-2013 - 15-47-571378756077_small.jpg",
        "score": 242,
        "is_accepted": true,
        "creation_date": "2013-09-10T15:41:11",
        "author": "Ofir Israel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57837609/python-typing-signature-typing-callable-for-function-with-kwargs",
    "title": "python typing signature (typing.Callable) for function with kwargs",
    "question_id": 57837609,
    "posted_date": "2019-09-07T17:31:47",
    "answers": [
      {
        "answer_id": 57840786,
        "body": "from typing import Protocol\n# Or, if you want to support Python 3.7 and below, install the typing_extensions\n# module via pip and do the below:\nfrom typing_extensions import Protocol\nclass MyCallable(Protocol):\n    def __call__(self, a: int, b: float) -> float: ...\ndef good(a: int, b: float) -> float: ...\ndef bad(x: int, y: float) -> float: ...\ndef function_executor(a: int, b: float, fn: MyCallable) -> float:\n    return fn(a=a, b=b)\nfunction_executor(1, 2.3, good)  # Ok!\nfunction_executor(1, 2.3, bad)   # Errors",
        "score": 141,
        "is_accepted": true,
        "creation_date": "2019-09-08T05:39:10",
        "author": "Michael0x2a"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52582685/using-asyncio-queue-for-producer-consumer-flow",
    "title": "Using asyncio.Queue for producer-consumer flow",
    "question_id": 52582685,
    "posted_date": "2018-09-30T18:29:58",
    "answers": [
      {
        "answer_id": 52615705,
        "body": "# like the above, but handling exceptions during processing:\nasync def consumer(queue):\n    while True:\n        token = await queue.get()\n        try:\n            # this uses aiohttp or whatever\n            await process(token)\n        except aiohttp.ClientError as e:\n            print(f\"Error processing token {token}: {e}\")\n            # If it makes sense, return the token to the queue to be\n            # processed again. (You can use a counter to avoid\n            # processing a faulty token infinitely.)\n            #await queue.put(token)\n        queue.task_done()\n        print(f'consumed {token}')",
        "score": 141,
        "is_accepted": true,
        "creation_date": "2018-10-02T16:11:20",
        "author": "user4815162342"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65076/how-do-i-set-up-vim-autoindentation-properly-for-editing-python-files",
    "title": "How do I set up Vim autoindentation properly for editing Python files?",
    "question_id": 65076,
    "posted_date": "2008-09-15T13:48:22",
    "answers": [
      {
        "answer_id": 65122,
        "body": "\" configure expanding of tabs for various file types\nau BufRead,BufNewFile *.py set expandtab\nau BufRead,BufNewFile *.c set expandtab\nau BufRead,BufNewFile *.h set expandtab\nau BufRead,BufNewFile Makefile* set noexpandtab\n\" --------------------------------------------------------------------------------\n\" configure editor with tabs and nice stuff...\n\" --------------------------------------------------------------------------------\nset expandtab           \" enter spaces when tab is pressed\nset textwidth=120       \" break lines when line length increases\nset tabstop=4           \" use 4 spaces to represent tab\nset softtabstop=4\nset shiftwidth=4        \" number of spaces to use for auto indent\nset autoindent          \" copy indent from current line when starting a new line\n\" make backspaces more powerfull\nset backspace=indent,eol,start\nset ruler               \" show line and column number\nsyntax on               \" syntax highlighting\nset showcmd             \" show (partial) command in status line",
        "score": 86,
        "is_accepted": false,
        "creation_date": "2008-09-15T13:53:33",
        "author": "Daren Thomas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7247298/size-of-a-python-list-in-memory",
    "title": "Size of a Python list in memory",
    "question_id": 7247298,
    "posted_date": "2011-08-30T13:29:01",
    "answers": [
      {
        "answer_id": 7247542,
        "body": "/* This over-allocates proportional to the list size, making room\n* for additional growth.  The over-allocation is mild, but is\n* enough to give linear-time amortized behavior over a long\n* sequence of appends() in the presence of a poorly-performing\n* system realloc().\n* The growth pattern is:  0, 4, 8, 16, 25, 35, 46, 58, 72, 88, ...\n*/\nnew_allocated = (newsize >> 3) + (newsize < 9 ? 3 : 6);\n/* check for integer overflow */\nif (new_allocated > PY_SIZE_MAX - newsize) {\n    PyErr_NoMemory();\n    return -1;\n} else {\n    new_allocated += newsize;\n}",
        "score": 175,
        "is_accepted": true,
        "creation_date": "2011-08-30T13:49:35",
        "author": "Eli Bendersky"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55684960/why-does-python-start-at-index-1-as-opposed-to-0-when-indexing-a-list-from-th",
    "title": "Why does Python start at index -1 (as opposed to 0) when indexing a list from the end?",
    "question_id": 55684960,
    "posted_date": "2019-04-15T04:12:29",
    "answers": [
      {
        "answer_id": 55685012,
        "body": "\"\"\"swap mirror node\"\"\"\ndef reverse(arr: List[int]) -> None:\n    for i in range(len(arr) // 2):\n        arr[i], arr[~i] = arr[~i], arr[i]\n\"\"\"find median in a sort list\"\"\"\ndef median(arr: List[float]) -> float:\n    mid = len(arr) // 2\n    return (arr[mid] + arr[~mid]) / 2\n\"\"\"deal with mirror pairs\"\"\"\n# verify the number is strobogrammatic, strobogrammatic number looks the same when rotated 180 degrees\ndef is_strobogrammatic(num: str) -> bool:\n    return all(num[i] + num[~i] in '696 00 11 88' for i in range(len(num) // 2 + 1))",
        "score": 185,
        "is_accepted": true,
        "creation_date": "2019-04-15T04:16:03",
        "author": "recnac"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4914008/how-to-efficiently-parse-fixed-width-files",
    "title": "How to efficiently parse fixed width files?",
    "question_id": 4914008,
    "posted_date": "2011-02-06T09:54:41",
    "answers": [
      {
        "answer_id": 4915359,
        "body": "import struct\nfieldwidths = (2, -10, 24)\nfmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's') for fw in fieldwidths)\n# Convert Unicode input to bytes and the result back to Unicode string.\nunpack = struct.Struct(fmtstring).unpack_from  # Alias.\nparse = lambda line: tuple(s.decode() for s in unpack(line.encode()))\nprint('fmtstring: {!r}, record size: {} chars'.format(fmtstring, struct.calcsize(fmtstring)))\nline = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\n'\nfields = parse(line)\nprint('fields: {}'.format(fields))",
        "score": 81,
        "is_accepted": true,
        "creation_date": "2011-02-06T13:52:16",
        "author": "martineau"
      },
      {
        "answer_id": 4915359,
        "body": "from itertools import zip_longest\nfrom itertools import accumulate\ndef make_parser(fieldwidths):\n    cuts = tuple(cut for cut in accumulate(abs(fw) for fw in fieldwidths))\n    pads = tuple(fw < 0 for fw in fieldwidths) # bool values for padding fields\n    flds = tuple(zip_longest(pads, (0,)+cuts, cuts))[:-1]  # ignore final one\n    parse = lambda line: tuple(line[i:j] for pad, i, j in flds if not pad)\n    # Optional informational function attributes.\n    parse.size = sum(abs(fw) for fw in fieldwidths)\n    parse.fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                                for fw in fieldwidths)\n    return parse\nline = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\n'\nfieldwidths = (2, -10, 24)  # negative widths represent ignored padding fields\nparse = make_parser(fieldwidths)\nfields = parse(line)\nprint('format: {!r}, rec size: {} chars'.format(parse.fmtstring, parse.size))\nprint('fields: {}'.format(fields))",
        "score": 81,
        "is_accepted": true,
        "creation_date": "2011-02-06T13:52:16",
        "author": "martineau"
      },
      {
        "answer_id": 4915359,
        "body": "def make_parser(fieldwidths):\n    cuts = tuple(cut for cut in accumulate(abs(fw) for fw in fieldwidths))\n    pads = tuple(fw < 0 for fw in fieldwidths) # bool flags for padding fields\n    flds = tuple(zip_longest(pads, (0,)+cuts, cuts))[:-1]  # ignore final one\n    slcs = ', '.join('line[{}:{}]'.format(i, j) for pad, i, j in flds if not pad)\n    parse = eval('lambda line: ({})\\n'.format(slcs))  # Create and compile source code.\n    # Optional informational function attributes.\n    parse.size = sum(abs(fw) for fw in fieldwidths)\n    parse.fmtstring = ' '.join('{}{}'.format(abs(fw), 'x' if fw < 0 else 's')\n                                                for fw in fieldwidths)\n    return parse",
        "score": 81,
        "is_accepted": true,
        "creation_date": "2011-02-06T13:52:16",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54646709/sklearn-pipeline-get-feature-names-after-onehotencode-in-columntransformer",
    "title": "Sklearn Pipeline: Get feature names after OneHotEncode In ColumnTransformer",
    "question_id": 54646709,
    "posted_date": "2019-02-12T04:27:06",
    "answers": [
      {
        "answer_id": 54648023,
        "body": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\ndf = pd.DataFrame({'brand': ['aaaa', 'asdfasdf', 'sadfds', 'NaN'],\n                   'category': ['asdf', 'asfa', 'asdfas', 'as'],\n                   'num1': [1, 1, 0, 0],\n                   'target': [0.2, 0.11, 1.34, 1.123]})\nnumeric_features = ['num1']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\ncategorical_features = ['brand', 'category']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor',  LinearRegression())])\nclf.fit(df.drop('target', 1), df['target'])\nclf.named_steps['preprocessor'].transformers_[1][1]\\\n   .named_steps['onehot'].get_feature_names(categorical_features)\n# ['brand_NaN' 'brand_aaaa' 'brand_asdfasdf' 'brand_sadfds' 'category_as'\n#  'category_asdf' 'category_asdfas' 'category_asfa']",
        "score": 94,
        "is_accepted": true,
        "creation_date": "2019-02-12T05:32:21",
        "author": "Venkatachalam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56183201/detect-and-visualize-differences-between-two-images-with-opencv-python",
    "title": "Detect and visualize differences between two images with OpenCV Python",
    "question_id": 56183201,
    "posted_date": "2019-05-17T05:11:07",
    "answers": [
      {
        "answer_id": 56193442,
        "body": "from skimage.metrics import structural_similarity\nimport cv2\nimport numpy as np\n# Load images\nbefore = cv2.imread('left.jpg')\nafter = cv2.imread('right.jpg')\n# Convert images to grayscale\nbefore_gray = cv2.cvtColor(before, cv2.COLOR_BGR2GRAY)\nafter_gray = cv2.cvtColor(after, cv2.COLOR_BGR2GRAY)\n# Compute SSIM between the two images\n(score, diff) = structural_similarity(before_gray, after_gray, full=True)\nprint(\"Image Similarity: {:.4f}%\".format(score * 100))\n# The diff image contains the actual image differences between the two images\n# and is represented as a floating point data type in the range [0,1]\n# so we must convert the array to 8-bit unsigned integers in the range\n# [0,255] before we can use it with OpenCV\ndiff = (diff * 255).astype(\"uint8\")\ndiff_box = cv2.merge([diff, diff, diff])\n# Threshold the difference image, followed by finding contours to\n# obtain the regions of the two input images that differ\nthresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\ncontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncontours = contours[0] if len(contours) == 2 else contours[1]\nmask = np.zeros(before.shape, dtype='uint8')\nfilled_after = after.copy()\nfor c in contours:\n    area = cv2.contourArea(c)\n    if area > 40:\n        x,y,w,h = cv2.boundingRect(c)\n        cv2.rectangle(before, (x, y), (x + w, y + h), (36,255,12), 2)\n        cv2.rectangle(after, (x, y), (x + w, y + h), (36,255,12), 2)\n        cv2.rectangle(diff_box, (x, y), (x + w, y + h), (36,255,12), 2)\n        cv2.drawContours(mask, [c], 0, (255,255,255), -1)\n        cv2.drawContours(filled_after, [c], 0, (0,255,0), -1)\ncv2.imshow('before', before)\ncv2.imshow('after', after)\ncv2.imshow('diff', diff)\ncv2.imshow('diff_box', diff_box)\ncv2.imshow('mask', mask)\ncv2.imshow('filled after', filled_after)\ncv2.waitKey()",
        "score": 128,
        "is_accepted": false,
        "creation_date": "2019-05-17T16:53:41",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/19672352/how-to-run-script-with-elevated-privilege-on-windows",
    "title": "How to run script with elevated privilege on windows",
    "question_id": 19672352,
    "posted_date": "2013-10-29T21:41:19",
    "answers": [
      {
        "answer_id": 19719292,
        "body": "#!/usr/bin/env python\n# -*- coding: utf-8; mode: python; py-indent-offset: 4; indent-tabs-mode: nil -*-\n# vim: fileencoding=utf-8 tabstop=4 expandtab shiftwidth=4\n# (C) COPYRIGHT \u00a9 Preston Landers 2010\n# Released under the same license as Python 2.6.5\n\nimport sys, os, traceback, types\n\ndef isUserAdmin():\n\n    if os.name == 'nt':\n        import ctypes\n        # WARNING: requires Windows XP SP2 or higher!\n        try:\n            return ctypes.windll.shell32.IsUserAnAdmin()\n        except:\n            traceback.print_exc()\n            print \"Admin check failed, assuming not an admin.\"\n            return False\n    elif os.name == 'posix':\n        # Check for root on Posix\n        return os.getuid() == 0\n    else:\n        raise RuntimeError, \"Unsupported operating system for this module: %s\" % (os.name,)\n\ndef runAsAdmin(cmdLine=None, wait=True):\n\n    if os.name != 'nt':\n        raise RuntimeError, \"This function is only implemented on Windows.\"\n\n    import win32api, win32con, win32event, win32process\n    from win32com.shell.shell import ShellExecuteEx\n    from win32com.shell import shellcon\n\n    python_exe = sys.executable\n\n    if cmdLine is None:\n        cmdLine = [python_exe] + sys.argv\n    elif type(cmdLine) not in (types.TupleType,types.ListType):\n        raise ValueError, \"cmdLine is not a sequence.\"\n    cmd = '\"%s\"' % (cmdLine[0],)\n    # XXX TODO: isn't there a function or something we can call to massage command line params?\n    params = \" \".join(['\"%s\"' % (x,) for x in cmdLine[1:]])\n    cmdDir = ''\n    showCmd = win32con.SW_SHOWNORMAL\n    #showCmd = win32con.SW_HIDE\n    lpVerb = 'runas'  # causes UAC elevation prompt.\n\n    # print \"Running\", cmd, params\n\n    # ShellExecute() doesn't seem to allow us to fetch the PID or handle\n    # of the process, so we can't get anything useful from it. Therefore\n    # the more complex ShellExecuteEx() must be used.\n\n    # procHandle = win32api.ShellExecute(0, lpVerb, cmd, params, cmdDir, showCmd)\n\n    procInfo = ShellExecuteEx(nShow=showCmd,\n                              fMask=shellcon.SEE_MASK_NOCLOSEPROCESS,\n                              lpVerb=lpVerb,\n                              lpFile=cmd,\n                              lpParameters=params)\n\n    if wait:\n        procHandle = procInfo['hProcess']\n        obj = win32event.WaitForSingleObject(procHandle, win32event.INFINITE)\n        rc = win32process.GetExitCodeProcess(procHandle)\n        #print \"Process handle %s returned code %s\" % (procHandle, rc)\n    else:\n        rc = None\n\n    return rc\n\ndef test():\n    rc = 0\n    if not isUserAdmin():\n        print \"You're not an admin.\", os.getpid(), \"params: \", sys.argv\n        #rc = runAsAdmin([\"c:\\\\Windows\\\\notepad.exe\"])\n        rc = runAsAdmin()\n    else:\n        print \"You are an admin!\", os.getpid(), \"params: \", sys.argv\n        rc = 0\n    x = raw_input('Press Enter to exit.')\n    return rc\n\n\nif __name__ == \"__main__\":\n    sys.exit(test())",
        "score": 117,
        "is_accepted": true,
        "creation_date": "2013-10-31T21:06:42",
        "author": "sundar_ima"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61463224/when-to-use-raise-for-status-vs-status-code-testing",
    "title": "When to use `raise_for_status` vs `status_code` testing",
    "question_id": 61463224,
    "posted_date": "2020-04-27T12:08:41",
    "answers": [
      {
        "answer_id": 61463451,
        "body": "import time\nfrom http import HTTPStatus\nimport requests\nfrom requests.exceptions import HTTPError\nurl = \"https://theurl.com\"\nretries = 3\nretry_codes = [\n    HTTPStatus.TOO_MANY_REQUESTS,\n    HTTPStatus.INTERNAL_SERVER_ERROR,\n    HTTPStatus.BAD_GATEWAY,\n    HTTPStatus.SERVICE_UNAVAILABLE,\n    HTTPStatus.GATEWAY_TIMEOUT,\n]\nfor n in range(retries):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        break\n    except HTTPError as exc:\n        code = exc.response.status_code\n\n        if code in retry_codes:\n            # retry after n seconds\n            time.sleep(n)\n            continue\n        raise",
        "score": 99,
        "is_accepted": true,
        "creation_date": "2020-04-27T12:20:33",
        "author": "Sam Morgan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45745661/lower-vs-casefold-in-string-matching-and-converting-to-lowercase",
    "title": "lower() vs. casefold() in string matching and converting to lowercase",
    "question_id": 45745661,
    "posted_date": "2017-08-17T18:08:27",
    "answers": [
      {
        "answer_id": 45745761,
        "body": "import sys\nfrom timeit import timeit\nunicode_codepoints = tuple(map(chr, range(sys.maxunicode)))\ndef compute_lower():\n    return tuple(codepoint.lower() for codepoint in unicode_codepoints)\ndef compute_casefold():\n    return tuple(codepoint.casefold() for codepoint in unicode_codepoints)\ntimer_repeat = 1000\nprint(f\"time to compute lower on unicode namespace: {timeit(compute_lower, number = timer_repeat) / timer_repeat} seconds\")\nprint(f\"time to compute casefold on unicode namespace: {timeit(compute_casefold, number = timer_repeat) / timer_repeat} seconds\")\nprint(f\"number of distinct characters from lower: {len(set(compute_lower()))}\")\nprint(f\"number of distinct characters from casefold: {len(set(compute_casefold()))}\")",
        "score": 99,
        "is_accepted": true,
        "creation_date": "2017-08-17T18:20:34",
        "author": "David Culbreth"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10629815/how-to-switch-to-new-window-in-selenium-for-python",
    "title": "How to switch to new window in Selenium for Python?",
    "question_id": 10629815,
    "posted_date": "2012-05-17T00:26:16",
    "answers": [
      {
        "answer_id": 29982298,
        "body": "import unittest\nfrom selenium import webdriver\nclass GoogleOrgSearch(unittest.TestCase):\n    def setUp(self):\n        self.driver = webdriver.Firefox()\n    def test_google_search_page(self):\n        driver = self.driver\n        driver.get(\"http://www.cdot.in\")\n        window_before = driver.window_handles[0]\n        print window_before\n        driver.find_element_by_xpath(\"//a[@href='http://www.cdot.in/home.htm']\").click()\n        window_after = driver.window_handles[1]\n        driver.switch_to.window(window_after)\n        print window_after\n        driver.find_element_by_link_text(\"ATM\").click()\n        driver.switch_to.window(window_before)\n    def tearDown(self):\n        self.driver.close()\nif __name__ == \"__main__\":\n    unittest.main()",
        "score": 90,
        "is_accepted": false,
        "creation_date": "2015-05-01T01:58:53",
        "author": "vishy dewangan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16329946/django-model-method-create-or-update",
    "title": "Django model method - create_or_update",
    "question_id": 16329946,
    "posted_date": "2013-05-01T23:37:06",
    "answers": [
      {
        "answer_id": 57752118,
        "body": "class TestCust(models.Model):\n    name = models.CharField(max_length=50)\n    password = models.CharField(max_length=100)\n    role = models.CharField(max_length=20)\nsqlite> select * from myapp_testcust;\n1|suhail|pass|admin\n2|suhail|pass1|\n>>> TestCust.objects.update_or_create(name='suhail',defaults={'password':'pass3'})\nTraceback (most recent call last):\n  File \"<console>\", line 1, in <module>\n  File \"/home/suhail/github/django_testing/env/lib/python3.10/site-packages/django/db/models/manager.py\", line 87, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/home/suhail/github/django_testing/env/lib/python3.10/site-packages/django/db/models/query.py\", line 986, in update_or_create\n    obj, created = self.select_for_update().get_or_create(\n  File \"/home/suhail/github/django_testing/env/lib/python3.10/site-packages/django/db/models/query.py\", line 948, in get_or_create\n    return self.get(**kwargs), False\n  File \"/home/suhail/github/django_testing/env/lib/python3.10/site-packages/django/db/models/query.py\", line 652, in get\n    raise self.model.MultipleObjectsReturned(\nmyapp.models.TestCust.MultipleObjectsReturned: get() returned more than one TestCust -- it returned 2!\n>>> TestCust.objects.update_or_create(name='suhail',password='pass1',defaults={'password':'pass3'})\n(<TestCust: TestCust object (2)>, False)\nsqlite> select * from myapp_testcust;\n1|suhail|pass|admin\n2|suhail|pass3|\n>>> TestCust.objects.update_or_create(name='suhail',password='pass1',defaults={'password':'pass3','role':'adminer'})\n(<TestCust: TestCust object (3)>, True)\nsqlite> select * from myapp_testcust;\n1|suhail|pass|admin\n2|suhail|pass3|\n3|suhail|pass3|adminer",
        "score": 157,
        "is_accepted": false,
        "creation_date": "2019-09-02T02:08:31",
        "author": "suhailvs"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python",
    "title": "Equivalent of Numpy.argsort() in basic python?",
    "question_id": 3382352,
    "posted_date": "2010-08-01T10:24:59",
    "answers": [
      {
        "answer_id": 6979121,
        "body": "import timeit\nimport random\nimport numpy as np\ndef f(seq):\n    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n    #non-lambda version by Tony Veijalainen\n    return [i for (v, i) in sorted((v, i) for (i, v) in enumerate(seq))]\ndef g(seq):\n    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n    #lambda version by Tony Veijalainen\n    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\ndef h(seq):\n    #http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3382369#3382369\n    #by unutbu\n    return sorted(range(len(seq)), key=seq.__getitem__)\nseq = list(range(10000))\nrandom.shuffle(seq)\nn_trials = 100\nfor cmd in [\n        'f(seq)', 'g(seq)', 'h(seq)', 'np.argsort(seq)',\n        'np.argsort(seq).tolist()'\n        ]:\n    t = timeit.Timer(cmd, globals={**globals(), **locals()})\n    print('time for {:d}x {:}: {:.6f}'.format(n_trials, cmd, t.timeit(n_trials)))",
        "score": 86,
        "is_accepted": true,
        "creation_date": "2011-08-08T03:49:49",
        "author": "Boris Gorelik"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59933946/difference-between-typevart-a-b-and-typevart-bound-uniona-b",
    "title": "Difference between TypeVar(&#39;T&#39;, A, B) and TypeVar(&#39;T&#39;, bound=Union[A, B])",
    "question_id": 59933946,
    "posted_date": "2020-01-27T10:18:06",
    "answers": [
      {
        "answer_id": 59937840,
        "body": "from typing import TypeVar, Union, List, Iterable\nmix1: List[Union[int, str]] = [1, \"a\", 3]\nmix2: List[Union[int, str]] = [4, \"x\", \"y\"]\nall_ints = [1, 2, 3]\nall_strs = [\"a\", \"b\", \"c\"]\nT1 = TypeVar('T1', bound=Union[int, str])\ndef concat1(x: Iterable[T1], y: Iterable[T1]) -> List[T1]:\n    out: List[T1] = []\n    out.extend(x)\n    out.extend(y)\n    return out\n# Type checks\na1 = concat1(mix1, mix2)\n# Also type checks (though your type checker may need a hint to deduce\n# you really do want a union)\na2: List[Union[int, str]] = concat1(all_ints, all_strs)\n# Also type checks\na3 = concat1(all_strs, all_strs)",
        "score": 127,
        "is_accepted": true,
        "creation_date": "2020-01-27T14:43:10",
        "author": "Michael0x2a"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42128467/plot-multiple-columns-of-pandas-dataframe-on-the-bar-chart",
    "title": "Plot multiple columns of pandas DataFrame on the bar chart",
    "question_id": 42128467,
    "posted_date": "2017-02-08T23:49:04",
    "answers": [
      {
        "answer_id": 42131286,
        "body": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(2022)  # creates a consistent sample\ny = np.random.rand(10,4)\ny[:,0]= np.arange(10)\ndf = pd.DataFrame(y, columns=[\"X\", \"A\", \"B\", \"C\"])\n     X         A         B         C\n0  0.0  0.499058  0.113384  0.049974\n1  1.0  0.486988  0.897657  0.647452\n2  2.0  0.721135  0.831353  0.827568\n3  3.0  0.957044  0.368044  0.494838\n4  4.0  0.619429  0.977530  0.096433\n5  5.0  0.292499  0.298675  0.752473\n6  6.0  0.523737  0.864436  0.388843\n7  7.0  0.475181  0.564672  0.349429\n8  8.0  0.037820  0.794270  0.357883\n9  9.0  0.914509  0.372662  0.964883",
        "score": 183,
        "is_accepted": true,
        "creation_date": "2017-02-09T03:11:50",
        "author": "ImportanceOfBeingErnest"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16258553/how-can-i-define-algebraic-data-types-in-python",
    "title": "How can I define algebraic data types in Python?",
    "question_id": 16258553,
    "posted_date": "2013-04-27T21:15:44",
    "answers": [
      {
        "answer_id": 71519690,
        "body": "from dataclasses import dataclass\n@dataclass\nclass Point:\n    x: float\n    y: float\n@dataclass\nclass Circle:\n    x: float\n    y: float\n    r: float\n@dataclass\nclass Rectangle:\n    x: float\n    y: float\n    w: float\n    h: float\nShape = Point | Circle | Rectangle\ndef print_shape(shape: Shape):\n    match shape:\n        case Point(x, y):\n            print(f\"Point {x} {y}\")\n        case Circle(x, y, r):\n            print(f\"Circle {x} {y} {r}\")\n        case Rectangle(x, y, w, h):\n            print(f\"Rectangle {x} {y} {w} {h}\")\nprint_shape(Point(1, 2))\nprint_shape(Circle(3, 5, 7))\nprint_shape(Rectangle(11, 13, 17, 19))\nprint_shape(4)  # mypy type error",
        "score": 71,
        "is_accepted": false,
        "creation_date": "2022-03-17T18:20:15",
        "author": "tehziyang"
      },
      {
        "answer_id": 71519690,
        "body": "from __future__ import annotations\nfrom dataclasses import dataclass\n@dataclass\nclass Branch:\n    value: int\n    left: Tree\n    right: Tree\nTree = Branch | None\ndef contains(tree: Tree, value: int):\n    match tree:\n        case None:\n            return False\n        case Branch(x, left, right):\n            return x == value or contains(left, value) or contains(right, value)\ntree = Branch(1, Branch(2, None, None), Branch(3, None, Branch(4, None, None)))\nassert contains(tree, 1)\nassert contains(tree, 2)\nassert contains(tree, 3)\nassert contains(tree, 4)\nassert not contains(tree, 5)",
        "score": 71,
        "is_accepted": false,
        "creation_date": "2022-03-17T18:20:15",
        "author": "tehziyang"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/13484726/safe-enough-8-character-short-unique-random-string",
    "title": "safe enough 8-character short unique random string",
    "question_id": 13484726,
    "posted_date": "2012-11-20T19:52:03",
    "answers": [
      {
        "answer_id": 56398787,
        "body": "import random\nimport secrets\nfrom statistics import mean\nfrom statistics import stdev\nimport string\nimport time\nimport timeit\nimport uuid\nimport shortuuid\nalphabet = string.ascii_lowercase + string.digits\nsu = shortuuid.ShortUUID(alphabet=alphabet)\ndef random_choice():\n    return ''.join(random.choices(alphabet, k=8))\ndef truncated_uuid4():\n    return str(uuid.uuid4())[:8]\ndef shortuuid_random():\n    return su.random(length=8)\ndef secrets_random_choice():\n    return ''.join(secrets.choice(alphabet) for _ in range(8))\ndef test_collisions(fun):\n    out = set()\n    count = 0\n    for _ in range(10_000_000):\n        new = fun()\n        if new in out:\n            count += 1\n        else:\n            out.add(new)\n    return count\ndef run_and_print_results(fun):\n    round_digits = 5\n    now = time.time()\n    collisions = test_collisions(fun)\n    total_time = round(time.time() - now, round_digits)\n    trials = 1_000\n    runs = 100\n    func_time = timeit.repeat(fun, repeat=runs, number=trials)\n    avg = round(mean(func_time), round_digits)\n    std = round(stdev(func_time), round_digits)\n    print(f'{fun.__name__}: collisions {collisions} - '\n          f'time (s) {avg} \u00b1 {std} - '\n          f'total (s) {total_time}')\nif __name__ == '__main__':\n    run_and_print_results(random_choice)\n    run_and_print_results(truncated_uuid4)\n    run_and_print_results(shortuuid_random)\n    run_and_print_results(secrets_random_choice)",
        "score": 93,
        "is_accepted": false,
        "creation_date": "2019-05-31T12:34:19",
        "author": "Oleg"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57126286/fastest-parallel-requests-in-python",
    "title": "Fastest parallel requests in Python",
    "question_id": 57126286,
    "posted_date": "2019-07-20T11:50:38",
    "answers": [
      {
        "answer_id": 57129241,
        "body": "import asyncio\nimport aiohttp\nimport time\nwebsites = \"\"\"https://www.youtube.com\nhttps://www.facebook.com\nhttps://www.baidu.com\nhttps://www.yahoo.com\nhttps://www.amazon.com\nhttps://www.wikipedia.org\nhttp://www.qq.com\nhttps://www.google.co.in\nhttps://www.twitter.com\nhttps://www.live.com\nhttp://www.taobao.com\nhttps://www.bing.com\nhttps://www.instagram.com\nhttp://www.weibo.com\nhttp://www.sina.com.cn\nhttps://www.linkedin.com\nhttp://www.yahoo.co.jp\nhttp://www.msn.com\nhttp://www.uol.com.br\nhttps://www.google.de\nhttp://www.yandex.ru\nhttp://www.hao123.com\nhttps://www.google.co.uk\nhttps://www.reddit.com\nhttps://www.ebay.com\nhttps://www.google.fr\nhttps://www.t.co\nhttp://www.tmall.com\nhttp://www.google.com.br\nhttps://www.360.cn\nhttp://www.sohu.com\nhttps://www.amazon.co.jp\nhttp://www.pinterest.com\nhttps://www.netflix.com\nhttp://www.google.it\nhttps://www.google.ru\nhttps://www.microsoft.com\nhttp://www.google.es\nhttps://www.wordpress.com\nhttp://www.gmw.cn\nhttps://www.tumblr.com\nhttp://www.paypal.com\nhttp://www.blogspot.com\nhttp://www.imgur.com\nhttps://www.stackoverflow.com\nhttps://www.aliexpress.com\nhttps://www.naver.com\nhttp://www.ok.ru\nhttps://www.apple.com\nhttp://www.github.com\nhttp://www.chinadaily.com.cn\nhttp://www.imdb.com\nhttps://www.google.co.kr\nhttp://www.fc2.com\nhttp://www.jd.com\nhttp://www.blogger.com\nhttp://www.163.com\nhttp://www.google.ca\nhttps://www.whatsapp.com\nhttps://www.amazon.in\nhttp://www.office.com\nhttp://www.google.co.id\nhttp://www.youku.com\nhttps://www.example.com\nhttp://www.craigslist.org\nhttps://www.amazon.de\nhttp://www.nicovideo.jp\nhttps://www.google.pl\nhttp://www.soso.com\nhttp://www.bilibili.com\nhttp://www.dropbox.com\nhttp://www.xinhuanet.com\nhttp://www.outbrain.com\nhttp://www.pixnet.net\nhttp://www.alibaba.com\nhttp://www.alipay.com\nhttp://www.chrome.com\nhttp://www.booking.com\nhttp://www.googleusercontent.com\nhttp://www.google.com.au\nhttp://www.popads.net\nhttp://www.cntv.cn\nhttp://www.zhihu.com\nhttps://www.amazon.co.uk\nhttp://www.diply.com\nhttp://www.coccoc.com\nhttps://www.cnn.com\nhttp://www.bbc.co.uk\nhttps://www.twitch.tv\nhttps://www.wikia.com\nhttp://www.google.co.th\nhttp://www.go.com\nhttps://www.google.com.ph\nhttp://www.doubleclick.net\nhttp://www.onet.pl\nhttp://www.googleadservices.com\nhttp://www.accuweather.com\nhttp://www.googleweblight.com\nhttp://www.answers.yahoo.com\"\"\"\nasync def get(url, session):\n    try:\n        async with session.get(url=url) as response:\n            resp = await response.read()\n            print(\"Successfully got url {} with resp of length {}.\".format(url, len(resp)))\n    except Exception as e:\n        print(\"Unable to get url {} due to {}.\".format(url, e.__class__))\nasync def main(urls):\n    async with aiohttp.ClientSession() as session:\n        ret = await asyncio.gather(*(get(url, session) for url in urls))\n    print(\"Finalized all. Return is a list of len {} outputs.\".format(len(ret)))\nurls = websites.split(\"\\n\")\nstart = time.time()\nasyncio.run(main(urls))\nend = time.time()\nprint(\"Took {} seconds to pull {} websites.\".format(end - start, len(urls)))",
        "score": 126,
        "is_accepted": false,
        "creation_date": "2019-07-20T19:08:06",
        "author": "felipe"
      },
      {
        "answer_id": 57129241,
        "body": "Successfully got url http://www.msn.com with resp of length 47967.\nSuccessfully got url http://www.google.com.br with resp of length 14823.\nSuccessfully got url https://www.t.co with resp of length 0.\nSuccessfully got url http://www.google.es with resp of length 14798.\nSuccessfully got url https://www.wikipedia.org with resp of length 66691.\nSuccessfully got url http://www.google.it with resp of length 14805.\nSuccessfully got url http://www.googleadservices.com with resp of length 1561.\nSuccessfully got url http://www.cntv.cn with resp of length 3232.\nSuccessfully got url https://www.example.com with resp of length 1256.\nSuccessfully got url https://www.google.co.uk with resp of length 14184.\nSuccessfully got url http://www.accuweather.com with resp of length 269.\nSuccessfully got url http://www.google.ca with resp of length 14172.\nSuccessfully got url https://www.facebook.com with resp of length 192898.\nSuccessfully got url https://www.apple.com with resp of length 75422.\nSuccessfully got url http://www.gmw.cn with resp of length 136136.\nSuccessfully got url https://www.google.ru with resp of length 14803.\nSuccessfully got url https://www.bing.com with resp of length 70314.\nSuccessfully got url http://www.googleusercontent.com with resp of length 1561.\nSuccessfully got url https://www.tumblr.com with resp of length 37500.\nSuccessfully got url http://www.googleweblight.com with resp of length 1619.\nSuccessfully got url https://www.google.co.in with resp of length 14230.\nSuccessfully got url http://www.qq.com with resp of length 101957.\nSuccessfully got url http://www.xinhuanet.com with resp of length 113239.\nSuccessfully got url https://www.twitch.tv with resp of length 105014.\nSuccessfully got url http://www.google.co.id with resp of length 14806.\nSuccessfully got url https://www.linkedin.com with resp of length 90047.\nSuccessfully got url https://www.google.fr with resp of length 14777.\nSuccessfully got url https://www.google.co.kr with resp of length 14797.\nSuccessfully got url http://www.google.co.th with resp of length 14783.\nSuccessfully got url https://www.google.pl with resp of length 14769.\nSuccessfully got url http://www.google.com.au with resp of length 14228.\nSuccessfully got url https://www.whatsapp.com with resp of length 84551.\nSuccessfully got url https://www.google.de with resp of length 14767.\nSuccessfully got url https://www.google.com.ph with resp of length 14196.\nSuccessfully got url https://www.cnn.com with resp of length 1135447.\nSuccessfully got url https://www.wordpress.com with resp of length 216637.\nSuccessfully got url https://www.twitter.com with resp of length 61869.\nSuccessfully got url http://www.alibaba.com with resp of length 282210.\nSuccessfully got url https://www.instagram.com with resp of length 20776.\nSuccessfully got url https://www.live.com with resp of length 36621.\nSuccessfully got url https://www.aliexpress.com with resp of length 37388.\nSuccessfully got url http://www.uol.com.br with resp of length 463614.\nSuccessfully got url https://www.microsoft.com with resp of length 230635.\nSuccessfully got url http://www.pinterest.com with resp of length 87012.\nSuccessfully got url http://www.paypal.com with resp of length 103763.\nSuccessfully got url https://www.wikia.com with resp of length 237977.\nSuccessfully got url http://www.sina.com.cn with resp of length 530525.\nSuccessfully got url https://www.amazon.de with resp of length 341222.\nSuccessfully got url https://www.stackoverflow.com with resp of length 190878.\nSuccessfully got url https://www.ebay.com with resp of length 263256.\nSuccessfully got url http://www.diply.com with resp of length 557848.\nSuccessfully got url http://www.office.com with resp of length 111909.\nSuccessfully got url http://www.imgur.com with resp of length 6223.\nSuccessfully got url https://www.amazon.co.jp with resp of length 417751.\nSuccessfully got url http://www.outbrain.com with resp of length 54481.\nSuccessfully got url https://www.amazon.co.uk with resp of length 362057.\nSuccessfully got url http://www.chrome.com with resp of length 223832.\nSuccessfully got url http://www.popads.net with resp of length 14517.\nSuccessfully got url https://www.youtube.com with resp of length 571028.\nSuccessfully got url http://www.doubleclick.net with resp of length 130244.\nSuccessfully got url https://www.yahoo.com with resp of length 510721.\nSuccessfully got url http://www.tianya.cn with resp of length 7619.\nSuccessfully got url https://www.netflix.com with resp of length 422277.\nSuccessfully got url https://www.naver.com with resp of length 210175.\nSuccessfully got url http://www.blogger.com with resp of length 94478.\nSuccessfully got url http://www.soso.com with resp of length 5816.\nSuccessfully got url http://www.github.com with resp of length 212285.\nSuccessfully got url https://www.amazon.com with resp of length 442097.\nSuccessfully got url http://www.go.com with resp of length 598355.\nSuccessfully got url http://www.chinadaily.com.cn with resp of length 102857.\nSuccessfully got url http://www.sohu.com with resp of length 216027.\nSuccessfully got url https://www.amazon.in with resp of length 417175.\nSuccessfully got url http://www.answers.yahoo.com with resp of length 104628.\nSuccessfully got url http://www.jd.com with resp of length 18217.\nSuccessfully got url http://www.blogspot.com with resp of length 94478.\nSuccessfully got url http://www.fc2.com with resp of length 16997.\nSuccessfully got url https://www.baidu.com with resp of length 301922.\nSuccessfully got url http://www.craigslist.org with resp of length 59438.\nSuccessfully got url http://www.imdb.com with resp of length 675494.\nSuccessfully got url http://www.yahoo.co.jp with resp of length 37036.\nSuccessfully got url http://www.onet.pl with resp of length 854384.\nSuccessfully got url http://www.dropbox.com with resp of length 200591.\nSuccessfully got url http://www.zhihu.com with resp of length 50543.\nSuccessfully got url http://www.yandex.ru with resp of length 174347.\nSuccessfully got url http://www.ok.ru with resp of length 206604.\nSuccessfully got url http://www.163.com with resp of length 588036.\nSuccessfully got url http://www.bbc.co.uk with resp of length 303267.\nSuccessfully got url http://www.nicovideo.jp with resp of length 116124.\nSuccessfully got url http://www.pixnet.net with resp of length 6448.\nSuccessfully got url http://www.bilibili.com with resp of length 96941.\nSuccessfully got url https://www.reddit.com with resp of length 718393.\nSuccessfully got url http://www.booking.com with resp of length 472655.\nSuccessfully got url https://www.360.cn with resp of length 79943.\nSuccessfully got url http://www.taobao.com with resp of length 384755.\nSuccessfully got url http://www.youku.com with resp of length 326873.\nSuccessfully got url http://www.coccoc.com with resp of length 64687.\nSuccessfully got url http://www.tmall.com with resp of length 137527.\nSuccessfully got url http://www.hao123.com with resp of length 331222.\nSuccessfully got url http://www.weibo.com with resp of length 93712.\nSuccessfully got url http://www.alipay.com with resp of length 24057.\nFinalized all. Return is a list of len 100 outputs.\nTook 3.9256999492645264 seconds to pull 100 websites.",
        "score": 126,
        "is_accepted": false,
        "creation_date": "2019-07-20T19:08:06",
        "author": "felipe"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3850022/how-can-i-load-an-existing-database-file-into-memory-in-python-sqlite-3",
    "title": "How can I load an existing database file into memory in Python SQLite 3?",
    "question_id": 3850022,
    "posted_date": "2010-10-03T09:55:00",
    "answers": [
      {
        "answer_id": 10856450,
        "body": "import sqlite3\nfrom io import StringIO\ndef init_sqlite_db(app):\n    # Read database to tempfile\n    con = sqlite3.connect(app.config['SQLITE_DATABASE'])\n    tempfile = StringIO()\n    for line in con.iterdump():\n        tempfile.write('%s\\n' % line)\n    con.close()\n    tempfile.seek(0)\n    # Create a database in memory and import from tempfile\n    app.sqlite = sqlite3.connect(\":memory:\")\n    app.sqlite.cursor().executescript(tempfile.read())\n    app.sqlite.commit()\n    app.sqlite.row_factory = sqlite3.Row",
        "score": 130,
        "is_accepted": true,
        "creation_date": "2012-06-01T15:46:07",
        "author": "Cenk Alti"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59156895/cannot-import-name-mydb-from-partially-initialized-module-connection-in-pyth",
    "title": "cannot import name &#39;mydb&#39; from partially initialized module &#39;connection&#39; in Python",
    "question_id": 59156895,
    "posted_date": "2019-12-03T07:13:52",
    "answers": [
      {
        "answer_id": 62303448,
        "body": "+----------------+-------------------------------------------------------------------------------------------+\n|    Filename    |                                        Description                                        |\n+----------------+-------------------------------------------------------------------------------------------+\n| app.py         | Creates the app and starts the server.                                                    |\n| models.py      | Define what the entity will look like (e.g, UserModel has username, email, password etc.) |\n| controllers.py | Fetches Data from database, generates HTML and sends the response to the user browser.    |\n+----------------+-------------------------------------------------------------------------------------------+",
        "score": 119,
        "is_accepted": true,
        "creation_date": "2020-06-10T08:20:29",
        "author": "Jayant Malik"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47060133/python-3-type-hinting-for-decorator",
    "title": "Python 3 type hinting for decorator",
    "question_id": 47060133,
    "posted_date": "2017-11-01T13:08:12",
    "answers": [
      {
        "answer_id": 68290080,
        "body": "from typing import Callable, ParamSpec, Concatenate, TypeVar\nParam = ParamSpec(\"Param\")\nRetType = TypeVar(\"RetType\")\ndef get_authenticated_user()->str:\n    return \"John\"\ndef inject_user() -> Callable[[Callable[Param, RetType]], Callable[Concatenate[str, Param], RetType]]:\n    def decorator(func: Callable[Param, RetType]) -> Callable[Concatenate[str, Param], RetType]:\n        def wrapper(user: str, *args:Param.args, **kwargs:Param.kwargs) -> RetType:\n            user = get_authenticated_user()\n            if user is None:\n                raise Exception(\"Don't!\")\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n@inject_user()\ndef foo(a: int) -> bool:\n    return bool(a % 2)\nreveal_type(foo)  #  # I: Revealed type is \"def (builtins.str, a: builtins.int) -> builtins.bool\"\nfoo(\"user\", 2)  # Type check OK\nfoo(\"no!\")  # E: Missing positional argument \"a\" in call to \"foo\"  [call-arg]\nfoo(3)  # # E: Missing positional argument \"a\" in call to \"foo\"  [call-arg] # E: Argument 1 to \"foo\" has incompatible type \"int\"; expected \"str\"  [arg-type]",
        "score": 98,
        "is_accepted": false,
        "creation_date": "2021-07-07T12:47:18",
        "author": "legogo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3346430/what-is-the-most-efficient-way-to-get-first-and-last-line-of-a-text-file",
    "title": "What is the most efficient way to get first and last line of a text file?",
    "question_id": 3346430,
    "posted_date": "2010-07-27T13:58:24",
    "answers": [
      {
        "answer_id": 18603065,
        "body": "from os import SEEK_END, SEEK_CUR\ndef readlast(f):\n    try:\n        f.seek(-2, SEEK_END)       # Jump to the second last byte.\n        while f.read(1) != b\"\\n\":  #  Until newline is found ...\n            f.seek(-2, SEEK_CUR)   #  ... jump back, over the read byte plus one.\n    except OSError:                # Reached begginning of File\n        f.seek(0)                  #  Set cursor to beginning of file as well.\n    return f.read()                # Read all data from this point on.\n\nwith open(path, \"rb\") as f:\n    first = f.readline()\n    last  = readlast(f)",
        "score": 97,
        "is_accepted": false,
        "creation_date": "2013-09-03T19:29:19",
        "author": "Trasp"
      },
      {
        "answer_id": 18603065,
        "body": "from collections import deque\nfrom os import SEEK_CUR, SEEK_END\ndef readlast(f, d = b'\\n'):\n    \"\"\"\"readlast(f: io.IOBase, d: bytes = b'\\n') -> bytes\n    Return the last segment of file `f`, containing data segments separated by\n    `d`.\n    \"\"\"\n    arr = deque(); step = 1; pos = -1\n    try:\n        # Seek to last byte of file, save it to arr as to not check for newline.\n        pos = f.seek(-1, SEEK_END)\n        arr.appendleft(f.read())\n        # Seek past the byte read, plus one to use as the first segment.\n        pos = f.seek(-2, SEEK_END)\n        seg = f.read(1)\n        # Break when 'd' occurs, store index of the rightmost match in 'i'.\n        while seg.rfind(d) == -1:\n            # Store segments with no b'\\n' in a memory-efficient 'deque'.\n            arr.appendleft(seg)\n            # Step back in file, past the bytes just read plus twice that.\n            pos = f.seek(-step*3, SEEK_CUR)\n            # Read new segment, twice as big as the one read previous iteration.\n            step *= 2\n            seg = f.read(step)\n        # Ignore the characters up to 'i', and the triggering newline character.\n        arr.appendleft(seg[seg.rfind(d)+1:])\n    except OSError:\n        # Reached beginning of file. Read remaining data and check for newline.\n        f.seek(0)\n        seg = f.read(pos)\n        arr.appendleft(seg[seg.rfind(d)+1:])\n    return b\"\".join(arr)",
        "score": 97,
        "is_accepted": false,
        "creation_date": "2013-09-03T19:29:19",
        "author": "Trasp"
      },
      {
        "answer_id": 18603065,
        "body": "from os import SEEK_CUR, SEEK_END\ndef _readlast__bytes(f, sep, size, step):\n    # Point cursor 'size' + 'step' bytes away from the end of the file.\n    o = f.seek(0 - size - step, SEEK_END)\n    # Step 'step' bytes each iteration, halt when 'sep' occurs.\n    while f.read(size) != sep:\n        f.seek(0 - size - step, SEEK_CUR)\ndef _readlast__text(f, sep, size, step):\n    # Text mode, same principle but without the use of relative offsets.\n    o = f.seek(0, SEEK_END)\n    o = f.seek(o - size - step)\n    while f.read(size) != sep:\n        o = f.seek(o - step)\ndef readlast(f, sep, fixed = False):\n    \"\"\"readlast(f: io.BaseIO, sep: bytes|str, fixed: bool = False) -> bytes|str\n    Return the last segment of file `f`, containing data segments separated by\n    `sep`.\n    Set `fixed` to True when parsing UTF-32 or UTF-16 encoded data (don't forget\n    to pass the correct delimiter) in files opened in byte mode.\n    \"\"\"\n    size = len(sep)\n    step = len(sep) if (fixed is True) else (fixed or 1)\n    step = size if fixed else 1\n    if not size:\n        raise ValueError(\"Zero-length separator.\")\n    try:\n        if 'b' in f.mode:\n            # Process file opened in byte mode.\n            _readlast__bytes(f, sep, size, step)\n        else:\n            # Process file opened in text mode.\n            _readlast__text(f, sep, size, step)\n    except (OSError, ValueError):\n        # Beginning of file reached.\n        f.seek(0, SEEK_SET)\n    return f.read()",
        "score": 97,
        "is_accepted": false,
        "creation_date": "2013-09-03T19:29:19",
        "author": "Trasp"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65504438/how-to-add-both-file-and-json-body-in-a-fastapi-post-request",
    "title": "How to add both file and JSON body in a FastAPI POST request?",
    "question_id": 65504438,
    "posted_date": "2020-12-30T04:05:11",
    "answers": [
      {
        "answer_id": 70640522,
        "body": "from fastapi import Form, File, UploadFile, Request, FastAPI\nfrom typing import List\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\n@app.post(\"/submit\")\ndef submit(\n    name: str = Form(...),\n    point: float = Form(...),\n    is_accepted: bool = Form(...),\n    files: List[UploadFile] = File(...),\n):\n    return {\n        \"JSON Payload\": {\"name\": name, \"point\": point, \"is_accepted\": is_accepted},\n        \"Filenames\": [file.filename for file in files],\n    }\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "<!DOCTYPE html>\n<html>\n   <body>\n      <form method=\"post\" action=\"http://127.0.0.1:8000/submit\"  enctype=\"multipart/form-data\">\n         name : <input type=\"text\" name=\"name\" value=\"foo\"><br>\n         point : <input type=\"text\" name=\"point\" value=0.134><br>\n         is_accepted : <input type=\"text\" name=\"is_accepted\" value=True><br>\n         <label for=\"files\">Choose file(s) to upload</label>\n         <input type=\"file\" id=\"files\" name=\"files\" multiple>\n         <input type=\"submit\" value=\"submit\">\n      </form>\n   </body>\n</html>",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "from fastapi import Form, File, UploadFile, Request, FastAPI, Depends\nfrom typing import List, Optional\nfrom fastapi.responses import HTMLResponse\nfrom pydantic import BaseModel\nfrom fastapi.templating import Jinja2Templates\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\nclass Base(BaseModel):\n    name: str\n    point: Optional[float] = None\n    is_accepted: Optional[bool] = False\n@app.post(\"/submit\")\ndef submit(base: Base = Depends(), files: List[UploadFile] = File(...)):\n    return {\n        \"JSON Payload\": base,\n        \"Filenames\": [file.filename for file in files],\n    }\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "<!DOCTYPE html>\n<html>\n   <body>\n      <form method=\"post\" id=\"myForm\" onsubmit=\"transformFormData();\" enctype=\"multipart/form-data\">\n         name : <input type=\"text\" name=\"name\" value=\"foo\"><br>\n         point : <input type=\"text\" name=\"point\" value=0.134><br>\n         is_accepted : <input type=\"text\" name=\"is_accepted\" value=True><br>\n         <label for=\"files\">Choose file(s) to upload</label>\n         <input type=\"file\" id=\"files\" name=\"files\" multiple>\n         <input type=\"submit\" value=\"submit\">\n      </form>\n      <script>\n         function transformFormData(){\n\t\t\tvar myForm = document.getElementById('myForm');\n\t\t\tvar qs = new URLSearchParams(new FormData(myForm)).toString();\n            myForm.action = 'http://127.0.0.1:8000/submit?' + qs;\n         }\n      </script>\n   </body>\n</html>",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "<!DOCTYPE html>\n<html>\n   <body>\n      <form id=\"myForm\" >\n         name : <input type=\"text\" name=\"name\" value=\"foo\"><br>\n         point : <input type=\"text\" name=\"point\" value=0.134><br>\n         is_accepted : <input type=\"text\" name=\"is_accepted\" value=True><br>\n      </form>\n      <label for=\"fileInput\">Choose file(s) to upload</label>\n      <input type=\"file\" id=\"fileInput\" onchange=\"reset()\" multiple><br>\n      <input type=\"button\" value=\"Submit\" onclick=\"submitUsingFetch()\">\n      <p id=\"resp\"></p>\n      <script>\n         function reset() {\n            var resp = document.getElementById(\"resp\");\n            resp.innerHTML = \"\";\n            resp.style.color = \"black\";\n         }\n\n         function submitUsingFetch() {\n            var resp = document.getElementById(\"resp\");\n            var fileInput = document.getElementById('fileInput');\n            if (fileInput.files[0]) {\n               var formData = new FormData();\n               for (const file of fileInput.files)\n                  formData.append('files', file);\n               var myForm = document.getElementById('myForm');\n               var qs = new URLSearchParams(new FormData(myForm)).toString();\n               fetch('/submit?' + qs, {\n                     method: 'POST',\n                     body: formData,\n                  })\n                  .then(response => response.json())\n                  .then(data => {\n                     resp.innerHTML = JSON.stringify(data); // data is a JSON object\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n            } else {\n               resp.innerHTML = \"Please choose some file(s)...\";\n               resp.style.color = \"red\";\n            }\n         }\n      </script>\n   </body>\n</html>",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "from fastapi import FastAPI, status, Form, UploadFile, File, Depends, Request\nfrom pydantic import BaseModel, ValidationError\nfrom fastapi.exceptions import HTTPException\nfrom fastapi.encoders import jsonable_encoder\nfrom typing import Optional, List\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\nclass Base(BaseModel):\n    name: str\n    point: Optional[float] = None\n    is_accepted: Optional[bool] = False\ndef checker(data: str = Form(...)):\n    try:\n        return Base.model_validate_json(data)\n    except ValidationError as e:\n        raise HTTPException(\n            detail=jsonable_encoder(e.errors()),\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        )\n@app.post(\"/submit\")\ndef submit(base: Base = Depends(checker), files: List[UploadFile] = File(...)):\n    return {\"JSON Payload\": base, \"Filenames\": [file.filename for file in files]}\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "# ...  rest of the code is the same as above\nclass Other(BaseModel):\n    msg: str\n    details: Base\n\n\nclass Checker:\n    def __init__(self, model: BaseModel):\n        self.model = model\n    def __call__(self, data: str = Form(...)):\n        try:\n            return self.model.model_validate_json(data)\n        except ValidationError as e:\n            raise HTTPException(\n                detail=jsonable_encoder(e.errors()),\n                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            )\n@app.post(\"/submit\")\ndef submit(base: Base = Depends(Checker(Base)), files: List[UploadFile] = File(...)):\n    pass\n@app.post(\"/submit_other\")\ndef submit_other(other: Other = Depends(Checker(Other)), files: List[UploadFile] = File(...)):\n    pass",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "<!DOCTYPE html>\n<html>\n   <head>\n      <script src=\"https://cdnjs.cloudflare.com/ajax/libs/axios/0.27.2/axios.min.js\"></script>\n   </head>\n   <body>\n      <input type=\"file\" id=\"fileInput\" name=\"file\" onchange=\"reset()\" multiple><br>\n      <input type=\"button\" value=\"Submit using fetch\" onclick=\"submitUsingFetch()\">\n      <input type=\"button\" value=\"Submit using axios\" onclick=\"submitUsingAxios()\">\n      <p id=\"resp\"></p>\n      <script>\n         function reset() {\n            var resp = document.getElementById(\"resp\");\n            resp.innerHTML = \"\";\n            resp.style.color = \"black\";\n         }\n\n         function submitUsingFetch() {\n            var resp = document.getElementById(\"resp\");\n            var fileInput = document.getElementById('fileInput');\n            if (fileInput.files[0]) {\n               var formData = new FormData();\n               formData.append(\"data\", JSON.stringify({\"name\": \"foo\", \"point\": 0.13, \"is_accepted\": false}));\n\n               for (const file of fileInput.files)\n                  formData.append('files', file);\n\n               fetch('/submit', {\n                     method: 'POST',\n                     body: formData,\n                  })\n                  .then(response => response.json())\n                  .then(data => {\n                     resp.innerHTML = JSON.stringify(data); // data is a JSON object\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n            } else {\n               resp.innerHTML = \"Please choose some file(s)...\";\n               resp.style.color = \"red\";\n            }\n         }\n\n         function submitUsingAxios() {\n            var resp = document.getElementById(\"resp\");\n            var fileInput = document.getElementById('fileInput');\n            if (fileInput.files[0]) {\n               var formData = new FormData();\n               formData.append(\"data\", JSON.stringify({\"name\": \"foo\", \"point\": 0.13, \"is_accepted\": false}));\n\n               for (const file of fileInput.files)\n                  formData.append('files', file);\n\n               axios({\n                     method: 'POST',\n                     url: '/submit',\n                     data: formData,\n                  })\n                  .then(response => {\n                     resp.innerHTML = JSON.stringify(response.data); // response.data is a JSON object\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n            } else {\n               resp.innerHTML = \"Please choose some file(s)...\";\n               resp.style.color = \"red\";\n            }\n         }\n\n      </script>\n   </body>\n</html>",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "from fastapi import FastAPI, File, Body, UploadFile, Request\nfrom pydantic import BaseModel, model_validator\nfrom typing import Optional, List\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.responses import HTMLResponse\nimport json\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\nclass Base(BaseModel):\n    name: str\n    point: Optional[float] = None\n    is_accepted: Optional[bool] = False\n    @model_validator(mode='before')\n    @classmethod\n    def validate_to_json(cls, value):\n        if isinstance(value, str):\n            return cls(**json.loads(value))\n        return value\n@app.post(\"/submit\")\ndef submit(data: Base = Body(...), files: List[UploadFile] = File(...)):\n    return {\"JSON Payload\": data, \"Filenames\": [file.filename for file in files]}\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "from fastapi import FastAPI, Request, HTTPException\nfrom typing import List\nfrom fastapi.responses import HTMLResponse\nfrom pydantic import BaseModel\nfrom fastapi.templating import Jinja2Templates\nimport base64\nimport binascii\napp = FastAPI()\ntemplates = Jinja2Templates(directory='templates')\nclass Bas64File(BaseModel):\n    filename: str\n    owner: str\n    bas64_str: str\n@app.post('/submit')\ndef submit(files: List[Bas64File]):\n    for file in files:\n        try:\n            contents = base64.b64decode(file.bas64_str.encode('utf-8'))\n            with open(file.filename, 'wb') as f:\n                f.write(contents)\n        except base64.binascii.Error as e:\n            raise HTTPException(\n                400, detail='There was an error decoding the base64 string'\n            )\n        except Exception:\n            raise HTTPException(\n                500, detail='There was an error uploading the file(s)'\n            )\n    return {'Filenames': [file.filename for file in files]}\n@app.get('/', response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse('index.html', {'request': request})",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      },
      {
        "answer_id": 70640522,
        "body": "<input type=\"file\" id=\"fileInput\" onchange=\"base64Handler()\" multiple><br>\n<script>\n   async function base64Handler() {\n      var fileInput = document.getElementById('fileInput');\n      var payload = [];\n      for (const file of fileInput.files) {\n         var dict = {};\n         dict.filename = file.name;\n         dict.owner = 'me';\n         base64String = await this.toBase64(file);\n         dict.bas64_str = base64String.replace(\"data:\", \"\").replace(/^.+,/, \"\");\n         payload.push(dict);\n      }\n\n      uploadFiles(payload);\n   }\n   function toBase64(file) {\n      return new Promise((resolve, reject) => {\n         const reader = new FileReader();\n         reader.readAsDataURL(file);\n         reader.onload = () => resolve(reader.result);\n         reader.onerror = error => reject(error);\n      });\n   };\n   function uploadFiles(payload) {\n      fetch('/submit', {\n            method: 'POST',\n            headers: {\n               'Content-Type': 'application/json'\n            },\n            body: JSON.stringify(payload)\n         })\n         .then(response => {\n            console.log(response);\n         })\n         .catch(error => {\n            console.error(error);\n         });\n   }\n</script>",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-09T05:47:41",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com",
    "title": "How can we use Selenium Webdriver in colab.research.google.com?",
    "question_id": 51046454,
    "posted_date": "2018-06-26T11:23:51",
    "answers": [
      {
        "answer_id": 54077842,
        "body": "%%shell\n# Ubuntu no longer distributes chromium-browser outside of snap\n#\n# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n# Add debian buster\ncat > /etc/apt/sources.list.d/debian.list <<'EOF'\ndeb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\ndeb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\ndeb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\nEOF\n# Add keys\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\napt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\napt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\napt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n# Prefer debian repo for chromium* packages only\n# Note the double-blank lines between entries\ncat > /etc/apt/preferences.d/chromium.pref << 'EOF'\nPackage: *\nPin: release a=eoan\nPin-Priority: 500\nPackage: *\nPin: origin \"deb.debian.org\"\nPin-Priority: 300\nPackage: chromium*\nPin: origin \"deb.debian.org\"\nPin-Priority: 700\nEOF\n# Install chromium and chromium-driver\napt-get update\napt-get install chromium chromium-driver\n# Install selenium\npip install selenium",
        "score": 127,
        "is_accepted": true,
        "creation_date": "2019-01-07T11:07:08",
        "author": "Thomas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60469202/unable-to-install-tkinter-with-pyenv-pythons-on-macos",
    "title": "Unable to install tkinter with pyenv Pythons on MacOS",
    "question_id": 60469202,
    "posted_date": "2020-02-29T15:11:05",
    "answers": [
      {
        "answer_id": 60469203,
        "body": "\u203b brew install tcl-tk\n\u203b brew info tcl-tk\ntcl-tk: stable 8.6.10 (bottled) [keg-only]\n...\n==> Caveats\ntcl-tk is keg-only, which means it was not symlinked into /usr/local,\nbecause tk installs some X11 headers and macOS provides an (older) Tcl/Tk.\nIf you need to have tcl-tk first in your PATH run:\n  echo 'export PATH=\"/usr/local/opt/tcl-tk/bin:$PATH\"' >> ~/.zshrc\nFor compilers to find tcl-tk you may need to set:\n  export LDFLAGS=\"-L/usr/local/opt/tcl-tk/lib\"\n  export CPPFLAGS=\"-I/usr/local/opt/tcl-tk/include\"\nFor pkg-config to find tcl-tk you may need to set:\n  export PKG_CONFIG_PATH=\"/usr/local/opt/tcl-tk/lib/pkgconfig\"\n...",
        "score": 136,
        "is_accepted": false,
        "creation_date": "2020-02-29T15:11:05",
        "author": "Carl G"
      },
      {
        "answer_id": 60469203,
        "body": "DEPRECATION WARNING: The system version of Tk is deprecated and may be removed in a future release. Please don't rely on it. Set TK_SILENCE_DEPRECATION=1 to suppress this warning.\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/factor/.pyenv/versions/3.8.1/lib/python3.8/tkinter/__init__.py\", line 4552, in _test\n    root = Tk()\n  File \"/Users/factor/.pyenv/versions/3.8.1/lib/python3.8/tkinter/__init__.py\", line 2263, in __init__\n    self._loadtk()\n  File \"/Users/factor/.pyenv/versions/3.8.1/lib/python3.8/tkinter/__init__.py\", line 2279, in _loadtk\n    raise RuntimeError(\"tk.h version (%s) doesn't match libtk.a version (%s)\"\nRuntimeError: tk.h version (8.6) doesn't match libtk.a version (8.5)",
        "score": 136,
        "is_accepted": false,
        "creation_date": "2020-02-29T15:11:05",
        "author": "Carl G"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72449482/f-string-representation-different-than-str",
    "title": "f-string representation different than str()",
    "question_id": 72449482,
    "posted_date": "2022-05-31T10:17:57",
    "answers": [
      {
        "answer_id": 72449614,
        "body": "class Foo:\n    def __repr__(self):\n        return \"Foo()\"\n    def __str__(self):\n        return \"A wild Foo\"\n\n    def __format__(self, format_spec):\n        if not format_spec:\n            return \"A formatted Foo\"\n        return f\"A formatted Foo, but also {format_spec}!\"\n>>> foo = Foo()\n>>> repr(foo)\n'Foo()'\n>>> str(foo)\n'A wild Foo'\n>>> format(foo)\n'A formatted Foo'\n>>> f\"{foo}\"\n'A formatted Foo'\n>>> format(foo, \"Bar\")\n'A formatted Foo, but also Bar!'\n>>> f\"{foo:Bar}\"\n'A formatted Foo, but also Bar!'",
        "score": 106,
        "is_accepted": true,
        "creation_date": "2022-05-31T10:26:30",
        "author": "decorator-factory"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16856788/slice-2d-array-into-smaller-2d-arrays",
    "title": "Slice 2d array into smaller 2d arrays",
    "question_id": 16856788,
    "posted_date": "2013-05-31T08:00:20",
    "answers": [
      {
        "answer_id": 16858283,
        "body": "def blockshaped(arr, nrows, ncols):\n    \"\"\"\n    Return an array of shape (n, nrows, ncols) where\n    n * nrows * ncols = arr.size\n    If arr is a 2D array, the returned array should look like n subblocks with\n    each subblock preserving the \"physical\" layout of arr.\n    \"\"\"\n    h, w = arr.shape\n    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n    return (arr.reshape(h//nrows, nrows, -1, ncols)\n               .swapaxes(1,2)\n               .reshape(-1, nrows, ncols))",
        "score": 110,
        "is_accepted": true,
        "creation_date": "2013-05-31T09:19:32",
        "author": "unutbu"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49323099/webdriverexception-message-service-chromedriver-unexpectedly-exited-status-co",
    "title": "WebDriverException: Message: Service chromedriver unexpectedly exited. Status code was: 127",
    "question_id": 49323099,
    "posted_date": "2018-03-16T10:26:46",
    "answers": [
      {
        "answer_id": 49710327,
        "body": "$ /usr/local/bin/chromedriver --version\nChromeDriver 83.0.4103.14 (be04594a2b8411758b860104bc0a1033417178be-refs/branch-heads/4103@{#119})\n$ ldd /usr/local/bin/chromedriver\n        linux-vdso.so.1 (0x00007fffff7f0000)\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f414739d000)\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f414737a000)\n        librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f414736f000)\n        libglib-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0 (0x00007f4147246000)\n        libnss3.so => /usr/lib/x86_64-linux-gnu/libnss3.so (0x00007f41470f7000)\n        libnssutil3.so => /usr/lib/x86_64-linux-gnu/libnssutil3.so (0x00007f41470c4000)\n        libnspr4.so => /usr/lib/x86_64-linux-gnu/libnspr4.so (0x00007f4147082000)\n        libX11.so.6 => /usr/lib/x86_64-linux-gnu/libX11.so.6 (0x00007f4146f45000)\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f4146df6000)\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f4146ddb000)\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f4146be9000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f4147e56000)\n        libpcre.so.3 => /lib/x86_64-linux-gnu/libpcre.so.3 (0x00007f4146b76000)\n        libplc4.so => /usr/lib/x86_64-linux-gnu/libplc4.so (0x00007f4146b6d000)\n        libplds4.so => /usr/lib/x86_64-linux-gnu/libplds4.so (0x00007f4146b68000)\n        libxcb.so.1 => /usr/lib/x86_64-linux-gnu/libxcb.so.1 (0x00007f4146b3e000)\n        libXau.so.6 => /usr/lib/x86_64-linux-gnu/libXau.so.6 (0x00007f4146b38000)\n        libXdmcp.so.6 => /usr/lib/x86_64-linux-gnu/libXdmcp.so.6 (0x00007f4146b30000)\n        libbsd.so.0 => /usr/lib/x86_64-linux-gnu/libbsd.so.0 (0x00007f4146b14000)",
        "score": 66,
        "is_accepted": false,
        "creation_date": "2018-04-07T13:59:05",
        "author": "TPPZ"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37573483/progress-bar-while-download-file-over-http-with-requests",
    "title": "Progress Bar while download file over http with Requests",
    "question_id": 37573483,
    "posted_date": "2016-06-01T11:53:42",
    "answers": [
      {
        "answer_id": 37573701,
        "body": "from tqdm import tqdm\nimport requests\nurl = \"http://www.ovh.net/files/10Mb.dat\"\nfilepath = \"test.dat\"\n# Streaming, so we can iterate over the response.\nresponse = requests.get(url, stream=True)\n# Sizes in bytes.\ntotal_size = int(response.headers.get(\"content-length\", 0))\nblock_size = 1024\nwith tqdm(total=total_size, unit=\"B\", unit_scale=True) as progress_bar:\n    with open(filepath, \"wb\") as file:\n        for data in response.iter_content(block_size):\n            progress_bar.update(len(data))\n            file.write(data)\nif total_size != 0 and progress_bar.n != total_size:\n    raise RuntimeError(\"Could not download file\")",
        "score": 163,
        "is_accepted": true,
        "creation_date": "2016-06-01T12:04:43",
        "author": "leovp"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10365624/sys-getsizeofint-returns-an-unreasonably-large-value",
    "title": "&quot;sys.getsizeof(int)&quot; returns an unreasonably large value?",
    "question_id": 10365624,
    "posted_date": "2012-04-28T12:59:15",
    "answers": [
      {
        "answer_id": 10365639,
        "body": "typedef struct _longobject PyLongObject;\nstruct _longobject {\n    PyObject_VAR_HEAD\n    digit ob_digit[1];\n};\n#define PyObject_VAR_HEAD      PyVarObject ob_base;\ntypedef struct {\n    PyObject ob_base;\n    Py_ssize_t ob_size; /* Number of items in variable part */\n} PyVarObject;\ntypedef struct _object PyObject;\nstruct _object {\n    _PyObject_HEAD_EXTRA\n    union {\n       Py_ssize_t ob_refcnt;\n#if SIZEOF_VOID_P > 4\n       PY_UINT32_T ob_refcnt_split[2];\n#endif\n    };\n    PyTypeObject *ob_type;\n};\n/* _PyObject_HEAD_EXTRA is nothing on non-debug builds */\n#  define _PyObject_HEAD_EXTRA\ntypedef uint32_t digit;",
        "score": 161,
        "is_accepted": true,
        "creation_date": "2012-04-28T13:00:54",
        "author": "senderle"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/14380371/export-a-latex-table-from-pandas-dataframe",
    "title": "Export a LaTeX table from pandas DataFrame",
    "question_id": 14380371,
    "posted_date": "2013-01-17T08:40:24",
    "answers": [
      {
        "answer_id": 14383654,
        "body": ">>> df = pd.DataFrame(np.random.random((5, 5)))\n>>> df\n          0         1         2         3         4\n0  0.886864  0.518538  0.359964  0.167291  0.940414\n1  0.834130  0.022920  0.265131  0.059002  0.530584\n2  0.648019  0.953043  0.263551  0.595798  0.153969\n3  0.207003  0.015721  0.931170  0.045044  0.432870\n4  0.039886  0.898780  0.728195  0.112069  0.468485\n>>> print(df.to_latex())\n\\begin{tabular}{|l|c|c|c|c|c|c|}\n\\hline\n{} &         0 &         1 &         2 &         3 &         4 \\\\\n\\hline\n0 &  0.886864 &  0.518538 &  0.359964 &  0.167291 &  0.940414 \\\\\n1 &  0.834130 &  0.022920 &  0.265131 &  0.059002 &  0.530584 \\\\\n2 &  0.648019 &  0.953043 &  0.263551 &  0.595798 &  0.153969 \\\\\n3 &  0.207003 &  0.015721 &  0.931170 &  0.045044 &  0.432870 \\\\\n4 &  0.039886 &  0.898780 &  0.728195 &  0.112069 &  0.468485 \\\\\n\\hline\n\\end{tabular}",
        "score": 113,
        "is_accepted": true,
        "creation_date": "2013-01-17T11:30:24",
        "author": "bmu"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5337070/how-can-i-get-the-unix-permission-mask-from-a-file",
    "title": "How can I get the Unix permission mask from a file?",
    "question_id": 5337070,
    "posted_date": "2011-03-17T05:19:04",
    "answers": [
      {
        "answer_id": 5337329,
        "body": "S_IRWXU 00700   mask for file owner permissions\nS_IRUSR 00400   owner has read permission\nS_IWUSR 00200   owner has write permission\nS_IXUSR 00100   owner has execute permission\nS_IRWXG 00070   mask for group permissions\nS_IRGRP 00040   group has read permission\nS_IWGRP 00020   group has write permission\nS_IXGRP 00010   group has execute permission\nS_IRWXO 00007   mask for permissions for others (not in group)\nS_IROTH 00004   others have read permission\nS_IWOTH 00002   others have write permission\nS_IXOTH 00001   others have execute permission",
        "score": 125,
        "is_accepted": false,
        "creation_date": "2011-03-17T05:44:00",
        "author": "miku"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/30949202/spark-dataframe-timestamptype-how-to-get-year-month-day-values-from-field",
    "title": "Spark DataFrame TimestampType - how to get Year, Month, Day values from field?",
    "question_id": 30949202,
    "posted_date": "2015-06-19T20:51:50",
    "answers": [
      {
        "answer_id": 30956282,
        "body": "import datetime\nfrom pyspark.sql.functions import year, month, dayofmonth\nelevDF = sc.parallelize([\n    (datetime.datetime(1984, 1, 1, 0, 0), 1, 638.55),\n    (datetime.datetime(1984, 1, 1, 0, 0), 2, 638.55),\n    (datetime.datetime(1984, 1, 1, 0, 0), 3, 638.55),\n    (datetime.datetime(1984, 1, 1, 0, 0), 4, 638.55),\n    (datetime.datetime(1984, 1, 1, 0, 0), 5, 638.55)\n]).toDF([\"date\", \"hour\", \"value\"])\nelevDF.select(\n    year(\"date\").alias('year'),\n    month(\"date\").alias('month'),\n    dayofmonth(\"date\").alias('day')\n).show()\n# +----+-----+---+\n# |year|month|day|\n# +----+-----+---+\n# |1984|    1|  1|\n# |1984|    1|  1|\n# |1984|    1|  1|\n# |1984|    1|  1|\n# |1984|    1|  1|\n# +----+-----+---+",
        "score": 107,
        "is_accepted": true,
        "creation_date": "2015-06-20T12:23:05",
        "author": "zero323"
      },
      {
        "answer_id": 30956282,
        "body": "elevDF = sqlContext.createDataFrame(sc.parallelize([\n    Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=1, value=638.55),\n    Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=2, value=638.55),\n    Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=3, value=638.55),\n    Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=4, value=638.55),\n    Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=5, value=638.55)]))\n(elevDF\n    .map(lambda (date, hour, value): (date.year, date.month, date.day))\n    .collect())",
        "score": 107,
        "is_accepted": true,
        "creation_date": "2015-06-20T12:23:05",
        "author": "zero323"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/34472872/purpose-of-python-antigravity-module",
    "title": "Purpose of python antigravity module",
    "question_id": 34472872,
    "posted_date": "2015-12-26T10:53:38",
    "answers": [
      {
        "answer_id": 62071049,
        "body": ">>> import this\nThe Zen of Python, by Tim Peters\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!",
        "score": 66,
        "is_accepted": false,
        "creation_date": "2020-05-28T13:39:02",
        "author": "cobrexus"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10361206/how-to-run-ipython-magic-from-a-script",
    "title": "How to run IPython magic from a script",
    "question_id": 10361206,
    "posted_date": "2012-04-28T02:29:04",
    "answers": [
      {
        "answer_id": 15898875,
        "body": "run_line_magic(magic_name: str, line, _stack_depth=1) method of ipykernel.zmqshell.ZMQInteractiveShell instance\n    Execute the given line magic.\n\n    Parameters\n    ----------\n    magic_name : str\n        Name of the desired magic function, without '%' prefix.\n    line : str\n        The rest of the input line as a single string.\n    _stack_depth : int\n        If run_line_magic() is called from magic() then _stack_depth=2.\n        This is added to ensure backward compatibility for use of 'get_ipython().magic()'",
        "score": 95,
        "is_accepted": true,
        "creation_date": "2013-04-09T05:56:59",
        "author": "user2261139"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59953431/how-to-change-plotly-figure-size",
    "title": "How to change plotly figure size",
    "question_id": 59953431,
    "posted_date": "2020-01-28T11:49:01",
    "answers": [
      {
        "answer_id": 59954928,
        "body": "import plotly.graph_objs as go\ntrace1 = go.Scatter(\n    x=x1_tsne,  # x-coordinates of trace\n    y=y1_tsne,  # y-coordinates of trace\n    mode=\"markers +text \",  # scatter mode (more in UG section 1)\n    text=label3,\n    opacity=1,\n    textposition=\"top center\",\n    marker=dict(size=12, color=color_4, symbol=marker_list_2, line=dict(width=0.5)),\n    textfont=dict(\n        color=\"black\",\n        size=18,  # can change the size of font here\n        family=\"Times New Roman\",\n    ),\n)\ndata = [trace1]\nlayout = go.Layout(\n    autosize=False,\n    width=1000,\n    height=1000,\n    xaxis=go.layout.XAxis(linecolor=\"black\", linewidth=1, mirror=True),\n    yaxis=go.layout.YAxis(linecolor=\"black\", linewidth=1, mirror=True),\n    margin=go.layout.Margin(l=50, r=50, b=100, t=100, pad=4),\n)\nfig = go.Figure(data=data, layout=layout)",
        "score": 108,
        "is_accepted": true,
        "creation_date": "2020-01-28T13:27:43",
        "author": "rpanai"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63048825/how-to-upload-file-using-fastapi",
    "title": "How to Upload File using FastAPI?",
    "question_id": 63048825,
    "posted_date": "2020-07-23T03:14:59",
    "answers": [
      {
        "answer_id": 70657621,
        "body": "from fastapi import File, UploadFile, HTTPException\nfrom typing import List\n@app.post(\"/upload\")\ndef upload(files: List[UploadFile] = File(...)):\n    for file in files:\n        try:\n            contents = file.file.read()\n            with open(file.filename, 'wb') as f:\n                f.write(contents)\n        except Exception:\n            raise HTTPException(status_code=500, detail='Something went wrong')\n        finally:\n            file.file.close()\n    return {\"message\": f\"Successfuly uploaded {[file.filename for file in files]}\"}",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-10T14:00:48",
        "author": "Chris"
      },
      {
        "answer_id": 70657621,
        "body": "from fastapi import File, UploadFile, HTTPException\nfrom typing import List\n@app.post(\"/upload\")\ndef upload(files: List[UploadFile] = File(...)):\n    for file in files:\n        try:\n            with open(file.filename, 'wb') as f:\n                while contents := file.file.read(1024 * 1024):\n                    f.write(contents)\n        except Exception:\n            raise HTTPException(status_code=500, detail='Something went wrong')\n        finally:\n            file.file.close()\n\n    return {\"message\": f\"Successfuly uploaded {[file.filename for file in files]}\"}",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-10T14:00:48",
        "author": "Chris"
      },
      {
        "answer_id": 70657621,
        "body": "from fastapi import File, UploadFile, HTTPException\nfrom typing import List\nimport shutil\n@app.post(\"/upload\")\ndef upload(files: List[UploadFile] = File(...)):\n    for file in files:\n        try:\n            with open(file.filename, 'wb') as f:\n                shutil.copyfileobj(file.file, f)\n        except Exception:\n            raise HTTPException(status_code=500, detail='Something went wrong')\n        finally:\n            file.file.close()\n    return {\"message\": f\"Successfuly uploaded {[file.filename for file in files]}\"}",
        "score": 129,
        "is_accepted": false,
        "creation_date": "2022-01-10T14:00:48",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54668000/type-hint-for-an-instance-of-a-non-specific-dataclass",
    "title": "type hint for an instance of a non specific dataclass",
    "question_id": 54668000,
    "posted_date": "2019-02-13T05:32:01",
    "answers": [
      {
        "answer_id": 55240861,
        "body": "from dataclasses import dataclass\nfrom typing import ClassVar, Dict, Protocol, Any\nclass IsDataclass(Protocol):\n    # as already noted in comments, checking for this attribute is currently\n    # the most reliable way to ascertain that something is a dataclass\n    __dataclass_fields__: ClassVar[Dict[str, Any]]\ndef dataclass_only(x: IsDataclass):\n    ...  # do something that only makes sense with a dataclass\n@dataclass\nclass Foo:\n    pass\nclass Bar:\n    pass\ndataclass_only(Foo())  # a static type check should show that this line is fine ..\ndataclass_only(Bar())  # .. and this one is not",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2019-03-19T08:14:53",
        "author": "Arne"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/17681670/extract-email-sub-strings-from-large-document",
    "title": "Extract email sub-strings from large document",
    "question_id": 17681670,
    "posted_date": "2013-07-16T12:10:01",
    "answers": [
      {
        "answer_id": 17681902,
        "body": "import re\n# Compiling the regex pattern for email validation\nregex = re.compile(\n    r\"(?i)\"  # Case-insensitive matching\n    r\"(?:[A-Z0-9!#$%&'*+/=?^_`{|}~-]+\"  # Unquoted local part\n    r\"(?:\\.[A-Z0-9!#$%&'*+/=?^_`{|}~-]+)*\"  # Dot-separated atoms in local part\n    r\"|\\\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]\"  # Quoted strings\n    r\"|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\\\")\"  # Escaped characters in local part\n    r\"@\"  # Separator\n    r\"[A-Z0-9](?:[A-Z0-9-]*[A-Z0-9])?\"  # Domain name\n    r\"\\.(?:[A-Z0-9](?:[A-Z0-9-]*[A-Z0-9])?)+\"  # Top-level domain and subdomains\n)\ndef isValid(email):\n    \"\"\"Check if the given email address is valid.\"\"\"\n    return \"Valid email\" if re.fullmatch(regex, email) else \"Invalid email\"\n# Example Usage\nprint(isValid(\"name.surname@gmail.com\"))\nprint(isValid(\"anonymous123@yahoo.co.uk\"))\nprint(isValid(\"anonymous123@...uk\"))\nprint(isValid(\"...@domain.us\"))",
        "score": 162,
        "is_accepted": true,
        "creation_date": "2013-07-16T12:20:33",
        "author": "0x90"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/46027653/adding-labels-in-x-y-scatter-plot-with-seaborn",
    "title": "Adding labels in x y scatter plot with seaborn",
    "question_id": 46027653,
    "posted_date": "2017-09-03T16:40:45",
    "answers": [
      {
        "answer_id": 46028674,
        "body": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = sns.load_dataset(\"iris\")\nax = sns.lmplot(x='sepal_length', # Horizontal axis\n                y='sepal_width', # Vertical axis\n                data=df, # Data source\n                fit_reg=False, # Don't fix a regression line\n                aspect=2) # size and dimension\nplt.title('Example Plot')\n# Set x-axis label\nplt.xlabel('Sepal Length')\n# Set y-axis label\nplt.ylabel('Sepal Width')\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x']+.02, point['y'], str(point['val']))\nlabel_point(df.sepal_length, df.sepal_width, df.species, plt.gca())",
        "score": 65,
        "is_accepted": true,
        "creation_date": "2017-09-03T19:30:31",
        "author": "Scott Boston"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4095940/running-unique-tasks-with-celery",
    "title": "Running &quot;unique&quot; tasks with celery",
    "question_id": 4095940,
    "posted_date": "2010-11-04T06:57:57",
    "answers": [
      {
        "answer_id": 7668350,
        "body": "from django.core.cache import cache\nimport functools\ndef single_instance_task(timeout):\n    def task_exc(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            lock_id = \"celery-single-instance-\" + func.__name__\n            acquire_lock = lambda: cache.add(lock_id, \"true\", timeout)\n            release_lock = lambda: cache.delete(lock_id)\n            if acquire_lock():\n                try:\n                    func(*args, **kwargs)\n                finally:\n                    release_lock()\n        return wrapper\n    return task_exc",
        "score": 47,
        "is_accepted": false,
        "creation_date": "2011-10-05T18:09:22",
        "author": "SteveJ"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58740043/how-do-i-catch-a-psycopg2-errors-uniqueviolation-error-in-a-python-flask-app",
    "title": "How do I catch a psycopg2.errors.UniqueViolation error in a Python (Flask) app?",
    "question_id": 58740043,
    "posted_date": "2019-11-06T18:49:54",
    "answers": [
      {
        "answer_id": 58743364,
        "body": "from sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom psycopg2.errors import UniqueViolation\nengine = create_engine(\"postgresql+psycopg2://some-user:mysecretpassword@localhost:5432/some-user\")\nBase = declarative_base()\nSession = sessionmaker(bind=engine)\nclass BadRequest(Exception):\n    pass\nclass Model(Base):\n    __tablename__ = \"model\"\n    id = Column(Integer, primary_key=True)\n    name = Column(String, unique=True)\nif __name__ == \"__main__\":\n    Base.metadata.drop_all(engine)\n    Base.metadata.create_all(engine)\n    s = Session()\n    s.add(Model(name=\"a\"))\n    s.commit()\n    s.add(Model(name=\"a\"))\n    try:\n        s.commit()\n    except IntegrityError as e:\n        assert isinstance(e.orig, UniqueViolation)  # proves the original exception\n        raise BadRequest from e",
        "score": 60,
        "is_accepted": false,
        "creation_date": "2019-11-07T01:51:41",
        "author": "SuperShoot"
      },
      {
        "answer_id": 58743364,
        "body": "sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"model_name_key\"\nDETAIL:  Key (name)=(a) already exists.\n[SQL: INSERT INTO model (name) VALUES (%(name)s) RETURNING model.id]\n[parameters: {'name': 'a'}]\n(Background on this error at: http://sqlalche.me/e/gkpj)\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \".\\main.py\", line 36, in <module>\n    raise BadRequest from e\n__main__.BadRequest",
        "score": 60,
        "is_accepted": false,
        "creation_date": "2019-11-07T01:51:41",
        "author": "SuperShoot"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9233095/memory-dump-formatted-like-xxd-from-gdb",
    "title": "Memory dump formatted like xxd from gdb",
    "question_id": 9233095,
    "posted_date": "2012-02-10T13:47:58",
    "answers": [
      {
        "answer_id": 9234007,
        "body": "class XXD(gdb.Command):\n  def __init__(self):\n    super(XXD, self).__init__(\"xxd\", gdb.COMMAND_USER)\n  def _PrintLine(self, offset, bytes, size):\n      print('{:08x}: '.format(offset), end='')\n      todo = size\n      while todo >= 4:\n        print(''.join('{:02x}'.format(b) for b in bytes[0:4]), end='')\n        todo -= 4\n        bytes = bytes[3:]\n        if todo:\n          print(' ', end='')\n      # Print any remaining bytes\n      print(''.join('{:02x}'.format(b) for b in bytes[0:todo]), end='')\n      print()\n      return size\n  def invoke(self, arg, from_tty):\n    args = arg.split()\n    if len(args) != 2:\n      print(\"xxd: <addr> <count>\")\n      return\n    size = int(args[1])\n    addr = gdb.parse_and_eval(args[0])\n    inferior = gdb.inferiors()[0]\n    bytes = inferior.read_memory(addr, size).tobytes()\n    offset = int(addr)\n    while size > 0:\n      n = self._PrintLine(offset, bytes, min(len(bytes), 16))\n      size -= n\n      offset += n\n      bytes = bytes[n:]\nXXD()",
        "score": 105,
        "is_accepted": true,
        "creation_date": "2012-02-10T14:56:22",
        "author": "Employed Russian"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57025836/how-to-check-if-a-given-number-is-a-power-of-two",
    "title": "How to check if a given number is a power of two?",
    "question_id": 57025836,
    "posted_date": "2019-07-14T04:44:11",
    "answers": [
      {
        "answer_id": 57025941,
        "body": "n = 8\ndecimal |   8 = 2**3   |  8 - 1 = 7   |   8 & 7 = 0\n        |          ^   |              |\nbinary  |   1 0 0 0    |   0 1 1 1    |    1 0 0 0\n        |   ^          |              |  & 0 1 1 1\nindex   |   3 2 1 0    |              |    -------\n                                           0 0 0 0\n-----------------------------------------------------\n                    n = 5\ndecimal | 5 = 2**2 + 1 |  5 - 1 = 4   |   5 & 4 = 4\n        |              |              |\nbinary  |    1 0 1     |    1 0 0     |    1 0 1\n        |              |              |  & 1 0 0\nindex   |    2 1 0     |              |    ------\n                                           1 0 0",
        "score": 185,
        "is_accepted": true,
        "creation_date": "2019-07-14T05:02:32",
        "author": "Tomerikoo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation",
    "title": "Calculating percentage of Bounding box overlap, for image detector evaluation",
    "question_id": 25349178,
    "posted_date": "2014-08-17T08:28:04",
    "answers": [
      {
        "answer_id": 58108241,
        "body": "    assert bb1['x1'] <= bb1['x2']\n    assert bb1['y1'] <= bb1['y2']\n    assert bb2['x1'] <= bb2['x2']\n    assert bb2['y1'] <= bb2['y2']\n................................................\n    # The intersection of two axis-aligned bounding boxes is always an\n    # axis-aligned bounding box.\n    # NOTE: We MUST ALWAYS add +1 to calculate area when working in\n    # screen coordinates, since 0,0 is the top left pixel, and w-1,h-1\n    # is the bottom right pixel. If we DON'T add +1, the result is wrong.\n    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)\n    # compute the area of both AABBs\n    bb1_area = (bb1['x2'] - bb1['x1'] + 1) * (bb1['y2'] - bb1['y1'] + 1)\n    bb2_area = (bb2['x2'] - bb2['x1'] + 1) * (bb2['y2'] - bb2['y1'] + 1)",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2019-09-25T21:00:25",
        "author": "Mitch McMabers"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3154460/python-human-readable-large-numbers",
    "title": "Python human-readable large numbers",
    "question_id": 3154460,
    "posted_date": "2010-06-30T20:54:50",
    "answers": [
      {
        "answer_id": 3155023,
        "body": "                 0.0:                    0\n                 0.1:                    0\n                 1.2:                    1\n                12.3:                   12\n               123.5:                  123\n              1234.6:           1 Thousand\n             12345.7:          12 Thousand\n            123456.8:         123 Thousand\n           1234567.9:            1 Million\n          12345678.9:           12 Million\n         123456789.0:          123 Million\n        1234567890.0:            1 Billion\n       12345678900.0:           12 Billion\n      123456789000.0:          123 Billion\n     1234567890000.0:           1 Trillion\n    12345678900000.0:          12 Trillion\n   123456789000000.0:         123 Trillion\n  1234567890000000.0:        1235 Trillion\n 12345678899999998.0:       12346 Trillion\n123456788999999984.0:      123457 Trillion\n1234567890000000000.0:     1234568 Trillion",
        "score": 112,
        "is_accepted": true,
        "creation_date": "2010-07-01T00:05:18",
        "author": "Janus"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66977227/could-not-load-dynamic-library-libcudnn-so-8-when-running-tensorflow-on-ubun",
    "title": "&quot;Could not load dynamic library &#39;libcudnn.so.8&#39;&quot; when running tensorflow on ubuntu 20.04",
    "question_id": 66977227,
    "posted_date": "2021-04-06T18:23:10",
    "answers": [
      {
        "answer_id": 69302029,
        "body": "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\nsudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\nexport last_public_key=3bf863cc # SEE NOTE BELOW\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/${last_public_key}.pub\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\nsudo apt-get update\nsudo apt-get install libcudnn8\nsudo apt-get install libcudnn8-dev",
        "score": 71,
        "is_accepted": true,
        "creation_date": "2021-09-23T10:32:52",
        "author": "J Agustin Barrachina"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/27426668/row-titles-for-matplotlib-subplot",
    "title": "Row titles for matplotlib subplot",
    "question_id": 27426668,
    "posted_date": "2014-12-11T10:39:30",
    "answers": [
      {
        "answer_id": 68209152,
        "body": "    # create 3x1 subplots\n    fig, axs = plt.subplots(nrows=3, ncols=1, constrained_layout=True)\n    fig.suptitle('Figure title')\n    # clear subplots\n    for ax in axs:\n        ax.remove()\n    # add subfigure per subplot\n    gridspec = axs[0].get_subplotspec().get_gridspec()\n    subfigs = [fig.add_subfigure(gs) for gs in gridspec]\n    for row, subfig in enumerate(subfigs):\n        subfig.suptitle(f'Subfigure title {row}')\n\n        # create 1x3 subplots per subfig\n        axs = subfig.subplots(nrows=1, ncols=3)\n        for col, ax in enumerate(axs):\n            ax.plot()\n            ax.set_title(f'Plot title {col}')",
        "score": 66,
        "is_accepted": true,
        "creation_date": "2021-07-01T07:15:18",
        "author": "tdy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69583134/why-is-there-a-difference-between-0-3-2-and-3-2",
    "title": "Why is there a difference between `0--3//2` and `--3//2`?",
    "question_id": 69583134,
    "posted_date": "2021-10-15T06:10:02",
    "answers": [
      {
        "answer_id": 69583208,
        "body": "---------------- ----------------\n|     --3//2     |    0--3//2     |\n|================|================|\n|                |    -------     |\n|                |   | 0 - z |    |\n|                |    -----+-     |\n|                |         |      |\n|     --------   |     ----+---   |\n|    | x // y |  |    | x // y |  |\n|     -+----+-   |     -+----+-   |\n|      |    |    |      |    |    |\n|  ----+    +--  |   ---+    +--  |\n| | --3 |  | 2 | |  | -3 |  | 2 | |\n|  -----    ---  |   ----    ---  |\n ---------------- ----------------",
        "score": 85,
        "is_accepted": true,
        "creation_date": "2021-10-15T06:15:56",
        "author": "MisterMiyagi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api",
    "title": "How can I send an HTTP request from my FastAPI app to another site (API)?",
    "question_id": 63872924,
    "posted_date": "2020-09-13T12:18:36",
    "answers": [
      {
        "answer_id": 63881674,
        "body": "from fastapi import FastAPI\nfrom time import time\nimport httpx\nimport asyncio\napp = FastAPI()\nURL = \"http://httpbin.org/uuid\"\nasync def request(client):\n    response = await client.get(URL)\n    return response.text\nasync def task():\n    async with httpx.AsyncClient() as client:\n        tasks = [request(client) for i in range(100)]\n        result = await asyncio.gather(*tasks)\n        print(result)\n@app.get('/')\nasync def f():\n    start = time()\n    await task()\n    print(\"time: \", time() - start)",
        "score": 97,
        "is_accepted": true,
        "creation_date": "2020-09-14T05:31:19",
        "author": "alex_noname"
      },
      {
        "answer_id": 63881674,
        "body": "`\nfrom fastapi import FastAPI\nfrom time import time\nimport aiohttp\nimport asyncio\napp = FastAPI()\nURL = \"http://httpbin.org/uuid\"\nasync def request(session):\n    async with session.get(URL) as response:\n        return await response.text()\nasync def task():\n    async with aiohttp.ClientSession() as session:\n        tasks = [request(session) for i in range(100)]\n        result = await asyncio.gather(*tasks)\n        print(result)\n@app.get('/')\nasync def f():\n    start = time()\n    await task()\n    print(\"time: \", time() - start)",
        "score": 97,
        "is_accepted": true,
        "creation_date": "2020-09-14T05:31:19",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63326840/specifying-command-line-scripts-in-pyproject-toml",
    "title": "Specifying command line scripts in pyproject.toml",
    "question_id": 63326840,
    "posted_date": "2020-08-09T09:19:49",
    "answers": [
      {
        "answer_id": 73066937,
        "body": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n[project]\nname = \"my_client\"\nversion = \"1.2.3\"\nauthors = [{name=\"Ubr Programmer\", email=\"ubr@gmailington.com\" }]\ndescription = \"Client for my awesome system\"\nreadme = \"README.md\"\ndependencies = [\"cachetools\",\"requests\"]\nrequires-python = \">=3.9\"\n[project.scripts]\nmy-client = \"my_package.my_module:main_cli\"\n[project.urls]\n\"Homepage\" = \"https://github.com/your_name_here/something\"\n\"Bug Tracker\" = \"https://github.com/your_name_here/something/issues\"",
        "score": 83,
        "is_accepted": false,
        "creation_date": "2022-07-21T09:15:09",
        "author": "chrisinmtown"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/77634955/why-is-the-simpler-loop-slower",
    "title": "Why is the simpler loop slower?",
    "question_id": 77634955,
    "posted_date": "2023-12-10T08:17:37",
    "answers": [
      {
        "answer_id": 77635068,
        "body": "In [_]: %timeit -n 1 -r 1 complex(10 ** 8)\n2.7 s \u00b1 0 ns per loop (mean \u00b1 std. dev. of 1 run, 1 loop each)\nIn [_]: dis(complex, adaptive=True)\n  5           0 RESUME_QUICK             0\n  6           2 NOP\n  7           4 LOAD_FAST                0 (n)\n              6 POP_JUMP_FORWARD_IF_TRUE     2 (to 12)\n  8           8 LOAD_CONST               0 (None)\n             10 RETURN_VALUE\n  9     >>   12 LOAD_FAST__LOAD_CONST     0 (n)\n             14 LOAD_CONST               2 (1)\n             16 BINARY_OP_SUBTRACT_INT    23 (-=)\n             20 STORE_FAST               0 (n)\n  6          22 JUMP_BACKWARD_QUICK     10 (to 4)",
        "score": 66,
        "is_accepted": true,
        "creation_date": "2023-12-10T08:57:18",
        "author": "Mechanic Pig"
      },
      {
        "answer_id": 77635068,
        "body": "In [_]: %timeit -n 1 -r 1 simple(10 ** 8)\n4.78 s \u00b1 0 ns per loop (mean \u00b1 std. dev. of 1 run, 1 loop each)\nIn [_]: dis(simple, adaptive=True)\n  1           0 RESUME                   0\n  2           2 LOAD_FAST                0 (n)\n              4 POP_JUMP_FORWARD_IF_FALSE     9 (to 24)\n  3     >>    6 LOAD_FAST                0 (n)\n              8 LOAD_CONST               1 (1)\n             10 BINARY_OP               23 (-=)\n             14 STORE_FAST               0 (n)\n  2          16 LOAD_FAST                0 (n)\n             18 POP_JUMP_BACKWARD_IF_TRUE     7 (to 6)\n             20 LOAD_CONST               0 (None)\n             22 RETURN_VALUE\n        >>   24 LOAD_CONST               0 (None)\n             26 RETURN_VALUE",
        "score": 66,
        "is_accepted": true,
        "creation_date": "2023-12-10T08:57:18",
        "author": "Mechanic Pig"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58422690/filtering-reducing-a-numpy-array",
    "title": "Filtering (reducing) a NumPy Array",
    "question_id": 58422690,
    "posted_date": "2019-10-16T18:56:29",
    "answers": [
      {
        "answer_id": 58422691,
        "body": "%%cython -c-O3 -c-march=native -a\n#cython: language_level=3, boundscheck=False, wraparound=False, initializedcheck=False, cdivision=True, infer_types=True\nimport numpy as np\ncdef long NUM = 1048576\ncdef long MAX_VAL = 1048576\ncdef long K = 1048576 // 2\ncdef int cond_cy(long x, long k=K):\n    return x < k\ncdef size_t _filter_cy(long[:] arr, long[:] result, size_t size):\n    cdef size_t j = 0\n    for i in range(size):\n        if cond_cy(arr[i]):\n            result[j] = arr[i]\n            j += 1\n    return j\ndef filter_cy(arr):\n    result = np.empty_like(arr)\n    new_size = _filter_cy(arr, result, arr.size)\n    return result[:new_size].copy()",
        "score": 116,
        "is_accepted": true,
        "creation_date": "2019-10-16T18:56:29",
        "author": "norok2"
      },
      {
        "answer_id": 58422691,
        "body": "%%cython -c-O3 -c-march=native -a\n#cython: language_level=3, boundscheck=False, wraparound=False, initializedcheck=False, cdivision=True, infer_types=True\ncdef size_t _filtered_size_cy(long[:] arr, size_t size):\n    cdef size_t j = 0\n    for i in range(size):\n        if cond_cy(arr[i]):\n            j += 1\n    return j\ndef filter2_cy(arr):\n    cdef size_t new_size = _filtered_size_cy(arr, arr.size)\n    result = np.empty(new_size, dtype=arr.dtype)\n    new_size = _filter_cy(arr, result, arr.size)\n    return result",
        "score": 116,
        "is_accepted": true,
        "creation_date": "2019-10-16T18:56:29",
        "author": "norok2"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48506460/python-simple-socket-client-server-using-asyncio",
    "title": "Python simple socket client/server using asyncio",
    "question_id": 48506460,
    "posted_date": "2018-01-29T12:06:41",
    "answers": [
      {
        "answer_id": 48507121,
        "body": "import asyncio, socket\nasync def handle_client(client):\n    loop = asyncio.get_event_loop()\n    request = None\n    while request != 'quit':\n        request = (await loop.sock_recv(client, 255)).decode('utf8')\n        response = str(eval(request)) + '\\n'\n        await loop.sock_sendall(client, response.encode('utf8'))\n    client.close()\nasync def run_server():\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.bind(('localhost', 15555))\n    server.listen(8)\n    server.setblocking(False)\n    loop = asyncio.get_event_loop()\n    while True:\n        client, _ = await loop.sock_accept(server)\n        loop.create_task(handle_client(client))\nasyncio.run(run_server())",
        "score": 89,
        "is_accepted": true,
        "creation_date": "2018-01-29T12:47:44",
        "author": "user4815162342"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43111029/how-to-find-the-average-colour-of-an-image-in-python-with-opencv",
    "title": "How to find the average colour of an image in Python with OpenCV?",
    "question_id": 43111029,
    "posted_date": "2017-03-30T03:17:41",
    "answers": [
      {
        "answer_id": 58177484,
        "body": "import cv2, numpy as np\nfrom sklearn.cluster import KMeans\ndef visualize_colors(cluster, centroids):\n    # Get the number of different clusters, create histogram, and normalize\n    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n    (hist, _) = np.histogram(cluster.labels_, bins = labels)\n    hist = hist.astype(\"float\")\n    hist /= hist.sum()\n    # Create frequency rect and iterate through each cluster's color and percentage\n    rect = np.zeros((50, 300, 3), dtype=np.uint8)\n    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n    start = 0\n    for (percent, color) in colors:\n        print(color, \"{:0.2f}%\".format(percent * 100))\n        end = start + (percent * 300)\n        cv2.rectangle(rect, (int(start), 0), (int(end), 50), \\\n                      color.astype(\"uint8\").tolist(), -1)\n        start = end\n    return rect\n# Load image and convert to a list of pixels\nimage = cv2.imread('1.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nreshape = image.reshape((image.shape[0] * image.shape[1], 3))\n# Find and display most dominant colors\ncluster = KMeans(n_clusters=5).fit(reshape)\nvisualize = visualize_colors(cluster, cluster.cluster_centers_)\nvisualize = cv2.cvtColor(visualize, cv2.COLOR_RGB2BGR)\ncv2.imshow('visualize', visualize)\ncv2.waitKey()",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2019-09-30T22:47:07",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/30631841/how-do-i-assign-values-based-on-multiple-conditions-for-existing-columns",
    "title": "How do I assign values based on multiple conditions for existing columns?",
    "question_id": 30631841,
    "posted_date": "2015-06-03T18:23:39",
    "answers": [
      {
        "answer_id": 60244752,
        "body": "conditions = [\n    df['gender'].eq('male') & df['pet1'].eq(df['pet2']),\n    df['gender'].eq('female') & df['pet1'].isin(['cat', 'dog'])\n]\nchoices = [5,5]\ndf['points'] = np.select(conditions, choices, default=0)\nprint(df)\n     gender      pet1      pet2  points\n0      male       dog       dog       5\n1      male       cat       cat       5\n2      male       dog       cat       0\n3    female       cat  squirrel       5\n4    female       dog       dog       5\n5    female  squirrel       cat       0\n6  squirrel       dog       cat       0",
        "score": 76,
        "is_accepted": false,
        "creation_date": "2020-02-15T20:52:44",
        "author": "Erfan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47432168/taking-subsets-of-a-pytorch-dataset",
    "title": "Taking subsets of a pytorch dataset",
    "question_id": 47432168,
    "posted_date": "2017-11-22T05:22:36",
    "answers": [
      {
        "answer_id": 58703467,
        "body": "import torchvision\nimport torch\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=None)\nevens = list(range(0, len(trainset), 2))\nodds = list(range(1, len(trainset), 2))\ntrainset_1 = torch.utils.data.Subset(trainset, evens)\ntrainset_2 = torch.utils.data.Subset(trainset, odds)\ntrainloader_1 = torch.utils.data.DataLoader(trainset_1, batch_size=4,\n                                            shuffle=True, num_workers=2)\ntrainloader_2 = torch.utils.data.DataLoader(trainset_2, batch_size=4,\n                                            shuffle=True, num_workers=2)",
        "score": 126,
        "is_accepted": false,
        "creation_date": "2019-11-04T21:03:34",
        "author": "jayelm"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/34647966/how-to-express-multiple-types-for-a-single-parameter-or-a-return-value-in-docstr",
    "title": "How to express multiple types for a single parameter or a return value in docstrings that are processed by Sphinx?",
    "question_id": 34647966,
    "posted_date": "2016-01-07T00:31:05",
    "answers": [
      {
        "answer_id": 40801906,
        "body": "from typing import Optional, Union\nclass C:\n    '''\n    My doc for C!\n    '''\n    pass\nclass D:\n    '''\n    My doc for D!\n    '''\n    pass\ndef main(i: Union[C, D]) -> Union[C, D]:\n    '''\n    My doc for main!\n    :param i: My doc for i!\n    '''\n    return C()\ndef main_docstring(i):\n    '''\n    My doc for main_docstring!\n    :param i: My doc for i!\n    :type i: Union[C, D]\n    :rtype: Union[C, D]\n    '''\n    return C()\ndef main_optional(i: Optional[C]) -> Optional[C]:\n    '''\n    My doc for main_optional!\n    '''\n    return None\ndef main_optional_docstring(i):\n    '''\n    My doc for main_optional_docstring!\n    :param i: My doc for i!\n    :type i: Optional[C]\n    :rtype: Optional[C]\n    '''\n    return None",
        "score": 86,
        "is_accepted": false,
        "creation_date": "2016-11-25T04:45:30",
        "author": "Ciro Santilli OurBigBook.com"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44309507/stacked-bar-plot-using-matplotlib",
    "title": "stacked bar plot using matplotlib",
    "question_id": 44309507,
    "posted_date": "2017-06-01T09:55:13",
    "answers": [
      {
        "answer_id": 50205834,
        "body": "def plot_stacked_bar(data, series_labels, category_labels=None,\n                     show_values=False, value_format=\"{}\", y_label=None,\n                     colors=None, grid=True, reverse=False):\n    \"\"\"Plots a stacked bar chart with the data and labels provided.\n    Keyword arguments:\n    data            -- 2-dimensional numpy array or nested list\n                       containing data for each series in rows\n    series_labels   -- list of series labels (these appear in\n                       the legend)\n    category_labels -- list of category labels (these appear\n                       on the x-axis)\n    show_values     -- If True then numeric value labels will\n                       be shown on each bar\n    value_format    -- Format string for numeric value labels\n                       (default is \"{}\")\n    y_label         -- Label for y-axis (str)\n    colors          -- List of color labels\n    grid            -- If True display grid\n    reverse         -- If True reverse the order that the\n                       series are displayed (left-to-right\n                       or right-to-left)\n    \"\"\"\n    ny = len(data[0])\n    ind = list(range(ny))\n    axes = []\n    cum_size = np.zeros(ny)\n    data = np.array(data)\n    if reverse:\n        data = np.flip(data, axis=1)\n        category_labels = reversed(category_labels)\n    for i, row_data in enumerate(data):\n        color = colors[i] if colors is not None else None\n        p = plt.bar(ind, row_data, bottom=cum_size,\n                    label=series_labels[i], color=color)\n        cum_size += row_data\n        if show_values:\n            plt.bar_label(p, label_type='center', fmt=value_format)\n    if category_labels:\n        plt.xticks(ind, category_labels)\n    if y_label:\n        plt.ylabel(y_label)\n    plt.legend()\n    if grid:\n        plt.grid()",
        "score": 57,
        "is_accepted": false,
        "creation_date": "2018-05-06T20:49:00",
        "author": "Bill"
      },
      {
        "answer_id": 50206097,
        "body": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nX_AXIS = ('60.0', '65.0', '70.0', '75.0', '80.0', '85.0', '90.0', '95.0', '100.0', '105.0', '110.0', '115.0', '120.0', '125.0', '130.0', '135.0', '140.0', '145.0', '150.0', '155.0', '160.0', '165.0', '170.0', '175.0', '180.0', '185.0', '190.0', '195.0', '200.0')\nindex = pd.Index(X_AXIS, name='test')\ndata = {'a': (0.0, 25.0, 48.94, 83.02, 66.67, 66.67, 70.97, 84.62, 93.33, 85.0, 92.86, 93.75, 95.0, 100.0, 100.0, 100.0, 100.0, 80.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0),\n        'b': (0.0, 50.0, 36.17, 11.32, 26.67, 33.33, 29.03, 15.38, 6.67, 15.0, 7.14, 6.25, 5.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0),\n        'c': (0.0, 12.5, 10.64, 3.77, 4.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0),\n        'd': (100.0, 12.5, 4.26, 1.89, 2.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)}\ndf = pd.DataFrame(data, index=index)\nax = df.plot(kind='bar', stacked=True, figsize=(10, 6))\nax.set_ylabel('foo')\nax.legend(title='labels', bbox_to_anchor=(1.0, 1), loc='upper left')\n# plt.savefig('stacked.png')  # if needed\nplt.show()",
        "score": 45,
        "is_accepted": false,
        "creation_date": "2018-05-06T21:44:21",
        "author": "Bill"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4072150/how-to-change-a-widgets-font-style-without-knowing-the-widgets-font-family-siz",
    "title": "How to change a widget&#39;s font style without knowing the widget&#39;s font family/size?",
    "question_id": 4072150,
    "posted_date": "2010-11-01T14:58:39",
    "answers": [
      {
        "answer_id": 4073037,
        "body": "import tkinter as tk\nimport tkinter.font\nclass App:\n    def __init__(self):\n        root=tk.Tk()\n        # create a custom font\n        self.customFont = tkinter.font.Font(family=\"Helvetica\", size=12)\n        # create a couple widgets that use that font\n        buttonframe = tk.Frame()\n        label = tk.Label(root, text=\"Hello, world\", font=self.customFont)\n        text = tk.Text(root, width=20, height=2, font=self.customFont)\n        buttonframe.pack(side=\"top\", fill=\"x\")\n        label.pack(side=\"top\", fill=\"x\")\n        text.pack(side=\"top\", fill=\"both\", expand=True)\n        text.insert(\"end\",\"press +/- buttons to change\\nfont size\")\n        # create buttons to adjust the font\n        increase_font = tk.Button(root, text=\"+\", command=self.increase_font)\n        decrease_font = tk.Button(root, text=\"-\", command=self.decrease_font)\n        increase_font.pack(in_=buttonframe, side=\"left\")\n        decrease_font.pack(in_=buttonframe, side=\"left\")\n        root.mainloop()\n    def increase_font(self):\n        '''Make the font 2 points bigger'''\n        size = self.customFont['size']\n        self.customFont.configure(size=size+2)\n    def decrease_font(self):\n        '''Make the font 2 points smaller'''\n        size = self.customFont['size']\n        self.customFont.configure(size=size-2)\napp=App()",
        "score": 69,
        "is_accepted": true,
        "creation_date": "2010-11-01T17:06:16",
        "author": "Bryan Oakley"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58648739/how-to-check-if-python-package-is-latest-version-programmatically",
    "title": "How to check if python package is latest version programmatically?",
    "question_id": 58648739,
    "posted_date": "2019-10-31T13:43:54",
    "answers": [
      {
        "answer_id": 58649262,
        "body": "import subprocess\nimport sys\ndef check(name):\n    latest_version = str(subprocess.run([sys.executable, '-m', 'pip', 'install', '{}==random'.format(name)], capture_output=True, text=True))\n    latest_version = latest_version[latest_version.find('(from versions:')+15:]\n    latest_version = latest_version[:latest_version.find(')')]\n    latest_version = latest_version.replace(' ','').split(',')[-1]\n    current_version = str(subprocess.run([sys.executable, '-m', 'pip', 'show', '{}'.format(name)], capture_output=True, text=True))\n    current_version = current_version[current_version.find('Version:')+8:]\n    current_version = current_version[:current_version.find('\\\\n')].replace(' ','')\n    if latest_version == current_version:\n        return True\n    else:\n        return False",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2019-10-31T14:21:34",
        "author": "1__"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/17377426/shared-variable-in-pythons-multiprocessing",
    "title": "Shared variable in python&#39;s multiprocessing",
    "question_id": 17377426,
    "posted_date": "2013-06-29T02:30:38",
    "answers": [
      {
        "answer_id": 17393879,
        "body": "import time\nfrom multiprocessing import Process, Manager, Value\ndef foo(data, name=''):\n    print(type(data), data.value, name)\n    data.value += 1\nif __name__ == \"__main__\":\n    manager = Manager()\n    x = manager.Value('i', 0)\n    y = Value('i', 0)\n    for i in range(5):\n        Process(target=foo, args=(x, 'x')).start()\n        Process(target=foo, args=(y, 'y')).start()\n    print('Before waiting: ')\n    print('x = {0}'.format(x.value))\n    print('y = {0}'.format(y.value))\n    time.sleep(5.0)\n    print('After waiting: ')\n    print('x = {0}'.format(x.value))\n    print('y = {0}'.format(y.value))",
        "score": 75,
        "is_accepted": true,
        "creation_date": "2013-06-30T15:07:01",
        "author": "ChrisP"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57663308/how-to-mock-requests-using-pytest",
    "title": "How to mock requests using pytest?",
    "question_id": 57663308,
    "posted_date": "2019-08-26T14:46:39",
    "answers": [
      {
        "answer_id": 57663322,
        "body": "from correct.package import __BASE_URL\nfrom requests import HTTPError\ndef test_get_employee(requests_mock):\n    test_id = 'random-id'\n    requests_mock.get(f'{__BASE_URL}/employee/{test_id}', json= {'name': 'awesome-mock'})\n    resp = get_employee('random-id')\n    assert resp == {'name': 'awesome-mock'}\ndef test_absent_employee(requests_mock):\n    test_id = 'does_not_exist'\n    requests_mock.get(f'{__BASE_URL}/employee/{test_id}', status_code=404)\n    with pytest.raises(HTTPError):\n        resp = get_employee(test_id)",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2019-08-26T14:47:52",
        "author": "ndclt"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/13872331/rotating-an-image-with-orientation-specified-in-exif-using-python-without-pil-in",
    "title": "Rotating an image with orientation specified in EXIF using Python without PIL including the thumbnail",
    "question_id": 13872331,
    "posted_date": "2012-12-13T22:43:12",
    "answers": [
      {
        "answer_id": 26928142,
        "body": "from PIL import Image, ExifTags\ntry:\n    image=Image.open(filepath)\n    for orientation in ExifTags.TAGS.keys():\n        if ExifTags.TAGS[orientation]=='Orientation':\n            break\n\n    exif = image._getexif()\n    if exif[orientation] == 3:\n        image=image.rotate(180, expand=True)\n    elif exif[orientation] == 6:\n        image=image.rotate(270, expand=True)\n    elif exif[orientation] == 8:\n        image=image.rotate(90, expand=True)\n    image.save(filepath)\n    image.close()\nexcept (AttributeError, KeyError, IndexError):\n    # cases: image don't have getexif\n    pass",
        "score": 127,
        "is_accepted": false,
        "creation_date": "2014-11-14T05:42:17",
        "author": "scabbiaza"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37288421/how-to-plot-a-chart-in-the-terminal",
    "title": "How to plot a chart in the terminal",
    "question_id": 37288421,
    "posted_date": "2016-05-17T20:46:48",
    "answers": [
      {
        "answer_id": 55098423,
        "body": "7 +---------------------------------------------------+\n    |                                                   |\n  6 |                                             **    |\n    |                                           **      |\n    |                                         **        |\n  5 |                                       **          |\n    |                                     ***           |\n  4 |                                  ****             |\n    |                              *****                |\n  3 |             *****************                     |\n    |          ****                                     |\n  2 |       ***                                         |\n    |     ***                                           |\n    |   ***                                             |\n  1 |  **                                               |\n    |**                                                 |\n  0 +---------------------------------------------------+\n    0      1       2      3       4      5       6      7",
        "score": 73,
        "is_accepted": false,
        "creation_date": "2019-03-11T05:09:58",
        "author": "Nico Schl&#246;mer"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63169865/how-to-do-multiprocessing-in-fastapi",
    "title": "How to do multiprocessing in FastAPI",
    "question_id": 63169865,
    "posted_date": "2020-07-30T05:09:06",
    "answers": [
      {
        "answer_id": 63171013,
        "body": "`\nimport asyncio\nfrom concurrent.futures.process import ProcessPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom calc import cpu_bound_func\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    app.state.executor = ProcessPoolExecutor()\n    yield\n    app.state.executor.shutdown()\napp = FastAPI(lifespan=lifespan)\nasync def run_in_process(fn, *args):\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(app.state.executor, fn, *args)  # wait and return result\n@app.get(\"/{param}\")\nasync def handler(param: int):\n    res = await run_in_process(cpu_bound_func, param)\n    return {\"result\": res}",
        "score": 124,
        "is_accepted": true,
        "creation_date": "2020-07-30T06:14:59",
        "author": "alex_noname"
      },
      {
        "answer_id": 63171013,
        "body": "`\nimport asyncio\nfrom concurrent.futures.process import ProcessPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom http import HTTPStatus\nfrom fastapi import BackgroundTasks\nfrom typing import Dict\nfrom uuid import UUID, uuid4\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nfrom calc import cpu_bound_func\nclass Job(BaseModel):\n    uid: UUID = Field(default_factory=uuid4)\n    status: str = \"in_progress\"\n    result: int = None\napp = FastAPI()\njobs: Dict[UUID, Job] = {}\nasync def run_in_process(fn, *args):\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(app.state.executor, fn, *args)  # wait and return result\nasync def start_cpu_bound_task(uid: UUID, param: int) -> None:\n    jobs[uid].result = await run_in_process(cpu_bound_func, param)\n    jobs[uid].status = \"complete\"\n@app.post(\"/new_cpu_bound_task/{param}\", status_code=HTTPStatus.ACCEPTED)\nasync def task_handler(param: int, background_tasks: BackgroundTasks):\n    new_task = Job()\n    jobs[new_task.uid] = new_task\n    background_tasks.add_task(start_cpu_bound_task, new_task.uid, param)\n    return new_task\n@app.get(\"/status/{uid}\")\nasync def status_handler(uid: UUID):\n    return jobs[uid]\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    app.state.executor = ProcessPoolExecutor()\n    yield\n    app.state.executor.shutdown()",
        "score": 124,
        "is_accepted": true,
        "creation_date": "2020-07-30T06:14:59",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53847404/how-to-check-uuid-validity-in-python",
    "title": "How to check UUID validity in Python?",
    "question_id": 53847404,
    "posted_date": "2018-12-19T03:39:33",
    "answers": [
      {
        "answer_id": 33245493,
        "body": "#!/usr/bin/env python\nfrom uuid import UUID\ndef is_valid_uuid(uuid_to_test, version=4):\n    \"\"\"\n    Check if uuid_to_test is a valid UUID.\n\n     Parameters\n    ----------\n    uuid_to_test : str\n    version : {1, 2, 3, 4}\n\n     Returns\n    -------\n    `True` if uuid_to_test is a valid UUID, otherwise `False`.\n\n     Examples\n    --------\n    >>> is_valid_uuid('c9bf9e57-1685-4c89-bafb-ff5af830be8a')\n    True\n    >>> is_valid_uuid('c9bf9e58')\n    False\n    \"\"\"\n\n    try:\n        uuid_obj = UUID(uuid_to_test, version=version)\n    except ValueError:\n        return False\n    return str(uuid_obj) == uuid_to_test\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod()",
        "score": 215,
        "is_accepted": true,
        "creation_date": "2015-10-20T15:43:04",
        "author": "Martin Thoma"
      },
      {
        "answer_id": 54254115,
        "body": ">>> is_valid_uuid(1)\nFalse\n>>> is_valid_uuid(\"123-UUID-wannabe\")\nFalse\n>>> is_valid_uuid({\"A\":\"b\"})\nFalse\n>>> is_valid_uuid([1, 2, 3])\nFalse\n>>> is_valid_uuid(uuid.uuid4())\nTrue\n>>> is_valid_uuid(str(uuid.uuid4()))\nTrue\n>>> is_valid_uuid(uuid.uuid4().hex)\nTrue\n>>> is_valid_uuid(uuid.uuid3(uuid.NAMESPACE_DNS, 'example.net'))\nTrue\n>>> is_valid_uuid(uuid.uuid5(uuid.NAMESPACE_DNS, 'example.net'))\nTrue\n>>> is_valid_uuid(\"{20f5484b-88ae-49b0-8af0-3a389b4917dd}\")\nTrue\n>>> is_valid_uuid(\"20f5484b88ae49b08af03a389b4917dd\")\nTrue",
        "score": 57,
        "is_accepted": false,
        "creation_date": "2019-01-18T07:32:31",
        "author": "slajma"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59737875/keras-change-learning-rate",
    "title": "Keras: change learning rate",
    "question_id": 59737875,
    "posted_date": "2020-01-14T11:22:25",
    "answers": [
      {
        "answer_id": 62113860,
        "body": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import backend as K\nimport keras\nimport numpy as np\nmodel = Sequential()\nmodel.add(Dense(1, input_shape=(10,)))\noptimizer = keras.optimizers.Adam(lr=0.01)\nmodel.compile(loss='mse', optimizer=optimizer)\nprint(\"Learning rate before first fit:\", model.optimizer.learning_rate.numpy())\nmodel.fit(np.random.randn(50,10), np.random.randn(50), epochs=50, verbose=0)\n# Change learning rate to 0.001 and train for 50 more epochs\nK.set_value(model.optimizer.learning_rate, 0.001)\nprint(\"Learning rate before second fit:\", model.optimizer.learning_rate.numpy())\nmodel.fit(np.random.randn(50,10),\n          np.random.randn(50),\n          initial_epoch=50,\n          epochs=50,\n          verbose=0)",
        "score": 66,
        "is_accepted": true,
        "creation_date": "2020-05-31T05:02:22",
        "author": "Timo.S"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44941082/plot-multiple-columns-of-pandas-dataframe-using-seaborn",
    "title": "Plot multiple columns of pandas DataFrame using Seaborn",
    "question_id": 44941082,
    "posted_date": "2017-07-06T02:14:27",
    "answers": [
      {
        "answer_id": 44941463,
        "body": "import pandas as pd\nimport seaborn as sns\ndf = pd.DataFrame({'X_Axis':[1,3,5,7,10,20],\n                   'col_2':[.4,.5,.4,.5,.5,.4],\n                   'col_3':[.7,.8,.9,.4,.2,.3],\n                   'col_4':[.1,.3,.5,.7,.1,.0],\n                   'col_5':[.5,.3,.6,.9,.2,.4]})\n# display(df)\n   X_Axis  col_2  col_3  col_4  col_5\n0       1    0.4    0.7    0.1    0.5\n1       3    0.5    0.8    0.3    0.3\n2       5    0.4    0.9    0.5    0.6\n3       7    0.5    0.4    0.7    0.9\n4      10    0.5    0.2    0.1    0.2\n5      20    0.4    0.3    0.0    0.4\n# convert to long (tidy) form\ndfm = df.melt('X_Axis', var_name='cols', value_name='vals')\n# display(dfm.head())\n   X_Axis   cols  vals\n0       1  col_2   0.4\n1       3  col_2   0.5\n2       5  col_2   0.4\n3       7  col_2   0.5\n4      10  col_2   0.5",
        "score": 123,
        "is_accepted": true,
        "creation_date": "2017-07-06T02:38:21",
        "author": "jezrael"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/927552/parsing-http-user-agent-string",
    "title": "Parsing HTTP User-Agent string",
    "question_id": 927552,
    "posted_date": "2009-05-29T14:53:46",
    "answers": [
      {
        "answer_id": 1151956,
        "body": ">>> import httpagentparser\n>>> s = \"Mozilla/5.0 (X11; U; Linux i686; en-US) AppleWebKit/532.9 (KHTML, like Gecko) \\\n        Chrome/5.0.307.11 Safari/532.9\"\n>>> print(httpagentparser.simple_detect(s))\n('Linux', 'Chrome 5.0.307.11')\n>>> print(httpagentparser.detect(s))\n{'os': {'name': 'Linux'},\n 'browser': {'version': '5.0.307.11', 'name': 'Chrome'}}\n>>> s = \"Mozilla/5.0 (Linux; U; Android 2.3.5; en-in; HTC_DesireS_S510e Build/GRJ90) \\\n        AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\"\n>>> print(httpagentparser.simple_detect(s))\n('Android Linux 2.3.5', 'Safari 4.0')\n>>> print(httpagentparser.detect(s))\n{'dist': {'version': '2.3.5', 'name': 'Android'},\n'os': {'name': 'Linux'},\n'browser': {'version': '4.0', 'name': 'Safari'}}",
        "score": 82,
        "is_accepted": true,
        "creation_date": "2009-07-20T02:24:40",
        "author": "Shekhar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/75354384/why-is-b-pop0-over-200-times-slower-than-del-b0-for-bytearray",
    "title": "Why is b.pop(0) over 200 times slower than del b[0] for bytearray?",
    "question_id": 75354384,
    "posted_date": "2023-02-05T13:04:17",
    "answers": [
      {
        "answer_id": 75354915,
        "body": "if (lo == 0) {\n    /* Shrink the buffer by advancing its logical start */\n    self->ob_start -= growth;\n    /*\n      0   lo               hi             old_size\n      |   |<----avail----->|<-----tail------>|\n      |      |<-bytes_len->|<-----tail------>|\n      0    new_lo         new_hi          new_size\n    */\n}\nelse {\n    /*\n      0   lo               hi               old_size\n      |   |<----avail----->|<-----tomove------>|\n      |   |<-bytes_len->|<-----tomove------>|\n      0   lo         new_hi              new_size\n    */\n    memmove(buf + lo + bytes_len, buf + hi,\n            Py_SIZE(self) - hi);\n}",
        "score": 82,
        "is_accepted": true,
        "creation_date": "2023-02-05T14:24:11",
        "author": "interjay"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5838605/python-dictwriter-writing-utf-8-encoded-csv-files",
    "title": "Python DictWriter writing UTF-8 encoded CSV files",
    "question_id": 5838605,
    "posted_date": "2011-04-29T20:22:25",
    "answers": [
      {
        "answer_id": 5838817,
        "body": "# coding: utf-8\nimport csv\nimport cStringIO\nimport codecs\nclass DictUnicodeWriter(object):\n    def __init__(self, f, fieldnames, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n        # Redirect output to a queue\n        self.queue = cStringIO.StringIO()\n        self.writer = csv.DictWriter(self.queue, fieldnames, dialect=dialect, **kwds)\n        self.stream = f\n        self.encoder = codecs.getincrementalencoder(encoding)()\n    def writerow(self, D):\n        self.writer.writerow({k:v.encode(\"utf-8\") for k, v in D.items()})\n        # Fetch UTF-8 output from the queue ...\n        data = self.queue.getvalue()\n        data = data.decode(\"utf-8\")\n        # ... and reencode it into the target encoding\n        data = self.encoder.encode(data)\n        # write to the target stream\n        self.stream.write(data)\n        # empty queue\n        self.queue.truncate(0)\n    def writerows(self, rows):\n        for D in rows:\n            self.writerow(D)\n    def writeheader(self):\n        self.writer.writeheader()\nD1 = {'name': u'\u9a6c\u514b', 'pinyin': u'M\u01cek\u00e8'}\nD2 = {'name': u'\u7f8e\u56fd', 'pinyin': u'M\u011bigu\u00f3'}\nf = open('out.csv', 'wb')\nf.write(u'\\ufeff'.encode('utf8'))  # BOM (optional...Excel needs it to open UTF-8 file properly)\nw = DictUnicodeWriter(f, sorted(D.keys()))\nw.writeheader()\nw.writerows([D1, D2])\nf.close()",
        "score": 104,
        "is_accepted": true,
        "creation_date": "2011-04-29T21:19:59",
        "author": "Mark Tolonen"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy",
    "title": "Weighted percentile using numpy",
    "question_id": 21844024,
    "posted_date": "2014-02-17T22:55:32",
    "answers": [
      {
        "answer_id": 29677616,
        "body": "def weighted_quantile(values, quantiles, sample_weight=None,\n                      values_sorted=False, old_style=False):\n    \"\"\" Very close to numpy.percentile, but supports weights.\n    NOTE: quantiles should be in [0, 1]!\n    :param values: numpy.array with data\n    :param quantiles: array-like with many quantiles needed\n    :param sample_weight: array-like of the same length as `array`\n    :param values_sorted: bool, if True, then will avoid sorting of\n        initial array\n    :param old_style: if True, will correct output to be consistent\n        with numpy.percentile.\n    :return: numpy.array with computed quantiles.\n    \"\"\"\n    values = np.array(values)\n    quantiles = np.array(quantiles)\n    if sample_weight is None:\n        sample_weight = np.ones(len(values))\n    sample_weight = np.array(sample_weight)\n    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n        'quantiles should be in [0, 1]'\n    if not values_sorted:\n        sorter = np.argsort(values)\n        values = values[sorter]\n        sample_weight = sample_weight[sorter]\n    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n    if old_style:\n        # To be convenient with numpy.percentile\n        weighted_quantiles -= weighted_quantiles[0]\n        weighted_quantiles /= weighted_quantiles[-1]\n    else:\n        weighted_quantiles /= np.sum(sample_weight)\n    return np.interp(quantiles, weighted_quantiles, values)",
        "score": 81,
        "is_accepted": false,
        "creation_date": "2015-04-16T10:22:35",
        "author": "Alleo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37745519/use-pytesseract-ocr-to-recognize-text-from-an-image",
    "title": "Use pytesseract OCR to recognize text from an image",
    "question_id": 37745519,
    "posted_date": "2016-06-10T06:08:02",
    "answers": [
      {
        "answer_id": 60161328,
        "body": "import cv2\nimport pytesseract\npytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n# Grayscale, Gaussian blur, Otsu's threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n# Morph open to remove noise and invert image\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\nopening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\ninvert = 255 - opening\n# Perform text extraction\ndata = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\nprint(data)\ncv2.imshow('thresh', thresh)\ncv2.imshow('opening', opening)\ncv2.imshow('invert', invert)\ncv2.waitKey()",
        "score": 63,
        "is_accepted": false,
        "creation_date": "2020-02-10T21:54:21",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58476654/how-to-remove-or-hide-x-axis-labels-from-a-plot",
    "title": "How to remove or hide x-axis labels from a plot",
    "question_id": 58476654,
    "posted_date": "2019-10-20T15:43:10",
    "answers": [
      {
        "answer_id": 58476779,
        "body": "fig, ax = plt.subplots(2, 1, figsize=(8, 8))\ng1 = sns.boxplot(x='time', y='pulse', hue='kind', data=exercise, ax=ax[0])\ng1.set(xticklabels=[])  # remove the tick labels\ng1.set(title='Exercise: Pulse by Time for Exercise Type')  # add a title\ng1.set(xlabel=None)  # remove the axis label\ng2 = sns.boxplot(x='species', y='body_mass_g', hue='sex', data=pen, ax=ax[1])\ng2.set(xticklabels=[])\ng2.set(title='Penguins: Body Mass by Species for Gender')\ng2.set(xlabel=None)\ng2.tick_params(bottom=False)  # remove the ticks\nplt.show()",
        "score": 109,
        "is_accepted": true,
        "creation_date": "2019-10-20T15:58:06",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 58476779,
        "body": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# sinusoidal sample data\nsample_length = range(1, 1+1) # number of columns of frequencies\nrads = np.arange(0, 2*np.pi, 0.01)\ndata = np.array([(np.cos(t*rads)*10**67) + 3*10**67 for t in sample_length])\ndf = pd.DataFrame(data.T, index=pd.Series(rads.tolist(), name='radians'), columns=[f'freq: {i}x' for i in sample_length])\ndf.reset_index(inplace=True)\n# plot\nfig, ax = plt.subplots(figsize=(8, 8))\nax.plot('radians', 'freq: 1x', data=df)\n# or skip the previous two lines and plot df directly\n# ax = df.plot(x='radians', y='freq: 1x', figsize=(8, 8), legend=False)",
        "score": 109,
        "is_accepted": true,
        "creation_date": "2019-10-20T15:58:06",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60440292/runtimeerror-expected-scalar-type-long-but-found-float",
    "title": "RuntimeError: expected scalar type Long but found Float",
    "question_id": 60440292,
    "posted_date": "2020-02-27T14:17:18",
    "answers": [
      {
        "answer_id": 60440460,
        "body": "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2566\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2566\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2566\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551        Data type         \u2551             dtype             \u2551     CPU tensor     \u2551       GPU tensor        \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256c\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256c\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256c\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551 32-bit floating point    \u2551 torch.float32 or torch.float  \u2551 torch.FloatTensor  \u2551 torch.cuda.FloatTensor  \u2551\n\u2551 64-bit floating point    \u2551 torch.float64 or torch.double \u2551 torch.DoubleTensor \u2551 torch.cuda.DoubleTensor \u2551\n\u2551 16-bit floating point    \u2551 torch.float16 or torch.half   \u2551 torch.HalfTensor   \u2551 torch.cuda.HalfTensor   \u2551\n\u2551 8-bit integer (unsigned) \u2551 torch.uint8                   \u2551 torch.ByteTensor   \u2551 torch.cuda.ByteTensor   \u2551\n\u2551 8-bit integer (signed)   \u2551 torch.int8                    \u2551 torch.CharTensor   \u2551 torch.cuda.CharTensor   \u2551\n\u2551 16-bit integer (signed)  \u2551 torch.int16 or torch.short    \u2551 torch.ShortTensor  \u2551 torch.cuda.ShortTensor  \u2551\n\u2551 32-bit integer (signed)  \u2551 torch.int32 or torch.int      \u2551 torch.IntTensor    \u2551 torch.cuda.IntTensor    \u2551\n\u2551 64-bit integer (signed)  \u2551 torch.int64 or torch.long     \u2551 torch.LongTensor   \u2551 torch.cuda.LongTensor   \u2551\n\u2551 Boolean                  \u2551 torch.bool                    \u2551 torch.BoolTensor   \u2551 torch.cuda.BoolTensor   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2569\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2569\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2569\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d",
        "score": 103,
        "is_accepted": true,
        "creation_date": "2020-02-27T14:29:04",
        "author": "Nicolas Gervais"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54307614/how-can-i-see-the-current-version-of-packages-installed-by-pipenv",
    "title": "How can I see the current version of packages installed by pipenv?",
    "question_id": 54307614,
    "posted_date": "2019-01-22T06:46:10",
    "answers": [
      {
        "answer_id": 54307615,
        "body": "appdirs==1.4.3\ndecorator==4.0.11\nflake8==3.3.0\n  - configparser [required: Any, installed: 3.5.0]\n  - enum34 [required: Any, installed: 1.1.6]\n  - mccabe [required: >=0.6.0,<0.7.0, installed: 0.6.1]\n  - pycodestyle [required: >=2.0.0,<2.4.0, installed: 2.3.1]\n  - pyflakes [required: >=1.5.0,<1.6.0, installed: 1.5.0]\nFlask-Admin==1.5.3\n  - Flask [required: >=0.7, installed: 0.12.4]\n    - click [required: >=2.0, installed: 6.7]\n    - itsdangerous [required: >=0.21, installed: 0.24]\n    - Jinja2 [required: >=2.4, installed: 2.10]\n      - MarkupSafe [required: >=0.23, installed: 1.0]\n    - Werkzeug [required: >=0.7, installed: 0.14.1]\n  - wtforms [required: Any, installed: 2.1]",
        "score": 55,
        "is_accepted": false,
        "creation_date": "2019-01-22T06:46:10",
        "author": "Sam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2982929/plotting-results-of-hierarchical-clustering-on-top-of-a-matrix-of-data",
    "title": "plotting results of hierarchical clustering on top of a matrix of data",
    "question_id": 2982929,
    "posted_date": "2010-06-05T22:50:24",
    "answers": [
      {
        "answer_id": 3011894,
        "body": "import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.cluster.hierarchy as sch\nfrom scipy.spatial.distance import squareform\n# Generate random features and distance matrix.\nnp.random.seed(200)  # for reproducible data\nx = np.random.rand(40)\nD = np.zeros([40, 40])\nfor i in range(40):\n    for j in range(40):\n        D[i,j] = abs(x[i] - x[j])\ncondensedD = squareform(D)\n# Compute and plot first dendrogram.\nfig = plt.figure(figsize=(8, 8))\nax1 = fig.add_axes([0.09, 0.1, 0.2, 0.6])\nY = sch.linkage(condensedD, method='centroid')\nZ1 = sch.dendrogram(Y, orientation='left')\nax1.set_xticks([])\nax1.set_yticks([])\n# Compute and plot second dendrogram.\nax2 = fig.add_axes([0.3, 0.71, 0.6, 0.2])\nY = sch.linkage(condensedD, method='single')\nZ2 = sch.dendrogram(Y)\nax2.set_xticks([])\nax2.set_yticks([])\n# Plot distance matrix.\naxmatrix = fig.add_axes([0.3, 0.1, 0.6, 0.6])\nidx1 = Z1['leaves']\nidx2 = Z2['leaves']\nD = D[idx1,:]\nD = D[:,idx2]\nim = axmatrix.matshow(D, aspect='auto', origin='lower', cmap=plt.cm.YlGnBu)\naxmatrix.set_xticks([])  # remove axis labels\naxmatrix.set_yticks([])  # remove axis labels\n# Plot colorbar.\naxcolor = fig.add_axes([0.91, 0.1, 0.02, 0.6])\nplt.colorbar(im, cax=axcolor)\nplt.show()\nfig.savefig('dendrogram.png')",
        "score": 108,
        "is_accepted": true,
        "creation_date": "2010-06-10T01:40:19",
        "author": "Steve Tjoa"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47242845/pandas-json-normalize-with-very-nested-json",
    "title": "pandas json_normalize with very nested json",
    "question_id": 47242845,
    "posted_date": "2017-11-11T16:14:10",
    "answers": [
      {
        "answer_id": 47242896,
        "body": ">>> data = [{'state': 'Florida',\n...          'shortname': 'FL',\n...         'info': {'governor': 'Rick Scott'},\n...         'counties': [{'name': 'Dade', 'population': 12345},\n...                      {'name': 'Broward', 'population': 40000},\n...                      {'name': 'Palm Beach', 'population': 60000}]},\n...         {'state': 'Ohio',\n...          'shortname': 'OH',\n...          'info': {'governor': 'John Kasich'},\n...          'counties': [{'name': 'Summit', 'population': 1234},\n...                       {'name': 'Cuyahoga', 'population': 1337}]}]\n>>> pprint(data[0]['counties'])\n[{'name': 'Dade', 'population': 12345},\n {'name': 'Broward', 'population': 40000},\n {'name': 'Palm Beach', 'population': 60000}]\n>>> pprint(data[1]['counties'])\n[{'name': 'Summit', 'population': 1234},\n {'name': 'Cuyahoga', 'population': 1337}]",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2017-11-11T16:20:31",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 47242896,
        "body": ">>> data[0]['state'], data[0]['shortname'], data[0]['info']['governor']\n('Florida', 'FL', 'Rick Scott')\n>>> data[1]['state'], data[1]['shortname'], data[1]['info']['governor']\n('Ohio', 'OH', 'John Kasich')\n>>> json_normalize(data, 'counties', ['state', 'shortname', ['info', 'governor']])\n         name  population    state shortname info.governor\n0        Dade       12345  Florida        FL    Rick Scott\n1     Broward       40000  Florida        FL    Rick Scott\n2  Palm Beach       60000  Florida        FL    Rick Scott\n3      Summit        1234     Ohio        OH   John Kasich\n4    Cuyahoga        1337     Ohio        OH   John Kasich",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2017-11-11T16:20:31",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 47242896,
        "body": ">>> d['hits']['hits'][0]['_source']['authors']   # this value is None, and is skipped\n>>> d['hits']['hits'][1]['_source']['authors']\n[{'affiliations': ['Punjabi University'],\n  'author_id': '780E3459',\n  'author_name': 'munish puri'},\n {'affiliations': ['Punjabi University'],\n  'author_id': '48D92C79',\n  'author_name': 'rajesh dhaliwal'},\n {'affiliations': ['Punjabi University'],\n  'author_id': '7D9BD37C',\n  'author_name': 'r s singh'}]\n>>> d['hits']['hits'][2]['_source']['authors']\n[{'author_id': '7FF872BC',\n  'author_name': 'barbara eileen ryan'}]\n>>> # etc.",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2017-11-11T16:20:31",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 47242896,
        "body": ">>> json_normalize(\n...     data['hits']['hits'],\n...     ['_source', 'authors'],\n...     ['_id', ['_source', 'journal'], ['_source', 'title']]\n... )\n           affiliations author_id          author_name       _id   \\\n0  [Punjabi University]  780E3459          munish puri  7AF8EBC3\n1  [Punjabi University]  48D92C79      rajesh dhaliwal  7AF8EBC3\n2  [Punjabi University]  7D9BD37C            r s singh  7AF8EBC3\n3                   NaN  7FF872BC  barbara eileen ryan  7521A721\n4                   NaN  0299B8E9     fraser j harbutt  7DAEB9A4\n5                   NaN  7DAB7B72   richard m freeland  7B3236C5\n                                     _source.journal\n0  Journal of Industrial Microbiology & Biotechno...\n1  Journal of Industrial Microbiology & Biotechno...\n2  Journal of Industrial Microbiology & Biotechno...\n3                     The American Historical Review\n4                     The American Historical Review\n5                     The American Historical Review\n                                       _source.title  \\\n0  Development of a stable continuous flow immobi...\n1  Development of a stable continuous flow immobi...\n2  Development of a stable continuous flow immobi...\n3  Feminism and the women's movement : dynamics o...\n4  The iron curtain : Churchill, America, and the...\n5  The Truman Doctrine and the origins of McCarth...",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2017-11-11T16:20:31",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50144628/python-logging-into-file-as-a-dictionary-or-json",
    "title": "Python logging into file as a dictionary or JSON",
    "question_id": 50144628,
    "posted_date": "2018-05-02T18:49:02",
    "answers": [
      {
        "answer_id": 70223539,
        "body": "import logging\nimport json\nclass JsonFormatter(logging.Formatter):\n    \"\"\"\n    Formatter that outputs JSON strings after parsing the LogRecord.\n    @param dict fmt_dict: Key: logging format attribute pairs. Defaults to {\"message\": \"message\"}.\n    @param str time_format: time.strftime() format string. Default: \"%Y-%m-%dT%H:%M:%S\"\n    @param str msec_format: Microsecond formatting. Appended at the end. Default: \"%s.%03dZ\"\n    \"\"\"\n    def __init__(self, fmt_dict: dict = None, time_format: str = \"%Y-%m-%dT%H:%M:%S\", msec_format: str = \"%s.%03dZ\"):\n        self.fmt_dict = fmt_dict if fmt_dict is not None else {\"message\": \"message\"}\n        self.default_time_format = time_format\n        self.default_msec_format = msec_format\n        self.datefmt = None\n    def usesTime(self) -> bool:\n        \"\"\"\n        Overwritten to look for the attribute in the format dict values instead of the fmt string.\n        \"\"\"\n        return \"asctime\" in self.fmt_dict.values()\n    def formatMessage(self, record) -> dict:\n        \"\"\"\n        Overwritten to return a dictionary of the relevant LogRecord attributes instead of a string.\n        KeyError is raised if an unknown attribute is provided in the fmt_dict.\n        \"\"\"\n        return {fmt_key: record.__dict__[fmt_val] for fmt_key, fmt_val in self.fmt_dict.items()}\n    def format(self, record) -> str:\n        \"\"\"\n        Mostly the same as the parent's class method, the difference being that a dict is manipulated and dumped as JSON\n        instead of a string.\n        \"\"\"\n        record.message = record.getMessage()\n\n        if self.usesTime():\n            record.asctime = self.formatTime(record, self.datefmt)\n        message_dict = self.formatMessage(record)\n        if record.exc_info:\n            # Cache the traceback text to avoid converting it multiple times\n            # (it's constant anyway)\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            message_dict[\"exc_info\"] = record.exc_text\n        if record.stack_info:\n            message_dict[\"stack_info\"] = self.formatStack(record.stack_info)\n        return json.dumps(message_dict, default=str)",
        "score": 47,
        "is_accepted": false,
        "creation_date": "2021-12-04T01:37:33",
        "author": "Bogdan Mircea"
      },
      {
        "answer_id": 70223539,
        "body": "json_handler = FileHandler(\"foo.json\")\n    json_formatter = JsonFormatter({\"level\": \"levelname\",\n                                    \"message\": \"message\",\n                                    \"loggerName\": \"name\",\n                                    \"processName\": \"processName\",\n                                    \"processID\": \"process\",\n                                    \"threadName\": \"threadName\",\n                                    \"threadID\": \"thread\",\n                                    \"timestamp\": \"asctime\"})\n    json_handler.setFormatter(json_formatter)",
        "score": 47,
        "is_accepted": false,
        "creation_date": "2021-12-04T01:37:33",
        "author": "Bogdan Mircea"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/68625748/attributeerror-cant-get-attribute-new-block-on-module-pandas-core-internal",
    "title": "AttributeError: Can&#39;t get attribute &#39;new_block&#39; on &lt;module &#39;pandas.core.internals.blocks&#39;&gt;",
    "question_id": 68625748,
    "posted_date": "2021-08-02T13:29:19",
    "answers": [
      {
        "answer_id": 69698232,
        "body": "import pickle\nwith open(\"dump_from_v1.3.4.pickle\", \"rb\") as f:\n    df = pickle.load(f)\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-2-ff5c218eca92> in <module>\n      1 with open(\"dump_from_v1.3.4.pickle\", \"rb\") as f:\n----> 2     df = pickle.load(f)\n      3\nAttributeError: Can't get attribute 'new_block' on <module 'pandas.core.internals.blocks' from '/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py'>",
        "score": 78,
        "is_accepted": true,
        "creation_date": "2021-10-24T11:32:10",
        "author": "Saibo-creator"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65686318/sharing-python-objects-across-multiple-workers",
    "title": "Sharing python objects across multiple workers",
    "question_id": 65686318,
    "posted_date": "2021-01-12T09:51:10",
    "answers": [
      {
        "answer_id": 65699375,
        "body": "# app_cache.py\nimport os\nfrom aiocache import Cache\nfrom fastapi import FastAPI, status\napp = FastAPI()\ncache = Cache(Cache.REDIS, endpoint=\"localhost\", port=6379, namespace=\"main\")\nclass Meta:\n    def __init__(self):\n        pass\n    async def get_count(self) -> int:\n        return await cache.get(\"count\", default=0)\n    async def set_count(self, value: int) -> None:\n        await cache.set(\"count\", value)\n    async def increment_count(self) -> None:\n        await cache.increment(\"count\", 1)\nmeta = Meta()\n# increases the count variable in the meta object by 1\n@app.post(\"/increment\")\nasync def increment():\n    await meta.increment_count()\n    return status.HTTP_200_OK\n# returns a json containing the current count from the meta object\n@app.get(\"/report\")\nasync def report():\n    count = await meta.get_count()\n    return {'count': count, \"current_process_id\": os.getpid()}\n# resets the count in the meta object to 0\n@app.post(\"/reset\")\nasync def reset():\n    await meta.set_count(0)\n    return status.HTTP_200_OK",
        "score": 42,
        "is_accepted": true,
        "creation_date": "2021-01-13T04:49:23",
        "author": "alex_noname"
      },
      {
        "answer_id": 65699375,
        "body": "# app_db.py\nfrom fastapi import FastAPI, status\nfrom tortoise import Model, fields\nfrom tortoise.contrib.fastapi import register_tortoise\nclass MetaModel(Model):\n    count = fields.IntField(default=0)\napp = FastAPI()\n# increases the count variable in the meta object by 1\n@app.post(\"/increment\")\nasync def increment():\n    meta, is_created = await MetaModel.get_or_create(id=1)\n    meta.count += 1  # it's better do it in transaction\n    await meta.save()\n    return status.HTTP_200_OK\n# returns a json containing the current count from the meta object\n@app.get(\"/report\")\nasync def report():\n    meta, is_created = await MetaModel.get_or_create(id=1)\n    return {'count': meta.count}\n# resets the count in the meta object to 0\n@app.post(\"/reset\")\nasync def reset():\n    meta, is_created = await MetaModel.get_or_create(id=1)\n    meta.count = 0\n    await meta.save()\n    return status.HTTP_200_OK\nregister_tortoise(\n    app,\n    db_url=\"postgres://test_user:test_pass@localhost:5432/test_db\",  # Don't expose login/pass in src, use environment variables\n    modules={\"models\": [\"app_db\"]},\n    generate_schemas=True,\n    add_exception_handlers=True,\n)",
        "score": 42,
        "is_accepted": true,
        "creation_date": "2021-01-13T04:49:23",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60455830/can-you-have-an-async-handler-in-lambda-python-3-6",
    "title": "Can you have an async handler in Lambda Python 3.6?",
    "question_id": 60455830,
    "posted_date": "2020-02-28T11:33:57",
    "answers": [
      {
        "answer_id": 62016270,
        "body": "import asyncio\nimport aioboto3\n# To reduce execution time for subsequent invocations,\n#   open a reusable resource in a global scope\ndynamodb = aioboto3.Session().resource('dynamodb')\nasync def async_handler(event, context):\n    # Put your asynchronous code here\n    table = await dynamodb.Table('test')\n    await table.put_item(\n        Item={'pk': 'test1', 'col1': 'some_data'},\n    )\n    return {'statusCode': 200, 'body': '{\"ok\": true}'}\n# Point to this function as a handler in the Lambda configuration\ndef lambda_handler(event, context):\n    loop = asyncio.get_event_loop()\n    # DynamoDB resource defined above is attached to this loop:\n    #   if you use asyncio.run instead\n    #   you will encounter \"Event loop closed\" exception\n    return loop.run_until_complete(async_handler(event, context))",
        "score": 68,
        "is_accepted": true,
        "creation_date": "2020-05-26T02:54:42",
        "author": "Anton Bryzgalov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4183208/how-do-i-rotate-an-image-around-its-center-using-pygame",
    "title": "How do I rotate an image around its center using Pygame?",
    "question_id": 4183208,
    "posted_date": "2010-11-15T04:55:23",
    "answers": [
      {
        "answer_id": 54714144,
        "body": "import pygame\npygame.init()\nscreen = pygame.display.set_mode((300, 300))\nclock = pygame.time.Clock()\ndef blitRotate(surf, image, pos, originPos, angle):\n    # offset from pivot to center\n    image_rect = image.get_rect(topleft = (pos[0] - originPos[0], pos[1]-originPos[1]))\n    offset_center_to_pivot = pygame.math.Vector2(pos) - image_rect.center\n\n    # roatated offset from pivot to center\n    rotated_offset = offset_center_to_pivot.rotate(-angle)\n    # roatetd image center\n    rotated_image_center = (pos[0] - rotated_offset.x, pos[1] - rotated_offset.y)\n    # get a rotated image\n    rotated_image = pygame.transform.rotate(image, angle)\n    rotated_image_rect = rotated_image.get_rect(center = rotated_image_center)\n    # rotate and blit the image\n    surf.blit(rotated_image, rotated_image_rect)\n\n    # draw rectangle around the image\n    pygame.draw.rect(surf, (255, 0, 0), (*rotated_image_rect.topleft, *rotated_image.get_size()),2)\ndef blitRotate2(surf, image, topleft, angle):\n    rotated_image = pygame.transform.rotate(image, angle)\n    new_rect = rotated_image.get_rect(center = image.get_rect(topleft = topleft).center)\n    surf.blit(rotated_image, new_rect.topleft)\n    pygame.draw.rect(surf, (255, 0, 0), new_rect, 2)\ntry:\n    image = pygame.image.load('AirPlaneFront.png')\nexcept:\n    text = pygame.font.SysFont('Times New Roman', 50).render('image', False, (255, 255, 0))\n    image = pygame.Surface((text.get_width()+1, text.get_height()+1))\n    pygame.draw.rect(image, (0, 0, 255), (1, 1, *text.get_size()))\n    image.blit(text, (1, 1))\nw, h = image.get_size()\nangle = 0\ndone = False\nwhile not done:\n    clock.tick(60)\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            done = True\n    pos = (screen.get_width()/2, screen.get_height()/2)\n\n    screen.fill(0)\n    blitRotate(screen, image, pos, (w/2, h/2), angle)\n    #blitRotate2(screen, image, pos, angle)\n    angle += 1\n\n    pygame.draw.line(screen, (0, 255, 0), (pos[0]-20, pos[1]), (pos[0]+20, pos[1]), 3)\n    pygame.draw.line(screen, (0, 255, 0), (pos[0], pos[1]-20), (pos[0], pos[1]+20), 3)\n    pygame.draw.circle(screen, (0, 255, 0), pos, 7, 0)\n    pygame.display.flip()\n\npygame.quit()\nexit()",
        "score": 150,
        "is_accepted": false,
        "creation_date": "2019-02-15T12:17:40",
        "author": "Rabbid76"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/34469060/python-native-coroutines-and-send",
    "title": "Python native coroutines and send()",
    "question_id": 34469060,
    "posted_date": "2015-12-26T01:25:15",
    "answers": [
      {
        "answer_id": 60118660,
        "body": "from queue import Queue\n# ------------------------------------------------------------\n#                       === Tasks ===\n# ------------------------------------------------------------\nclass Task:\n    taskid = 0\n    def __init__(self,target):\n        Task.taskid += 1\n        self.tid = Task.taskid   # Task ID\n        self.target = target        # Target coroutine\n        self.sendval = None          # Value to send\n    # Run a task until it hits the next yield statement\n    def run(self):\n        return self.target.send(self.sendval)\n# ------------------------------------------------------------\n#                      === Scheduler ===\n# ------------------------------------------------------------\nclass Scheduler:\n    def __init__(self):\n        self.ready = Queue()\n        self.taskmap = {}\n    def new(self,target):\n        newtask = Task(target)\n        self.taskmap[newtask.tid] = newtask\n        self.schedule(newtask)\n        return newtask.tid\n    def exit(self,task):\n        print(\"Task %d terminated\" % task.tid)\n        del self.taskmap[task.tid]\n    def schedule(self,task):\n        self.ready.put(task)\n    def mainloop(self):\n         while self.taskmap:\n            task = self.ready.get()\n            try:\n                result = task.run()\n                if isinstance(result,SystemCall):\n                    result.task  = task\n                    result.sched = self\n                    result.handle()\n                    continue\n            except StopIteration:\n                self.exit(task)\n                continue\n            self.schedule(task)\n# ------------------------------------------------------------\n#                   === System Calls ===\n# ------------------------------------------------------------\nclass SystemCall:\n    def handle(self):\n        pass\n    def __await__(self):\n        return (yield self)\n# Return a task's ID number\nclass GetTid(SystemCall):\n    def handle(self):\n        self.task.sendval = self.task.tid\n        self.sched.schedule(self.task)\nclass YieldControl(SystemCall):\n    def handle(self):\n        self.task.sendval = None   # setting sendval is optional\n        self.sched.schedule(self.task)\n# ------------------------------------------------------------\n#                      === Example ===\n# ------------------------------------------------------------\nif __name__ == '__main__':\n    async def foo():\n        mytid = await GetTid()\n        for i in range(3):\n            print(\"I'm foo\", mytid)\n            await YieldControl()\n    async def bar():\n        mytid = await GetTid()\n        for i in range(5):\n            print(\"I'm bar\", mytid)\n            await YieldControl()\n    sched = Scheduler()\n    sched.new(foo())\n    sched.new(bar())\n    sched.mainloop()",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2020-02-07T12:51:54",
        "author": "plamut"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57528350/can-you-consistently-keep-track-of-column-labels-using-sklearns-transformer-api",
    "title": "Can You Consistently Keep Track of Column Labels Using Sklearn&#39;s Transformer API?",
    "question_id": 57528350,
    "posted_date": "2019-08-16T12:47:10",
    "answers": [
      {
        "answer_id": 57534118,
        "body": "import pandas as pd\nimport numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\nfrom sklearn.feature_extraction.text import _VectorizerMixin\nfrom sklearn.feature_selection._base import SelectorMixin\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_extraction.text import CountVectorizer\ntrain = pd.DataFrame({'age': [23,12, 12, np.nan],\n                      'Gender': ['M','F', np.nan, 'F'],\n                      'income': ['high','low','low','medium'],\n                      'sales': [10000, 100020, 110000, 100],\n                      'foo' : [1,0,0,1],\n                      'text': ['I will test this',\n                               'need to write more sentence',\n                               'want to keep it simple',\n                               'hope you got that these sentences are junk'],\n                      'y': [0,1,1,1]})\nnumeric_columns = ['age']\ncat_columns     = ['Gender','income']\nnumeric_pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\ncat_pipeline     = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\ntext_pipeline = make_pipeline(CountVectorizer(), SelectKBest(k=5))\ntransformers = [\n    ('num', numeric_pipeline, numeric_columns),\n    ('cat', cat_pipeline, cat_columns),\n    ('text', text_pipeline, 'text'),\n    ('simple_transformer', MinMaxScaler(), ['sales']),\n]\ncombined_pipe = ColumnTransformer(\n    transformers, remainder='passthrough')\ntransformed_data = combined_pipe.fit_transform(\n    train.drop('y',1), train['y'])",
        "score": 54,
        "is_accepted": true,
        "creation_date": "2019-08-17T03:12:01",
        "author": "Venkatachalam"
      },
      {
        "answer_id": 57534118,
        "body": "def get_feature_out(estimator, feature_in):\n    if hasattr(estimator,'get_feature_names'):\n        if isinstance(estimator, _VectorizerMixin):\n            # handling all vectorizers\n            return [f'vec_{f}' \\\n                for f in estimator.get_feature_names()]\n        else:\n            return estimator.get_feature_names(feature_in)\n    elif isinstance(estimator, SelectorMixin):\n        return np.array(feature_in)[estimator.get_support()]\n    else:\n        return feature_in\ndef get_ct_feature_names(ct):\n    # handles all estimators, pipelines inside ColumnTransfomer\n    # doesn't work when remainder =='passthrough'\n    # which requires the input column names.\n    output_features = []\n    for name, estimator, features in ct.transformers_:\n        if name!='remainder':\n            if isinstance(estimator, Pipeline):\n                current_features = features\n                for step in estimator:\n                    current_features = get_feature_out(step, current_features)\n                features_out = current_features\n            else:\n                features_out = get_feature_out(estimator, features)\n            output_features.extend(features_out)\n        elif estimator=='passthrough':\n            output_features.extend(ct._feature_names_in[features])\n\n    return output_features\npd.DataFrame(transformed_data,\n             columns=get_ct_feature_names(combined_pipe))",
        "score": 54,
        "is_accepted": true,
        "creation_date": "2019-08-17T03:12:01",
        "author": "Venkatachalam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67255653/how-to-set-up-and-tear-down-a-database-between-tests-in-fastapi",
    "title": "How to set up and tear down a database between tests in FastAPI?",
    "question_id": 67255653,
    "posted_date": "2021-04-25T12:21:51",
    "answers": [
      {
        "answer_id": 67348153,
        "body": "import pytest\nfrom fastapi.testclient import TestClient\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom main import app, get_db\nfrom database import Base\nSQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\nengine = create_engine(\n    SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False}\n)\nTestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\ndef override_get_db():\n    try:\n        db = TestingSessionLocal()\n        yield db\n    finally:\n        db.close()\n@pytest.fixture()\ndef test_db():\n    Base.metadata.create_all(bind=engine)\n    yield\n    Base.metadata.drop_all(bind=engine)\napp.dependency_overrides[get_db] = override_get_db\nclient = TestClient(app)\ndef test_get_todos(test_db):\n    response = client.post(\"/todos/\", json={\"text\": \"some new todo\"})\n    data1 = response.json()\n    response = client.post(\"/todos/\", json={\"text\": \"some even newer todo\"})\n    data2 = response.json()\n    assert data1[\"user_id\"] == data2[\"user_id\"]\n    response = client.get(\"/todos/\")\n    assert response.status_code == 200\n    assert response.json() == [\n        {\"id\": data1[\"id\"], \"user_id\": data1[\"user_id\"], \"text\": data1[\"text\"]},\n        {\"id\": data2[\"id\"], \"user_id\": data2[\"user_id\"], \"text\": data2[\"text\"]},\n    ]\ndef test_get_empty_todos_list(test_db):\n    response = client.get(\"/todos/\")\n    assert response.status_code == 200\n    assert response.json() == []",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2021-05-01T11:52:48",
        "author": "mihi"
      },
      {
        "answer_id": 67348153,
        "body": "import pytest\nimport sqlalchemy as sa\nfrom fastapi.testclient import TestClient\nfrom sqlalchemy.orm import sessionmaker\nfrom database import Base\nfrom main import app, get_db\nSQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\nengine = sa.create_engine(\n    SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False}\n)\nTestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n# Set up the database once\nBase.metadata.drop_all(bind=engine)\nBase.metadata.create_all(bind=engine)\n# These two event listeners are only needed for sqlite for proper\n# SAVEPOINT / nested transaction support. Other databases like postgres\n# don't need them.\n# From: https://docs.sqlalchemy.org/en/14/dialects/sqlite.html#serializable-isolation-savepoints-transactional-ddl\n@sa.event.listens_for(engine, \"connect\")\ndef do_connect(dbapi_connection, connection_record):\n    # disable pysqlite's emitting of the BEGIN statement entirely.\n    # also stops it from emitting COMMIT before any DDL.\n    dbapi_connection.isolation_level = None\n@sa.event.listens_for(engine, \"begin\")\ndef do_begin(conn):\n    # emit our own BEGIN\n    conn.exec_driver_sql(\"BEGIN\")\n# This fixture is the main difference to before. It creates a nested\n# transaction, recreates it when the application code calls session.commit\n# and rolls it back at the end.\n# Based on: https://docs.sqlalchemy.org/en/14/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites\n@pytest.fixture()\ndef session():\n    connection = engine.connect()\n    transaction = connection.begin()\n    session = TestingSessionLocal(bind=connection)\n    # Begin a nested transaction (using SAVEPOINT).\n    nested = connection.begin_nested()\n    # If the application code calls session.commit, it will end the nested\n    # transaction. Need to start a new one when that happens.\n    @sa.event.listens_for(session, \"after_transaction_end\")\n    def end_savepoint(session, transaction):\n        nonlocal nested\n        if not nested.is_active:\n            nested = connection.begin_nested()\n    yield session\n    # Rollback the overall transaction, restoring the state before the test ran.\n    session.close()\n    transaction.rollback()\n    connection.close()\n# A fixture for the fastapi test client which depends on the\n# previous session fixture. Instead of creating a new session in the\n# dependency override as before, it uses the one provided by the\n# session fixture.\n@pytest.fixture()\ndef client(session):\n    def override_get_db():\n        yield session\n    app.dependency_overrides[get_db] = override_get_db\n    yield TestClient(app)\n    del app.dependency_overrides[get_db]\ndef test_get_empty_todos_list(client):\n    response = client.get(\"/todos/\")\n    assert response.status_code == 200\n    assert response.json() == []",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2021-05-01T11:52:48",
        "author": "mihi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53841509/how-does-adaptive-pooling-in-pytorch-work",
    "title": "How does adaptive pooling in pytorch work?",
    "question_id": 53841509,
    "posted_date": "2018-12-18T16:42:05",
    "answers": [
      {
        "answer_id": 63603993,
        "body": "from typing import List\nimport math\ndef kernels(ind,outd) -> List:\n    \"\"\"Returns a List [(kernel_offset_start,kernel_length)] defining all the pooling kernels for a 1-D adaptive pooling layer that takes an input of dimension `ind` and yields an output of dimension `outd`\"\"\"\n    def start_index(a,b,c):\n        return math.floor((float(a) * float(c)) / b)\n    def end_index(a,b,c):\n        return math.ceil((float(a + 1) * float(c)) / b)\n    results = []\n    for ow in range(outd):\n        start = start_index(ow,outd,ind)\n        end = end_index(ow,outd,ind)\n        sz = end - start\n        results.append((start,sz))\n    return results\ndef kernel_indexes(ind,out) -> List:\n    \"\"\"Returns a List [[*ind]] containing the indexes of the pooling kernels\"\"\"\n    startsLengths = kernels(ind,out)\n    return [list(range(start,start+length)) for (start,length) in startsLengths]",
        "score": 36,
        "is_accepted": false,
        "creation_date": "2020-08-26T14:53:49",
        "author": "algal"
      },
      {
        "answer_id": 63603993,
        "body": "import torch\nimport torch.nn as nn\ndef compare1DAdaptivity(ind,outd,inputpattern):\n    c = 1\n    padding = 0\n    input = torch.Tensor(inputpattern).view(1,c,ind)\n    stride = ind // outd\n    kernel_size = (ind - (outd-1)*stride)\n    avg_pool = nn.AvgPool1d(stride=stride,kernel_size=kernel_size,padding=padding)\n    avg_out = avg_pool(input)\n    adap_avg_pool = torch.nn.AdaptiveAvgPool1d(outd)\n    adap_avg_out = adap_avg_pool(input)\n\n    try:\n        equal_output = torch.allclose(avg_out,adap_avg_out)\n    except:\n        equal_output = False\n    print(\"input.shape: {}\".format(input.shape))\n    print(\"in_dims: {}\".format(ind))\n    print(\"out_dims: {}\".format(outd))\n    print(\"\")\n    print(\"AAL strides: {}\".format(stride))\n    print(\"AAL kernel_sizes: {}\".format(kernel_size))\n    print(\"AAL pad: {}\".format(padding))\n    print(\"\")\n    print(\"outputs equal: {}\".format(equal_output))\n    print(\"\")\n    print(\"AAL input -> output: {} -> {}\".format(input,avg_out))\n    print(\"adap input -> output: {} -> {}\".format(input,adap_avg_out))\n    return equal_output",
        "score": 36,
        "is_accepted": false,
        "creation_date": "2020-08-26T14:53:49",
        "author": "algal"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63580229/how-to-save-uploadfile-in-fastapi",
    "title": "How to save UploadFile in FastAPI",
    "question_id": 63580229,
    "posted_date": "2020-08-25T09:44:52",
    "answers": [
      {
        "answer_id": 63581187,
        "body": "`\nimport shutil\nfrom pathlib import Path\nfrom tempfile import NamedTemporaryFile\nfrom typing import Callable\nfrom fastapi import UploadFile\ndef save_upload_file(upload_file: UploadFile, destination: Path) -> None:\n    try:\n        with destination.open(\"wb\") as buffer:\n            shutil.copyfileobj(upload_file.file, buffer)\n    finally:\n        upload_file.file.close()\ndef save_upload_file_tmp(upload_file: UploadFile) -> Path:\n    try:\n        suffix = Path(upload_file.filename).suffix\n        with NamedTemporaryFile(delete=False, suffix=suffix) as tmp:\n            shutil.copyfileobj(upload_file.file, tmp)\n            tmp_path = Path(tmp.name)\n    finally:\n        upload_file.file.close()\n    return tmp_path\ndef handle_upload_file(\n    upload_file: UploadFile, handler: Callable[[Path], None]\n) -> None:\n    tmp_path = save_upload_file_tmp(upload_file)\n    try:\n        handler(tmp_path)  # Do something with the saved temp file\n    finally:\n        tmp_path.unlink()  # Delete the temp file",
        "score": 71,
        "is_accepted": true,
        "creation_date": "2020-08-25T10:33:25",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29640685/how-do-i-detect-collision-in-pygame",
    "title": "How do I detect collision in pygame?",
    "question_id": 29640685,
    "posted_date": "2015-04-14T22:38:48",
    "answers": [
      {
        "answer_id": 65064907,
        "body": "  import pygame\n  pygame.init()\n  window = pygame.display.set_mode((250, 250))\n  rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(100, 100)\n  run = True\n  while run:\n      for event in pygame.event.get():\n          if event.type == pygame.QUIT:\n              run = False\n      point = pygame.mouse.get_pos()\n      collide = rect.collidepoint(point)\n      color = (255, 0, 0) if collide else (255, 255, 255)\n      window.fill(0)\n      pygame.draw.rect(window, color, rect)\n      pygame.display.flip()\n  pygame.quit()\n  exit()",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2020-11-29T15:36:32",
        "author": "Rabbid76"
      },
      {
        "answer_id": 65064907,
        "body": "  import pygame\n  pygame.init()\n  window = pygame.display.set_mode((250, 250))\n  rect1 = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n  rect2 = pygame.Rect(0, 0, 75, 75)\n  run = True\n  while run:\n      for event in pygame.event.get():\n          if event.type == pygame.QUIT:\n              run = False\n      rect2.center = pygame.mouse.get_pos()\n      collide = rect1.colliderect(rect2)\n      color = (255, 0, 0) if collide else (255, 255, 255)\n      window.fill(0)\n      pygame.draw.rect(window, color, rect1)\n      pygame.draw.rect(window, (0, 255, 0), rect2, 6, 1)\n      pygame.display.flip()\n  pygame.quit()\n  exit()",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2020-11-29T15:36:32",
        "author": "Rabbid76"
      },
      {
        "answer_id": 65064907,
        "body": "  import pygame\n  pygame.init()\n  window = pygame.display.set_mode((250, 250))\n  sprite1 = pygame.sprite.Sprite()\n  sprite1.image = pygame.Surface((75, 75))\n  sprite1.image.fill((255, 0, 0))\n  sprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n  sprite2 = pygame.sprite.Sprite()\n  sprite2.image = pygame.Surface((75, 75))\n  sprite2.image.fill((0, 255, 0))\n  sprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n  all_group = pygame.sprite.Group([sprite2, sprite1])\n  test_group = pygame.sprite.Group(sprite2)\n  run = True\n  while run:\n      for event in pygame.event.get():\n          if event.type == pygame.QUIT:\n              run = False\n      sprite1.rect.center = pygame.mouse.get_pos()\n      collide = pygame.sprite.spritecollide(sprite1, test_group, False)\n      window.fill(0)\n      all_group.draw(window)\n      for s in collide:\n          pygame.draw.rect(window, (255, 255, 255), s.rect, 5, 1)\n      pygame.display.flip()\n  pygame.quit()\n  exit()",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2020-11-29T15:36:32",
        "author": "Rabbid76"
      },
      {
        "answer_id": 65064907,
        "body": "  import pygame\n  pygame.init()\n  window = pygame.display.set_mode((250, 250))\n  sprite1 = pygame.sprite.Sprite()\n  sprite1.image = pygame.Surface((80, 80), pygame.SRCALPHA)\n  pygame.draw.circle(sprite1.image, (255, 0, 0), (40, 40), 40)\n  sprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(80, 80)\n  sprite1.radius = 40\n  sprite2 = pygame.sprite.Sprite()\n  sprite2.image = pygame.Surface((80, 89), pygame.SRCALPHA)\n  pygame.draw.circle(sprite2.image, (0, 255, 0), (40, 40), 40)\n  sprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(80, 80)\n  sprite2.radius = 40\n  all_group = pygame.sprite.Group([sprite2, sprite1])\n  test_group = pygame.sprite.Group(sprite2)\n  run = True\n  while run:\n      for event in pygame.event.get():\n          if event.type == pygame.QUIT:\n              run = False\n      sprite1.rect.center = pygame.mouse.get_pos()\n      collide = pygame.sprite.spritecollide(sprite1, test_group, False, pygame.sprite.collide_circle)\n      window.fill(0)\n      all_group.draw(window)\n      for s in collide:\n          pygame.draw.circle(window, (255, 255, 255), s.rect.center, s.rect.width // 2, 5)\n      pygame.display.flip()\n  pygame.quit()\n  exit()",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2020-11-29T15:36:32",
        "author": "Rabbid76"
      },
      {
        "answer_id": 65064907,
        "body": "#Define the sprite class\nclass Sprite:\n    def __init__(self, x, y, name):\n        self.image = pygame.image.load(name)\n        self.rect = self.image.get_rect(topleft = (x, y))\n    def render(self):\n        window.blit(self.image, self.rect)\n# Define the bullet class to create bullets\nclass Bullet:\n    def __init__(self, x, y):\n        self.bullet = pygame.image.load(\"user_bullet.BMP\")\n        self.rect = self.bullet.get_rect(topleft = (x + 23, y))\n    def render(self):\n        window.blit(self.bullet, self.rect)",
        "score": 102,
        "is_accepted": true,
        "creation_date": "2020-11-29T15:36:32",
        "author": "Rabbid76"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/35736598/cannot-pip-install-cryptography-in-docker-alpine-linux-3-3-with-openssl-1-0-2g",
    "title": "Cannot &quot;pip install cryptography&quot; in Docker Alpine Linux 3.3 with OpenSSL 1.0.2g and Python 2.7",
    "question_id": 35736598,
    "posted_date": "2016-03-01T20:03:12",
    "answers": [
      {
        "answer_id": 53562393,
        "body": "writing manifest file 'src/cryptography.egg-info/SOURCES.txt'\nrunning build_ext\ngenerating cffi module 'build/temp.linux-x86_64-2.7/_padding.c'\ncreating build/temp.linux-x86_64-2.7\ngenerating cffi module 'build/temp.linux-x86_64-2.7/_constant_time.c'\ngenerating cffi module 'build/temp.linux-x86_64-2.7/_openssl.c'\nbuilding '_openssl' extension\ncreating build/temp.linux-x86_64-2.7/build\ncreating build/temp.linux-x86_64-2.7/build/temp.linux-x86_64-2.7\ngcc -fno-strict-aliasing -Os -fomit-frame-pointer -g -DNDEBUG -Os -fomit-frame-pointer -g -DTHREAD_STACK_SIZE=0x100000 -fPIC -I/usr/include/python2.7 -c build/temp.linux-x86_64-2.7/_openssl.c -o build/temp.linux-x86_64-2.7/build/temp.linux-x86_64-2.7/_openssl.o -Wconversion -Wno-error=sign-conversion\nbuild/temp.linux-x86_64-2.7/_openssl.c:493:30: fatal error: openssl/opensslv.h: No such file or directory\n #include <openssl/opensslv.h>\n                              ^\ncompilation terminated.\nerror: command 'gcc' failed with exit status 1",
        "score": 80,
        "is_accepted": false,
        "creation_date": "2018-11-30T12:43:23",
        "author": "Manoj Kasyap"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50792316/what-does-1-of-view-mean-in-pytorch",
    "title": "What does `-1` of `view()` mean in PyTorch?",
    "question_id": 50792316,
    "posted_date": "2018-06-11T03:21:32",
    "answers": [
      {
        "answer_id": 50793899,
        "body": "import torch\nx = torch.arange(6)\nprint(x.view(3, -1))      # inferred size will be 2 as 6 / 3 = 2\n# tensor([[ 0.,  1.],\n#         [ 2.,  3.],\n#         [ 4.,  5.]])\nprint(x.view(-1, 6))      # inferred size will be 1 as 6 / 6 = 1\n# tensor([[ 0.,  1.,  2.,  3.,  4.,  5.]])\nprint(x.view(1, -1, 2))   # inferred size will be 3 as 6 / (1 * 2) = 3\n# tensor([[[ 0.,  1.],\n#          [ 2.,  3.],\n#          [ 4.,  5.]]])\n# print(x.view(-1, 5))    # throw error as there's no int N so that 5 * N = 6\n# RuntimeError: invalid argument 2: size '[-1 x 5]' is invalid for input with 6 elements\nprint(x.view(-1, -1, 3))  # throw error as only one dimension can be inferred\n# RuntimeError: invalid argument 1: only one dimension can be inferred",
        "score": 71,
        "is_accepted": true,
        "creation_date": "2018-06-11T04:59:33",
        "author": "benjaminplanche"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41403458/how-do-i-send-html-formatted-emails-through-the-gmail-api-for-python",
    "title": "How do I send HTML Formatted emails, through the gmail-api for python",
    "question_id": 41403458,
    "posted_date": "2016-12-30T17:27:06",
    "answers": [
      {
        "answer_id": 41403459,
        "body": "def create_message(sender, to, cc, subject, message_text):\n    \"\"\"Create a message for an email.\n    Args:\n    sender: Email address of the sender.\n    to: Email address of the receiver.\n    subject: The subject of the email message.\n    message_text: The text of the email message.\n    Returns:\n    An object containing a base64url encoded email object.\n    \"\"\"\n    print(sender + ', ' + to + ', ' + subject + ', ' + message_text)\n    message = MIMEText(message_text,'html')\n    message['to'] = to\n    message['from'] = sender\n    message['subject'] = subject\n    message['cc'] = cc\n    pprint(message)\n    return {'raw': base64.urlsafe_b64encode(message.as_string())}",
        "score": 60,
        "is_accepted": true,
        "creation_date": "2016-12-30T17:27:06",
        "author": "Andrew"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/14982836/rendering-and-saving-images-through-blender-python",
    "title": "rendering and saving images through Blender python",
    "question_id": 14982836,
    "posted_date": "2013-02-20T09:55:00",
    "answers": [
      {
        "answer_id": 17604149,
        "body": "def rotate_and_render(output_dir, output_file_pattern_string = 'render%d.jpg', rotation_steps = 32, rotation_angle = 360.0, subject = bpy.context.object):\n  import os\n  original_rotation = subject.rotation_euler\n  for step in range(0, rotation_steps):\n    subject.rotation_euler[2] = radians(step * (rotation_angle / rotation_steps))\n    bpy.context.scene.render.filepath = os.path.join(output_dir, (output_file_pattern_string % step))\n    bpy.ops.render.render(write_still = True)\n  subject.rotation_euler = original_rotation\nrotate_and_render('/Users/myusername/Pictures/VR', 'render%d.jpg')",
        "score": 58,
        "is_accepted": false,
        "creation_date": "2013-07-11T17:52:09",
        "author": "shybovycha"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47402435/pytest-fixture-of-fixture-not-found",
    "title": "pytest fixture of fixture, not found",
    "question_id": 47402435,
    "posted_date": "2017-11-20T17:48:21",
    "answers": [
      {
        "answer_id": 55454635,
        "body": "======================================= test session starts ========================================\nplatform darwin -- Python 3.6.8, pytest-4.3.0\ncollected 1 item\ntest2.py E                                                                                   [100%]\n============================================== ERRORS ==============================================\n__________________________________ ERROR at setup of test_foo_bar __________________________________\nfile .../test_foo_bar.py, line 3\n  def test_foo_bar(bar):\n.../test.py, line 7\n  @pytest.fixture\n  def bar(foo):\nE       fixture 'foo' not found\n>       available fixtures: TIMEOUT, bar, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, doctest_namespace, monkeypatch, no_cover, once_without_docker, pytestconfig, record_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n.../test.py:7\n===================================== 1 error in 0.03 seconds ======================================",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2019-04-01T08:00:31",
        "author": "m. bron"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18159221/remove-namespace-and-prefix-from-xml-in-python-using-lxml",
    "title": "Remove namespace and prefix from xml in python using lxml",
    "question_id": 18159221,
    "posted_date": "2013-08-10T02:17:56",
    "answers": [
      {
        "answer_id": 51972010,
        "body": "from lxml import etree\ninput_xml = \"\"\"\n<package xmlns=\"http://apple.com/itunes/importer\">\n  <provider>some data</provider>\n  <language>en-GB</language>\n  <!-- some comment -->\n  <?xml-some-processing-instruction ?>\n</package>\n\"\"\"\nroot = etree.fromstring(input_xml)\n# Iterate through all XML elements\nfor elem in root.getiterator():\n    # Skip comments and processing instructions,\n    # because they do not have names\n    if not (\n        isinstance(elem, etree._Comment)\n        or isinstance(elem, etree._ProcessingInstruction)\n    ):\n        # Remove a namespace URI in the element's name\n        elem.tag = etree.QName(elem).localname\n# Remove unused namespace declarations\netree.cleanup_namespaces(root)\nprint(etree.tostring(root).decode())",
        "score": 105,
        "is_accepted": false,
        "creation_date": "2018-08-22T13:13:08",
        "author": "SergiyKolesnikov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67807596/pyenv-install-3-x-build-failed-ubuntu-20-04-using-python-build-20180424",
    "title": "pyenv install: 3.x BUILD FAILED (Ubuntu 20.04 using python-build 20180424)",
    "question_id": 67807596,
    "posted_date": "2021-06-02T10:56:04",
    "answers": [
      {
        "answer_id": 67853440,
        "body": "/tmp/python-build.20210602162502.2268/Python-3.9.4/Modules/_ctypes/_ctypes.c:107:10: fatal error: ffi.h: No such file or directory\n  107 | #include <ffi.h>\n      |          ^~~~~~~\ncompilation terminated.\nPython build finished successfully!\nThe necessary bits to build these optional modules were not found:\n_bz2                  _curses_panel         _dbm\n_gdbm                 _lzma                 _sqlite3\n_tkinter              _uuid                 zlib\nTo find the necessary bits, look in setup.py in detect_modules() for the module's name.\nThe following modules found by detect_modules() in setup.py, have been\nbuilt by the Makefile instead, as configured by the Setup files:\n_abc                  atexit                pwd\ntime\nFailed to build these modules:\n_ctypes               _curses",
        "score": 123,
        "is_accepted": true,
        "creation_date": "2021-06-05T15:54:37",
        "author": "Marlon Richert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57983431/whats-the-most-space-efficient-way-to-compress-serialized-python-data",
    "title": "What&#39;s the most space-efficient way to compress serialized Python data?",
    "question_id": 57983431,
    "posted_date": "2019-09-17T20:14:35",
    "answers": [
      {
        "answer_id": 57983757,
        "body": "import bz2\nimport gzip\nimport lzma\nimport pickle\nimport brotli\nclass SomeObject():\n    a = 'some data'\n    b = 123\n    c = 'more data'\n    def __init__(self, i):\n        self.i = i\ndata = [SomeObject(i) for i in range(1, 1000000)]\nwith open('no_compression.pickle', 'wb') as f:\n    pickle.dump(data, f)\nwith gzip.open(\"gzip_test.gz\", \"wb\") as f:\n    pickle.dump(data, f)\nwith bz2.BZ2File('bz2_test.pbz2', 'wb') as f:\n    pickle.dump(data, f)\nwith lzma.open(\"lzma_test.xz\", \"wb\") as f:\n    pickle.dump(data, f)\nwith open('no_compression.pickle', 'rb') as f:\n    pdata = f.read()\n    with open('brotli_test.bt', 'wb') as b:\n        b.write(brotli.compress(pdata))",
        "score": 55,
        "is_accepted": true,
        "creation_date": "2019-09-17T21:12:29",
        "author": "Gabriel Cappelli"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/36162414/how-to-add-bold-annotated-text-to-a-plot",
    "title": "How to add bold annotated text to a plot",
    "question_id": 36162414,
    "posted_date": "2016-03-22T14:30:44",
    "answers": [
      {
        "answer_id": 57350258,
        "body": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nswing = pd.read_csv('https://assets.datacamp.com/production/repositories/469/datasets/e079fddb581197780e1a7b7af2aeeff7242535f0/2008_swing_states.csv')\n\nplt.figure(figsize=(10, 10))\nsns.scatterplot(x='total_votes', y='dem_share', data=swing, hue='state')\nplt.xlabel('total votes')\nplt.ylabel('% of vote for Obama')\nplt.xticks(range(0, 1000000, 100000), rotation=40)\nplt.yticks(range(0, 100, 10))\n\n# Create a Rectangle patch\nplt.gca().add_patch(Rectangle((400000, 52), 500000, 34, linewidth=1, edgecolor='b', facecolor='none'))\n\nplt.gca().add_patch(Rectangle((0, 5), 50000, 45, linewidth=1, edgecolor='r', facecolor='none'))",
        "score": 63,
        "is_accepted": false,
        "creation_date": "2019-08-04T17:15:59",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 57350258,
        "body": "fig, ax = plt.subplots(figsize=(10, 10))\nsns.scatterplot(x='total_votes', y='dem_share', data=swing, hue='state', ax=ax)\nax.set_xlabel('total votes')\nax.set_ylabel('% of vote for Obama')\nax.set_xticks(range(0, 1000000, 100000), range(0, 1000000, 100000), rotation=40)\nax.set_yticks(range(0, 100, 10))\n\n# Create a Rectangle patch\nax.add_patch(Rectangle((400000, 52), 500000, 34, linewidth=1, edgecolor='b', facecolor='none'))\n\nax.add_patch(Rectangle((0, 5), 50000, 45, linewidth=1, edgecolor='r', facecolor='none'))\nax.annotate('12 largest counties; most vote for Obama', xy=(650000, 52),\n             xytext=(400000, 35), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='b'))\nax.annotate('small counties; most vote for McCain', xy=(50000, 20), weight='bold',\n             xytext=(150000, 7), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='r'))\nax.text(600000, 20, '2008 Swing-State Counties', weight='bold')\nplt.show()",
        "score": 63,
        "is_accepted": false,
        "creation_date": "2019-08-04T17:15:59",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 57350258,
        "body": "g = sns.relplot(x='total_votes', y='dem_share', data=swing, hue='state', height=10)\n# iterate through each axes of the figure-level plot\nfor ax in g.axes.flat:\n    ax.set_xlabel('total votes')\n    ax.set_ylabel('% of vote for Obama')\n    ax.set_xticks(range(0, 1000000, 100000), range(0, 1000000, 100000), rotation=40)\n    ax.set_yticks(range(0, 100, 10))\n    # Create a Rectangle patch\n    ax.add_patch(Rectangle((400000, 52), 500000, 34, linewidth=1, edgecolor='b', facecolor='none'))\n    ax.add_patch(Rectangle((0, 5), 50000, 45, linewidth=1, edgecolor='r', facecolor='none'))\n    ax.annotate('12 largest counties; most vote for Obama', xy=(650000, 52),\n                 xytext=(400000, 35), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='b'))\n    ax.annotate('small counties; most vote for McCain', xy=(50000, 20), weight='bold',\n                 xytext=(150000, 7), fontsize=10, arrowprops=dict(arrowstyle=\"->\", color='r'))\n    ax.text(600000, 20, '2008 Swing-State Counties', weight='bold')\nplt.show()",
        "score": 63,
        "is_accepted": false,
        "creation_date": "2019-08-04T17:15:59",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 57350258,
        "body": "state,county,total_votes,dem_votes,rep_votes,dem_share\nPA,Erie County,127691,75775,50351,60.08\nPA,Bradford County,25787,10306,15057,40.64\nPA,Tioga County,17984,6390,11326,36.07\nPA,McKean County,15947,6465,9224,41.21\nPA,Potter County,7507,2300,5109,31.04\nPA,Wayne County,22835,9892,12702,43.78\nPA,Susquehanna County,19286,8381,10633,44.08\nPA,Warren County,18517,8537,9685,46.85\nOH,Ashtabula County,44874,25027,18949,56.94\nOH,Lake County,121335,60155,59142,50.46\nPA,Crawford County,38134,16780,20750,44.71\nOH,Lucas County,219830,142852,73706,65.99\nOH,Fulton County,21973,9900,11689,45.88\nOH,Geauga County,51102,21250,29096,42.23\nOH,Williams County,18397,8174,9880,45.26\nPA,Wyoming County,13138,5985,6983,46.15\nPA,Lackawanna County,107876,67520,39488,63.1\nPA,Elk County,14271,7290,6676,52.2\nPA,Forest County,2444,1038,1366,43.18\nPA,Venango County,23307,9238,13718,40.24\nOH,Erie County,41229,23148,17432,57.01\nOH,Wood County,65022,34285,29648,53.61\nPA,Cameron County,2245,879,1323,39.92\nPA,Pike County,24284,11493,12518,47.87\nPA,Lycoming County,49237,18381,30280,37.77\nPA,Sullivan County,3120,1233,1841,40.11\nOH,Lorain County,146859,85276,59068,59.1\nOH,Trumbull County,106911,64145,40164,61.48\nPA,Mercer County,53821,26411,26565,49.85\nOH,Henry County,14840,6320,8239,43.43\nPA,Clinton County,14791,7097,7504,48.61\nPA,Clarion County,17766,6756,10737,38.62\nPA,Luzerne County,135175,72492,61127,54.25\nOH,Defiance County,19195,8399,10407,44.69\nPA,Jefferson County,18802,6447,12057,34.84\nOH,Portage County,78206,41856,34822,54.59\nPA,Columbia County,28063,13230,14477,47.75\nOH,Huron County,25582,12076,12884,48.36\nOH,Medina County,90451,40924,48189,45.89\nOH,Seneca County,27449,13087,13823,48.62\nPA,Clearfield County,33813,14555,18662,43.82\nPA,Centre County,75763,41950,32992,55.97\nPA,Monroe County,68443,39453,28293,58.23\nOH,Paulding County,9769,4165,5317,43.92\nPA,Northumberland County,33939,14329,19018,42.97\nPA,Montour County,8023,3364,4574,42.38\nPA,Butler County,90425,32260,57074,36.11\nPA,Armstrong County,30081,11138,18542,37.53\nOH,Hancock County,36981,13870,22420,38.23\nOH,Putnam County,18680,5281,13072,28.79\nPA,Union County,17400,7333,9859,42.65\nOH,Mahoning County,127032,79173,45319,63.57\nPA,Carbon County,26923,13464,12957,50.96\nPA,Lawrence County,42103,19711,21851,47.43\nOH,Ashland County,25168,9300,15158,38.07\nOH,Crawford County,21173,8288,12316,40.18\nOH,Richland County,61122,25727,34034,43.05\nOH,Wyandot County,10977,4461,6270,41.56\nOH,Wayne County,52142,21712,29342,42.49\nOH,Van Wert County,14652,5178,9168,36.06\nOH,Stark County,187545,96990,86743,52.76\nPA,Northampton County,135587,75255,58551,56.24\nPA,Schuylkill County,63057,28300,33767,45.6\nOH,Columbiana County,48487,21882,25585,46.07\nOH,Allen County,50263,19522,29940,39.43\nPA,Indiana County,37302,17065,19727,46.39\nPA,Snyder County,15479,5382,9900,35.22\nPA,Beaver County,84488,40499,42895,48.56\nPA,Mifflin County,16502,5375,10929,32.97\nOH,Hardin County,13114,5013,7749,39.26\nPA,Lehigh County,152473,87089,63382,57.88\nPA,Huntingdon County,18632,6621,11745,36.05\nPA,Blair County,53102,19813,32708,37.72\nOH,Carroll County,13953,6423,7097,47.47\nOH,Mercer County,21271,5853,15100,27.92\nPA,Cambria County,65670,32451,31995,50.36\nOH,Morrow County,16643,6177,10067,38.01\nOH,Marion County,29017,12870,15454,45.45\nPA,Juniata County,9711,3068,6484,32.12\nOH,Auglaize County,23486,6727,16395,29.07\nPA,Westmoreland County,176873,72721,102294,41.55\nPA,Berks County,180000,97047,80513,54.66\nPA,Allegheny County,651436,373153,272347,57.81\nOH,Holmes County,11113,3141,7720,28.94\nOH,Tuscarawas County,42950,21498,20454,51.28\nPA,Dauphin County,129529,69975,58238,54.58\nPA,Perry County,19745,6396,13058,32.88\nPA,Bucks County,332924,179031,150248,54.37\nOH,Jefferson County,35939,17635,17559,50.1\nOH,Knox County,28231,11014,16640,39.84\nPA,Lebanon County,58297,23310,34314,40.45\nOH,Logan County,22217,7936,13848,36.43\nOH,Union County,24928,8761,15744,35.71\nOH,Shelby County,23668,7317,15924,31.47\nPA,Washington County,98047,46122,50752,47.61\nOH,Coshocton County,16863,7689,8675,47.01\nPA,Montgomery County,422419,253393,165552,60.49\nOH,Delaware County,92416,36653,54778,40.1\nOH,Harrison County,7787,3683,3872,48.76\nOH,Darke County,25793,7964,17290,31.56\nPA,Cumberland County,113304,48306,63739,43.11\nPA,Bedford County,22443,6059,16124,27.32\nPA,Lancaster County,228137,99586,126568,44.03\nPA,Franklin County,63641,21169,41906,33.56\nPA,Somerset County,35168,12878,21686,37.26\nOH,Champaign County,18887,7385,11141,39.86\nPA,Chester County,254354,137833,114421,54.64\nPA,York County,194210,82839,109268,43.12\nOH,Guernsey County,17325,7625,9197,45.31\nOH,Miami County,52807,18372,33417,35.47\nOH,Belmont County,32411,16302,15422,51.38\nOH,Muskingum County,39071,17730,20549,46.33\nPA,Fulton County,6306,1576,4642,25.34\nPA,Fayette County,52560,25866,26081,49.79\nPA,Philadelphia County,717329,595980,117221,83.56\nPA,Adams County,44491,17633,26349,40.09\nPA,Delaware County,297004,178870,115273,60.81\nOH,Clark County,66770,31958,33634,48.73\nPA,Greene County,15976,7829,7889,49.81\nOH,Noble County,6172,2474,3450,41.77\nOH,Fairfield County,71945,29250,41580,41.32\nOH,Perry County,15404,7261,7721,48.46\nOH,Montgomery County,278511,145997,128679,53.14\nOH,Preble County,21002,6999,13562,34.01\nOH,Monroe County,6982,3705,3066,54.74\nOH,Greene County,83589,33540,48936,40.67\nOH,Pickaway County,23726,9077,14228,38.96\nOH,Morgan County,6608,2966,3440,46.29\nOH,Fayette County,11694,4401,7102,38.25\nOH,Washington County,18802,1238,17019,6.8\nOH,Warren County,106216,33398,71691,31.75\nOH,Ross County,31840,14455,16759,46.33\nOH,Vinton County,5646,2463,3021,44.9\nOH,Clermont County,95480,31611,62559,33.57\nOH,Brown County,20113,7503,12192,38.1\nOH,Jackson County,13993,5397,8219,39.67\nOH,Meigs County,10354,4094,6015,40.47\nOH,Pike County,12506,6033,6162,49.44\nOH,Adams County,11388,4170,6914,37.62\nOH,Gallia County,13318,4777,8247,36.71\nOH,Scioto County,32571,14926,16994,46.73\nOH,Lawrence County,27194,11262,15415,42.2\nFL,Jackson County,21565,7671,13717,35.86\nFL,Escambia County,154447,61572,91411,40.25\nFL,Santa Rosa County,76185,19470,55972,25.81\nFL,Okaloosa County,95529,25872,68789,27.33\nFL,Holmes County,8589,1446,7033,17.06\nFL,Walton County,27046,7174,19561,26.84\nFL,Washington County,11131,2863,8178,25.93\nFL,Nassau County,38304,10618,27403,27.93\nFL,Gadsden County,22510,15582,6811,69.58\nFL,Leon County,148608,91747,55705,62.23\nFL,Jefferson County,7957,4088,3797,51.85\nFL,Madison County,8907,4270,4544,48.44\nFL,Hamilton County,5587,2364,3179,42.65\nFL,Calhoun County,6244,1821,4345,29.53\nFL,Liberty County,3278,895,2339,27.67\nFL,Columbia County,28128,9171,18670,32.94\nFL,Duval County,415761,202618,210537,49.04\nFL,Baker County,11059,2327,8672,21.15\nFL,Bay County,81127,23653,56683,29.45\nFL,Suwannee County,17662,4916,12534,28.17\nFL,Taylor County,9366,2803,6457,30.27\nFL,Wakulla County,14376,5311,8877,37.43\nFL,Lafayette County,3359,642,2679,19.33\nFL,Saint Johns County,105844,35791,69222,34.08\nFL,Gulf County,7205,2149,4980,30.15\nFL,Clay County,94577,26697,67203,28.43\nFL,Bradford County,11676,3430,8136,29.66\nFL,Union County,5293,1300,3940,24.81\nFL,Franklin County,6029,2134,3818,35.86\nFL,Alachua County,125519,75565,48513,60.9\nFL,Gilchrist County,7819,1996,5656,26.09\nFL,Putnam County,33171,13236,19637,40.26\nFL,Dixie County,7264,1925,5194,27.04\nFL,Flagler County,49031,24726,23951,50.8\nFL,Levy County,18725,6711,11754,36.35\nFL,Marion County,162022,70839,89628,44.14\nFL,Volusia County,243824,127795,113938,52.86\nFL,Lake County,146926,62948,82802,43.19\nFL,Citrus County,76158,31460,43706,41.85\nFL,Sumter County,48868,17655,30866,36.39\nFL,Seminole County,205895,99335,105070,48.6\nFL,Brevard County,287859,127620,157589,44.74\nFL,Orange County,462711,273009,186832,59.37\nFL,Hernando County,87901,41886,45021,48.19\nFL,Pasco County,214866,102417,110104,48.2\nFL,Polk County,244833,113865,128878,46.91\nFL,Osceola County,100670,59962,40086,59.93\nFL,Pinellas County,463282,248299,210066,54.17\nFL,Hillsborough County,513312,272963,236355,53.59\nFL,Indian River County,70591,29710,40176,42.52\nFL,Highlands County,44783,18135,26221,40.89\nFL,Hardee County,7412,2568,4763,35.03\nFL,Manatee County,151994,70034,80721,46.46\nFL,Okeechobee County,12786,5108,7561,40.32\nFL,Saint Lucie County,120579,67125,52512,56.11\nFL,Sarasota County,207353,102686,102897,49.95\nFL,DeSoto County,10131,4383,5632,43.76\nFL,Martin County,78294,33508,44143,43.15\nFL,Glades County,3358,1381,1938,41.61\nFL,Charlotte County,85158,39031,45205,46.34\nFL,Palm Beach County,590500,361271,226037,61.51\nFL,Hendry County,10879,4998,5780,46.37\nFL,Lee County,269276,119701,147608,44.78\nFL,Collier County,141988,54450,86379,38.66\nFL,Broward County,733899,492640,237729,67.45\nFL,Miami-Dade County,863486,499831,360551,58.09\nFL,Monroe County,40272,20907,18933,52.48\nOH,Ottawa County,23069,12049,10618,53.16\nOH,Sandusky County,30373,15601,14190,52.4\nOH,Summit County,269059,155105,110499,58.36\nOH,Athens County,31098,20722,9742,68.02\nOH,Butler County,173777,66030,105341,38.53\nOH,Clinton County,19305,6558,12409,34.58\nOH,Cuyahoga County,665352,458422,199880,69.64\nOH,Franklin County,560325,334709,218486,60.5\nOH,Hamilton County,425086,225213,195530,53.53\nOH,Highland County,19186,6856,11907,36.54\nOH,Hocking County,12961,6259,6364,49.58\nOH,Licking County,82356,33932,46918,41.97\nOH,Madison County,17454,6532,10606,38.11",
        "score": 63,
        "is_accepted": false,
        "creation_date": "2019-08-04T17:15:59",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/78427983/why-does-dictid-1-id-2-sometimes-raise-keyerror-id-instead-of-a",
    "title": "Why does `dict(id=1, **{&#39;id&#39;: 2})` sometimes raise `KeyError: &#39;id&#39;` instead of a TypeError?",
    "question_id": 78427983,
    "posted_date": "2024-05-04T02:19:19",
    "answers": [
      {
        "answer_id": 78428126,
        "body": "In [1]: import dis\nIn [2]: dis.dis(\"dict(id=1, **{'id': 2})\")\n  1           0 LOAD_NAME                0 (dict)\n              2 LOAD_CONST               3 (())\n              4 LOAD_CONST               0 ('id')\n              6 LOAD_CONST               1 (1)\n              8 BUILD_MAP                1\n             10 LOAD_CONST               0 ('id')\n             12 LOAD_CONST               2 (2)\n             14 BUILD_MAP                1\n             16 DICT_MERGE               1\n             18 CALL_FUNCTION_EX         1\n             20 RETURN_VALUE",
        "score": 48,
        "is_accepted": true,
        "creation_date": "2024-05-04T03:15:42",
        "author": "user2357112"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9505898/conditional-command-line-arguments-in-python-using-argparse",
    "title": "Conditional command line arguments in Python using argparse",
    "question_id": 9505898,
    "posted_date": "2012-02-29T15:13:15",
    "answers": [
      {
        "answer_id": 13706448,
        "body": "$ python ap.py tmp.txt upload\nusage: ap.py file upload [-h] {amazon,imgur}\nap.py file upload: error: too few arguments\n$ python ap.py tmp.txt upload amazo\nusage: ap.py file upload [-h] {amazon,imgur}\nap.py file upload: error: argument server: invalid choice: 'amazo' (choose from 'amazon', 'imgur')\n$ python ap.py tmp.txt upload amazon\nNamespace(file='tmp.txt', server='amazon', subcommand='upload')\nI will now upload \"tmp.txt\" to amazon\n$ python ap.py tmp.txt upload imgur\nNamespace(file='tmp.txt', server='imgur', subcommand='upload')\nI will now upload \"tmp.txt\" to imgur",
        "score": 83,
        "is_accepted": false,
        "creation_date": "2012-12-04T10:37:52",
        "author": "Niels Bom"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72005302/completely-uninstall-python-3-on-mac",
    "title": "Completely uninstall Python 3 on Mac",
    "question_id": 72005302,
    "posted_date": "2022-04-25T16:16:55",
    "answers": [
      {
        "answer_id": 72005684,
        "body": "# Remove the application\nsudo rm -rf /Applications/Python\\ 3.x\n# Check for framework files\nls -la /Library/Frameworks/Python.framework/Versions/\n# If found, remove the specific version\nsudo rm -rf /Library/Frameworks/Python.framework/Versions/3.x\n# Check for and remove symbolic links\n# For Intel Macs:\ncd /usr/local/bin\nls -l | grep '../Library/Frameworks/Python.framework/Versions/3.x' | awk '{print $9}' | xargs rm -f\n# For Apple Silicon:\ncd /opt/homebrew/bin\nls -l | grep '../Library/Frameworks/Python.framework/Versions/3.x' | awk '{print $9}' | xargs rm -f\n# Check for user-specific packages\nls -l ~/Library/Python/\n# Remove if needed\nrm -rf ~/Library/Python/3.x/",
        "score": 67,
        "is_accepted": true,
        "creation_date": "2022-04-25T16:58:50",
        "author": "zayadur"
      },
      {
        "answer_id": 72005684,
        "body": "# List all installed Python versions\npyenv versions\n# Show the current active version\npyenv version\n# Uninstall a specific version\npyenv uninstall 3.x.y\n# Check pyenv installation location\nls -la ~/.pyenv/versions/\n# Remove pyenv shims and rehash\npyenv rehash\n# If you want to completely remove pyenv itself\n# For Homebrew installation:\nbrew uninstall pyenv\n# For manual installation:\nrm -rf ~/.pyenv\n# Don't forget to remove pyenv initialization from your shell profile\n# (.bash_profile, .zshrc, etc.)",
        "score": 67,
        "is_accepted": true,
        "creation_date": "2022-04-25T16:58:50",
        "author": "zayadur"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/12788217/how-can-i-extract-a-single-value-from-a-nested-data-structure-such-as-from-pars",
    "title": "How can I extract a single value from a nested data structure (such as from parsing JSON)?",
    "question_id": 12788217,
    "posted_date": "2012-10-08T15:30:29",
    "answers": [
      {
        "answer_id": 12788284,
        "body": ">>> print(json.dumps(my_json, indent=4))\n{\n    \"name\": \"ns1:timeSeriesResponseType\",\n    \"declaredType\": \"org.cuahsi.waterml.TimeSeriesResponseType\",\n    \"scope\": \"javax.xml.bind.JAXBElement$GlobalScope\",\n    \"value\": {\n        \"queryInfo\": {\n            \"creationTime\": 1349724919000,\n            \"queryURL\": \"http://waterservices.usgs.gov/nwis/iv/\",\n            \"criteria\": {\n                \"locationParam\": \"[ALL:103232434]\",\n                \"variableParam\": \"[00060, 00065]\"\n            },\n            \"note\": [\n                {\n                    \"value\": \"[ALL:103232434]\",\n                    \"title\": \"filter:sites\"\n                },\n                {\n                    \"value\": \"[mode=LATEST, modifiedSince=null]\",\n                    \"title\": \"filter:timeRange\"\n                },\n                {\n                    \"value\": \"sdas01\",\n                    \"title\": \"server\"\n                }\n            ]\n        }\n    },\n    \"nil\": false,\n    \"globalScope\": true,\n    \"typeSubstituted\": false\n}",
        "score": 91,
        "is_accepted": true,
        "creation_date": "2012-10-08T15:35:45",
        "author": "dm03514"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21182725/how-to-use-query-strings-for-filtering-querysets-in-django",
    "title": "How to use Query Strings for filtering Querysets in Django?",
    "question_id": 21182725,
    "posted_date": "2014-01-17T04:50:35",
    "answers": [
      {
        "answer_id": 21186065,
        "body": "class PassengerList(generics.ListCreateAPIView):\n    model = Passenger\n    serializer_class = PassengerSerializer\n    # Show all of the PASSENGERS in particular WORKSPACE\n    # or all of the PASSENGERS in particular AIRLINE\n    def get_queryset(self):\n        queryset = Passenger.objects.all()\n        workspace = self.request.query_params.get('workspace')\n        airline = self.request.query_params.get('airline')\n        if workspace:\n            queryset = queryset.filter(workspace_id=workspace)\n        elif airline:\n            queryset = queryset.filter(workspace__airline_id=airline)\n        return queryset",
        "score": 81,
        "is_accepted": true,
        "creation_date": "2014-01-17T07:29:00",
        "author": "knowbody"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45022566/create-python-cli-with-select-interface",
    "title": "Create Python CLI with select interface",
    "question_id": 45022566,
    "posted_date": "2017-07-10T18:22:41",
    "answers": [
      {
        "answer_id": 45033647,
        "body": "from whaaaaat import prompt, print_json, Separator\nquestions = [\n    {\n        \"type\": \"list\",\n        \"name\": \"theme\",\n        \"message\": \"What do you want to do?\",\n        \"choices\": [\n            \"Order a pizza\",\n            \"Make a reservation\",\n            Separator(),\n            \"Ask for opening hours\",\n            {\"name\": \"Contact support\", \"disabled\": \"Unavailable at this time\"},\n            \"Talk to the receptionist\",\n        ],\n    },\n    {\n        \"type\": \"list\",\n        \"name\": \"size\",\n        \"message\": \"What size do you need?\",\n        \"choices\": [\"Jumbo\", \"Large\", \"Standard\", \"Medium\", \"Small\", \"Micro\"],\n        \"filter\": lambda val: val.lower(),\n    },\n]\nanswers = prompt(questions)\nprint_json(answers)",
        "score": 67,
        "is_accepted": true,
        "creation_date": "2017-07-11T07:44:36",
        "author": "Dan Zheng"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/75556221/why-is-np-dot-so-much-faster-than-np-sum",
    "title": "Why is np.dot so much faster than np.sum?",
    "question_id": 75556221,
    "posted_date": "2023-02-24T06:48:28",
    "answers": [
      {
        "answer_id": 75556678,
        "body": "# L3 cache of 9 MiB\n# 2 x 22.9 = 45.8 MiB\na = np.ones(3_000_000)\nb = np.ones(3_000_000)\n%timeit -n 100 np.dot(a, a)   #  494 \u00b5s => read from RAM\n%timeit -n 100 np.dot(a, b)   # 1007 \u00b5s => read from RAM\n# 2 x 7.6 = 15.2 MiB\na = np.ones(1_000_000)\nb = np.ones(1_000_000)\n%timeit -n 100 np.dot(a, a)   #  90 \u00b5s => read from the L3 cache\n%timeit -n 100 np.dot(a, b)   # 283 \u00b5s => read from RAM\n# 2 x 1.9 = 3.8 MiB\na = np.ones(250_000)\nb = np.ones(250_000)\n%timeit -n 100 np.dot(a, a)   # 40 \u00b5s => read from the L3 cache (quite compute-bound)\n%timeit -n 100 np.dot(a, b)   # 46 \u00b5s => read from the L3 cache too (quite memory-bound)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2023-02-24T07:40:02",
        "author": "J&#233;r&#244;me Richard"
      },
      {
        "answer_id": 75556678,
        "body": ".LBB0_7:\n        vaddpd  (%r9,%rdx,8), %ymm0, %ymm0\n        vaddpd  32(%r9,%rdx,8), %ymm1, %ymm1\n        vaddpd  64(%r9,%rdx,8), %ymm2, %ymm2\n        vaddpd  96(%r9,%rdx,8), %ymm3, %ymm3\n        vaddpd  128(%r9,%rdx,8), %ymm0, %ymm0\n        vaddpd  160(%r9,%rdx,8), %ymm1, %ymm1\n        vaddpd  192(%r9,%rdx,8), %ymm2, %ymm2\n        vaddpd  224(%r9,%rdx,8), %ymm3, %ymm3\n        vaddpd  256(%r9,%rdx,8), %ymm0, %ymm0\n        vaddpd  288(%r9,%rdx,8), %ymm1, %ymm1\n        vaddpd  320(%r9,%rdx,8), %ymm2, %ymm2\n        vaddpd  352(%r9,%rdx,8), %ymm3, %ymm3\n        vaddpd  384(%r9,%rdx,8), %ymm0, %ymm0\n        vaddpd  416(%r9,%rdx,8), %ymm1, %ymm1\n        vaddpd  448(%r9,%rdx,8), %ymm2, %ymm2\n        vaddpd  480(%r9,%rdx,8), %ymm3, %ymm3\n        addq    $64, %rdx\n        addq    $-4, %r11\n        jne     .LBB0_7",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2023-02-24T07:40:02",
        "author": "J&#233;r&#244;me Richard"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/35538882/how-to-remove-the-duplicate-legend-when-overlaying-boxplot-and-stripplot",
    "title": "How to remove the duplicate legend when overlaying boxplot and stripplot",
    "question_id": 35538882,
    "posted_date": "2016-02-21T11:48:03",
    "answers": [
      {
        "answer_id": 35539098,
        "body": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ntips = sns.load_dataset(\"tips\")\nsns.stripplot(x=\"day\", y=\"total_bill\", hue=\"smoker\", data=tips, jitter=True, palette=\"Set2\", dodge=True, linewidth=1, edgecolor='gray')\n# Get the ax object to use later.\nax = sns.boxplot(x=\"day\", y=\"total_bill\", hue=\"smoker\", data=tips, palette=\"Set2\", fliersize=0)\n# Get the handles and labels. For this example it'll be 2 tuples\n# of length 4 each.\nhandles, labels = ax.get_legend_handles_labels()\n# When creating the legend, only use the first two elements\n# to effectively remove the last two.\nl = plt.legend(handles[0:2], labels[0:2], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)",
        "score": 57,
        "is_accepted": true,
        "creation_date": "2016-02-21T12:05:56",
        "author": "Ffisegydd"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/36243538/how-often-do-i-have-to-commit-to-ensure-sqlite-execution-statements-all-get-comm",
    "title": "How often do I have to commit to ensure SQLite execution statements all get committed?",
    "question_id": 36243538,
    "posted_date": "2016-03-26T23:31:40",
    "answers": [
      {
        "answer_id": 36244223,
        "body": "import os\nimport sqlite3\n_DBPATH = \"./q6996603.sqlite\"\ndef fresh_db():\n    if os.path.isfile(_DBPATH):\n        os.remove(_DBPATH)\n    with sqlite3.connect(_DBPATH) as conn:\n        cur = conn.cursor().executescript(\"\"\"\n            CREATE TABLE \"mytable\" (\n                \"id\" INTEGER PRIMARY KEY AUTOINCREMENT, -- rowid\n                \"data\" INTEGER\n            );\n            \"\"\")\n    print \"created %s\" % _DBPATH\n# functions are syntactic sugar only and use global conn, cur, rowid\ndef select():\n    sql = 'select * from \"mytable\"'\n    rows = cur.execute(sql).fetchall()\n    print \"   same connection sees\", rows\n    # simulate another script accessing tha database concurrently\n    with sqlite3.connect(_DBPATH) as conn2:\n        rows = conn2.cursor().execute(sql).fetchall()\n    print \"   other connection sees\", rows\ndef count():\n    print \"counting up\"\n    cur.execute('update \"mytable\" set data = data + 1 where \"id\" = ?', (rowid,))\ndef commit():\n    print \"commit\"\n    conn.commit()\n# now the script\nfresh_db()\nwith sqlite3.connect(_DBPATH) as conn:\n    print \"--- prepare test case\"\n    sql = 'insert into \"mytable\"(data) values(17)'\n    print sql\n    cur = conn.cursor().execute(sql)\n    rowid = cur.lastrowid\n    print \"rowid =\", rowid\n    commit()\n    select()\n    print \"--- two consecutive w/o commit\"\n    count()\n    select()\n    count()\n    select()\n    commit()\n    select()\n    print \"--- two consecutive with commit\"\n    count()\n    select()\n    commit()\n    select()\n    count()\n    select()\n    commit()\n    select()",
        "score": 62,
        "is_accepted": true,
        "creation_date": "2016-03-27T01:38:33",
        "author": "flaschbier"
      },
      {
        "answer_id": 36244223,
        "body": "$ python try.py\ncreated ./q6996603.sqlite\n--- prepare test case\ninsert into \"mytable\"(data) values(17)\nrowid = 1\ncommit\n   same connection sees [(1, 17)]\n   other connection sees [(1, 17)]\n--- two consecutive w/o commit\ncounting up\n   same connection sees [(1, 18)]\n   other connection sees [(1, 17)]\ncounting up\n   same connection sees [(1, 19)]\n   other connection sees [(1, 17)]\ncommit\n   same connection sees [(1, 19)]\n   other connection sees [(1, 19)]\n--- two consecutive with commit\ncounting up\n   same connection sees [(1, 20)]\n   other connection sees [(1, 19)]\ncommit\n   same connection sees [(1, 20)]\n   other connection sees [(1, 20)]\ncounting up\n   same connection sees [(1, 21)]\n   other connection sees [(1, 20)]\ncommit\n   same connection sees [(1, 21)]\n   other connection sees [(1, 21)]\n$",
        "score": 62,
        "is_accepted": true,
        "creation_date": "2016-03-27T01:38:33",
        "author": "flaschbier"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/38649501/labeling-boxplot-in-seaborn-with-median-value",
    "title": "Labeling boxplot in seaborn with median value",
    "question_id": 38649501,
    "posted_date": "2016-07-28T22:13:10",
    "answers": [
      {
        "answer_id": 63295846,
        "body": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as path_effects\ndef add_median_labels(ax: plt.Axes, fmt: str = \".1f\") -> None:\n    \"\"\"Add text labels to the median lines of a seaborn boxplot.\n    Args:\n        ax: plt.Axes, e.g. the return value of sns.boxplot()\n        fmt: format string for the median value\n    \"\"\"\n    lines = ax.get_lines()\n    boxes = [c for c in ax.get_children() if \"Patch\" in str(c)]\n    start = 4\n    if not boxes:  # seaborn v0.13 => fill=False => no patches => +1 line\n        boxes = [c for c in ax.get_lines() if len(c.get_xdata()) == 5]\n        start += 1\n    lines_per_box = len(lines) // len(boxes)\n    for median in lines[start::lines_per_box]:\n        x, y = (data.mean() for data in median.get_data())\n        # choose value depending on horizontal or vertical plot orientation\n        value = x if len(set(median.get_xdata())) == 1 else y\n        text = ax.text(x, y, f'{value:{fmt}}', ha='center', va='center',\n                       fontweight='bold', color='white')\n        # create median-colored border around white text for contrast\n        text.set_path_effects([\n            path_effects.Stroke(linewidth=3, foreground=median.get_color()),\n            path_effects.Normal(),\n        ])\ntips = sns.load_dataset(\"tips\")\nax = sns.boxplot(data=tips, x='day', y='total_bill', hue=\"sex\")\nadd_median_labels(ax)\nplt.show()",
        "score": 48,
        "is_accepted": false,
        "creation_date": "2020-08-07T01:39:52",
        "author": "Christian Karcher"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48619517/call-a-click-command-from-code",
    "title": "Call a click command from code",
    "question_id": 48619517,
    "posted_date": "2018-02-05T04:40:03",
    "answers": [
      {
        "answer_id": 54259095,
        "body": "import click\n@click.command()\n@click.option('-w', '--width', type=int, default=0)\n@click.option('--option2')\n@click.argument('argument')\ndef app(width, option2, argument):\n    click.echo(\"params: {} {} {}\".format(width, option2, argument))\n    assert width == 3\n    assert option2 == '4'\n    assert argument == 'arg'\napp([\"arg\", \"--option2\", \"4\", \"-w\", 3], standalone_mode=False)\napp([\"arg\", \"-w\", 3, \"--option2\", \"4\" ], standalone_mode=False)\napp([\"-w\", 3, \"--option2\", \"4\", \"arg\"], standalone_mode=False)",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2019-01-18T12:48:27",
        "author": "Massimo Frasson"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47094949/labeling-edges-in-networkx",
    "title": "Labeling edges in networkx",
    "question_id": 47094949,
    "posted_date": "2017-11-03T07:41:05",
    "answers": [
      {
        "answer_id": 47135311,
        "body": "import matplotlib.pyplot as plt\nimport networkx as nx\nedges = [['A', 'B'], ['B', 'C'], ['B', 'D']]\nG = nx.Graph()\nG.add_edges_from(edges)\npos = nx.spring_layout(G)\nplt.figure()\nnx.draw(\n    G, pos, edge_color='black', width=1, linewidths=1,\n    node_size=500, node_color='pink', alpha=0.9,\n    labels={node: node for node in G.nodes()}\n)\nnx.draw_networkx_edge_labels(\n    G, pos,\n    edge_labels={('A', 'B'): 'AB',\n                 ('B', 'C'): 'BC',\n                 ('B', 'D'): 'BD'},\n    font_color='red'\n)\nplt.axis('off')\nplt.show()",
        "score": 101,
        "is_accepted": true,
        "creation_date": "2017-11-06T05:56:42",
        "author": "Odin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56637973/how-to-fix-selenium-devtoolsactiveport-file-doesnt-exist-exception-in-python",
    "title": "How to fix selenium &quot;DevToolsActivePort file doesn&#39;t exist&quot; exception in Python",
    "question_id": 56637973,
    "posted_date": "2019-06-17T15:47:18",
    "answers": [
      {
        "answer_id": 56638103,
        "body": "chromeOptions = webdriver.ChromeOptions()\nchromeOptions.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\nchromeOptions.add_argument(\"--no-sandbox\")\nchromeOptions.add_argument(\"--disable-setuid-sandbox\")\nchromeOptions.add_argument(\"--remote-debugging-port=9222\")  # this\nchromeOptions.add_argument(\"--disable-dev-shm-using\")\nchromeOptions.add_argument(\"--disable-extensions\")\nchromeOptions.add_argument(\"--disable-gpu\")\nchromeOptions.add_argument(\"start-maximized\")\nchromeOptions.add_argument(\"disable-infobars\")\nchromeOptions.add_argument(r\"user-data-dir=.\\cookies\\\\test\")\nb = webdriver.Chrome(chrome_options=chromeOptions)\nb.get(\"https://google.com/\")\nb.quit()",
        "score": 109,
        "is_accepted": true,
        "creation_date": "2019-06-17T15:57:06",
        "author": "vffuunnyy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2070276/where-can-i-find-source-or-algorithm-of-pythons-hash-function",
    "title": "Where can I find source or algorithm of Python&#39;s hash() function?",
    "question_id": 2070276,
    "posted_date": "2010-01-15T03:26:46",
    "answers": [
      {
        "answer_id": 50224935,
        "body": "/* For numeric types, the hash of a number x is based on the reduction\n   of x modulo the prime P = 2**_PyHASH_BITS - 1.  It's designed so that\n   hash(x) == hash(y) whenever x and y are numerically equal, even if\n   x and y have different types.\n   A quick summary of the hashing strategy:\n   (1) First define the 'reduction of x modulo P' for any rational\n   number x; this is a standard extension of the usual notion of\n   reduction modulo P for integers.  If x == p/q (written in lowest\n   terms), the reduction is interpreted as the reduction of p times\n   the inverse of the reduction of q, all modulo P; if q is exactly\n   divisible by P then define the reduction to be infinity.  So we've\n   got a well-defined map\n      reduce : { rational numbers } -> { 0, 1, 2, ..., P-1, infinity }.\n   (2) Now for a rational number x, define hash(x) by:\n      reduce(x)   if x >= 0\n      -reduce(-x) if x < 0\n   If the result of the reduction is infinity (this is impossible for\n   integers, floats and Decimals) then use the predefined hash value\n   _PyHASH_INF for x >= 0, or -_PyHASH_INF for x < 0, instead.\n   _PyHASH_INF and -_PyHASH_INF are also used for the\n   hashes of float and Decimal infinities.\n   NaNs hash with a pointer hash.  Having distinct hash values prevents\n   catastrophic pileups from distinct NaN instances which used to always\n   have the same hash value but would compare unequal.\n   A selling point for the above strategy is that it makes it possible\n   to compute hashes of decimal and binary floating-point numbers\n   efficiently, even if the exponent of the binary or decimal number\n   is large.  The key point is that\n      reduce(x * y) == reduce(x) * reduce(y) (modulo _PyHASH_MODULUS)\n   provided that {reduce(x), reduce(y)} != {0, infinity}.  The reduction of a\n   binary or decimal float is never infinity, since the denominator is a power\n   of 2 (for binary) or a divisor of a power of 10 (for decimal).  So we have,\n   for nonnegative x,\n      reduce(x * 2**e) == reduce(x) * reduce(2**e) % _PyHASH_MODULUS\n      reduce(x * 10**e) == reduce(x) * reduce(10**e) % _PyHASH_MODULUS\n   and reduce(10**e) can be computed efficiently by the usual modular\n   exponentiation algorithm.  For reduce(2**e) it's even better: since\n   P is of the form 2**n-1, reduce(2**e) is 2**(e mod n), and multiplication\n   by 2**(e mod n) modulo 2**n-1 just amounts to a rotation of bits.\n   */",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      },
      {
        "answer_id": 50224935,
        "body": "Py_hash_t\n_Py_HashDouble(double v)\n{\n    int e, sign;\n    double m;\n    Py_uhash_t x, y;\n    if (!Py_IS_FINITE(v)) {\n        if (Py_IS_INFINITY(v))\n            return v > 0 ? _PyHASH_INF : -_PyHASH_INF;\n        else\n            return _PyHASH_NAN;\n    }\n    m = frexp(v, &e);\n    sign = 1;\n    if (m < 0) {\n        sign = -1;\n        m = -m;\n    }\n    /* process 28 bits at a time;  this should work well both for binary\n       and hexadecimal floating point. */\n    x = 0;\n    while (m) {\n        x = ((x << 28) & _PyHASH_MODULUS) | x >> (_PyHASH_BITS - 28);\n        m *= 268435456.0;  /* 2**28 */\n        e -= 28;\n        y = (Py_uhash_t)m;  /* pull out integer part */\n        m -= y;\n        x += y;\n        if (x >= _PyHASH_MODULUS)\n            x -= _PyHASH_MODULUS;\n    }\n    /* adjust for the exponent;  first reduce it modulo _PyHASH_BITS */\n    e = e >= 0 ? e % _PyHASH_BITS : _PyHASH_BITS-1-((-1-e) % _PyHASH_BITS);\n    x = ((x << e) & _PyHASH_MODULUS) | x >> (_PyHASH_BITS - e);\n    x = x * sign;\n    if (x == (Py_uhash_t)-1)\n        x = (Py_uhash_t)-2;\n    return (Py_hash_t)x;\n}",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      },
      {
        "answer_id": 50224935,
        "body": "Py_hash_t\n_Py_HashBytes(const void *src, Py_ssize_t len)\n{\n    Py_hash_t x;\n    /*\n      We make the hash of the empty string be 0, rather than using\n      (prefix ^ suffix), since this slightly obfuscates the hash secret\n    */\n    if (len == 0) {\n        return 0;\n    }\n#ifdef Py_HASH_STATS\n    hashstats[(len <= Py_HASH_STATS_MAX) ? len : 0]++;\n#endif\n#if Py_HASH_CUTOFF > 0\n    if (len < Py_HASH_CUTOFF) {\n        /* Optimize hashing of very small strings with inline DJBX33A. */\n        Py_uhash_t hash;\n        const unsigned char *p = src;\n        hash = 5381; /* DJBX33A starts with 5381 */\n        switch(len) {\n            /* ((hash << 5) + hash) + *p == hash * 33 + *p */\n            case 7: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 6: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 5: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 4: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 3: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 2: hash = ((hash << 5) + hash) + *p++; /* fallthrough */\n            case 1: hash = ((hash << 5) + hash) + *p++; break;\n            default:\n                Py_UNREACHABLE();\n        }\n        hash ^= len;\n        hash ^= (Py_uhash_t) _Py_HashSecret.djbx33a.suffix;\n        x = (Py_hash_t)hash;\n    }\n    else\n#endif /* Py_HASH_CUTOFF */\n        x = PyHash_Func.hash(src, len);\n    if (x == -1)\n        return -2;\n    return x;\n}",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      },
      {
        "answer_id": 50224935,
        "body": "#if Py_HASH_ALGORITHM == Py_HASH_FNV\n/* **************************************************************************\n * Modified Fowler-Noll-Vo (FNV) hash function\n */\nstatic Py_hash_t\nfnv(const void *src, Py_ssize_t len)\n{\n    const unsigned char *p = src;\n    Py_uhash_t x;\n    Py_ssize_t remainder, blocks;\n    union {\n        Py_uhash_t value;\n        unsigned char bytes[SIZEOF_PY_UHASH_T];\n    } block;\n#ifdef Py_DEBUG\n    assert(_Py_HashSecret_Initialized);\n#endif\n    remainder = len % SIZEOF_PY_UHASH_T;\n    if (remainder == 0) {\n        /* Process at least one block byte by byte to reduce hash collisions\n         * for strings with common prefixes. */\n        remainder = SIZEOF_PY_UHASH_T;\n    }\n    blocks = (len - remainder) / SIZEOF_PY_UHASH_T;\n    x = (Py_uhash_t) _Py_HashSecret.fnv.prefix;\n    x ^= (Py_uhash_t) *p << 7;\n    while (blocks--) {\n        PY_UHASH_CPY(block.bytes, p);\n        x = (_PyHASH_MULTIPLIER * x) ^ block.value;\n        p += SIZEOF_PY_UHASH_T;\n    }\n    /* add remainder */\n    for (; remainder > 0; remainder--)\n        x = (_PyHASH_MULTIPLIER * x) ^ (Py_uhash_t) *p++;\n    x ^= (Py_uhash_t) len;\n    x ^= (Py_uhash_t) _Py_HashSecret.fnv.suffix;\n    if (x == -1) {\n        x = -2;\n    }\n    return x;\n}\nstatic PyHash_FuncDef PyHash_Func = {fnv, \"fnv\", 8 * SIZEOF_PY_HASH_T,\n                                     16 * SIZEOF_PY_HASH_T};\n#endif /* Py_HASH_ALGORITHM == Py_HASH_FNV */",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      },
      {
        "answer_id": 50224935,
        "body": "/* byte swap little endian to host endian\n * Endian conversion not only ensures that the hash function returns the same\n * value on all platforms. It is also required to for a good dispersion of\n * the hash values' least significant bits.\n */\n#if PY_LITTLE_ENDIAN\n#  define _le64toh(x) ((uint64_t)(x))\n#elif defined(__APPLE__)\n#  define _le64toh(x) OSSwapLittleToHostInt64(x)\n#elif defined(HAVE_LETOH64)\n#  define _le64toh(x) le64toh(x)\n#else\n#  define _le64toh(x) (((uint64_t)(x) << 56) | \\\n                      (((uint64_t)(x) << 40) & 0xff000000000000ULL) | \\\n                      (((uint64_t)(x) << 24) & 0xff0000000000ULL) | \\\n                      (((uint64_t)(x) << 8)  & 0xff00000000ULL) | \\\n                      (((uint64_t)(x) >> 8)  & 0xff000000ULL) | \\\n                      (((uint64_t)(x) >> 24) & 0xff0000ULL) | \\\n                      (((uint64_t)(x) >> 40) & 0xff00ULL) | \\\n                      ((uint64_t)(x)  >> 56))\n#endif\n#ifdef _MSC_VER\n#  define ROTATE(x, b)  _rotl64(x, b)\n#else\n#  define ROTATE(x, b) (uint64_t)( ((x) << (b)) | ( (x) >> (64 - (b))) )\n#endif\n#define HALF_ROUND(a,b,c,d,s,t)         \\\n    a += b; c += d;             \\\n    b = ROTATE(b, s) ^ a;           \\\n    d = ROTATE(d, t) ^ c;           \\\n    a = ROTATE(a, 32);\n#define DOUBLE_ROUND(v0,v1,v2,v3)       \\\n    HALF_ROUND(v0,v1,v2,v3,13,16);      \\\n    HALF_ROUND(v2,v1,v0,v3,17,21);      \\\n    HALF_ROUND(v0,v1,v2,v3,13,16);      \\\n    HALF_ROUND(v2,v1,v0,v3,17,21);\nstatic uint64_t\nsiphash24(uint64_t k0, uint64_t k1, const void *src, Py_ssize_t src_sz) {\n    uint64_t b = (uint64_t)src_sz << 56;\n    const uint64_t *in = (uint64_t*)src;\n    uint64_t v0 = k0 ^ 0x736f6d6570736575ULL;\n    uint64_t v1 = k1 ^ 0x646f72616e646f6dULL;\n    uint64_t v2 = k0 ^ 0x6c7967656e657261ULL;\n    uint64_t v3 = k1 ^ 0x7465646279746573ULL;\n    uint64_t t;\n    uint8_t *pt;\n    uint8_t *m;\n    while (src_sz >= 8) {\n        uint64_t mi = _le64toh(*in);\n        in += 1;\n        src_sz -= 8;\n        v3 ^= mi;\n        DOUBLE_ROUND(v0,v1,v2,v3);\n        v0 ^= mi;\n    }\n    t = 0;\n    pt = (uint8_t *)&t;\n    m = (uint8_t *)in;\n    switch (src_sz) {\n        case 7: pt[6] = m[6]; /* fall through */\n        case 6: pt[5] = m[5]; /* fall through */\n        case 5: pt[4] = m[4]; /* fall through */\n        case 4: memcpy(pt, m, sizeof(uint32_t)); break;\n        case 3: pt[2] = m[2]; /* fall through */\n        case 2: pt[1] = m[1]; /* fall through */\n        case 1: pt[0] = m[0]; /* fall through */\n    }\n    b |= _le64toh(t);\n    v3 ^= b;\n    DOUBLE_ROUND(v0,v1,v2,v3);\n    v0 ^= b;\n    v2 ^= 0xff;\n    DOUBLE_ROUND(v0,v1,v2,v3);\n    DOUBLE_ROUND(v0,v1,v2,v3);\n    /* modified */\n    t = (v0 ^ v1) ^ (v2 ^ v3);\n    return t;\n}\nstatic Py_hash_t\npysiphash(const void *src, Py_ssize_t src_sz) {\n    return (Py_hash_t)siphash24(\n        _le64toh(_Py_HashSecret.siphash.k0), _le64toh(_Py_HashSecret.siphash.k1),\n        src, src_sz);\n}\nuint64_t\n_Py_KeyedHash(uint64_t key, const void *src, Py_ssize_t src_sz)\n{\n    return siphash24(key, 0, src, src_sz);\n}\n#if Py_HASH_ALGORITHM == Py_HASH_SIPHASH24\nstatic PyHash_FuncDef PyHash_Func = {pysiphash, \"siphash24\", 64, 128};\n#endif",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      },
      {
        "answer_id": 50224935,
        "body": "static Py_hash_t\ntuplehash(PyTupleObject *v)\n{\n    Py_uhash_t x;  /* Unsigned for defined overflow behavior. */\n    Py_hash_t y;\n    Py_ssize_t len = Py_SIZE(v);\n    PyObject **p;\n    Py_uhash_t mult = _PyHASH_MULTIPLIER;\n    x = 0x345678UL;\n    p = v->ob_item;\n    while (--len >= 0) {\n        y = PyObject_Hash(*p++);\n        if (y == -1)\n            return -1;\n        x = (x ^ y) * mult;\n        /* the cast might truncate len; that doesn't change hash stability */\n        mult += (Py_hash_t)(82520UL + len + len);\n    }\n    x += 97531UL;\n    if (x == (Py_uhash_t)-1)\n        x = -2;\n    return x;\n}",
        "score": 51,
        "is_accepted": false,
        "creation_date": "2018-05-07T22:30:34",
        "author": "qwr"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69786885/after-conda-update-python-kernel-crashes-when-matplotlib-is-used",
    "title": "After conda update, python kernel crashes when matplotlib is used",
    "question_id": 69786885,
    "posted_date": "2021-10-31T08:30:30",
    "answers": [
      {
        "answer_id": 69788527,
        "body": "  2021-10-31 10:47:22  (rev 3)\n     bokeh  {2.3.3 (defaults/win-64) -> 2.4.1 (defaults/win-64)}\n     click  {8.0.1 (defaults/noarch) -> 8.0.3 (defaults/noarch)}\n     filelock  {3.0.12 (defaults/noarch) -> 3.3.1 (defaults/noarch)}\n     freetype  {2.10.4 (defaults/win-64) -> 2.11.0 (defaults/win-64)}\n     imagecodecs  {2021.6.8 (defaults/win-64) -> 2021.8.26 (defaults/win-64)}\n     joblib  {1.0.1 (defaults/noarch) -> 1.1.0 (defaults/noarch)}\n     lerc  {2.2.1 (defaults/win-64) -> 3.0 (defaults/win-64)}\n     more-itertools  {8.8.0 (defaults/noarch) -> 8.10.0 (defaults/noarch)}\n     pyopenssl  {20.0.1 (defaults/noarch) -> 21.0.0 (defaults/noarch)}\n     scikit-learn  {0.24.2 (defaults/win-64) -> 1.0.1 (defaults/win-64)}\n     statsmodels  {0.12.2 (defaults/win-64) -> 0.13.0 (defaults/win-64)}\n     sympy  {1.8 (defaults/win-64) -> 1.9 (defaults/win-64)}\n     tqdm  {4.62.2 (defaults/noarch) -> 4.62.3 (defaults/noarch)}\n     xlwings  {0.24.7 (defaults/win-64) -> 0.24.9 (defaults/win-64)}",
        "score": 75,
        "is_accepted": true,
        "creation_date": "2021-10-31T12:33:54",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/22029562/python-how-to-make-simple-animated-loading-while-process-is-running",
    "title": "Python how to make simple animated loading while process is running",
    "question_id": 22029562,
    "posted_date": "2014-02-25T20:00:50",
    "answers": [
      {
        "answer_id": 66558182,
        "body": "from itertools import cycle\nfrom shutil import get_terminal_size\nfrom threading import Thread\nfrom time import sleep\nclass Loader:\n    def __init__(self, desc=\"Loading...\", end=\"Done!\", timeout=0.1):\n        \"\"\"\n        A loader-like context manager\n        Args:\n            desc (str, optional): The loader's description. Defaults to \"Loading...\".\n            end (str, optional): Final print. Defaults to \"Done!\".\n            timeout (float, optional): Sleep time between prints. Defaults to 0.1.\n        \"\"\"\n        self.desc = desc\n        self.end = end\n        self.timeout = timeout\n        self._thread = Thread(target=self._animate, daemon=True)\n        self.steps = [\"\u28bf\", \"\u28fb\", \"\u28fd\", \"\u28fe\", \"\u28f7\", \"\u28ef\", \"\u28df\", \"\u287f\"]\n        self.done = False\n    def start(self):\n        self._thread.start()\n        return self\n    def _animate(self):\n        for c in cycle(self.steps):\n            if self.done:\n                break\n            print(f\"\\r{self.desc} {c}\", flush=True, end=\"\")\n            sleep(self.timeout)\n    def __enter__(self):\n        self.start()\n    def stop(self):\n        self.done = True\n        cols = get_terminal_size((80, 20)).columns\n        print(\"\\r\" + \" \" * cols, end=\"\", flush=True)\n        print(f\"\\r{self.end}\", flush=True)\n    def __exit__(self, exc_type, exc_value, tb):\n        # handle exceptions with those variables ^\n        self.stop()\nif __name__ == \"__main__\":\n    with Loader(\"Loading with context manager...\"):\n        for i in range(10):\n            sleep(0.25)\n    loader = Loader(\"Loading with object...\", \"That was fast!\", 0.05).start()\n    for i in range(10):\n        sleep(0.25)\n    loader.stop()",
        "score": 49,
        "is_accepted": false,
        "creation_date": "2021-03-09T23:02:21",
        "author": "ted"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/17553543/pyserial-non-blocking-read-loop",
    "title": "PySerial non-blocking read loop",
    "question_id": 17553543,
    "posted_date": "2013-07-09T12:31:30",
    "answers": [
      {
        "answer_id": 38758773,
        "body": "import serial\nimport time # Optional (required if using time.sleep() below)\nser = serial.Serial(port='COM4', baudrate=9600)\nwhile (True):\n    # Check if incoming bytes are waiting to be read from the serial input\n    # buffer.\n    # NB: for PySerial v3.0 or later, use property `in_waiting` instead of\n    # function `inWaiting()` below!\n    if (ser.inWaiting() > 0):\n        # read the bytes and convert from binary array to ASCII\n        data_str = ser.read(ser.inWaiting()).decode('ascii')\n        # print the incoming string without putting a new-line\n        # ('\\n') automatically after every print()\n        print(data_str, end='')\n    # Put the rest of your code you want here\n\n    # Optional, but recommended: sleep 10 ms (0.01 sec) once per loop to let\n    # other threads on your PC run during this time.\n    time.sleep(0.01)",
        "score": 69,
        "is_accepted": false,
        "creation_date": "2016-08-04T00:59:03",
        "author": "Gabriel Staples"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44780736/setting-up-s3-for-logs-in-airflow",
    "title": "setting up s3 for logs in airflow",
    "question_id": 44780736,
    "posted_date": "2017-06-27T08:49:26",
    "answers": [
      {
        "answer_id": 48194903,
        "body": "# -*- coding: utf-8 -*-\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os\nfrom airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG\nfrom airflow import configuration as conf\nfrom copy import deepcopy\nS3_LOG_FOLDER = 's3://your/s3/log/folder'\nLOG_LEVEL = conf.get('logging', 'LOGGING_LEVEL').upper()\nLOG_FORMAT = conf.get('logging', 'log_format')\nBASE_LOG_FOLDER = conf.get('logging', 'BASE_LOG_FOLDER')\nPROCESSOR_LOG_FOLDER = conf.get('scheduler', 'child_process_log_directory')\nFILENAME_TEMPLATE = '{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log'\nPROCESSOR_FILENAME_TEMPLATE = '{{ filename }}.log'\nLOGGING_CONFIG = deepcopy(DEFAULT_LOGGING_CONFIG)\n# Attach formatters to loggers (airflow.task, airflow.processor)\nLOGGING_CONFIG['formatters']['airflow.task'] = { 'format': LOG_FORMAT }\nLOGGING_CONFIG['formatters']['airflow.processor'] = { 'format': LOG_FORMAT }\n# Add an S3 task handler\nLOGGING_CONFIG['handlers']['s3.task'] = {\n    'class': 'airflow.providers.amazon.aws.log.s3_task_handler.S3TaskHandler',\n    'formatter': 'airflow.task',\n    'base_log_folder': os.path.expanduser(BASE_LOG_FOLDER),\n    's3_log_folder': S3_LOG_FOLDER,\n    'filename_template': FILENAME_TEMPLATE\n}\n# Specify handler for airflow.task\nLOGGING_CONFIG['loggers']['airflow.task']['handlers'] = ['task', 's3.task']",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2018-01-10T14:40:42",
        "author": "Arne Huang"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55590343/asyncio-run-or-run-until-complete",
    "title": "asyncio run or run_until_complete",
    "question_id": 55590343,
    "posted_date": "2019-04-09T06:12:12",
    "answers": [
      {
        "answer_id": 55595696,
        "body": "import asyncio, sys, types\ndef run(coro):\n    if sys.version_info >= (3, 7):\n        return asyncio.run(coro)\n    # Emulate asyncio.run() on older versions\n    # asyncio.run() requires a coroutine, so require it here as well\n    if not isinstance(coro, types.CoroutineType):\n        raise TypeError(\"run() requires a coroutine object\")\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n    try:\n        return loop.run_until_complete(coro)\n    finally:\n        loop.close()\n        asyncio.set_event_loop(None)",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2019-04-09T10:54:19",
        "author": "user4815162342"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63392426/how-to-use-tailwindcss-with-django",
    "title": "How to use TailwindCSS with Django?",
    "question_id": 63392426,
    "posted_date": "2020-08-13T05:46:53",
    "answers": [
      {
        "answer_id": 63392427,
        "body": "#!/bin/sh\nset -e\nTAILWIND_ARCHITECTURE=arm64 # chose the right architecture for you\nTAILWIND_VERSION=v3.1.4 # chose the right version\nSOURCE_NAME=tailwindcss-linux-${TAILWIND_ARCHITECTURE}\nOUTPUT_NAME=tailwindcss\nDOWNLOAD_URL=https://github.com/tailwindlabs/tailwindcss/releases/download/${TAILWIND_VERSION}/${SOURCE_NAME}\ncurl -sLO ${DOWNLOAD_URL} && chmod +x ${SOURCE_NAME}\nmv ${SOURCE_NAME} ${OUTPUT_NAME} # rename it\nmv ${OUTPUT_NAME} /usr/bin # move it to be used globally in a folder already in the PATH var",
        "score": 107,
        "is_accepted": true,
        "creation_date": "2020-08-13T05:46:53",
        "author": "David Dahan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/32054066/how-to-run-multiple-coroutines-concurrently-using-asyncio",
    "title": "How to run multiple coroutines concurrently using asyncio?",
    "question_id": 32054066,
    "posted_date": "2015-08-17T11:21:54",
    "answers": [
      {
        "answer_id": 57877288,
        "body": "import asyncio\nasync def factorial(name, number):\n    f = 1\n    for i in range(2, number + 1):\n        print(f\"Task {name}: Compute factorial({i})...\")\n        await asyncio.sleep(1)\n        f *= i\n    print(f\"Task {name}: factorial({number}) = {f}\")\nasync def main():\n    # Schedule three calls *concurrently*:\n    await asyncio.gather(\n        factorial(\"A\", 2),\n        factorial(\"B\", 3),\n        factorial(\"C\", 4),\n    )\nasyncio.run(main())\n# Expected output:\n#\n#     Task A: Compute factorial(2)...\n#     Task B: Compute factorial(2)...\n#     Task C: Compute factorial(2)...\n#     Task A: factorial(2) = 2\n#     Task B: Compute factorial(3)...\n#     Task C: Compute factorial(3)...\n#     Task B: factorial(3) = 6\n#     Task C: Compute factorial(4)...\n#     Task C: factorial(4) = 24",
        "score": 50,
        "is_accepted": false,
        "creation_date": "2019-09-10T15:42:27",
        "author": "Cyril N."
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54023782/pydantic-make-field-none-in-validator-based-on-other-fields-value",
    "title": "Pydantic: Make field None in validator based on other field&#39;s value",
    "question_id": 54023782,
    "posted_date": "2019-01-03T08:59:35",
    "answers": [
      {
        "answer_id": 65128634,
        "body": ">>> from datetime import date\n>>> from typing import List, Optional\n>>> from pydantic import BaseModel, validator\n>>> class Model(BaseModel):\n        some_list: List[date]\n        some_date: Optional[date]\n\n        @validator(\"some_date\", always=True)\n        def validate_date(cls, value, values):\n            if len(values[\"some_list\"]) < 2:\n                return None\n            return values[\"some_list\"][0]\n>>> Model(some_list=['2019-01-03', '2020-01-03', '2021-01-03'])\nModel(some_list=[datetime.date(2019, 1, 3), datetime.date(2020, 1, 3), datetime.date(2021, 1, 3)],\n      some_date=datetime.date(2019, 1, 3))",
        "score": 67,
        "is_accepted": false,
        "creation_date": "2020-12-03T10:09:24",
        "author": "tupui"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21213417/select-checkbox-using-selenium-with-python",
    "title": "Select checkbox using Selenium with Python",
    "question_id": 21213417,
    "posted_date": "2014-01-19T00:05:10",
    "answers": [
      {
        "answer_id": 21213482,
        "body": "import time\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.common.exceptions import NoSuchElementException\nbrowser = webdriver.Firefox()\nurl = 'http://reverb.echo.nasa.gov/reverb/'\nbrowser.get(url)\nfor i in range(10):\n    try:\n        browser.find_element(By.XPATH,\n            \".//*[contains(text(), '15 Minute Stream Flow Data: USGS (FIFE)')]\"\n        ).click()\n        break\n    except NoSuchElementException as e:\n        print('Retry in 1 second')\n        time.sleep(1)\nelse:\n    raise e",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2014-01-19T00:15:46",
        "author": "falsetru"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58293187/opencv-real-time-streaming-video-capture-is-slow-how-to-drop-frames-or-get-sync",
    "title": "OpenCV real time streaming video capture is slow. How to drop frames or get synced with real time?",
    "question_id": 58293187,
    "posted_date": "2019-10-08T15:52:39",
    "answers": [
      {
        "answer_id": 58386085,
        "body": "from threading import Thread\nimport cv2, time\nclass ThreadedCamera(object):\n    def __init__(self, src=0):\n        self.capture = cv2.VideoCapture(src)\n        self.capture.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n\n        # FPS = 1/X\n        # X = desired FPS\n        self.FPS = 1/30\n        self.FPS_MS = int(self.FPS * 1000)\n\n        # Start frame retrieval thread\n        self.thread = Thread(target=self.update, args=())\n        self.thread.daemon = True\n        self.thread.start()\n\n    def update(self):\n        while True:\n            if self.capture.isOpened():\n                (self.status, self.frame) = self.capture.read()\n            time.sleep(self.FPS)\n\n    def show_frame(self):\n        cv2.imshow('frame', self.frame)\n        cv2.waitKey(self.FPS_MS)\nif __name__ == '__main__':\n    src = 'https://videos3.earthcam.com/fecnetwork/9974.flv/chunklist_w1421640637.m3u8'\n    threaded_camera = ThreadedCamera(src)\n    while True:\n        try:\n            threaded_camera.show_frame()\n        except AttributeError:\n            pass",
        "score": 43,
        "is_accepted": true,
        "creation_date": "2019-10-14T21:37:43",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16650945/merge-on-single-level-of-multiindex",
    "title": "Merge on single level of MultiIndex",
    "question_id": 16650945,
    "posted_date": "2013-05-20T09:45:50",
    "answers": [
      {
        "answer_id": 22365284,
        "body": "index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n                                        ('K1', 'X2')],\n                                        names=['key', 'X'])\nleft = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                     'B': ['B0', 'B1', 'B2']}, index=index_left)\nindex_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n                                        ('K2', 'Y2'), ('K2', 'Y3')],\n                                        names=['key', 'Y'])\nright = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\nleft.join(right)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2014-03-12T18:31:00",
        "author": "joelostblom"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9522877/pythonic-way-to-have-a-choice-of-2-3-options-as-an-argument-to-a-function",
    "title": "Pythonic way to have a choice of 2-3 options as an argument to a function",
    "question_id": 9522877,
    "posted_date": "2012-03-01T14:45:19",
    "answers": [
      {
        "answer_id": 72832981,
        "body": "from typing import Literal, get_args, get_origin\nfrom sys import _getframe\ndef enforce_literals(function):\n    kwargs = _getframe(1).f_locals\n    for name, type_ in function.__annotations__.items():\n        value = kwargs.get(name)\n        options = get_args(type_)\n        if get_origin(type_) is Literal and name in kwargs and value not in options:\n            raise AssertionError(f\"'{value}' is not in {options} for '{name}'\")\n_TYPES = Literal[\"solar\", \"view\", \"both\"]\n_NUMS = Literal[1, 2, 3, 4, 5]\ndef func(a, b, c, type_: _TYPES = \"solar\", num: _NUMS = 1):\n    enforce_literals(func)\nfunc(1, 2, 3, \"solar\", 6)",
        "score": 42,
        "is_accepted": false,
        "creation_date": "2022-07-01T13:49:33",
        "author": "Mandera"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61693014/how-to-hide-plotly-yaxis-title-in-python",
    "title": "how to hide plotly yaxis title (in python)?",
    "question_id": 61693014,
    "posted_date": "2020-05-09T03:04:51",
    "answers": [
      {
        "answer_id": 61693190,
        "body": "import plotly.graph_objects as go\nfig = go.Figure(\n    data=[go.Bar(y=[2, 1, 3])],\n    layout_title_text=\"A Figure with no axis-title and modified margins\",\n    layout = {\n        'xaxis': {'title': 'x-label',\n                'visible': False,\n                'showticklabels': True},\n        'yaxis': {'title': 'y-label',\n                'visible': False,\n                'showticklabels': False},\n        # specify margins in px\n        'margin': dict(\n            l = 10,        # left\n            r = 10,        # right\n            t = 50,        # top\n            b = 10,        # bottom\n        ),\n    },\n)\nfig",
        "score": 74,
        "is_accepted": true,
        "creation_date": "2020-05-09T03:24:33",
        "author": "CypherX"
      },
      {
        "answer_id": 61693190,
        "body": "## ALL THREE METHODS BELOW ARE EQUIVALENT\n# No dict-flattening\n# layout = dict with yaxis as key\nlayout = {'yaxis': {'title': 'y-label',\n                    'visible': False,\n                    'showticklabels': False}\n}\n# Partial dict-flattening\n# layout_yaxis = dict with key-names\n#     title, visible, showticklabels\nlayout_yaxis = {'title': 'y-label',\n                'visible': False,\n                'showticklabels': False}\n# Complete dict-flattening\n# layout_yaxis_key-name for each of the key-names\nlayout_yaxis_title = 'y-label'\nlayout_yaxis_visible = False\nlayout_yaxis_showticklabels = False",
        "score": 74,
        "is_accepted": true,
        "creation_date": "2020-05-09T03:24:33",
        "author": "CypherX"
      },
      {
        "answer_id": 61693190,
        "body": "import plotly.graph_objects as go\n# Method-1: Shortest (less detailed)\nfig = go.Figure(\n    data=[go.Bar(y=[2, 1, 3])],\n    layout_title_text=\"A Figure Displaying Itself\",\n    layout_yaxis_visible = False,\n    layout_xaxis_title = 'x-label'\n)\nfig.show()\n# Method-2: A hibrid of dicts and underscore-separated-syntax\nfig = go.Figure(\n    data=[go.Bar(y=[2, 1, 3])],\n    layout_title_text=\"A Figure Displaying Itself\",\n    layout_xaxis_title = 'x-label',\n    layout_yaxis = {'title': 'y-label',\n                        'visible': False,\n                        'showticklabels': False}\n)\nfig.show()\n# Method-3: A complete dict syntax\nfig = go.Figure(\n    data=[go.Bar(y=[2, 1, 3])],\n    layout_title_text=\"A Figure Displaying Itself\",\n    layout = {'xaxis': {'title': 'x-label',\n                        'visible': True,\n                        'showticklabels': True},\n              'yaxis': {'title': 'y-label',\n                        'visible': False,\n                        'showticklabels': False}\n              }\n)\nfig.show()",
        "score": 74,
        "is_accepted": true,
        "creation_date": "2020-05-09T03:24:33",
        "author": "CypherX"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61392633/how-to-validate-more-than-one-field-of-a-pydantic-model",
    "title": "How to validate more than one field of a Pydantic model?",
    "question_id": 61392633,
    "posted_date": "2020-04-23T12:49:40",
    "answers": [
      {
        "answer_id": 68486168,
        "body": "import pydantic\nclass Parent(pydantic.BaseModel):\n    name: str\n    comments: str\nclass Customer(Parent):\n    address: str\n    phone: str\n    # If you want to apply the Validator to the fields \"name\", \"comments\", \"address\", \"phone\"\n    @pydantic.validator(\"name\", \"comments\", \"address\", \"phone\")\n    @classmethod\n    def validate_all_fields_one_by_one(cls, field_value):\n        # Do the validation instead of printing\n        print(f\"{cls}: Field value {field_value}\")\n        return field_value  # this is the value written to the class field\n    # if you want to validate to content of \"phone\" using the other fields of the Parent and Child class\n    @pydantic.validator(\"phone\")\n    @classmethod\n    def validate_one_field_using_the_others(cls, field_value, values, field, config):\n        parent_class_name = values[\"name\"]\n        parent_class_address = values[\"address\"] # works because \"address\" is already validated once we validate \"phone\"\n        # Do the validation instead of printing\n        print(f\"{field_value} is the {field.name} of {parent_class_name}\")\n        return field_value\nCustomer(name=\"Peter\", comments=\"Pydantic User\", address=\"Home\", phone=\"117\")",
        "score": 46,
        "is_accepted": false,
        "creation_date": "2021-07-22T09:59:44",
        "author": "wueli"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72425408/interrupt-not-prevent-from-starting-screensaver",
    "title": "Interrupt (NOT prevent from starting) screensaver",
    "question_id": 72425408,
    "posted_date": "2022-05-29T12:28:13",
    "answers": [
      {
        "answer_id": 73286378,
        "body": "import win32con, win32api, win32service\nimport random\n# Get a handle to the current active Desktop\nhdesk = win32service.OpenInputDesktop(0, False, win32con.MAXIMUM_ALLOWED);\n# Get a handle to the Desktop this process is associated with\nhdeskOld = win32service.GetThreadDesktop(win32api.GetCurrentThreadId())\n# Set this process to handle messages and input on the active Desktop\nhdesk.SetThreadDesktop()\n# Move the mouse some random amount, most Screen Savers will react to this,\n# close the window, which in turn causes Windows to destroy this Desktop\n# Also, move the mouse a few times to avoid the edge case of moving\n# it randomly to the location it was already at.\nfor _ in range(4):\n    win32api.SetCursorPos((random.randint(0, 100), random.randint(0, 100)))\n# Revert back to the old desktop association so the rest of this script works\nhdeskOld.SetThreadDesktop()",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2022-08-08T23:56:59",
        "author": "Anon Coward"
      },
      {
        "answer_id": 73286378,
        "body": "from datetime import datetime, timedelta\nimport ctypes\nimport tkinter as tk\n# Constants for calling SetThreadExecutionState\nES_CONTINUOUS = 0x80000000\nES_SYSTEM_REQUIRED = 0x00000001\nES_DISPLAY_REQUIRED= 0x00000002\n# Example work, show nothing, but when the timer hits, \"alert\" the user\nALERT_AT = datetime.utcnow() + timedelta(minutes=2)\ndef timer(root):\n    # Called every second until we alert the user\n    # TODO: This is just alerting the user after a set time goes by,\n    #       you could perform a custom check here, to see if the user\n    #       should be alerted based off other conditions.\n    if datetime.utcnow() >= ALERT_AT:\n        # Just alert the user\n        root.configure(bg='red')\n    else:\n        # Nothing to do, check again in a bit\n        root.after(1000, timer, root)\n# Create a full screen window\nroot = tk.Tk()\n# Simple way to dismiss the window\nroot.bind(\"<Escape>\", lambda e: e.widget.destroy())\nroot.wm_attributes(\"-fullscreen\", 1)\nroot.wm_attributes(\"-topmost\", 1)\nroot.configure(bg='black')\nroot.config(cursor=\"none\")\nroot.after(1000, timer, root)\n# Disable the screen saver while the main window is shown\nctypes.windll.kernel32.SetThreadExecutionState(ES_CONTINUOUS | ES_DISPLAY_REQUIRED)\nroot.mainloop()\n# All done, let the screen saver run again\nctypes.windll.kernel32.SetThreadExecutionState(ES_CONTINUOUS)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2022-08-08T23:56:59",
        "author": "Anon Coward"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57893902/how-can-i-set-an-attribute-in-a-frozen-dataclass-custom-init-method",
    "title": "How can I set an attribute in a frozen dataclass custom __init__ method?",
    "question_id": 57893902,
    "posted_date": "2019-09-11T13:11:32",
    "answers": [
      {
        "answer_id": 58336722,
        "body": "def dataclass_with_default_init(_cls=None, *args, **kwargs):\n    def wrap(cls):\n        # Save the current __init__ and remove it so dataclass will\n        # create the default __init__.\n        user_init = getattr(cls, \"__init__\")\n        delattr(cls, \"__init__\")\n        # let dataclass process our class.\n        result = dataclass(cls, *args, **kwargs)\n        # Restore the user's __init__ save the default init to __default_init__.\n        setattr(result, \"__default_init__\", result.__init__)\n        setattr(result, \"__init__\", user_init)\n        # Just in case that dataclass will return a new instance,\n        # (currently, does not happen), restore cls's __init__.\n        if result is not cls:\n            setattr(cls, \"__init__\", user_init)\n        return result\n    # Support both dataclass_with_default_init() and dataclass_with_default_init\n    if _cls is None:\n        return wrap\n    else:\n        return wrap(_cls)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2019-10-11T03:56:54",
        "author": "Shmuel H."
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/1877999/delete-final-line-in-file-with-python",
    "title": "Delete final line in file with python",
    "question_id": 1877999,
    "posted_date": "2009-12-09T19:57:00",
    "answers": [
      {
        "answer_id": 10289740,
        "body": "with open(sys.argv[1], \"r+\", encoding = \"utf-8\") as file:\n\n    # Move the pointer (similar to a cursor in a text editor) to the end of the file\n    file.seek(0, os.SEEK_END)\n\n    # This code means the following code skips the very last character in the file -\n    # i.e. in the case the last line is null we delete the last line\n    # and the penultimate one\n    pos = file.tell() - 1\n\n    # Read each character in the file one at a time from the penultimate\n    # character going backwards, searching for a newline character\n    # If we find a new line, exit the search\n    while pos > 0 and file.read(1) != \"\\n\":\n        pos -= 1\n        file.seek(pos, os.SEEK_SET)\n\n    # So long as we're not at the start of the file, delete all the characters ahead\n    # of this position\n    if pos > 0:\n        file.seek(pos, os.SEEK_SET)\n        file.truncate()",
        "score": 92,
        "is_accepted": false,
        "creation_date": "2012-04-23T19:32:06",
        "author": "Saqib"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67639234/count-how-many-arguments-passed-as-positional",
    "title": "Count how many arguments passed as positional",
    "question_id": 67639234,
    "posted_date": "2021-05-21T10:53:03",
    "answers": [
      {
        "answer_id": 67639379,
        "body": "from functools import wraps\nfrom inspect import signature\ndef checkargs(func):\n    @wraps(func)\n    def inner(*args, **kwargs):\n        for param in signature(func).parameters:\n            if param in kwargs:\n                print(param, 'passed with its keyword!')\n            else:\n                print(param, 'passed positionally.')\n        result = func(*args, **kwargs)\n        return result\n    return inner\n>>>  @checkargs\n...: def foo(x, y, z) -> int:\n...:     return x + y\n>>> foo(2, 3, z=4)\nx passed positionally.\ny passed positionally.\nz passed with its keyword!\n9\n>>> inspect.getfullargspec(foo)\nFullArgSpec(args=[], varargs='args', varkw='kwargs', defaults=None,\nkwonlyargs=[], kwonlydefaults=None, annotations={'return': <class 'int'>})\n                                             _____________HERE____________",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2021-05-21T11:02:17",
        "author": "Sayandip Dutta"
      },
      {
        "answer_id": 67639379,
        "body": "from functools import wraps\nfrom inspect import signature\nfrom typing import Callable, ParamSpec, TypeVar, TYPE_CHECKING\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\ndef check_args(func: Callable[P, T]) -> Callable[P, T]:\n    \"\"\"\n    Decorator to monitor whether an argument is passed\n    positionally or with its keyword, during function call.\n    \"\"\"\n    @wraps(func)\n    def inner(*args: P.args, **kwargs: P.kwargs) -> T:\n        for param in signature(func).parameters:\n            if param in kwargs:\n                print(param, 'passed with its keyword!')\n            else:\n                print(param, 'passed positionally.')\n        return func(*args, **kwargs)\n    return inner",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2021-05-21T11:02:17",
        "author": "Sayandip Dutta"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11927278/how-to-configure-logging-in-python",
    "title": "How to configure Logging in Python",
    "question_id": 11927278,
    "posted_date": "2012-08-12T21:36:51",
    "answers": [
      {
        "answer_id": 11927374,
        "body": "# app.py (runs when application starts)\nimport logging\nimport os.path\ndef main():\n    logging_config = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'standard': {\n                'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'\n            },\n        },\n        'handlers': {\n            'default_handler': {\n                'class': 'logging.FileHandler',\n                'level': 'DEBUG',\n                'formatter': 'standard',\n                'filename': os.path.join('logs', 'application.log'),\n                'encoding': 'utf8'\n            },\n        },\n        'loggers': {\n            '': {\n                'handlers': ['default_handler'],\n                'level': 'DEBUG',\n                'propagate': False\n            }\n        }\n    }\n    logging.config.dictConfig(logging_config)\n    # start application ...\nif __name__ == '__main__':\n    main()",
        "score": 53,
        "is_accepted": true,
        "creation_date": "2012-08-12T21:57:27",
        "author": "Torsten Engelbrecht"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47776486/python-struct-error-i-format-requires-2147483648-number-2147483647",
    "title": "python struct.error: &#39;i&#39; format requires -2147483648 &lt;= number &lt;= 2147483647",
    "question_id": 47776486,
    "posted_date": "2017-12-12T10:47:35",
    "answers": [
      {
        "answer_id": 47776649,
        "body": "import functools\nimport logging\nimport struct\nimport sys\nlogger = logging.getLogger()\ndef patch_mp_connection_bpo_17560():\n    \"\"\"Apply PR-10305 / bpo-17560 connection send/receive max size update\n    See the original issue at https://bugs.python.org/issue17560 and\n    https://github.com/python/cpython/pull/10305 for the pull request.\n    This only supports Python versions 3.3 - 3.7, this function\n    does nothing for Python versions outside of that range.\n    \"\"\"\n    patchname = \"Multiprocessing connection patch for bpo-17560\"\n    if not (3, 3) < sys.version_info < (3, 8):\n        logger.info(\n            patchname + \" not applied, not an applicable Python version: %s\",\n            sys.version\n        )\n        return\n    from multiprocessing.connection import Connection\n    orig_send_bytes = Connection._send_bytes\n    orig_recv_bytes = Connection._recv_bytes\n    if (\n        orig_send_bytes.__code__.co_filename == __file__\n        and orig_recv_bytes.__code__.co_filename == __file__\n    ):\n        logger.info(patchname + \" already applied, skipping\")\n        return\n    @functools.wraps(orig_send_bytes)\n    def send_bytes(self, buf):\n        n = len(buf)\n        if n > 0x7fffffff:\n            pre_header = struct.pack(\"!i\", -1)\n            header = struct.pack(\"!Q\", n)\n            self._send(pre_header)\n            self._send(header)\n            self._send(buf)\n        else:\n            orig_send_bytes(self, buf)\n    @functools.wraps(orig_recv_bytes)\n    def recv_bytes(self, maxsize=None):\n        buf = self._recv(4)\n        size, = struct.unpack(\"!i\", buf.getvalue())\n        if size == -1:\n            buf = self._recv(8)\n            size, = struct.unpack(\"!Q\", buf.getvalue())\n        if maxsize is not None and size > maxsize:\n            return None\n        return self._recv(size)\n    Connection._send_bytes = send_bytes\n    Connection._recv_bytes = recv_bytes\n    logger.info(patchname + \" applied\")",
        "score": 48,
        "is_accepted": true,
        "creation_date": "2017-12-12T10:55:34",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58280484/ssl-module-in-python-is-not-available-on-osx",
    "title": "SSL module in Python is not available (on OSX)",
    "question_id": 58280484,
    "posted_date": "2019-10-08T01:09:10",
    "answers": [
      {
        "answer_id": 58280749,
        "body": "Mac-Admin:~ admin$ python3\nPython 3.7.4 (default, Sep  7 2019, 18:27:02)\n[Clang 10.0.1 (clang-1001.0.46.4)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import ssl\n>>> ssl\n<module 'ssl' from '/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py'>\n>>> import _ssl\n>>> _ssl\n<module '_ssl' from '/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ssl.cpython-37m-darwin.so'>",
        "score": 86,
        "is_accepted": true,
        "creation_date": "2019-10-08T01:44:36",
        "author": "ivan_pozdeev"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11665628/read-data-from-csv-file-and-transform-from-string-to-correct-data-type-includin",
    "title": "Read data from CSV file and transform from string to correct data-type, including a list-of-integer column",
    "question_id": 11665628,
    "posted_date": "2012-07-26T04:49:12",
    "answers": [
      {
        "answer_id": 54794212,
        "body": "#!/usr/bin/env python3.6\nimport ast\nimport csv\nfrom typing import NamedTuple\nclass Record(NamedTuple):\n    \"\"\" Define the fields and their types in a record. \"\"\"\n    IsActive: bool\n    Type: str\n    Price: float\n    States: ast.literal_eval  # Handles string represenation of literals.\n    @classmethod\n    def _transform(cls: 'Record', dict_: dict) -> dict:\n        \"\"\" Convert string values in given dictionary to corresponding Record\n            field type.\n        \"\"\"\n        return {name: cls.__annotations__[name](value)\n                    for name, value in dict_.items()}\nfilename = 'test_transform.csv'\nwith open(filename, newline='') as file:\n    for i, row in enumerate(csv.DictReader(file)):\n        row = Record._transform(row)\n        print(f'row {i}: {row}')",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-20T14:49:35",
        "author": "martineau"
      },
      {
        "answer_id": 54794212,
        "body": "#!/usr/bin/env python3.7\nimport ast\nimport csv\nfrom dataclasses import dataclass, fields\nfrom typing import Type, TypeVar\nT = TypeVar('T', bound='GenericRecord')\nclass GenericRecord:\n    \"\"\" Generic base class for transforming dataclasses. \"\"\"\n    @classmethod\n    def _transform(cls: Type[T], dict_: dict) -> dict:\n        \"\"\" Convert string values in given dictionary to corresponding type. \"\"\"\n        return {field.name: field.type(dict_[field.name])\n                    for field in fields(cls)}\n@dataclass\nclass CSV_Record(GenericRecord):\n    \"\"\" Define the fields and their types in a record.\n        Field names must match column names in CSV file header.\n    \"\"\"\n    IsActive: bool\n    Type: str\n    Price: float\n    States: ast.literal_eval  # Handles string represenation of literals.\nfilename = 'test_transform.csv'\nwith open(filename, newline='') as file:\n    for i, row in enumerate(csv.DictReader(file)):\n        row = CSV_Record._transform(row)\n        print(f'row {i}: {row}')",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-20T14:49:35",
        "author": "martineau"
      },
      {
        "answer_id": 54794212,
        "body": "#!/usr/bin/env python3.8\nimport ast\nimport csv\nfrom dataclasses import dataclass, fields\nfrom typing import TypedDict\ndef transform(dict_, typed_dict) -> dict:\n    \"\"\" Convert values in given dictionary to corresponding types in TypedDict . \"\"\"\n    fields = typed_dict.__annotations__\n    return {name: fields[name](value) for name, value in dict_.items()}\nclass CSV_Record_Types(TypedDict):\n    \"\"\" Define the fields and their types in a record.\n        Field names must match column names in CSV file header.\n    \"\"\"\n    IsActive: bool\n    Type: str\n    Price: float\n    States: ast.literal_eval\nfilename = 'test_transform.csv'\nwith open(filename, newline='') as file:\n    for i, row in enumerate(csv.DictReader(file), 1):\n        row = transform(row, CSV_Record_Types)\n        print(f'row {i}: {row}')",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-20T14:49:35",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/75740652/fastapi-streamingresponse-not-streaming-with-generator-function",
    "title": "FastAPI StreamingResponse not streaming with generator function",
    "question_id": 75740652,
    "posted_date": "2023-03-15T00:48:33",
    "answers": [
      {
        "answer_id": 75760884,
        "body": "from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nimport asyncio\napp = FastAPI()\nasync def fake_data_streamer():\n    for i in range(10):\n        yield b'some fake data\\n\\n'\n        await asyncio.sleep(0.5)\n# If your generator contains blocking operations such as time.sleep(), then define the\n# generator function with normal `def`. Alternatively, use `async def` and run any\n# blocking operations in an external ThreadPool/ProcessPool. (see 2nd paragraph of this answer)\n'''\nimport time\ndef fake_data_streamer():\n    for i in range(10):\n        yield b'some fake data\\n\\n'\n        time.sleep(0.5)\n'''\n\n@app.get('/')\nasync def main():\n    return StreamingResponse(fake_data_streamer(), media_type='text/event-stream')\n    # or, use:\n    '''\n    headers = {'X-Content-Type-Options': 'nosniff'}\n    return StreamingResponse(fake_data_streamer(), headers=headers, media_type='text/plain')\n    '''",
        "score": 79,
        "is_accepted": true,
        "creation_date": "2023-03-16T15:30:49",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/20892799/using-pandas-calculate-cram%c3%a9rs-coefficient-matrix",
    "title": "Using pandas, calculate Cram&#233;r&#39;s coefficient matrix",
    "question_id": 20892799,
    "posted_date": "2014-01-02T17:06:08",
    "answers": [
      {
        "answer_id": 39266194,
        "body": "import scipy.stats as ss\ndef cramers_corrected_stat(confusion_matrix):\n    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n        uses correction from Bergsma and Wicher,\n        Journal of the Korean Statistical Society 42 (2013): 323-328\n    \"\"\"\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum()\n    phi2 = chi2/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n    rcorr = r - ((r-1)**2)/(n-1)\n    kcorr = k - ((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))",
        "score": 60,
        "is_accepted": false,
        "creation_date": "2016-09-01T04:15:09",
        "author": "Ziggy Eunicien"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63682956/fastapi-retrieve-url-from-view-name-route-name",
    "title": "FastAPI: Retrieve URL from view name ( route name )",
    "question_id": 63682956,
    "posted_date": "2020-09-01T03:10:48",
    "answers": [
      {
        "answer_id": 63682957,
        "body": "from fastapi import FastAPI, Request\napp = FastAPI()\n@app.get('/hello/')\ndef hello_world():\n    return {\"msg\": \"Hello World\"}\n@app.get('/hello/{number}/')\ndef hello_world_number(number: int):\n    return {\"msg\": \"Hello World Number\", \"number\": number}\n@app.get('/')\ndef named_url_reveres(request: Request):\n    return {\n        \"URL for 'hello_world'\": request.url_for(\"hello_world\"),\n        \"URL for 'hello_world_number' with number '1'\": request.url_for(\"hello_world_number\", number=1),\n        \"URL for 'hello_world_number' with number '2''\": request.url_for(\"hello_world_number\", number=2})\n    }\n# Result Response\n{\n    \"URL for 'hello_world'\": \"http://0.0.0.0:6022/hello/\",\n    \"URL for 'hello_world_number' with number '1'\": \"http://0.0.0.0:6022/hello/1/\",\n    \"URL for 'hello_world_number' with number '2''\": \"http://0.0.0.0:6022/hello/2/\"\n}",
        "score": 65,
        "is_accepted": true,
        "creation_date": "2020-09-01T03:10:48",
        "author": "JPG"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5824382/enabling-comparison-for-classes",
    "title": "&quot;Enabling&quot; comparison for classes",
    "question_id": 5824382,
    "posted_date": "2011-04-28T16:12:16",
    "answers": [
      {
        "answer_id": 5824757,
        "body": "import functools\n@functools.total_ordering\nclass Student:\n    def _is_valid_operand(self, other):\n        return (hasattr(other, \"lastname\") and\n                hasattr(other, \"firstname\"))\n    def __eq__(self, other):\n        if not self._is_valid_operand(other):\n            return NotImplemented\n        return ((self.lastname.lower(), self.firstname.lower()) ==\n                (other.lastname.lower(), other.firstname.lower()))\n    def __lt__(self, other):\n        if not self._is_valid_operand(other):\n            return NotImplemented\n        return ((self.lastname.lower(), self.firstname.lower()) <\n                (other.lastname.lower(), other.firstname.lower()))",
        "score": 52,
        "is_accepted": false,
        "creation_date": "2011-04-28T16:44:07",
        "author": "Juri Robl"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch",
    "title": "Label Smoothing in PyTorch",
    "question_id": 55681502,
    "posted_date": "2019-04-14T21:14:30",
    "answers": [
      {
        "answer_id": 66773267,
        "body": "import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.nn.modules.loss import _WeightedLoss\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, smoothing=0.0, dim=-1, weight = None):\n        \"\"\"if smoothing == 0, it's one-hot method\n           if 0 < smoothing < 1, it's smooth method\n        \"\"\"\n        super(LabelSmoothingLoss, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.weight = weight\n        self.cls = classes\n        self.dim = dim\n    def forward(self, pred, target):\n        assert 0 <= self.smoothing < 1\n        pred = pred.log_softmax(dim=self.dim)\n        if self.weight is not None:\n            pred = pred * self.weight.unsqueeze(0)\n        with torch.no_grad():\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (self.cls - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      },
      {
        "answer_id": 66773267,
        "body": "class SmoothCrossEntropyLoss(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n    def k_one_hot(self, targets:torch.Tensor, n_classes:int, smoothing=0.0):\n        with torch.no_grad():\n            targets = torch.empty(size=(targets.size(0), n_classes),\n                                  device=targets.device) \\\n                                  .fill_(smoothing /(n_classes-1)) \\\n                                  .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n        return targets\n    def reduce_loss(self, loss):\n        return loss.mean() if self.reduction == 'mean' else loss.sum() \\\n        if self.reduction == 'sum' else loss\n    def forward(self, inputs, targets):\n        assert 0 <= self.smoothing < 1\n        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n        log_preds = F.log_softmax(inputs, -1)\n        if self.weight is not None:\n            log_preds = log_preds * self.weight.unsqueeze(0)\n        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      },
      {
        "answer_id": 66773267,
        "body": "import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.nn.modules.loss import _WeightedLoss\nif __name__==\"__main__\":\n    # 1. Devin Yang\n    crit = LabelSmoothingLoss(classes=5, smoothing=0.5)\n    predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n                                 [0, 0.9, 0.2, 0.2, 1],\n                                 [1, 0.2, 0.7, 0.9, 1]])\n    v = crit(Variable(predict),\n             Variable(torch.LongTensor([2, 1, 0])))\n    print(v)\n    # 2. Shital Shah\n    crit = SmoothCrossEntropyLoss(smoothing=0.5)\n    predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n                                 [0, 0.9, 0.2, 0.2, 1],\n                                 [1, 0.2, 0.7, 0.9, 1]])\n    v = crit(Variable(predict),\n             Variable(torch.LongTensor([2, 1, 0])))\n    print(v)\ntensor(1.4178)\ntensor(1.4178)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      },
      {
        "answer_id": 66773267,
        "body": "class LabelSmoothingLoss(torch.nn.Module):\n    def __init__(self, smoothing: float = 0.1,\n                 reduction=\"mean\", weight=None):\n        super(LabelSmoothingLoss, self).__init__()\n        self.smoothing   = smoothing\n        self.reduction = reduction\n        self.weight    = weight\n    def reduce_loss(self, loss):\n        return loss.mean() if self.reduction == 'mean' else loss.sum() \\\n         if self.reduction == 'sum' else loss\n    def linear_combination(self, x, y):\n        return self.smoothing * x + (1 - self.smoothing) * y\n    def forward(self, preds, target):\n        assert 0 <= self.smoothing < 1\n        if self.weight is not None:\n            self.weight = self.weight.to(preds.device)\n        n = preds.size(-1)\n        log_preds = F.log_softmax(preds, dim=-1)\n        loss = self.reduce_loss(-log_preds.sum(dim=-1))\n        nll = F.nll_loss(\n            log_preds, target, reduction=self.reduction, weight=self.weight\n        )\n        return self.linear_combination(loss / n, nll)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      },
      {
        "answer_id": 66773267,
        "body": "class LabelSmoothing(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LabelSmoothing module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n    def forward(self, x, target):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      },
      {
        "answer_id": 66773267,
        "body": "if __name__==\"__main__\":\n    # Wangleiofficial\n    crit = LabelSmoothingLoss(smoothing=0.3, reduction=\"mean\")\n    predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n                                 [0, 0.9, 0.2, 0.2, 1],\n                                 [1, 0.2, 0.7, 0.9, 1]])\n    v = crit(Variable(predict),\n             Variable(torch.LongTensor([2, 1, 0])))\n    print(v)\n    # NVIDIA\n    crit = LabelSmoothing(smoothing=0.3)\n    predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n                                 [0, 0.9, 0.2, 0.2, 1],\n                                 [1, 0.2, 0.7, 0.9, 1]])\n    v = crit(Variable(predict),\n             Variable(torch.LongTensor([2, 1, 0])))\n    print(v)\ntensor(1.3883)\ntensor(1.3883)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2021-03-23T20:51:01",
        "author": "Innat"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59499061/how-to-run-custom-shell-script-file-before-pre-commit-hook",
    "title": "How to run custom shell script file before pre commit hook",
    "question_id": 59499061,
    "posted_date": "2019-12-27T05:05:42",
    "answers": [
      {
        "answer_id": 59499550,
        "body": "- repo: local\n  hooks:\n    - id: simple-pylint\n      name: simple-pylint\n      entry: pylint\n      args: [\"api/\"]\n      language: system\n      types: [python]\n      pass_filenames: false\n    - id: inline-pylint-with-bash\n      name: inline-pylint-with-bash\n      entry: bash -c 'lines=$(pylint api/ | wc -l) && (( lines > 10)) && exit 1'\n      language: system\n      types: [python]\n      pass_filenames: false\n\n    - id: custom-script-file\n      name: custom-script-file\n      entry: relative/path/to/repo/root/check_pylint.sh\n      language: script\n      types: [python]\n      pass_filenames: false",
        "score": 60,
        "is_accepted": false,
        "creation_date": "2019-12-27T05:42:45",
        "author": "RafalS"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21808657/what-is-a-unicode-string",
    "title": "What is a unicode string?",
    "question_id": 21808657,
    "posted_date": "2014-02-16T02:51:02",
    "answers": [
      {
        "answer_id": 21809081,
        "body": ">>> my_str = 'A unicode \\u018e string \\xf1' # no need for \"u\" prefix\n# the escape sequence \"\\u\" denotes a Unicode code point (in hex)\n>>> my_str\n'A unicode \u018e string \u00f1'\n# the Unicode code points U+018E and U+00F1 were displayed\n# as their corresponding glyphs\n>>> my_bytes = my_str.encode('utf-8') # convert to a bytes object\n>>> my_bytes\nb'A unicode \\xc6\\x8e string \\xc3\\xb1'\n# the \"b\" prefix means a bytes literal\n# the escape sequence \"\\x\" denotes a byte using its hex value\n# the code points U+018E and U+00F1 were encoded as 2-byte sequences\n>>> my_str2 = my_bytes.decode('utf-8') # convert back to str\n>>> my_str2 == my_str\nTrue",
        "score": 60,
        "is_accepted": true,
        "creation_date": "2014-02-16T03:48:17",
        "author": "tom"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52413246/how-to-provide-a-reproducible-copy-of-your-dataframe-with-to-clipboard",
    "title": "How to provide a reproducible copy of your DataFrame with to_clipboard()",
    "question_id": 52413246,
    "posted_date": "2018-09-19T15:48:20",
    "answers": [
      {
        "answer_id": 52413247,
        "body": "# if you have a datetime column, convert it to a str\ndf['date'] = df['date'].astype('str')\n# if you have a datetime index, convert it to a str\ndf.index = df.index.astype('str')\n# output to a dict\ndf.head(10).to_dict(orient='index')\n# which will look like\n{'2020-07-30': {'a': 2, 'b': 4},\n '2020-07-31': {'a': 1, 'b': 5},\n '2020-08-01': {'a': 2, 'b': 2},\n '2020-08-02': {'a': 9, 'b': 8},\n '2020-08-03': {'a': 4, 'b': 0},\n '2020-08-04': {'a': 3, 'b': 3},\n '2020-08-05': {'a': 7, 'b': 7},\n '2020-08-06': {'a': 7, 'b': 0},\n '2020-08-07': {'a': 8, 'b': 4},\n '2020-08-08': {'a': 3, 'b': 2}}\n# copy the previous dict and paste into a code block on SO\n# the dict can be converted to a dataframe with\n# df = pd.DataFrame.from_dict(d, orient='index')  # d is the name of the dict\n# convert datatime column or index back to datetime",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2018-09-19T15:48:20",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39614027/list-available-font-families-in-tkinter",
    "title": "List available font families in `tkinter`",
    "question_id": 39614027,
    "posted_date": "2016-09-21T06:30:00",
    "answers": [
      {
        "answer_id": 64301819,
        "body": "System\nTerminal\nFixedsys\nModern\nRoman\nScript\nCourier\nMS Serif\nMS Sans Serif\nSmall Fonts\nBell Gothic Std Black\nBell Gothic Std Light\nEccentric Std\nStencil Std\nTekton Pro\nTekton Pro Cond\nTekton Pro Ext\nTrajan Pro\nRosewood Std Regular\nPrestige Elite Std\nPoplar Std\nOrator Std\nOCR A Std\nNueva Std Cond\nMinion Pro SmBd\nMinion Pro Med\nMinion Pro Cond\nMesquite Std\nLithos Pro Regular\nKozuka Mincho Pro R\n@Kozuka Mincho Pro R\nKozuka Mincho Pro M\n@Kozuka Mincho Pro M\nKozuka Mincho Pro L\n@Kozuka Mincho Pro L\nKozuka Mincho Pro H\n@Kozuka Mincho Pro H\nKozuka Mincho Pro EL\n@Kozuka Mincho Pro EL\nKozuka Mincho Pro B\n@Kozuka Mincho Pro B\nKozuka Gothic Pro R\n@Kozuka Gothic Pro R\nKozuka Gothic Pro M\n@Kozuka Gothic Pro M\nKozuka Gothic Pro L\n@Kozuka Gothic Pro L\nKozuka Gothic Pro H\n@Kozuka Gothic Pro H\nKozuka Gothic Pro EL\n@Kozuka Gothic Pro EL\nKozuka Gothic Pro B\n@Kozuka Gothic Pro B\nHobo Std\nGiddyup Std\nCooper Std Black\nCharlemagne Std\nChaparral Pro\nBrush Script Std\nBlackoak Std\nBirch Std\nAdobe Garamond Pro\nAdobe Garamond Pro Bold\nAdobe Kaiti Std R\n@Adobe Kaiti Std R\nAdobe Heiti Std R\n@Adobe Heiti Std R\nAdobe Fangsong Std R\n@Adobe Fangsong Std R\nAdobe Caslon Pro\nAdobe Caslon Pro Bold\nAdobe Arabic\nAdobe Devanagari\nAdobe Hebrew\nAdobe Ming Std L\n@Adobe Ming Std L\nAdobe Myungjo Std M\n@Adobe Myungjo Std M\nAdobe Song Std L\n@Adobe Song Std L\nKozuka Gothic Pr6N B\n@Kozuka Gothic Pr6N B\nKozuka Gothic Pr6N EL\n@Kozuka Gothic Pr6N EL\nKozuka Gothic Pr6N H\n@Kozuka Gothic Pr6N H\nKozuka Gothic Pr6N L\n@Kozuka Gothic Pr6N L\nKozuka Gothic Pr6N M\n@Kozuka Gothic Pr6N M\nKozuka Gothic Pr6N R\n@Kozuka Gothic Pr6N R\nKozuka Mincho Pr6N B\n@Kozuka Mincho Pr6N B\nKozuka Mincho Pr6N EL\n@Kozuka Mincho Pr6N EL\nKozuka Mincho Pr6N H\n@Kozuka Mincho Pr6N H\nKozuka Mincho Pr6N L\n@Kozuka Mincho Pr6N L\nKozuka Mincho Pr6N M\n@Kozuka Mincho Pr6N M\nKozuka Mincho Pr6N R\n@Kozuka Mincho Pr6N R\nLetter Gothic Std\nMinion Pro\nMyriad Hebrew\nMyriad Pro\nMyriad Pro Cond\nMyriad Pro Light\nRosewood Std Fill\nMarlett\nArial\nArabic Transparent\nArial Baltic\nArial CE\nArial CYR\nArial Greek\nArial TUR\nBatang\n@Batang\nBatangChe\n@BatangChe\nGungsuh\n@Gungsuh\nGungsuhChe\n@GungsuhChe\nCourier New\nCourier New Baltic\nCourier New CE\nCourier New CYR\nCourier New Greek\nCourier New TUR\nDaunPenh\nDokChampa\nEstrangelo Edessa\nEuphemia\nGautami\nVani\nGulim\n@Gulim\nGulimChe\n@GulimChe\nDotum\n@Dotum\nDotumChe\n@DotumChe\nImpact\nIskoola Pota\nKalinga\nKartika\nKhmer UI\nLao UI\nLatha\nLucida Console\nMalgun Gothic\n@Malgun Gothic\nMangal\nMeiryo\n@Meiryo\nMeiryo UI\n@Meiryo UI\nMicrosoft Himalaya\nMicrosoft JhengHei\n@Microsoft JhengHei\nMicrosoft YaHei\n@Microsoft YaHei\nMingLiU\n@MingLiU\nPMingLiU\n@PMingLiU\nMingLiU_HKSCS\n@MingLiU_HKSCS\nMingLiU-ExtB\n@MingLiU-ExtB\nPMingLiU-ExtB\n@PMingLiU-ExtB\nMingLiU_HKSCS-ExtB\n@MingLiU_HKSCS-ExtB\nMongolian Baiti\nMS Gothic\n@MS Gothic\nMS PGothic\n@MS PGothic\nMS UI Gothic\n@MS UI Gothic\nMS Mincho\n@MS Mincho\nMS PMincho\n@MS PMincho\nMV Boli\nMicrosoft New Tai Lue\nNyala\nMicrosoft PhagsPa\nPlantagenet Cherokee\nRaavi\nSegoe Script\nSegoe UI\nSegoe UI Semibold\nSegoe UI Light\nSegoe UI Symbol\nShruti\nSimSun\n@SimSun\nNSimSun\n@NSimSun\nSimSun-ExtB\n@SimSun-ExtB\nSylfaen\nMicrosoft Tai Le\nTimes New Roman\nTimes New Roman Baltic\nTimes New Roman CE\nTimes New Roman CYR\nTimes New Roman Greek\nTimes New Roman TUR\nTunga\nVrinda\nShonar Bangla\nMicrosoft Yi Baiti\nTahoma\nMicrosoft Sans Serif\nAngsana New\nAparajita\nCordia New\nEbrima\nGisha\nKokila\nLeelawadee\nMicrosoft Uighur\nMoolBoran\nSymbol\nUtsaah\nVijaya\nWingdings\nAndalus\nArabic Typesetting\nSimplified Arabic\nSimplified Arabic Fixed\nSakkal Majalla\nTraditional Arabic\nAharoni\nDavid\nFrankRuehl\nLevenim MT\nMiriam\nMiriam Fixed\nNarkisim\nRod\nFangSong\n@FangSong\nSimHei\n@SimHei\nKaiTi\n@KaiTi\nAngsanaUPC\nBrowallia New\nBrowalliaUPC\nCordiaUPC\nDilleniaUPC\nEucrosiaUPC\nFreesiaUPC\nIrisUPC\nJasmineUPC\nKodchiangUPC\nLilyUPC\nDFKai-SB\n@DFKai-SB\nLucida Sans Unicode\nArial Black\nCalibri\nCambria\nCambria Math\nCandara\nComic Sans MS\nConsolas\nConstantia\nCorbel\nFranklin Gothic Medium\nGabriola\nGeorgia\nPalatino Linotype\nSegoe Print\nTrebuchet MS\nVerdana\nWebdings\nHaettenschweiler\nMS Outlook\nBook Antiqua\nCentury Gothic\nBookshelf Symbol 7\nMS Reference Sans Serif\nMS Reference Specialty\nBradley Hand ITC\nFreestyle Script\nFrench Script MT\nJuice ITC\nKristen ITC\nLucida Handwriting\nMistral\nPapyrus\nPristina\nTempus Sans ITC\nGaramond\nMonotype Corsiva\nAgency FB\nArial Rounded MT Bold\nBlackadder ITC\nBodoni MT\nBodoni MT Black\nBodoni MT Condensed\nBookman Old Style\nCalisto MT\nCastellar\nCentury Schoolbook\nCopperplate Gothic Bold\nCopperplate Gothic Light\nCurlz MT\nEdwardian Script ITC\nElephant\nEngravers MT\nEras Bold ITC\nEras Demi ITC\nEras Light ITC\nEras Medium ITC\nFelix Titling\nForte\nFranklin Gothic Book\nFranklin Gothic Demi\nFranklin Gothic Demi Cond\nFranklin Gothic Heavy\nFranklin Gothic Medium Cond\nGigi\nGill Sans MT\nGill Sans MT Condensed\nGill Sans Ultra Bold\nGill Sans Ultra Bold Condensed\nGill Sans MT Ext Condensed Bold\nGloucester MT Extra Condensed\nGoudy Old Style\nGoudy Stout\nImprint MT Shadow\nLucida Sans\nLucida Sans Typewriter\nMaiandra GD\nOCR A Extended\nPalace Script MT\nPerpetua\nPerpetua Titling MT\nRage Italic\nRockwell\nRockwell Condensed\nRockwell Extra Bold\nScript MT Bold\nTw Cen MT\nTw Cen MT Condensed\nTw Cen MT Condensed Extra Bold\nAlgerian\nBaskerville Old Face\nBauhaus 93\nBell MT\nBerlin Sans FB\nBerlin Sans FB Demi\nBernard MT Condensed\nBodoni MT Poster Compressed\nBritannic Bold\nBroadway\nBrush Script MT\nCalifornian FB\nCentaur\nChiller\nColonna MT\nCooper Black\nFootlight MT Light\nHarlow Solid Italic\nHarrington\nHigh Tower Text\nJokerman\nKunstler Script\nLucida Bright\nLucida Calligraphy\nLucida Fax\nMagneto\nMatura MT Script Capitals\nModern No. 20\nNiagara Engraved\nNiagara Solid\nOld English Text MT\nOnyx\nParchment\nPlaybill\nPoor Richard\nRavie\nInformal Roman\nShowcard Gothic\nSnap ITC\nStencil\nViner Hand ITC\nVivaldi\nVladimir Script\nWide Latin\nCentury\nWingdings 2\nWingdings 3\nArial Unicode MS\n@Arial Unicode MS\nArial Narrow\nRupee Foradian\nRupee\nDevLys 010\nCalibri Light\nMonoton\nUbuntu Medium\nUbuntu\nUbuntu Light\nYatra One\nHelvLight\nLato\nGreat Vibes",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2020-10-11T04:02:33",
        "author": "Akshat Bhardwaj"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/8763451/how-to-handle-urllibs-timeout-in-python-3",
    "title": "How to handle urllib&#39;s timeout in Python 3?",
    "question_id": 8763451,
    "posted_date": "2012-01-06T14:36:45",
    "answers": [
      {
        "answer_id": 8763542,
        "body": "from socket import timeout\nfrom urllib.error import HTTPError, URLError\ntry:\n    response = urllib.request.urlopen(url, timeout=10).read().decode('utf-8')\nexcept HTTPError as error:\n    logging.error('HTTP Error: Data of %s not retrieved because %s\\nURL: %s', name, error, url)\nexcept URLError as error:\n    if isinstance(error.reason, timeout):\n        logging.error('Timeout Error: Data of %s not retrieved because %s\\nURL: %s', name, error, url)\n    else:\n        logging.error('URL Error: Data of %s not retrieved because %s\\nURL: %s', name, error, url)\nelse:\n    logging.info('Access successful.')",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2012-01-06T14:45:33",
        "author": "danodonovan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65316863/is-asyncio-to-thread-method-different-to-threadpoolexecutor",
    "title": "is asyncio.to_thread() method different to ThreadPoolExecutor?",
    "question_id": 65316863,
    "posted_date": "2020-12-15T22:25:01",
    "answers": [
      {
        "answer_id": 65319037,
        "body": "async def to_thread(func, /, *args, **kwargs):\n    \"\"\"Asynchronously run function *func* in a separate thread.\n    Any *args and **kwargs supplied for this function are directly passed\n    to *func*. Also, the current :class:`contextvars.Context` is propogated,\n    allowing context variables from the main thread to be accessed in the\n    separate thread.\n    Return a coroutine that can be awaited to get the eventual result of *func*.\n    \"\"\"\n    loop = events.get_running_loop()\n    ctx = contextvars.copy_context()\n    func_call = functools.partial(ctx.run, func, *args, **kwargs)\n    return await loop.run_in_executor(None, func_call)",
        "score": 54,
        "is_accepted": true,
        "creation_date": "2020-12-16T02:39:23",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25692440/mocking-a-subprocess-call-in-python",
    "title": "Mocking a subprocess call in Python",
    "question_id": 25692440,
    "posted_date": "2014-09-05T15:08:04",
    "answers": [
      {
        "answer_id": 25693097,
        "body": "from unittest import mock\nimport subprocess\ndef run_script(file_path):\n    process = subprocess.Popen([\"myscript\", -M, file_path], stdout=subprocess.PIPE)\n    output, err = process.communicate()\n    return process.returncode\n@mock.patch(\"subprocess.Popen\")\ndef test_run_script(self, mock_subproc_popen):\n    process_mock = mock.Mock()\n    attrs = {\"communicate.return_value\": (\"output\", \"error\")}\n    process_mock.configure_mock(**attrs)\n    mock_subproc_popen.return_value = process_mock\n    am.account_manager(\"path\")  # this calls run_script somewhere, is that right?\n    self.assertTrue(mock_subproc_popen.called)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2014-09-05T15:55:10",
        "author": "PawelP"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74289077/attributeerror-multiprocessingdataloaderiter-object-has-no-attribute-next",
    "title": "AttributeError: &#39;_MultiProcessingDataLoaderIter&#39; object has no attribute &#39;next&#39;",
    "question_id": 74289077,
    "posted_date": "2022-11-02T08:20:55",
    "answers": [
      {
        "answer_id": 74331018,
        "body": "class WineDataset(Dataset):\n    def __init__(self):\n        # Initialize data, download, etc.\n        # read with numpy or pandas\n        xy = np.loadtxt('./data/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n        self.n_samples = xy.shape[0]\n        # here the first column is the class label, the rest are the features\n        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n    # we can call len(dataset) to return the size\n    def __len__(self):\n        return self.n_samples\ndataset = WineDataset()\ndataloader = DataLoader(dataset=dataset,\n                              batch_size=4,\n                              shuffle=True,\n                              num_workers=2)\ndataiter = iter(dataloader)\ndata = next(dataiter)",
        "score": 95,
        "is_accepted": true,
        "creation_date": "2022-11-05T15:50:12",
        "author": "Syed Jameel Ahmed"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55271912/flask-cli-throws-oserror-errno-8-exec-format-error-when-run-through-docker",
    "title": "Flask CLI throws &#39;OSError: [Errno 8] Exec format error&#39; when run through docker-compose",
    "question_id": 55271912,
    "posted_date": "2019-03-20T20:03:48",
    "answers": [
      {
        "answer_id": 55272071,
        "body": ">    [cfati@cfati-5510-0:/cygdrive/e/Work/Dev/StackOverflow/q055271912]> ~/sopr.sh\n>    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n>\n>    [064bit prompt]> ls\n>    code00.py  code01.py\n>    [064bit prompt]>\n>    [064bit prompt]> cat code00.py\n>    print(\"This is:\", __file__)\n>\n>    [064bit prompt]> python3 -c \"import os, subprocess;subprocess.Popen(os.path.join(os.getcwd(), \\\"code00.py\\\")).communicate()\"\n>    Traceback (most recent call last):\n>      File \"<string>\", line 1, in <module>\n>      File \"/usr/lib/python3.6/subprocess.py\", line 709, in __init__\n>        restore_signals, start_new_session)\n>      File \"/usr/lib/python3.6/subprocess.py\", line 1344, in _execute_child\n>        raise child_exception_type(errno_num, err_msg, err_filename)\n>    OSError: [Errno 8] Exec format error: '/cygdrive/e/Work/Dev/StackOverflow/q055271912/code00.py'\n>    [064bit prompt]>\n>    [064bit prompt]> cat code01.py\n>    #!/usr/bin/env python3\n>\n>    print(\"This is:\", __file__)\n>\n>    [064bit prompt]> python3 -c \"import os, subprocess;subprocess.Popen(os.path.join(os.getcwd(), \\\"code01.py\\\")).communicate()\"\n>    This is: /cygdrive/e/Work/Dev/StackOverflow/q055271912/code01.py\n>",
        "score": 53,
        "is_accepted": true,
        "creation_date": "2019-03-20T20:30:32",
        "author": "CristiFati"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25513043/python-argparse-fails-to-parse-hex-formatting-to-int-type",
    "title": "Python argparse fails to parse hex formatting to int type",
    "question_id": 25513043,
    "posted_date": "2014-08-26T14:45:28",
    "answers": [
      {
        "answer_id": 25513044,
        "body": "def _get_value(self, action, arg_string):\n        type_func = self._registry_get('type', action.type, action.type)\n        if not _callable(type_func):\n            msg = _('%r is not callable')\n            raise ArgumentError(action, msg % type_func)\n\n        # convert the value to the appropriate type\n        try:\n            result = type_func(arg_string)\n\n        # ArgumentTypeErrors indicate errors\n        except ArgumentTypeError:\n            name = getattr(action.type, '__name__', repr(action.type))\n            msg = str(_sys.exc_info()[1])\n            raise ArgumentError(action, msg)\n\n        # TypeErrors or ValueErrors also indicate errors\n        except (TypeError, ValueError):\n            name = getattr(action.type, '__name__', repr(action.type))\n            msg = _('invalid %s value: %r')\n            raise ArgumentError(action, msg % (name, arg_string))\n\n        # return the converted value\n        return result",
        "score": 53,
        "is_accepted": false,
        "creation_date": "2014-08-26T14:45:28",
        "author": "devanl"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55169645/square-detection-in-image",
    "title": "Square detection in image",
    "question_id": 55169645,
    "posted_date": "2019-03-14T14:26:30",
    "answers": [
      {
        "answer_id": 57193144,
        "body": "import cv2\nimport numpy as np\n# Load image, grayscale, median blur, sharpen image\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.medianBlur(gray, 5)\nsharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\nsharpen = cv2.filter2D(blur, -1, sharpen_kernel)\n# Threshold and morph close\nthresh = cv2.threshold(sharpen, 160, 255, cv2.THRESH_BINARY_INV)[1]\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\nclose = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n# Find contours and filter using threshold area\ncnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nmin_area = 100\nmax_area = 1500\nimage_number = 0\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area > min_area and area < max_area:\n        x,y,w,h = cv2.boundingRect(c)\n        ROI = image[y:y+h, x:x+w]\n        cv2.imwrite('ROI_{}.png'.format(image_number), ROI)\n        cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n        image_number += 1\ncv2.imshow('sharpen', sharpen)\ncv2.imshow('close', close)\ncv2.imshow('thresh', thresh)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 67,
        "is_accepted": true,
        "creation_date": "2019-07-24T21:36:57",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10120295/valid-characters-in-a-python-class-name",
    "title": "Valid characters in a python class name",
    "question_id": 10120295,
    "posted_date": "2012-04-12T04:50:16",
    "answers": [
      {
        "answer_id": 10120327,
        "body": "> identifier   ::=  xid_start xid_continue*\n> id_start     ::=  <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>\n> id_continue  ::=  <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>\n> xid_start    ::=  <all characters in id_start whose NFKC normalization is in \"id_start xid_continue*\">\n> xid_continue ::=  <all characters in id_continue whose NFKC normalization is in \"id_continue*\">\n>",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2012-04-12T04:52:14",
        "author": "Ignacio Vazquez-Abrams"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/9586630/python-paths-and-import-order",
    "title": "python paths and import order",
    "question_id": 9586630,
    "posted_date": "2012-03-06T10:28:04",
    "answers": [
      {
        "answer_id": 58156551,
        "body": "myproject/ # <-- This is not a package (no __init__.py file).\n  modules/ # <-- This is a package (has an __init__.py file).\n    __init__.py\n    foo.py\n  run.py\n  second.py\nexecuted with: python /path/to/the/myproject/run.py\nwill cause sys.path[0] to be \"/path/to/the/myproject/\"\nrun.py contents:\nimport modules.foo as foo # will import \"/path/to/the/myproject/\" + \"modules/foo.py\"\nimport second # will import \"/path/to/the/myproject/\" + \"second.py\"\nsecond.py contents:\nimport modules.foo as foo # will import \"/path/to/the/myproject/\" + \"modules/foo.py\"",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2019-09-29T11:16:49",
        "author": "Mitch McMabers"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55876683/hook-into-the-builtin-python-f-string-format-machinery-to-override-extend-built",
    "title": "Hook into the builtin python f-string format machinery to override/extend built-in `__format__` methods",
    "question_id": 55876683,
    "posted_date": "2019-04-26T22:12:30",
    "answers": [
      {
        "answer_id": 69501391,
        "body": "# line 2      # Put the value of function parameter x on the stack\n  2           0 LOAD_FAST                0 (x)\n              # Put the format spec on the stack as a string\n              2 LOAD_CONST               1 ('foo')\n              # Pop both values from the stack and perform the actual formatting\n              # This puts the formatted string on the stack\n              4 FORMAT_VALUE             4 (with format)\n              # pop the result from the stack and return it\n              6 RETURN_VALUE",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-08T16:27:37",
        "author": "Michilus"
      },
      {
        "answer_id": 69501391,
        "body": "from bytecode import Bytecode\ndef formathack_rewrite_bytecode__(code):\n    \"\"\"\n    Modifies a code object to override the behavior of the FORMAT_VALUE\n    instructions used by f-strings.\n    \"\"\"\n    decompiled = Bytecode.from_code(code)\n    modified_instructions = []\n    for instruction in decompiled:\n        name = getattr(instruction, 'name', None)\n        if name == 'FORMAT_VALUE':\n            # 0x04 means that a format spec is present\n            if instruction.arg & 0x04 == 0x04:\n                callback_arg_count = 2\n            else:\n                callback_arg_count = 1\n            modified_instructions.extend([\n                # Load in the callback\n                Instr(\"LOAD_GLOBAL\", \"formathack_hook__\"),\n                # Shuffle around the top of the stack to put the arguments on top\n                # of the function global\n                Instr(\"ROT_THREE\" if callback_arg_count == 2 else \"ROT_TWO\"),\n                # Call the callback function instead of executing FORMAT_VALUE\n                Instr(\"CALL_FUNCTION\", callback_arg_count)\n            ])\n        # Kind of nasty: we want to recursively alter the code of functions.\n        elif name == 'LOAD_CONST' and isinstance(instruction.arg, types.CodeType):\n            modified_instructions.extend([\n                Instr(\"LOAD_CONST\", formathack_rewrite_bytecode__(instruction.arg), lineno=instruction.lineno)\n            ])\n        else:\n            modified_instructions.append(instruction)\n    modified_bytecode = Bytecode(modified_instructions)\n    # For functions, copy over argument definitions\n    modified_bytecode.argnames = decompiled.argnames\n    modified_bytecode.argcount = decompiled.argcount\n    modified_bytecode.name = decompiled.name\n    return modified_bytecode.to_code()",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-08T16:27:37",
        "author": "Michilus"
      },
      {
        "answer_id": 69501391,
        "body": "class _FormatHackLoader(importlib.machinery.SourceFileLoader):\n    \"\"\"\n    A module loader that modifies the code of the modules it imports to override\n    the behavior of f-strings. Nasty stuff.\n    \"\"\"\n    @classmethod\n    def find_spec(cls, name, path, target=None):\n        # Start out with a spec from a default finder\n        spec = importlib.machinery.PathFinder.find_spec(\n            fullname=name,\n             # Only apply to modules and packages in the current directory\n             # This prevents standard library modules or site-packages\n             # from being patched.\n            path=[\"\"],\n            target=target\n        )\n        if spec is None:\n            return None\n\n        # Modify the loader in the spec to this loader\n        spec.loader = cls(name, spec.origin)\n        return spec\n    def get_code(self, fullname):\n        # This is called by exec_module to get the code of the module\n        # to execute it.\n        code = super().get_code(fullname)\n        # Rewrite the code to modify the f-string formatting opcodes\n        rewritten_code = formathack_rewrite_bytecode__(code)\n        return rewritten_code\n    def exec_module(self, module):\n        # We introduce the callback that hooks into the f-string formatting\n        # process in every imported module\n        module.__dict__[\"formathack_hook__\"] = formathack_hook__\n        return super().exec_module(module)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-08T16:27:37",
        "author": "Michilus"
      },
      {
        "answer_id": 69501391,
        "body": "def install():\n    # If the _FormatHackLoader is not registered as a finder,\n    # do it now!\n    if sys.meta_path[0] is not _FormatHackLoader:\n        sys.meta_path.insert(0, _FormatHackLoader)\n        # Tricky part: we want to be able to use our custom f-string behavior\n        # in the main module where install was called. That module was loaded\n        # with a standard loader though, so that's impossible without additional\n        # dirty hacks.\n        # Here, we execute the module _again_, this time with _FormatHackLoader\n        module_globals = inspect.currentframe().f_back.f_globals\n        module_name = module_globals[\"__name__\"]\n        module_file = module_globals[\"__file__\"]\n        loader = _FormatHackLoader(module_name, module_file)\n        loader.load_module(module_name)\n        # This is actually pretty important. If we don't exit here, the main module\n        # will continue from the formathack.install method, causing it to run twice!\n        sys.exit(0)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-08T16:27:37",
        "author": "Michilus"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52285104/3d-scatterplots-with-hue-colormap-and-legend",
    "title": "3D scatterplots with hue colormap and legend",
    "question_id": 52285104,
    "posted_date": "2018-09-11T18:44:18",
    "answers": [
      {
        "answer_id": 64603317,
        "body": "import re, seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.colors import ListedColormap\n# generate data\nn = 200\nx = np.random.uniform(1, 20, size=n)\ny = np.random.uniform(1, 100, size=n)\nz = np.random.uniform(1, 100, size=n)\n# axes instance\nfig = plt.figure(figsize=(6,6))\nax = Axes3D(fig, auto_add_to_figure=False)\nfig.add_axes(ax)\n# get colormap from seaborn\ncmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\n# plot\nsc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\n# legend\nplt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n# save\nplt.savefig(\"scatter_hue\", bbox_inches='tight')",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2020-10-30T01:49:39",
        "author": "L&#233;onard"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/78997019/in-python-3-12-why-does-%c3%96l-take-less-memory-than-%c3%96",
    "title": "In Python 3.12, why does &#39;&#214;l&#39; take less memory than &#39;&#214;&#39;?",
    "question_id": 78997019,
    "posted_date": "2024-09-18T03:30:44",
    "answers": [
      {
        "answer_id": 78997185,
        "body": "import ctypes\nimport sys\nclass PyUnicodeObject(ctypes.Structure):\n    _fields_ = [\n        (\"ob_refcnt\", ctypes.c_ssize_t),\n        (\"ob_type\", ctypes.c_void_p),\n        (\"length\", ctypes.c_ssize_t),\n        (\"hash\", ctypes.c_ssize_t),\n        (\"state\", ctypes.c_uint64),\n    ]\nclass StateBitField(ctypes.LittleEndianStructure):\n    _fields_ = [\n        (\"interned\", ctypes.c_uint, 2),\n        (\"kind\", ctypes.c_uint, 3),\n        (\"compact\", ctypes.c_uint, 1),\n        (\"ascii\", ctypes.c_uint, 1),\n        (\"statically_allocated\", ctypes.c_uint, 1),\n        (\"_padding\", ctypes.c_uint, 24),\n    ]\n    def __repr__(self):\n        return \", \".join(f\"{k}: {getattr(self, k)}\" for k, *_ in self._fields_ if not k.startswith(\"_\"))\ndef dump_s(s: str):\n    o = PyUnicodeObject.from_address(id(s))\n    state_int = o.state\n    state = StateBitField.from_buffer(ctypes.c_uint64(state_int))\n    print(f\"{s!r}\".ljust(8), f\"{o.length=}, {sys.getsizeof(s)=}, {state}\")\ndump_s('5')\ndump_s('a')\ndump_s('\u00e4')\ndump_s('vvv')\ndump_s('\u00d6\u00d6\u00d6')\ndump_s(str(chr(214)))  # avoid the string having been interned into module source\ndump_s(str(chr(214) + chr(108)))  # avoid the string having been interned into module source",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2024-09-18T04:12:22",
        "author": "AKX"
      },
      {
        "answer_id": 78997185,
        "body": "'5'      o.length=1, sys.getsizeof(s)=42, interned: 3, kind: 1, compact: 1, ascii: 1, statically_allocated: 1\n'a'      o.length=1, sys.getsizeof(s)=42, interned: 3, kind: 1, compact: 1, ascii: 1, statically_allocated: 1\n'\u00e4'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1\n'vvv'    o.length=3, sys.getsizeof(s)=44, interned: 2, kind: 1, compact: 1, ascii: 1, statically_allocated: 0\n'\u00d6\u00d6\u00d6'    o.length=3, sys.getsizeof(s)=60, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 0\n'\u00d6'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1\n'\u00d6l'     o.length=2, sys.getsizeof(s)=59, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 0\n'\u00d6'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2024-09-18T04:12:22",
        "author": "AKX"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39767297/how-to-use-sha256-hmac-in-python-code",
    "title": "How to use SHA256-HMAC in python code?",
    "question_id": 39767297,
    "posted_date": "2016-09-29T06:04:04",
    "answers": [
      {
        "answer_id": 66958131,
        "body": "`\nimport hashlib\nimport hmac\n# Define my and key as per question\nmy = \"/api/embedded_dashboard?data=%7B%22dashboard%22%3A7863%2C%22embed%22%3A%22v2%22%2C%22filters%22%3A%5B%7B%22name%22%3A%22Filter1%22%2C%22value%22%3A%22value1%22%7D%2C%7B%22name%22%3A%22Filter2%22%2C%22value%22%3A%221234%22%7D%5D%7D\"\nkey = \"e179017a-62b0-4996-8a38-e91aa9f1\"\n# Encode as per other answers\nbyte_key = key.encode(\"UTF-8\")\nmessage = my.encode()\n# Now use the hmac.new function and the hexdigest method\nh = hmac.new(byte_key, message, hashlib.sha256).hexdigest()\n# Print the output\nprint(h)",
        "score": 44,
        "is_accepted": false,
        "creation_date": "2021-04-05T14:45:30",
        "author": "Bilbottom"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66597894/why-cannot-add-ppa-deadsnakes",
    "title": "Why cannot add PPA deadsnakes?",
    "question_id": 66597894,
    "posted_date": "2021-03-12T05:08:38",
    "answers": [
      {
        "answer_id": 67619514,
        "body": "$ sudo add-apt-repository -y 'ppa:deadsnakes/ppa'\nCannot add PPA: 'ppa:~deadsnakes/ubuntu/ppa'.\nERROR: '~deadsnakes' user or team does not exist.\n$ sudo -E add-apt-repository -y 'ppa:deadsnakes/ppa'\n This PPA contains more recent Python versions packaged for Ubuntu.\nDisclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\nUpdate Note\n===========\n...",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2021-05-20T07:32:34",
        "author": "CodeMonkey"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70916649/how-to-change-the-x-axis-and-y-axis-labels-in-plotly",
    "title": "How to change the x-axis and y-axis labels in plotly?",
    "question_id": 70916649,
    "posted_date": "2022-01-30T11:31:50",
    "answers": [
      {
        "answer_id": 70916879,
        "body": "import pandas as pd\nimport io, requests\ndf = pd.read_csv(\n    io.StringIO(\n        requests.get(\n            \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv\"\n        ).text\n    )\n)\ndf[\"Date\"] = pd.to_datetime(df[\"date\"])\ndf[\"Country\"] = df[\"location\"]\ndf[\"7day_rolling_avg\"] = df[\"daily_people_vaccinated_per_hundred\"]\nDate = df[df.Country == \"India\"].Date\nNew_cases = df[df.Country == \"India\"][\"7day_rolling_avg\"]\npx.line(df, x=Date, y=New_cases, title=\"India Daily New Covid Cases\").update_layout(\n    xaxis_title=\"Date\", yaxis_title=\"7 day avg\"\n)",
        "score": 56,
        "is_accepted": true,
        "creation_date": "2022-01-30T11:59:06",
        "author": "Rob Raymond"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60703127/how-to-catch-botocore-errorfactory-usernotfoundexception",
    "title": "How to catch `botocore.errorfactory.UserNotFoundException`?",
    "question_id": 60703127,
    "posted_date": "2020-03-16T05:12:13",
    "answers": [
      {
        "answer_id": 68521788,
        "body": "import boto3\neks = boto3.client('eks')\nprint(dir(eks.exceptions))\n# ['BadRequestException',\n# 'ClientError',\n# 'ClientException',\n# 'InvalidParameterException',\n# 'InvalidRequestException',\n# 'NotFoundException',\n# 'ResourceInUseException',\n# 'ResourceLimitExceededException',\n# 'ResourceNotFoundException',\n# 'ServerException',\n# 'ServiceUnavailableException',\n# 'UnsupportedAvailabilityZoneException', ...]\ntry:\n    response = eks.list_nodegroups(clusterName='my-cluster')\nexcept eks.exceptions.ResourceNotFoundException as e:\n    # do something with e\n    print(\"handled: \" + str(e))\ncognito_idp = boto3.client('cognito-idp')\nprint(dir(cognito_idp.exceptions))\n# [ 'ClientError',\n# 'ConcurrentModificationException',\n# 'DeveloperUserAlreadyRegisteredException',\n# 'ExternalServiceException',\n# 'InternalErrorException',\n# 'InvalidIdentityPoolConfigurationException',\n# 'InvalidParameterException',\n# 'LimitExceededException',\n# 'NotAuthorizedException',\n# 'ResourceConflictException',\n# 'ResourceNotFoundException',\n# 'TooManyRequestsException', ... ]\ntry:\n    response = cognito_idp.admin_get_user(\n        UserPoolId='pool_id',\n        Username='username'\n    )\nexcept cognito_idp.exceptions.UserNotFoundException as e:\n    # do something with e\n    print(\"handled: \" + str(e))",
        "score": 42,
        "is_accepted": false,
        "creation_date": "2021-07-25T15:11:45",
        "author": "Maxim Suslov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/27396339/attributeerror-cant-set-attribute",
    "title": "AttributeError: can&#39;t set attribute",
    "question_id": 27396339,
    "posted_date": "2014-12-10T03:29:40",
    "answers": [
      {
        "answer_id": 27627094,
        "body": "class MAMLMetaLearner(nn.Module):\n    def __init__(\n            self,\n            args,\n            base_model,\n            inner_debug=False,\n            target_type='classification'\n    ):\n        super().__init__()\n        self.args = args  # args for experiment\n        self.base_model = base_model\n        assert base_model is args.model\n        self.inner_debug = inner_debug\n        self.target_type = target_type\n    @property\n    def lr_inner(self) -> float:\n        return self.args.inner_lr\n    @lr_inner.setter\n    def lr_inner(self, new_val: float):\n        self.args.inner_lr = new_val",
        "score": 117,
        "is_accepted": false,
        "creation_date": "2014-12-23T14:52:30",
        "author": "yoniLavi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50533812/what-is-the-best-way-to-define-constant-variables-python-3",
    "title": "what is the best way to define constant variables python 3",
    "question_id": 50533812,
    "posted_date": "2018-05-25T12:56:36",
    "answers": [
      {
        "answer_id": 65706030,
        "body": "from typing import Final\n# Annotate module variables\n# (with or without an explicit type, using the syntax Final[<type>])\n# (type is auto-determined in absence of an explicit type)\nPI: Final[float] = 3.141592654\nANSWER_TO_EVERYTHING: Final = 42\n# Annotate instance variables in class bodies\n# (explicit type is needed if no value is assigned)\nclass Point:\n    x: Final[int]\n    y: Final = 0\n    def __init__(self, x: int):\n        self.x = x\n# Annotate instance variables directly\n# (only allowed in __init__ methods)\nclass Person:\n    def __init__(self, birth_year: int):\n        self.birth_year: Final = birth_year",
        "score": 42,
        "is_accepted": false,
        "creation_date": "2021-01-13T11:31:44",
        "author": "user14733755"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71520075/zip-longest-for-the-left-list-always",
    "title": "zip_longest for the left list always",
    "question_id": 71520075,
    "posted_date": "2022-03-17T19:12:37",
    "answers": [
      {
        "answer_id": 71520401,
        "body": "10 iterables of 10,000 to 90,000 elements, first has 50,000:\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 2.2 ms   2.2 ms   2.3 ms  limit_cheat\n 2.6 ms   2.6 ms   2.6 ms  Kelly_Bundy_chain\n 3.3 ms   3.3 ms   3.3 ms  Kelly_Bundy_compress\n50.2 ms  50.6 ms  50.7 ms  CrazyChucky\n54.7 ms  55.0 ms  55.0 ms  Sven_Marnach\n74.8 ms  74.9 ms  75.0 ms  Mad_Physicist\n 5.4 ms   5.4 ms   5.4 ms  Kelly_Bundy_3\n 5.9 ms   6.0 ms   6.0 ms  Kelly_Bundy_4\n 4.6 ms   4.7 ms   4.7 ms  Kelly_Bundy_5\n10,000 iterables of 0 to 100 elements, first has 50:\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 4.6 ms   4.7 ms   4.8 ms  limit_cheat\n 4.8 ms   4.8 ms   4.8 ms  Kelly_Bundy_compress\n 8.4 ms   8.4 ms   8.4 ms  Kelly_Bundy_chain\n27.1 ms  27.3 ms  27.5 ms  CrazyChucky\n38.3 ms  38.5 ms  38.7 ms  Sven_Marnach\n73.0 ms  73.0 ms  73.1 ms  Mad_Physicist\n 4.9 ms   4.9 ms   5.0 ms  Kelly_Bundy_3\n 4.9 ms   4.9 ms   5.0 ms  Kelly_Bundy_4\n 5.0 ms   5.0 ms   5.0 ms  Kelly_Bundy_5",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2022-03-17T19:59:52",
        "author": "Kelly Bundy"
      },
      {
        "answer_id": 71520401,
        "body": "def limit_cheat(*iterables, fillvalue=None):\n    return islice(zip_longest(*iterables, fillvalue=fillvalue), cheat_length)\ndef Kelly_Bundy_chain(first, *rest, fillvalue=None):\n    return zip(first, *map(chain, rest, repeat(repeat(fillvalue))))\ndef Kelly_Bundy_compress(first, *rest, fillvalue=None):\n    a, b = tee(first)\n    return compress(zip_longest(b, *rest, fillvalue=fillvalue), zip(a))\ndef CrazyChucky(*iterables, fillvalue=None):\n    SENTINEL = object()\n\n    for first, *others in zip_longest(*iterables, fillvalue=SENTINEL):\n        if first is SENTINEL:\n            return\n        others = [i if i is not SENTINEL else fillvalue for i in others]\n        yield (first, *others)\ndef Sven_Marnach(first, *rest, fillvalue=None):\n    rest = [iter(r) for r in rest]\n    for x in first:\n        yield x, *(next(r, fillvalue) for r in rest)\ndef Mad_Physicist(*args, fillvalue=None):\n    # zip_by_first('ABCD', 'xy', fillvalue='-') --> Ax By C- D-\n    # zip_by_first('ABC', 'xyzw', fillvalue='-') --> Ax By Cz\n    if not args:\n        return\n    iterators = [iter(it) for it in args]\n    while True:\n        values = []\n        for i, it in enumerate(iterators):\n            try:\n                value = next(it)\n            except StopIteration:\n                if i == 0:\n                    return\n                iterators[i] = repeat(fillvalue)\n                value = fillvalue\n            values.append(value)\n        yield tuple(values)\ndef Kelly_Bundy_3(first, *rest, fillvalue=None):\n    a, b = tee(first)\n    return map(itemgetter(1), zip(a, zip_longest(b, *rest, fillvalue=fillvalue)))\ndef Kelly_Bundy_4(first, *rest, fillvalue=None):\n    sentinel = object()\n    for z in zip_longest(chain(first, [sentinel]), *rest, fillvalue=fillvalue):\n        if z[0] is sentinel:\n            break\n        yield z\ndef Kelly_Bundy_5(first, *rest, fillvalue=None):\n    stopped = False\n    def stop():\n        nonlocal stopped\n        stopped = True\n        return\n        yield\n    for z in zip_longest(chain(first, stop()), *rest, fillvalue=fillvalue):\n        if stopped:\n            break\n        yield z\nimport timeit\nfrom itertools import chain, repeat, zip_longest, islice, tee, compress\nfrom operator import itemgetter\nfrom collections import deque\nfuncs = [\n    limit_cheat,\n    Kelly_Bundy_chain,\n    Kelly_Bundy_compress,\n    CrazyChucky,\n    Sven_Marnach,\n    Mad_Physicist,\n    Kelly_Bundy_3,\n    Kelly_Bundy_4,\n    Kelly_Bundy_5,\n]\ndef test(args_creator):\n    # Correctness\n    expect = list(funcs[0](*args_creator()))\n    for func in funcs:\n        result = list(func(*args_creator()))\n        print(result == expect, func.__name__)\n\n    # Speed\n    tss = [[] for _ in funcs]\n    for _ in range(5):\n        print()\n        print(args_creator.__name__)\n        for func, ts in zip(funcs, tss):\n            t = min(timeit.repeat(lambda: deque(func(*args_creator()), 0), number=1))\n            ts.append(t)\n            print(*('%4.1f ms ' % (t * 1e3) for t in sorted(ts)[:3]), func.__name__)\ndef args_few_but_long_iterables():\n    global cheat_length\n    cheat_length = 50_000\n    first = repeat(0, 50_000)\n    rest = [repeat(i, 10_000 * i) for i in range(1, 10)]\n    return first, *rest\ndef args_many_but_short_iterables():\n    global cheat_length\n    cheat_length = 50\n    first = repeat(0, 50)\n    rest = [repeat(i, i % 101) for i in range(1, 10_000)]\n    return first, *rest\ntest(args_few_but_long_iterables)\nfuncs[1:3] = funcs[1:3][::-1]\ntest(args_many_but_short_iterables)",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2022-03-17T19:59:52",
        "author": "Kelly Bundy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/28453545/connecting-to-an-oracle-database-using-sqlalchemy",
    "title": "Connecting to an Oracle database using SQLAlchemy",
    "question_id": 28453545,
    "posted_date": "2015-02-11T06:44:26",
    "answers": [
      {
        "answer_id": 57693172,
        "body": "from sqlalchemy.engine import create_engine\nDIALECT = 'oracle'\nSQL_DRIVER = 'cx_oracle'\nUSERNAME = 'your_username' #enter your username\nPASSWORD = 'your_password' #enter your password\nHOST = 'subdomain.domain.tld' #enter the oracle db host url\nPORT = 1521 # enter the oracle port number\nSERVICE = 'your_oracle_service_name' # enter the oracle db service name\nENGINE_PATH_WIN_AUTH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\nengine = create_engine(ENGINE_PATH_WIN_AUTH)\n#test query\nimport pandas as pd\ntest_df = pd.read_sql_query('SELECT * FROM global_name', engine)",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2019-08-28T09:07:09",
        "author": "Luis Arteaga"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/19130986/python-equivalent-of-golangs-select-on-channels",
    "title": "Python equivalent of Golang&#39;s select on channels",
    "question_id": 19130986,
    "posted_date": "2013-10-02T02:16:08",
    "answers": [
      {
        "answer_id": 19131479,
        "body": "import threading\nimport Queue\ndef main():\n    c1 = Queue.Queue(maxsize=0)\n    c2 = Queue.Queue(maxsize=0)\n    quit = Queue.Queue(maxsize=0)\n    def func1():\n        for i in range(10):\n            c1.put(i)\n        quit.put(0)\n    threading.Thread(target=func1).start()\n    def func2():\n        for i in range(2):\n            c2.put(i)\n    threading.Thread(target=func2).start()\n    combined = Queue.Queue(maxsize=0)\n    def listen_and_forward(queue):\n        while True:\n            combined.put((queue, queue.get()))\n    t = threading.Thread(target=listen_and_forward, args=(c1,))\n    t.daemon = True\n    t.start()\n    t = threading.Thread(target=listen_and_forward, args=(c2,))\n    t.daemon = True\n    t.start()\n    t = threading.Thread(target=listen_and_forward, args=(quit,))\n    t.daemon = True\n    t.start()\n    while True:\n        which, message = combined.get()\n        if which is c1:\n            print 'Received value from c1'\n        elif which is c2:\n            print 'Received value from c2'\n        elif which is quit:\n            print 'Received value from quit'\n            return\nmain()",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2013-10-02T02:57:00",
        "author": "Thomas"
      },
      {
        "answer_id": 19131479,
        "body": "import threading\nimport Queue\ndef select(*queues):\n    combined = Queue.Queue(maxsize=0)\n    def listen_and_forward(queue):\n        while True:\n            combined.put((queue, queue.get()))\n    for queue in queues:\n        t = threading.Thread(target=listen_and_forward, args=(queue,))\n        t.daemon = True\n        t.start()\n    while True:\n        yield combined.get()\ndef main():\n    c1 = Queue.Queue(maxsize=0)\n    c2 = Queue.Queue(maxsize=0)\n    quit = Queue.Queue(maxsize=0)\n    def func1():\n        for i in range(10):\n            c1.put(i)\n        quit.put(0)\n    threading.Thread(target=func1).start()\n    def func2():\n        for i in range(2):\n            c2.put(i)\n    threading.Thread(target=func2).start()\n    for which, msg in select(c1, c2, quit):\n        if which is c1:\n            print 'Received value from c1'\n        elif which is c2:\n            print 'Received value from c2'\n        elif which is quit:\n            print 'Received value from quit'\n            return\nmain()",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2013-10-02T02:57:00",
        "author": "Thomas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48170682/can-structured-logging-be-done-with-pythons-standard-library",
    "title": "Can structured logging be done with Pythons standard library?",
    "question_id": 48170682,
    "posted_date": "2018-01-09T09:46:22",
    "answers": [
      {
        "answer_id": 67953106,
        "body": "from datetime import datetime\nimport json\nimport logging\nimport sys\nimport traceback\nAPP_NAME = 'hello world json logging'\nAPP_VERSION = 'git rev-parse HEAD'\nLOG_LEVEL = logging._nameToLevel['INFO']\nclass JsonEncoderStrFallback(json.JSONEncoder):\n  def default(self, obj):\n    try:\n      return super().default(obj)\n    except TypeError as exc:\n      if 'not JSON serializable' in str(exc):\n        return str(obj)\n      raise\nclass JsonEncoderDatetime(JsonEncoderStrFallback):\n  def default(self, obj):\n    if isinstance(obj, datetime):\n      return obj.strftime('%Y-%m-%dT%H:%M:%S%z')\n    else:\n      return super().default(obj)\nlogging.basicConfig(\n  format='%(json_formatted)s',\n  level=LOG_LEVEL,\n  handlers=[\n    # if you wish to also log to a file:\n    # logging.FileHandler(log_file_path, 'a'),\n    logging.StreamHandler(sys.stdout),\n  ],\n)\n_record_factory_bak = logging.getLogRecordFactory()\ndef record_factory(*args, **kwargs) -> logging.LogRecord:\n  record = _record_factory_bak(*args, **kwargs)\n\n  record.json_formatted = json.dumps(\n    {\n      'level': record.levelname,\n      'unixtime': record.created,\n      'thread': record.thread,\n      'location': '{}:{}:{}'.format(\n        record.pathname or record.filename,\n        record.funcName,\n        record.lineno,\n      ),\n      'exception': record.exc_info,\n      'traceback': (\n        traceback.format_exception(*record.exc_info)\n        if record.exc_info\n        else None\n      ),\n      'app': {\n        'name': APP_NAME,\n        'releaseId': APP_VERSION,\n        'message': record.getMessage(),\n      },\n    },\n    cls=JsonEncoderDatetime,\n  )\n  # clear exc data since it is included in the json format\n  # without clearing this, logging.exception will print the\n  # traceback across multiple lines, which is not json formatted\n  record.exc_info = None\n  record.exc_text = None\n  return record\nlogging.setLogRecordFactory(record_factory)",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2021-06-12T17:22:28",
        "author": "sam2426679"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59180574/string-concatenation-with-vs-f-string",
    "title": "String concatenation with + vs. f-string",
    "question_id": 59180574,
    "posted_date": "2019-12-04T11:29:07",
    "answers": [
      {
        "answer_id": 59183178,
        "body": "from timeit import timeit\nimport matplotlib.pyplot as plt\nn = 1000000000\nsetup = \"\"\"\\\na = 'a'*{str_len}\nb = 'b'*{str_len}\n\"\"\"\nfstr_stmt = \"\"\"\\\nf'{a}{b}'\n\"\"\"\nconcat_stmt = \"\"\"\\\na+b\n\"\"\"\nstr_lens = [10, 100, 1000, 10000, 100000, 1000000]\nfstr_t = []\nconcat_t = []\nfor str_len in str_lens:\n    n_iters = n//str_len\n    fstr_t.append(timeit(setup=setup.format(str_len=str_len), stmt=fstr_stmt, number=n_iters)/n_iters)\n    concat_t.append(timeit(setup=setup.format(str_len=str_len), stmt=concat_stmt, number=n_iters)/n_iters)\n    ratio = fstr_t[-1]/concat_t[-1]\n    print(f\"For two strings of length {str_len:7d}, concatenation is {ratio:.5f} times faster than f-strings\")\nplt.plot(str_lens, fstr_t, \"r*-\")\nplt.plot(str_lens, concat_t, \"c*-\")\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.xlabel(\"String length (log scale)\")\nplt.ylabel(\"Seconds per iteration (log scale)\")\nplt.grid()\nplt.show()",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2019-12-04T14:12:56",
        "author": "SyntaxVoid"
      },
      {
        "answer_id": 59183178,
        "body": "For two strings of length      10, concatenation is 1.06938 times faster than f-strings\nFor two strings of length     100, concatenation is 1.14887 times faster than f-strings\nFor two strings of length    1000, concatenation is 1.13994 times faster than f-strings\nFor two strings of length   10000, concatenation is 1.26934 times faster than f-strings\nFor two strings of length  100000, concatenation is 1.21585 times faster than f-strings\nFor two strings of length 1000000, concatenation is 1.01816 times faster than f-strings",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2019-12-04T14:12:56",
        "author": "SyntaxVoid"
      },
      {
        "answer_id": 59183178,
        "body": "For three strings of length      10, concatenation is 0.77931 times faster than f-strings\nFor three strings of length     100, concatenation is 0.67699 times faster than f-strings\nFor three strings of length    1000, concatenation is 0.60220 times faster than f-strings\nFor three strings of length   10000, concatenation is 1.27484 times faster than f-strings\nFor three strings of length  100000, concatenation is 0.98911 times faster than f-strings\nFor three strings of length 1000000, concatenation is 0.60201 times faster than f-strings",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2019-12-04T14:12:56",
        "author": "SyntaxVoid"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/22381497/python-scikit-learn-linear-model-parameter-standard-error",
    "title": "Python scikit learn Linear Model Parameter Standard Error",
    "question_id": 22381497,
    "posted_date": "2014-03-13T10:20:43",
    "answers": [
      {
        "answer_id": 58357360,
        "body": "...\n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.2867      0.247     -1.161      0.290      -0.891       0.317\nx1             0.1750      0.297      0.590      0.577      -0.551       0.901\nx2            -0.6929      0.352     -1.969      0.096      -1.554       0.168\nx3             0.2234      0.325      0.687      0.518      -0.572       1.019\n==============================================================================",
        "score": 37,
        "is_accepted": false,
        "creation_date": "2019-10-12T14:44:48",
        "author": "william_grisaitis"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64124931/how-to-fix-versionconflict-locking-failure-in-pipenv",
    "title": "How to fix VersionConflict locking failure in pipenv?",
    "question_id": 64124931,
    "posted_date": "2020-09-29T13:47:29",
    "answers": [
      {
        "answer_id": 64141185,
        "body": "Traceback (most recent call last):\n  File \"/usr/local/bin/pipenv\", line 8, in <module>\n    sys.exit(cli())\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/decorators.py\", line 73, in new_func\n    return ctx.invoke(f, obj, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/vendor/click/decorators.py\", line 21, in new_func\n    return f(get_current_context(), *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/cli/command.py\", line 252, in install\n    site_packages=state.site_packages\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/core.py\", line 1928, in do_install\n    site_packages=site_packages,\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/core.py\", line 580, in ensure_project\n    pypi_mirror=pypi_mirror,\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/core.py\", line 512, in ensure_virtualenv\n    python=python, site_packages=site_packages, pypi_mirror=pypi_mirror\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/core.py\", line 999, in do_create_virtualenv\n    project._environment.add_dist(\"pipenv\")\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/environment.py\", line 135, in add_dist\n    self.extend_dists(dist)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/environment.py\", line 127, in extend_dists\n    extras = self.resolve_dist(dist, self.base_working_set)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/environment.py\", line 122, in resolve_dist\n    deps |= cls.resolve_dist(dist, working_set)\n  File \"/usr/local/lib/python3.6/site-packages/pipenv/environment.py\", line 121, in resolve_dist\n    dist = working_set.find(req)\n  File \"/usr/local/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 642, in find\n    raise VersionConflict(dist, req)\npkg_resources.VersionConflict: (importlib-metadata 2.0.0 (/usr/local/lib/python3.6/site-packages), Requirement.parse('importlib-metadata<2,>=0.12; python_version < \"3.8\"'))",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2020-09-30T11:45:56",
        "author": "Brent O&#39;Connor"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/28237955/same-name-for-classmethod-and-instancemethod",
    "title": "Same name for classmethod and instancemethod",
    "question_id": 28237955,
    "posted_date": "2015-01-30T09:25:28",
    "answers": [
      {
        "answer_id": 28238047,
        "body": "from typing import Generic, Callable, TypeVar, overload\nfrom typing_extensions import Concatenate, ParamSpec, Self\n_T = TypeVar(\"_T\")\n_R_co = TypeVar(\"_R_co\", covariant=True)\n_R1_co = TypeVar(\"_R1_co\", covariant=True)\n_R2_co = TypeVar(\"_R2_co\", covariant=True)\n_P = ParamSpec(\"_P\")\nclass class_or_instancemethod(classmethod[_T, _P, _R_co]):\n    def __get__(\n        self, instance: _T, type_: type[_T] | None = None\n    ) -> Callable[_P, _R_co]:\n        descr_get = super().__get__ if instance is None else self.__func__.__get__\n        return descr_get(instance, type_)\nclass hybridmethod(Generic[_T, _P, _R1_co, _R2_co]):\n    fclass: Callable[Concatenate[type[_T], _P], _R1_co]\n    finstance: Callable[Concatenate[_T, _P], _R2_co] | None\n    __doc__: str | None\n    __isabstractmethod__: bool\n    def __init__(\n        self,\n        fclass: Callable[Concatenate[type[_T], _P], _R1_co],\n        finstance: Callable[Concatenate[_T, _P], _R2_co] | None = None,\n        doc: str | None = None,\n    ):\n        self.fclass = fclass\n        self.finstance = finstance\n        self.__doc__ = doc or fclass.__doc__\n        # support use on abstract base classes\n        self.__isabstractmethod__ = bool(getattr(fclass, \"__isabstractmethod__\", False))\n    def classmethod(self, fclass: Callable[Concatenate[type[_T], _P], _R1_co]) -> Self:\n        return type(self)(fclass, self.finstance, None)\n    def instancemethod(self, finstance: Callable[Concatenate[_T, _P], _R2_co]) -> Self:\n        return type(self)(self.fclass, finstance, self.__doc__)\n    @overload\n    def __get__(self, instance: None, cls: type[_T]) -> Callable[_P, _R1_co]: ...\n    @overload\n    def __get__(self, instance: _T, cls: type[_T] | None = ...) -> Callable[_P, _R1_co] | Callable[_P, _R2_co]: ...\n    def __get__(self, instance: _T, cls: type[_T] | None = None) -> Callable[_P, _R1_co] | Callable[_P, _R2_co]:\n        if instance is None or self.finstance is None:\n            # either bound to the class, or no instance method available\n            return self.fclass.__get__(cls, None)\n        return self.finstance.__get__(instance, cls)",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2015-01-30T09:30:19",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41296313/stacked-bar-chart-with-centered-labels",
    "title": "Stacked Bar Chart with Centered Labels",
    "question_id": 41296313,
    "posted_date": "2016-12-23T01:32:52",
    "answers": [
      {
        "answer_id": 60895640,
        "body": "# plot\ng = sns.displot(data=df, x='cat', hue='variable', weights='value', discrete=True, multiple='stack')\n# iterate through each axes\nfor ax in g.axes.flat:\n    # iterate through each container\n    for c in ax.containers:\n        # Optional: if the segment is small or 0, customize the labels\n        labels = [v.get_height() if v.get_height() > 0 else '' for v in c]\n        # remove the labels parameter if it's not needed for customized labels\n        ax.bar_label(c, labels=labels, label_type='center')",
        "score": 67,
        "is_accepted": false,
        "creation_date": "2020-03-27T19:50:25",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 60895640,
        "body": "plt.style.use('ggplot')\nax = df.plot(stacked=True, kind='bar', figsize=(12, 8), rot='horizontal')\n# .patches is everything inside of the chart\nfor rect in ax.patches:\n    # Find where everything is located\n    height = rect.get_height()\n    width = rect.get_width()\n    x = rect.get_x()\n    y = rect.get_y()\n\n    # The height of the bar is the data value and can be used as the label\n    label_text = f'{height}'  # f'{height:.2f}' to format decimal values\n\n    # ax.text(x, y, text)\n    label_x = x + width / 2\n    label_y = y + height / 2\n    # plot only when height is greater than specified value\n    if height > 0:\n        ax.text(label_x, label_y, label_text, ha='center', va='center', fontsize=8)\n\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\nax.set_ylabel(\"Count\", fontsize=18)\nax.set_xlabel(\"Class\", fontsize=18)\nplt.show()",
        "score": 67,
        "is_accepted": false,
        "creation_date": "2020-03-27T19:50:25",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/14355499/how-to-model-a-unique-constraint-in-sqlalchemy",
    "title": "How to model a `UNIQUE` constraint in SQLAlchemy?",
    "question_id": 14355499,
    "posted_date": "2013-01-16T04:51:35",
    "answers": [
      {
        "answer_id": 76066471,
        "body": "from sqlalchemy.orm import declarative_base\nfrom sqlalchemy import Column, Integer, UniqueConstraint\nBase = declarative_base()\nclass Model(Base):\n    __tablename__ = \"model\"\n    model_id = Column(Integer, primary_key=True)\n    # will create \"model_num_key\" UNIQUE CONSTRAINT, btree (num)\n    num = Column(Integer, unique=True)\n    # same with UniqueConstraint:\n    num2 = Column(Integer)\n    __table_args__ = (UniqueConstraint(\"num2\", name=\"model_num2_key\"),)\n    # for multiple columns:\n    # __table_args__ = (UniqueConstraint(\"num\", \"num2\", name=\"two_columns\"),)",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2023-04-20T12:42:57",
        "author": "kosciej16"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65883869/can-i-override-fields-from-a-pydantic-parent-model-to-make-them-optional",
    "title": "Can I override fields from a Pydantic parent model to make them optional?",
    "question_id": 65883869,
    "posted_date": "2021-01-25T06:29:14",
    "answers": [
      {
        "answer_id": 65907609,
        "body": "class ParentBase(BaseModel):\n    \"\"\"Shared properties.\"\"\"\n    name: str\n    email: str\nclass ParentCreate(ParentBase):\n    \"\"\"Properties to receive on item creation.\"\"\"\n    # dont need id here if your db autocreates it\n    pass\nclass ParentUpdate(ParentBase):\n    \"\"\"Properties to receive on item update.\"\"\"\n    # dont need id as you are likely PUTing to /parents/{id}\n    # other fields should not be optional in a PUT\n    # maybe what you are wanting is a PATCH schema?\n    pass\nclass ParentInDBBase(ParentBase):\n    \"\"\"Properties shared by models stored in DB - !exposed in create/update.\"\"\"\n    # primary key exists in db, but not in base/create/update\n    id: int\nclass Parent(ParentInDBBase):\n    \"\"\"Properties to return to client.\"\"\"\n    # optionally include things like relationships returned to consumer\n    # related_things: List[Thing]\n    pass\nclass ParentInDB(ParentInDBBase):\n    \"\"\"Additional properties stored in DB.\"\"\"\n    # could be secure things like passwords?\n    pass",
        "score": 22,
        "is_accepted": true,
        "creation_date": "2021-01-26T14:00:38",
        "author": "shawnwall"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73365780/why-is-not-recommended-to-install-poetry-with-homebrew",
    "title": "Why is not recommended to install poetry with homebrew?",
    "question_id": 73365780,
    "posted_date": "2022-08-15T15:48:15",
    "answers": [
      {
        "answer_id": 73365831,
        "body": "\u276f pipx list\nvenvs are in /Users/redacted/.local/pipx/venvs\napps are exposed on your $PATH at /Users/redacted/Code/dotfiles/bin\n   package hatch 1.7.0, installed using Python 3.11.5\n    - hatch\n   package poetry 1.2.2, installed using Python 3.11.5\n    - poetry\n   package poetry 1.3.2 (poetry@1.3), installed using Python 3.11.5\n    - poetry@1.3\n   package poetry 1.6.1 (poetry@1.6), installed using Python 3.11.5\n    - poetry@1.6\n\u276f poetry --version\nPoetry (version 1.2.2)\n\u276f poetry@1.3 --version\nPoetry (version 1.3.2)",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2022-08-15T15:54:18",
        "author": "Kache"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54491156/validate-json-data-using-python",
    "title": "Validate JSON data using python",
    "question_id": 54491156,
    "posted_date": "2019-02-02T02:57:13",
    "answers": [
      {
        "answer_id": 54491882,
        "body": "import json\nfrom jsonschema import validate\n# Describe what kind of json you expect.\nschema = {\n    \"type\" : \"object\",\n    \"properties\" : {\n        \"description\" : {\"type\" : \"string\"},\n        \"status\" : {\"type\" : \"boolean\"},\n        \"value_a\" : {\"type\" : \"number\"},\n        \"value_b\" : {\"type\" : \"number\"},\n    },\n}\n# Convert json to python object.\nmy_json = json.loads('{\"description\": \"Hello world!\", \"status\": true, \"value_a\": 1, \"value_b\": 3.14}')\n# Validate will raise exception if given json is not\n# what is described in schema.\nvalidate(instance=my_json, schema=schema)\n# print for debug\nprint(my_json)",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2019-02-02T04:54:14",
        "author": "T.Nylund"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/77001129/how-to-configure-fastapi-logging-so-that-it-works-both-with-uvicorn-locally-and",
    "title": "How to configure FastAPI logging so that it works both with Uvicorn locally and in production?",
    "question_id": 77001129,
    "posted_date": "2023-08-29T10:32:37",
    "answers": [
      {
        "answer_id": 77007723,
        "body": "LOGGING_CONFIG = {\n    'version': 1,\n    'disable_existing_loggers': True,\n    'formatters': {\n        'standard': {\n            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'\n        },\n        'custom_formatter': {\n            'format': \"%(asctime)s [%(processName)s: %(process)d] [%(threadName)s: %(thread)d] [%(levelname)s] %(name)s: %(message)s\"\n\n        },\n    },\n    'handlers': {\n        'default': {\n            'formatter': 'standard',\n            'class': 'logging.StreamHandler',\n            'stream': 'ext://sys.stdout',  # Default is stderr\n        },\n        'stream_handler': {\n            'formatter': 'custom_formatter',\n            'class': 'logging.StreamHandler',\n            'stream': 'ext://sys.stdout',  # Default is stderr\n        },\n        'file_handler': {\n            'formatter': 'custom_formatter',\n            'class': 'logging.handlers.RotatingFileHandler',\n            'filename': 'app.log',\n            'maxBytes': 1024 * 1024 * 1, # = 1MB\n            'backupCount': 3,\n        },\n    },\n    'loggers': {\n        'uvicorn': {\n            'handlers': ['default', 'file_handler'],\n            'level': 'TRACE',\n            'propagate': False\n        },\n        'uvicorn.access': {\n            'handlers': ['stream_handler', 'file_handler'],\n            'level': 'TRACE',\n            'propagate': False\n        },\n        'uvicorn.error': {\n            'handlers': ['stream_handler', 'file_handler'],\n            'level': 'TRACE',\n            'propagate': False\n        },\n        'uvicorn.asgi': {\n            'handlers': ['stream_handler', 'file_handler'],\n            'level': 'TRACE',\n            'propagate': False\n        },\n    },\n}",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2023-08-30T07:50:16",
        "author": "Chris"
      },
      {
        "answer_id": 77007723,
        "body": "LOGGING_CONFIG = {\n    'version': 1,\n    'disable_existing_loggers': True,\n    'formatters': {\n        'standard': ...,  # same as above or customize that as well\n        'custom_formatter': {\n            'format': \"{'time':'%(asctime)s', 'process_name': '%(processName)s', 'process_id': '%(process)s', 'thread_name': '%(threadName)s', 'thread_id': '%(thread)s','level': '%(levelname)s', 'logger_name': '%(name)s', 'message': '%(message)s'}\"\n        },\n    },\n    ...  # the rest is the same as in the original settings.py above\n}",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2023-08-30T07:50:16",
        "author": "Chris"
      },
      {
        "answer_id": 77007723,
        "body": "import logging, json\nclass CustomJSONFormatter(logging.Formatter):\n    def __init__(self, fmt):\n        logging.Formatter.__init__(self, fmt)\n    def format(self, record):\n        logging.Formatter.format(self, record)\n        return json.dumps(get_log(record), indent=2)\ndef get_log(record):\n    d = {\n        \"time\": record.asctime,\n        \"process_name\": record.processName,\n        \"process_id\": record.process,\n        \"thread_name\": record.threadName,\n        \"thread_id\": record.thread,\n        \"level\": record.levelname,\n        \"logger_name\": record.name,\n        \"pathname\": record.pathname,\n        \"line\": record.lineno,\n        \"message\": record.message,\n    }\n    if hasattr(record, \"extra_info\"):\n        d[\"req\"] = record.extra_info[\"req\"]\n        d[\"res\"] = record.extra_info[\"res\"]\n    return d\nLOGGING_CONFIG = {\n    'version': 1,\n    'disable_existing_loggers': True,\n    'formatters': {\n        'standard': ...,  # same as above or customize that as well\n        'custom_formatter': {\n            '()':  lambda: CustomJSONFormatter(fmt='%(asctime)s')\n        },\n    },\n    ...  # the rest is the same as in the original settings.py above\n}",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2023-08-30T07:50:16",
        "author": "Chris"
      },
      {
        "answer_id": 77007723,
        "body": "{\n  \"time\": \"2024-10-27 11:05:00,300\",\n  \"process_name\": \"MainProcess\",\n  \"process_id\": 4102,\n  \"thread_name\": \"AnyIO worker thread\",\n  \"thread_id\": 1147,\n  \"level\": \"INFO\",\n  \"logger_name\": \"uvicorn.error\",\n  \"pathname\": \"C:\\\\...\",\n  \"line\": 33,\n  \"message\": \"GET /\",\n  \"req\": {\n    \"url\": \"/\",\n    \"headers\": {\n      \"host\": \"localhost:8000\",\n      \"user-agent\": \"Mozilla...\",\n      \"accept\": \"text/html,application/xhtml+xml,...\"\n    },\n    \"method\": \"GET\",\n    \"http_version\": \"1.1\",\n    \"original_url\": \"/\",\n    \"query\": {}\n  },\n  \"res\": {\n    \"status_code\": 200,\n    \"status\": \"OK\"\n  }\n}",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2023-08-30T07:50:16",
        "author": "Chris"
      },
      {
        "answer_id": 77007723,
        "body": "from fastapi import FastAPI\nimport logging\nimport uvicorn\nimport sys\napp = FastAPI()\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\"%(asctime)s [%(processName)s: %(process)d] [%(threadName)s: %(thread)d] [%(levelname)s] %(name)s: %(message)s\")\nstream_handler = logging.StreamHandler(sys.stdout)\nstream_handler.setFormatter(formatter)\nfile_handler = logging.FileHandler(\"info.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(stream_handler)\nlogger.addHandler(file_handler)\nlogger.info('API is starting up')\n@app.get('/')\nasync def main():\n    logger.info('GET /')\n    return 'ok'\nif __name__ == '__main__':\n    uvicorn.run(app, log_level=\"trace\")  # or `log_config=settings.LOGGING_CONFIG`",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2023-08-30T07:50:16",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4596962/display-graph-without-saving-using-pydot",
    "title": "Display graph without saving using pydot",
    "question_id": 4596962,
    "posted_date": "2011-01-04T13:19:40",
    "answers": [
      {
        "answer_id": 18522941,
        "body": "import io\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport networkx as nx\n# create a `networkx` graph\ng = nx.MultiDiGraph()\ng.add_nodes_from([1,2])\ng.add_edge(1, 2)\n# convert from `networkx` to a `pydot` graph\npydot_graph = nx.drawing.nx_pydot.to_pydot(g)\n# render the `pydot` by calling `dot`, no file saved to disk\npng_str = pydot_graph.create_png(prog='dot')\n# treat the DOT output as an image file\nsio = io.BytesIO()\nsio.write(png_str)\nsio.seek(0)\nimg = mpimg.imread(sio)\n# plot the image\nimgplot = plt.imshow(img, aspect='equal')\nplt.show()",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2013-08-29T20:13:23",
        "author": "0 _"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62853539/how-to-plot-on-secondary-y-axis-with-plotly-express",
    "title": "How to plot on secondary y-Axis with plotly express",
    "question_id": 62853539,
    "posted_date": "2020-07-11T15:18:24",
    "answers": [
      {
        "answer_id": 62853540,
        "body": "# import some stuff\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport pandas as pd\nimport numpy as np\n# create some data\ndf = pd.DataFrame()\nn = 50\ndf[\"Time\"] = np.arange(n)\ndf[\"Linear-\"] = np.arange(n)+np.random.rand(n)\ndf[\"Linear+\"] = np.arange(n)+np.random.rand(n)\ndf[\"Log-\"] = np.arange(n)+np.random.rand(n)\ndf[\"Log+\"] = np.arange(n)+np.random.rand(n)\ndf.set_index(\"Time\", inplace=True)\nsubfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n# create two independent figures with px.line each containing data from multiple columns\nfig = px.line(df, y=df.filter(regex=\"Linear\").columns, render_mode=\"webgl\",)\nfig2 = px.line(df, y=df.filter(regex=\"Log\").columns, render_mode=\"webgl\",)\nfig2.update_traces(yaxis=\"y2\")\nsubfig.add_traces(fig.data + fig2.data)\nsubfig.layout.xaxis.title=\"Time\"\nsubfig.layout.yaxis.title=\"Linear Y\"\nsubfig.layout.yaxis2.type=\"log\"\nsubfig.layout.yaxis2.title=\"Log Y\"\n# recoloring is necessary otherwise lines from fig und fig2 would share each color\n# e.g. Linear-, Log- = blue; Linear+, Log+ = red... we don't want this\nsubfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color)))\nsubfig.show()",
        "score": 61,
        "is_accepted": false,
        "creation_date": "2020-07-11T15:18:24",
        "author": "derflo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch",
    "title": "Understanding accumulated gradients in PyTorch",
    "question_id": 62067400,
    "posted_date": "2020-05-28T10:35:41",
    "answers": [
      {
        "answer_id": 62076913,
        "body": "def calculate_loss(x: torch.Tensor) -> torch.Tensor:\n    y = 2 * x\n    y_hat = model(x)\n    loss = (y - y_hat) ** 2\n    return loss.mean()\n# With mulitple batches of size 1\nbatches = [torch.tensor([4.0]), torch.tensor([2.0])]\noptimizer.zero_grad()\nfor i, batch in enumerate(batches):\n    # The loss needs to be scaled, because the mean should be taken across the whole\n    # dataset, which requires the loss to be divided by the number of batches.\n    loss = calculate_loss(batch) / len(batches)\n    loss.backward()\n    print(f\"Batch size 1 (batch {i}) - grad: {model.weight.grad}\")\n    print(f\"Batch size 1 (batch {i}) - weight: {model.weight}\")\n# Updating the model only after all batches\noptimizer.step()\nprint(f\"Batch size 1 (final) - grad: {model.weight.grad}\")\nprint(f\"Batch size 1 (final) - weight: {model.weight}\")",
        "score": 64,
        "is_accepted": true,
        "creation_date": "2020-05-28T20:51:43",
        "author": "Michael Jungo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69670125/how-to-log-raw-http-request-response-in-fastapi",
    "title": "How to log raw HTTP request/response in FastAPI?",
    "question_id": 69670125,
    "posted_date": "2021-10-21T20:22:15",
    "answers": [
      {
        "answer_id": 73464007,
        "body": "from fastapi import FastAPI, APIRouter, Response, Request\nfrom starlette.background import BackgroundTask\nfrom fastapi.routing import APIRoute\nfrom starlette.types import Message\nfrom typing import Dict, Any\nimport logging\napp = FastAPI()\nlogging.basicConfig(filename='info.log', level=logging.DEBUG)\ndef log_info(req_body, res_body):\n    logging.info(req_body)\n    logging.info(res_body)\n# not needed when using FastAPI>=0.108.0.\n'''\nasync def set_body(request: Request, body: bytes):\n    async def receive() -> Message:\n        return {'type': 'http.request', 'body': body}\n    request._receive = receive\n'''\n@app.middleware('http')\nasync def some_middleware(request: Request, call_next):\n    req_body = await request.body()\n    #await set_body(request, req_body)  # not needed when using FastAPI>=0.108.0.\n    response = await call_next(request)\n\n    chunks = []\n    async for chunk in response.body_iterator:\n        chunks.append(chunk)\n    res_body = b''.join(chunks)\n\n    task = BackgroundTask(log_info, req_body, res_body)\n    return Response(content=res_body, status_code=response.status_code,\n        headers=dict(response.headers), media_type=response.media_type, background=task)\n@app.post('/')\ndef main(payload: Dict[Any, Any]):\n    return payload",
        "score": 59,
        "is_accepted": false,
        "creation_date": "2022-08-23T15:12:06",
        "author": "Chris"
      },
      {
        "answer_id": 73464007,
        "body": "from fastapi import FastAPI, APIRouter, Response, Request\nfrom starlette.background import BackgroundTask\nfrom starlette.responses import StreamingResponse\nfrom fastapi.routing import APIRoute\nfrom starlette.types import Message\nfrom typing import Callable, Dict, Any\nimport logging\nimport httpx\ndef log_info(req_body, res_body):\n    logging.info(req_body)\n    logging.info(res_body)\n\nclass LoggingRoute(APIRoute):\n    def get_route_handler(self) -> Callable:\n        original_route_handler = super().get_route_handler()\n        async def custom_route_handler(request: Request) -> Response:\n            req_body = await request.body()\n            response = await original_route_handler(request)\n            tasks = response.background\n\n            if isinstance(response, StreamingResponse):\n                chunks = []\n                async for chunk in response.body_iterator:\n                    chunks.append(chunk)\n                res_body = b''.join(chunks)\n\n                task = BackgroundTask(log_info, req_body, res_body)\n                response = Response(content=res_body, status_code=response.status_code,\n                        headers=dict(response.headers), media_type=response.media_type)\n            else:\n                task = BackgroundTask(log_info, req_body, response.body)\n\n            # check if the original response had background tasks already attached to it\n            if tasks:\n                tasks.add_task(task)  # add the new task to the tasks list\n                response.background = tasks\n            else:\n                response.background = task\n\n            return response\n\n        return custom_route_handler\napp = FastAPI()\nrouter = APIRouter(route_class=LoggingRoute)\nlogging.basicConfig(filename='info.log', level=logging.DEBUG)\n@router.post('/')\ndef main(payload: Dict[Any, Any]):\n    return payload\n@router.get('/video')\ndef get_video():\n    url = 'https://storage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4'\n\n    def gen():\n        with httpx.stream('GET', url) as r:\n            for chunk in r.iter_raw():\n                yield chunk\n    return StreamingResponse(gen(), media_type='video/mp4')\napp.include_router(router)",
        "score": 59,
        "is_accepted": false,
        "creation_date": "2022-08-23T15:12:06",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37669222/how-can-i-hint-that-a-type-is-comparable-with-typing",
    "title": "How can I hint that a type is comparable with typing",
    "question_id": 37669222,
    "posted_date": "2016-06-06T21:38:19",
    "answers": [
      {
        "answer_id": 65224102,
        "body": "from __future__ import annotations\nfrom abc import abstractmethod\nfrom typing import MutableSequence, Protocol, TypeVar\nclass Comparable(Protocol):\n    \"\"\"Protocol for annotating comparable types.\"\"\"\n    @abstractmethod\n    def __lt__(self: CT, other: CT) -> bool:\n        pass\nCT = TypeVar(\"CT\", bound=Comparable)\ndef comparison_sort(s: MutableSequence[CT]) -> None:\n    pass\ncomparison_sort([1, 2, 3])  # OK\ncomparison_sort([1.0, 2.0, 3.0])  # OK\ncomparison_sort([\"42\", \"420\", \"2137\"])  # OK\ncomparison_sort([1, 2, \"3\"])  # mypy error",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2020-12-09T15:06:16",
        "author": "Pawe\u0142 Rubin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56808693/customizing-the-order-of-legends-in-plotly",
    "title": "Customizing the order of legends in plotly",
    "question_id": 56808693,
    "posted_date": "2019-06-28T10:24:50",
    "answers": [
      {
        "answer_id": 56810052,
        "body": "import plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\ntrace1 = go.Bar(x=['A', 'B', 'C'],\n                y=[20, 14, 23],\n                name='first')\ntrace2 = go.Bar(x=['A', 'B', 'C'],\n                y=[12, 18, 29],\n                name='second')\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   legend={'traceorder':'normal'})\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='stacked-bar')",
        "score": 40,
        "is_accepted": true,
        "creation_date": "2019-06-28T12:06:21",
        "author": "sentence"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/24917700/adding-a-row-to-a-multiindex-dataframe-series",
    "title": "Adding a row to a MultiIndex DataFrame/Series",
    "question_id": 24917700,
    "posted_date": "2014-07-23T14:03:52",
    "answers": [
      {
        "answer_id": 58418153,
        "body": "# say you have dataframe x\nx\nOut[78]:\n              a    b       time\nindA indB\na    i      0.0  NaN 2018-09-12\nb    j      1.0  2.0 2018-10-12\nc    k      2.0  3.0 2018-11-12\n     f      NaN  NaN        NaT\nd    i      5.0  NaN        NaT\nx.loc[('a','k'),:] = (3.5,6,pd.NaT)\nx\nOut[80]:\n              a    b       time\nindA indB\na    i      0.0  NaN 2018-09-12\nb    j      1.0  2.0 2018-10-12\nc    k      2.0  3.0 2018-11-12\n     f      NaN  NaN        NaT\nd    i      5.0  NaN        NaT\na    k      3.5  6.0        NaT",
        "score": 28,
        "is_accepted": false,
        "creation_date": "2019-10-16T12:49:29",
        "author": "user3820991"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45093811/installing-pygraphviz-on-windows-10-64-bit-python-3-6",
    "title": "Installing pygraphviz on Windows 10 64-bit, Python 3.6",
    "question_id": 45093811,
    "posted_date": "2017-07-13T22:50:13",
    "answers": [
      {
        "answer_id": 54890705,
        "body": ">    [cfati@cfati-5510-0:/cygdrive/e/Work/Dev/StackOverflow/q045093811/src/graphviz]> ~/sopr.sh\n>    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n>\n>    [064bit prompt]> git clone https://gitlab.com/graphviz/graphviz.git .\n>    Cloning into '.'...\n>    remote: Enumerating objects: 71728, done.\n>    remote: Counting objects: 100% (71728/71728), done.\n>    remote: Compressing objects: 100% (19331/19331), done.\n>    remote: Total 71728 (delta 52200), reused 71681 (delta 52157)\n>    Receiving objects: 100% (71728/71728), 163.79 MiB | 480.00 KiB/s, done.\n>    Resolving deltas: 100% (52200/52200), done.\n>    Checking out files: 100% (3870/3870), done.\n>    [064bit prompt]>\n>    [064bit prompt]> git submodule update --init\n>    Submodule 'dependencies/criterion' (https://github.com/Snaipe/Criterion.git) registered for path 'dependencies/criterion'\n>    Submodule 'windows/dependencies/graphviz-build-utilities' (https://github.com/ErwinJanssen/graphviz-build-utilities.git) registered for path 'windows/dependencies/graphviz-build-utilities'\n>    Submodule 'windows/dependencies/libraries' (https://github.com/ErwinJanssen/graphviz-windows-dependencies.git) registered for path 'windows/dependencies/libraries'\n>    Cloning into '/cygdrive/e/Work/Dev/StackOverflow/q045093811/src/graphviz/dependencies/criterion'...\n>    Cloning into '/cygdrive/e/Work/Dev/StackOverflow/q045093811/src/graphviz/windows/dependencies/graphviz-build-utilities'...\n>    Cloning into '/cygdrive/e/Work/Dev/StackOverflow/q045093811/src/graphviz/windows/dependencies/libraries'...\n>    Submodule path 'dependencies/criterion': checked out '301d143ea42c024f22b673b69c72a4cb3c8d151f'\n>    Submodule path 'windows/dependencies/graphviz-build-utilities': checked out '050fff84ce195e0740878748760fd801eeb07b23'\n>    Submodule path 'windows/dependencies/libraries': checked out '141d3a21be904fa8dc2ae3ed01d36684db07a35d'\n>    [064bit prompt]>\n>    [064bit prompt]> git show head\n>    commit 89292b5945933b1501293c04894ed9cf886241be (HEAD -> master, origin/master, origin/HEAD)\n>    Merge: 429d43615 97811bd35\n>    Author: Stephen C North <scnorth@gmail.com>\n>    Date:   Mon Feb 4 08:09:40 2019 -0500\n>\n>        Merge branch 'wasbridge/graphviz-master' into HEAD\n>\n>    [064bit prompt]> git status\n>    On branch master\n>    Your branch is up to date with 'origin/master'.\n>\n>    nothing to commit, working tree clean\n>",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-26T12:07:44",
        "author": "CristiFati"
      },
      {
        "answer_id": 54890705,
        "body": ">    [064bit prompt]> git status\n>    On branch master\n>    Your branch is up to date with 'origin/master'.\n>\n>    Changes not staged for commit:\n>      (use \"git add <file>...\" to update what will be committed)\n>      (use \"git checkout -- <file>...\" to discard changes in working directory)\n>      (commit or discard the untracked or modified content in submodules)\n>\n>            modified:   lib/cdt/cdt.vcxproj\n>            modified:   lib/cgraph/cgraph.vcxproj\n>            modified:   windows/dependencies/graphviz-build-utilities (modified content)\n>\n>    no changes added to commit (use \"git add\" and/or \"git commit -a\")\n>",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-26T12:07:44",
        "author": "CristiFati"
      },
      {
        "answer_id": 54890705,
        "body": ">    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811]> sopr.bat\n>    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n>\n>    [prompt]> \"c:\\Install\\x86\\Microsoft\\Visual Studio Community\\2015\\vc\\vcvarsall.bat\" x64\n>\n>    [prompt]> set PATH=%PATH%;%CD%\\src\\graphviz\\windows\\dependencies\\graphviz-build-utilities\n>\n>    [prompt]> msbuild src\\graphviz\\lib\\cdt\\cdt.vcxproj /t:Rebuild /p:Platform=x64;Configuration=Release;SolutionDir=%CD%\\src\\graphviz\\;OutDir=%CD%\\bin\\Win\\dynamic\\064\\UCRTv140\\md\\Release\\graphviz\\ >build_cdt_064.txt 2>&1\n>\n>    [prompt]> echo %errorlevel%\n>    0\n>\n>    [prompt]> dir /b\n>    bin\n>    build_cdt.txt\n>    other\n>    src\n>\n>    [prompt]> msbuild src\\graphviz\\lib\\cgraph\\cgraph.vcxproj /t:Rebuild /p:Platform=x64;Configuration=Release;SolutionDir=%CD%\\src\\graphviz\\;OutDir=%CD%\\bin\\Win\\dynamic\\064\\UCRTv140\\md\\Release\\graphviz\\ >build_cgraph_064.txt 2>&1\n>\n>    [prompt]> echo %errorlevel%\n>    0\n>\n>    [prompt]> dir /b \"bin\\Win\\dynamic\\064\\UCRTv140\\md\\Release\\graphviz\"\n>    cdt.dll\n>    cdt.dll.lastcodeanalysissucceeded\n>    cdt.exp\n>    cdt.lib\n>    cgraph.dll\n>    cgraph.dll.lastcodeanalysissucceeded\n>    cgraph.exp\n>    cgraph.lib\n>",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-26T12:07:44",
        "author": "CristiFati"
      },
      {
        "answer_id": 54890705,
        "body": "--- pygraphviz/graphviz_wrap.c.orig\t2018-09-10 16:07:12.000000000 +0300\n+++ pygraphviz/graphviz_wrap.c\t2019-02-26 18:05:20.281741400 +0200\n@@ -2988,7 +2988,18 @@\n\n\n #if PY_VERSION_HEX >= 0x03000000\n-extern PyTypeObject PyIOBase_Type;\n+static PyObject *PyIOBase_TypeObj;\n+\n+static int init_file_emulator(void)\n+{\n+  PyObject *io = PyImport_ImportModule(\"_io\");\n+  if (io == NULL)\n+    return -1;\n+  PyIOBase_TypeObj = PyObject_GetAttrString(io, \"_IOBase\");\n+  if (PyIOBase_TypeObj == NULL)\n+    return -1;\n+  return 0;\n+}\n #endif\n\n\n@@ -3449,7 +3460,7 @@\n   {\n #if PY_VERSION_HEX >= 0x03000000 || defined(PYPY_VERSION)\n #if !defined(PYPY_VERSION)\n-    if (!PyObject_IsInstance(obj0, (PyObject *)&PyIOBase_Type)) {\n+    if (!PyObject_IsInstance(obj0, PyIOBase_TypeObj)) {\n       PyErr_SetString(PyExc_TypeError, \"not a file handle\");\n       return NULL;\n     }\n@@ -3523,7 +3534,7 @@\n   {\n #if PY_VERSION_HEX >= 0x03000000 || defined(PYPY_VERSION)\n #if !defined(PYPY_VERSION)\n-    if (!PyObject_IsInstance(obj1, (PyObject *)&PyIOBase_Type)) {\n+    if (!PyObject_IsInstance(obj1, PyIOBase_TypeObj)) {\n       PyErr_SetString(PyExc_TypeError, \"not a file handle\");\n       return NULL;\n     }\n@@ -6051,6 +6062,12 @@\n\n   SWIG_InstallConstants(d,swig_const_table);\n\n+#if PY_VERSION_HEX >= 0x03000000\n+  if (init_file_emulator() < 0) {\n+    return NULL;\n+  }\n+#endif\n+\n   PyDict_SetItemString(md,(char*)\"cvar\", SWIG_globals());\n   SWIG_addvarlink(SWIG_globals(),(char*)\"Agdirected\",Swig_var_Agdirected_get, Swig_var_Agdirected_set);\n   SWIG_addvarlink(SWIG_globals(),(char*)\"Agstrictdirected\",Swig_var_Agstrictdirected_get, Swig_var_Agstrictdirected_set);",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-26T12:07:44",
        "author": "CristiFati"
      },
      {
        "answer_id": 54890705,
        "body": ">    [prompt]> :: Restore the original prompt as cwd is important\n>    [prompt]> exit\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811]> set _TOP_DIR=%CD%\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811]> pushd src\\pygraphviz\\pygraphviz-pygraphviz-1.5\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811\\src\\pygraphviz\\pygraphviz-pygraphviz-1.5]> pushd pygraphviz && \"c:\\Install\\x64\\Cygwin\\Cygwin\\AllVers\\bin\\patch.exe\" -p 1 -buNi ..\\pygraphviz-1.5-all-pyiobase_b85d12ac22d39063f7dbcc396e825c563431e352.patch && popd\n>    patching file graphviz_wrap.c\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811\\src\\pygraphviz\\pygraphviz-pygraphviz-1.5]> echo %errorlevel%\n>    0\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811\\src\\pygraphviz\\pygraphviz-pygraphviz-1.5]> \"e:\\Work\\Dev\\VEnvs\\py_064_03.06.08_test0\\Scripts\\python.exe\" setup.py install --include-path=%_TOP_DIR%\\include --library-path=%_TOP_DIR%\\bin\\Win\\dynamic\\064\\UCRTv140\\md\\Release\\graphviz >%_TOP_DIR%\\install_pygraphviz_064.txt 2>&1\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811\\src\\pygraphviz\\pygraphviz-pygraphviz-1.5]> echo %errorlevel%\n>    0\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811\\src\\pygraphviz\\pygraphviz-pygraphviz-1.5]> popd\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811]> set PATH=%PATH%;%CD%\\bin\\Win\\dynamic\\064\\UCRTv140\\md\\Release\\graphviz\n>\n>    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q045093811]> \"e:\\Work\\Dev\\VEnvs\\py_064_03.06.08_test0\\Scripts\\python.exe\" -c \"import pygraphviz;print(dir(pygraphviz), \\\"\\n\\\", pygraphviz.graphviz._graphviz)\"\n>    ['AGraph', 'Attribute', 'DotError', 'Edge', 'ItemAttribute', 'Node', '__all__', '__author__', '__builtins__', '__cached__', '__date__', '__doc__', '__file__', '__license__', '__loader__', '__name__', '__package__', '__path__', '__revision__', '__spec__', '__version__', 'absolute_import', 'agraph', 'division', 'graphviz', 'print_function', 'release', 'test', 'tests', 'version']\n>     <module '_graphviz' (e:\\Work\\Dev\\VEnvs\\py_064_03.06.08_test0\\lib\\site-packages\\pygraphviz\\_graphviz.cp36-win_amd64.pyd)>\n>",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2019-02-26T12:07:44",
        "author": "CristiFati"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61234609/how-to-import-python-package-from-another-directory",
    "title": "How to Import python package from another directory?",
    "question_id": 61234609,
    "posted_date": "2020-04-15T13:13:01",
    "answers": [
      {
        "answer_id": 61235118,
        "body": "#!/usr/bin/env python\n# -*- encoding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nimport io\nimport re\nfrom glob import glob\nfrom os.path import basename\nfrom os.path import dirname\nfrom os.path import join\nfrom os.path import splitext\nfrom setuptools import find_packages\nfrom setuptools import setup\ndef read(*names, **kwargs):\n    with io.open(\n        join(dirname(__file__), *names),\n        encoding=kwargs.get('encoding', 'utf8')\n    ) as fh:\n        return fh.read()\nsetup(\n    name='nameless',\n    version='1.644.11',\n    license='BSD-2-Clause',\n    description='An example package. Generated with cookiecutter-pylibrary.',\n    author='mpr',\n    author_email='contact@ionelmc.ro',\n    packages=find_packages('src'),\n    package_dir={'': 'src'},\n    include_package_data=True,\n    zip_safe=False,\n    classifiers=[\n        # complete classifier list: http://pypi.python.org/pypi?%3Aaction=list_classifiers\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: BSD License',\n        'Operating System :: Unix',\n        'Operating System :: POSIX',\n        'Operating System :: Microsoft :: Windows',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 2.7',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: Implementation :: CPython',\n        'Programming Language :: Python :: Implementation :: PyPy',\n        # uncomment if you test on these interpreters:\n        # 'Programming Language :: Python :: Implementation :: IronPython',\n        # 'Programming Language :: Python :: Implementation :: Jython',\n        # 'Programming Language :: Python :: Implementation :: Stackless',\n        'Topic :: Utilities',\n    ],\n    keywords=[\n        # eg: 'keyword1', 'keyword2', 'keyword3',\n    ],\n    python_requires='>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*',\n    install_requires=[\n        # eg: 'aspectlib==1.1.1', 'six>=1.7',\n    ],\n    extras_require={\n        # eg:\n        #   'rst': ['docutils>=0.11'],\n        #   ':python_version==\"2.6\"': ['argparse'],\n    },\n    setup_requires=[\n        # 'pytest-runner',\n    ],\n    entry_points={\n        'console_scripts': [\n            'api = api.api:main',\n        ]\n    },\n)",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2020-04-15T13:41:06",
        "author": "RMPR"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69864793/efficient-summation-in-python",
    "title": "Efficient summation in Python",
    "question_id": 69864793,
    "posted_date": "2021-11-06T10:20:44",
    "answers": [
      {
        "answer_id": 69866177,
        "body": "from fractions import Fraction\nimport math\nfrom functools import reduce\ndef naive(n):\n    return sum(x**2 * sum(range(x+1)) for x in range(n+1))\ndef lcm(ints):\n    return reduce(lambda r, i: r * i // math.gcd(r, i), ints)\ndef polynomial(xys):\n    xs, ys = zip(*xys)\n    n = len(xs)\n    A = [[Fraction(x**i) for i in range(n)] for x in xs]\n    b = list(ys)\n    for _ in range(2):\n        for i0 in range(n):\n            for i in range(i0 + 1, n):\n                f = A[i][i0] / A[i0][i0]\n                for j in range(i0, n):\n                    A[i][j] -= f * A[i0][j]\n                b[i] -= f * b[i0]\n        A = [row[::-1] for row in A[::-1]]\n        b.reverse()\n    coeffs = [b[i] / A[i][i] for i in range(n)]\n    denominator = lcm(c.denominator for c in coeffs)\n    coeffs = [int(c * denominator) for c in coeffs]\n    horner = str(coeffs[-1])\n    for c in coeffs[-2::-1]:\n        horner += ' * n'\n        if c:\n            horner = f\"({horner} {'+' if c > 0 else '-'} {abs(c)})\"\n    return f'{horner} // {denominator}'\nprint(polynomial((x, naive(x)) for x in range(6)))",
        "score": 61,
        "is_accepted": false,
        "creation_date": "2021-11-06T13:11:58",
        "author": "Kelly Bundy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66209119/automation-google-login-with-python-and-selenium-shows-this-browser-or-app-may",
    "title": "Automation Google login with python and selenium shows &quot;&quot;This browser or app may be not secure&quot;&quot;",
    "question_id": 66209119,
    "posted_date": "2021-02-15T08:38:52",
    "answers": [
      {
        "answer_id": 66308429,
        "body": "from selenium import webdriver\nimport geckodriver_autoinstaller\nfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilities\ngeckodriver_autoinstaller.install()\nprofile = webdriver.FirefoxProfile(\n    '/Users/<user name>/Library/Application Support/Firefox/Profiles/xxxxx.default-release')\nprofile.set_preference(\"dom.webdriver.enabled\", False)\nprofile.set_preference('useAutomationExtension', False)\nprofile.update_preferences()\ndesired = DesiredCapabilities.FIREFOX\ndriver = webdriver.Firefox(firefox_profile=profile,\n                           desired_capabilities=desired)",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2021-02-21T18:53:09",
        "author": "yusufusta"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58378374/why-does-keras-model-predict-slower-after-compile",
    "title": "Why does keras model predict slower after compile?",
    "question_id": 58378374,
    "posted_date": "2019-10-14T09:58:18",
    "answers": [
      {
        "answer_id": 58385156,
        "body": "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D\nfrom tensorflow.keras.layers import Flatten, Dropout\nfrom tensorflow.keras.models import Model\nimport numpy as np\nfrom time import time\ndef timeit(func, arg, iterations):\n    t0 = time()\n    for _ in range(iterations):\n        func(arg)\n    print(\"%.4f sec\" % (time() - t0))\nbatch_size = 32\nbatch_shape = (batch_size, 400, 16)\nipt   = Input(batch_shape=batch_shape)\nx     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)\nx     = LSTM(512, activation='relu', return_sequences=True)(ipt)\nx     = Conv1D(128, 400, 1, padding='same')(x)\nx     = Flatten()(x)\nx     = Dense(256, activation='relu')(x)\nx     = Dropout(0.5)(x)\nx     = Dense(128, activation='relu')(x)\nx     = Dense(64,  activation='relu')(x)\nout   = Dense(1,  activation='sigmoid')(x)\nmodel = Model(ipt, out)\nX = np.random.randn(*batch_shape)\ntimeit(model.predict, X, 10)\nmodel.compile('adam', loss='binary_crossentropy')\ntimeit(model.predict, X, 10)",
        "score": 47,
        "is_accepted": true,
        "creation_date": "2019-10-14T19:15:41",
        "author": "OverLordGoldDragon"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51125356/proper-way-to-build-menus-with-python-telegram-bot",
    "title": "Proper way to build menus with python-telegram-bot",
    "question_id": 51125356,
    "posted_date": "2018-07-01T13:12:40",
    "answers": [
      {
        "answer_id": 51126393,
        "body": "#!/usr/bin/env python3.8\nfrom telegram.ext import Updater\nfrom telegram.ext import CommandHandler, CallbackQueryHandler\nfrom telegram import InlineKeyboardButton, InlineKeyboardMarkup\n############################### Bot ############################################\ndef start(bot, update):\n  bot.message.reply_text(main_menu_message(),\n                         reply_markup=main_menu_keyboard())\ndef main_menu(bot, update):\n  bot.callback_query.message.edit_text(main_menu_message(),\n                          reply_markup=main_menu_keyboard())\ndef first_menu(bot, update):\n  bot.callback_query.message.edit_text(first_menu_message(),\n                          reply_markup=first_menu_keyboard())\ndef second_menu(bot, update):\n  bot.callback_query.message.edit_text(second_menu_message(),\n                          reply_markup=second_menu_keyboard())\ndef first_submenu(bot, update):\n  pass\ndef second_submenu(bot, update):\n  pass\ndef error(update, context):\n    print(f'Update {update} caused error {context.error}')\n############################ Keyboards #########################################\ndef main_menu_keyboard():\n  keyboard = [[InlineKeyboardButton('Menu 1', callback_data='m1')],\n              [InlineKeyboardButton('Menu 2', callback_data='m2')],\n              [InlineKeyboardButton('Menu 3', callback_data='m3')]]\n  return InlineKeyboardMarkup(keyboard)\ndef first_menu_keyboard():\n  keyboard = [[InlineKeyboardButton('Submenu 1-1', callback_data='m1_1')],\n              [InlineKeyboardButton('Submenu 1-2', callback_data='m1_2')],\n              [InlineKeyboardButton('Main menu', callback_data='main')]]\n  return InlineKeyboardMarkup(keyboard)\ndef second_menu_keyboard():\n  keyboard = [[InlineKeyboardButton('Submenu 2-1', callback_data='m2_1')],\n              [InlineKeyboardButton('Submenu 2-2', callback_data='m2_2')],\n              [InlineKeyboardButton('Main menu', callback_data='main')]]\n  return InlineKeyboardMarkup(keyboard)\n############################# Messages #########################################\ndef main_menu_message():\n  return 'Choose the option in main menu:'\ndef first_menu_message():\n  return 'Choose the submenu in first menu:'\ndef second_menu_message():\n  return 'Choose the submenu in second menu:'\n############################# Handlers #########################################\nupdater = Updater('XXXXXXXXX:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX', use_context=True)\nupdater.dispatcher.add_handler(CommandHandler('start', start))\nupdater.dispatcher.add_handler(CallbackQueryHandler(main_menu, pattern='main'))\nupdater.dispatcher.add_handler(CallbackQueryHandler(first_menu, pattern='m1'))\nupdater.dispatcher.add_handler(CallbackQueryHandler(second_menu, pattern='m2'))\nupdater.dispatcher.add_handler(CallbackQueryHandler(first_submenu, pattern='m1_1'))\nupdater.dispatcher.add_handler(CallbackQueryHandler(second_submenu, pattern='m2_1'))\nupdater.dispatcher.add_error_handler(error)\nupdater.start_polling()\n################################################################################",
        "score": 32,
        "is_accepted": false,
        "creation_date": "2018-07-01T15:31:30",
        "author": "dzNET"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66807878/pretty-print-dataclasses-prettier-with-line-breaks-and-indentation",
    "title": "Pretty-print dataclasses prettier with line breaks and indentation",
    "question_id": 66807878,
    "posted_date": "2021-03-25T17:30:30",
    "answers": [
      {
        "answer_id": 66821096,
        "body": "[ins] In [1]: from dataclasses import dataclass\n         ...:\n         ...: @dataclass\n         ...: class Point:\n         ...:     x: int\n         ...:     y: int\n         ...:\n         ...: @dataclass\n         ...: class Coords:\n         ...:     my_points: list\n         ...:     my_dict: dict\n         ...:\n         ...: coords = Coords([Point(1, 2), Point(3, 4)], {'a': (1, 2), (1, 2): 'a'})\n[ins] In [15]: pprint.pprint(coords, width=20)\nCoords(my_points=[Point(x=1,\n                        y=2),\n                  Point(x=3,\n                        y=4)],\n       my_dict={'a': (1,\n                      2),\n                (1, 2): 'a'})",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2021-03-26T12:49:22",
        "author": "maxschlepzig"
      },
      {
        "answer_id": 66821096,
        "body": "[ins] In [1]: from dataclasses import dataclass\n         ...:\n         ...: @dataclass\n         ...: class Point:\n         ...:     x: int\n         ...:     y: int\n         ...:\n         ...: @dataclass\n         ...: class Coords:\n         ...:     my_points: list\n         ...:     my_dict: dict\n         ...:\n         ...: coords = Coords([Point(1, 2), Point(3, 4)], {'a': (1, 2), (1, 2): 'a'})\n[nav] In [2]: import prettyprinter as pp\n[ins] In [3]: pp.pprint(coords)\nCoords(my_points=[Point(x=1, y=2), Point(x=3, y=4)], my_dict={'a': (1, 2), (1, 2): 'a'})",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2021-03-26T12:49:22",
        "author": "maxschlepzig"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/23696705/how-to-upload-a-file-to-sharepoint-site-using-python-script",
    "title": "How to upload a file to sharepoint site using python script",
    "question_id": 23696705,
    "posted_date": "2014-05-16T09:43:06",
    "answers": [
      {
        "answer_id": 64164123,
        "body": "import os\nfrom office365.runtime.auth.authentication_context import AuthenticationContext\nfrom office365.sharepoint.client_context import ClientContext\nbaseurl = 'https://your_company.sharepoint.com'\nbasesite = '/path/to/site' # every share point has a home.\nsiteurl = baseurl + basesite\nlocalpath = './file.txt'\nremotepath = \"Shared Documents/file.txt\" # existing folder path under sharepoint site.\nctx_auth = AuthenticationContext(siteurl) # should also be the siteurl\nctx_auth.acquire_token_for_user(username, password)\nctx = ClientContext(siteurl, ctx_auth) # make sure you auth to the siteurl.\nwith open(localpath, 'rb') as content_file:\n    file_content = content_file.read()\ndir, name = os.path.split(remotepath)\nfile = ctx.web.get_folder_by_server_relative_url(dir).upload_file(name, file_content).execute_query()",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2020-10-01T18:46:17",
        "author": "Josh"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74922314/yield-from-vs-yield-in-for-loop",
    "title": "yield from vs yield in for-loop",
    "question_id": 74922314,
    "posted_date": "2022-12-26T11:48:14",
    "answers": [
      {
        "answer_id": 74923483,
        "body": "    >>> class Class5(collections.abc.Generator):\n    ...     def __init__(self, gen):\n    ...         self.gen = gen\n    ...     def send(self, value):\n    ...         return next(self.gen)\n    ...     def throw(self, value):\n    ...         raise StopIteration\n    ...     def close(self):          # optional, but more complete\n    ...         self.gen.close()\n    ...\n    >>> e = Class5((i for i in range(10)))\n    >>> next(e)        # NOTE iter is not necessary!\n    0\n    >>> next(e)\n    1\n    >>> next(iter(e))  # but still works\n    2\n    >>> next(iter(e))  # doesn't close e?? (should it?)\n    3\n    >>> e.close()\n    >>> next(e)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n      File \"/usr/lib/python3.9/_collections_abc.py\", line 330, in __next__\n        return self.send(None)\n      File \"<stdin>\", line 5, in send\n    StopIteration",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2022-12-26T14:38:29",
        "author": "ti7"
      },
      {
        "answer_id": 74923483,
        "body": ">>> a = Class1((i for i in range(3)))\n>>> dis.dis(a.__iter__)\n  6           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                0 (gen)\n              4 GET_ITER\n        >>    6 FOR_ITER                10 (to 18)\n              8 STORE_FAST               1 (el)\n  7          10 LOAD_FAST                1 (el)\n             12 YIELD_VALUE\n             14 POP_TOP\n             16 JUMP_ABSOLUTE            6\n        >>   18 LOAD_CONST               0 (None)\n             20 RETURN_VALUE\n>>> b = Class2((i for i in range(3)))\n>>> dis.dis(b.__iter__)\n  6           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                0 (gen)\n              4 GET_YIELD_FROM_ITER\n              6 LOAD_CONST               0 (None)\n              8\n             10 POP_TOP\n             12 LOAD_CONST               0 (None)\n             14 RETURN_VALUE",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2022-12-26T14:38:29",
        "author": "ti7"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/77469097/how-can-i-process-a-pdf-using-openais-apis-gpts",
    "title": "How can I process a pdf using OpenAI&#39;s APIs (GPTs)?",
    "question_id": 77469097,
    "posted_date": "2023-11-12T08:25:44",
    "answers": [
      {
        "answer_id": 78924474,
        "body": "from openai import OpenAI\nfrom openai.types.beta.threads.message_create_params import (\n    Attachment,\n    AttachmentToolFileSearch,\n)\nimport os\nfilename = \"foobar.pdf\"\nprompt = \"Extract the content from the file provided without altering it. Just output its exact content and nothing else.\"\nclient = OpenAI(api_key=os.environ.get(\"MY_OPENAI_KEY\"))\npdf_assistant = client.beta.assistants.create(\n    model=\"gpt-4o\",\n    description=\"An assistant to extract the contents of PDF files.\",\n    tools=[{\"type\": \"file_search\"}],\n    name=\"PDF assistant\",\n)\n# Create thread\nthread = client.beta.threads.create()\nfile = client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n# Create assistant\nclient.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    attachments=[\n        Attachment(\n            file_id=file.id, tools=[AttachmentToolFileSearch(type=\"file_search\")]\n        )\n    ],\n    content=prompt,\n)\n# Run thread\nrun = client.beta.threads.runs.create_and_poll(\n    thread_id=thread.id, assistant_id=pdf_assistant.id, timeout=1000\n)\nif run.status != \"completed\":\n    raise Exception(\"Run failed:\", run.status)\nmessages_cursor = client.beta.threads.messages.list(thread_id=thread.id)\nmessages = [message for message in messages_cursor]\n# Output text\nres_txt = messages[0].content[0].text.value\nprint(res_txt)",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2024-08-28T12:58:14",
        "author": "Davide Fiocco"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60785825/vscode-how-to-pass-pytest-command-line-arguments-running-in-debugger",
    "title": "VSCode: How to pass pytest command-line arguments running in debugger?",
    "question_id": 60785825,
    "posted_date": "2020-03-21T04:28:00",
    "answers": [
      {
        "answer_id": 60795665,
        "body": "import pytest\ndef pytest_addoption(parser):\n    parser.addoption('--username', action='store', help='Repository user')\n    parser.addoption('--password', action='store', help='Repository password')\ndef pytest_generate_tests(metafunc):\n    username = metafunc.config.option.username\n    if 'username' in metafunc.fixturenames and username is not None:\n        metafunc.parametrize('username', [username])\n    password = metafunc.config.option.password\n    if 'password' in metafunc.fixturenames and password is not None:\n        metafunc.parametrize('password', [password])",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2020-03-21T23:28:45",
        "author": "Uriel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier",
    "title": "Multiclass classification with xgboost classifier?",
    "question_id": 57986259,
    "posted_date": "2019-09-18T02:23:13",
    "answers": [
      {
        "answer_id": 62566724,
        "body": "class XGBClassifier(XGBModel, XGBClassifierBase):\n    # pylint: disable=missing-docstring,invalid-name,too-many-instance-attributes\n    def __init__(self, objective=\"binary:logistic\", **kwargs):\n        super().__init__(objective=objective, **kwargs)\n    def fit(self, X, y, sample_weight=None, base_margin=None,\n            eval_set=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True, xgb_model=None,\n            sample_weight_eval_set=None, callbacks=None):\n        # pylint: disable = attribute-defined-outside-init,arguments-differ\n        evals_result = {}\n        self.classes_ = np.unique(y)\n        self.n_classes_ = len(self.classes_)\n        xgb_options = self.get_xgb_params()\n        if callable(self.objective):\n            obj = _objective_decorator(self.objective)\n            # Use default value. Is it really not used ?\n            xgb_options[\"objective\"] = \"binary:logistic\"\n        else:\n            obj = None\n        if self.n_classes_ > 2:\n            # Switch to using a multiclass objective in the underlying\n            # XGB instance\n            xgb_options['objective'] = 'multi:softprob'\n            xgb_options['num_class'] = self.n_classes_",
        "score": 55,
        "is_accepted": false,
        "creation_date": "2020-06-24T21:56:47",
        "author": "Joey Gao"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72465421/how-to-use-poetry-with-docker",
    "title": "How to use poetry with docker?",
    "question_id": 72465421,
    "posted_date": "2022-06-01T12:45:03",
    "answers": [
      {
        "answer_id": 72465422,
        "body": "FROM python:3.10\n# Configure Poetry\nENV POETRY_VERSION=1.2.0\nENV POETRY_HOME=/opt/poetry\nENV POETRY_VENV=/opt/poetry-venv\nENV POETRY_CACHE_DIR=/opt/.cache\n# Install poetry separated from system interpreter\nRUN python3 -m venv $POETRY_VENV \\\n\t&& $POETRY_VENV/bin/pip install -U pip setuptools \\\n\t&& $POETRY_VENV/bin/pip install poetry==${POETRY_VERSION}\n# Add `poetry` to PATH\nENV PATH=\"${PATH}:${POETRY_VENV}/bin\"\nWORKDIR /app\n# Install dependencies\nCOPY poetry.lock pyproject.toml ./\nRUN poetry install\n# Run your app\nCOPY . /app\nCMD [ \"poetry\", \"run\", \"python\", \"-c\", \"print('Hello, World!')\" ]",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2022-06-01T12:45:03",
        "author": "Soof Golan"
      },
      {
        "answer_id": 72465422,
        "body": "FROM python:3.10 as python-base\n# https://python-poetry.org/docs#ci-recommendations\nENV POETRY_VERSION=1.2.0\nENV POETRY_HOME=/opt/poetry\nENV POETRY_VENV=/opt/poetry-venv\n# Tell Poetry where to place its cache and virtual environment\nENV POETRY_CACHE_DIR=/opt/.cache\n# Create stage for Poetry installation\nFROM python-base as poetry-base\n# Creating a virtual environment just for poetry and install it with pip\nRUN python3 -m venv $POETRY_VENV \\\n\t&& $POETRY_VENV/bin/pip install -U pip setuptools \\\n\t&& $POETRY_VENV/bin/pip install poetry==${POETRY_VERSION}\n# Create a new stage from the base python image\nFROM python-base as example-app\n# Copy Poetry to app image\nCOPY --from=poetry-base ${POETRY_VENV} ${POETRY_VENV}\n# Add Poetry to PATH\nENV PATH=\"${PATH}:${POETRY_VENV}/bin\"\nWORKDIR /app\n# Copy Dependencies\nCOPY poetry.lock pyproject.toml ./\n# [OPTIONAL] Validate the project is properly configured\nRUN poetry check\n# Install Dependencies\nRUN poetry install --no-interaction --no-cache --without dev\n# Copy Application\nCOPY . /app\n# Run Application\nEXPOSE 5000\nCMD [ \"poetry\", \"run\", \"python\", \"-m\", \"flask\", \"run\", \"--host=0.0.0.0\" ]",
        "score": 59,
        "is_accepted": true,
        "creation_date": "2022-06-01T12:45:03",
        "author": "Soof Golan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61140398/fastapi-return-a-file-response-with-the-output-of-a-sql-query",
    "title": "FastAPI, return a File response with the output of a sql query",
    "question_id": 61140398,
    "posted_date": "2020-04-10T08:37:34",
    "answers": [
      {
        "answer_id": 61910803,
        "body": "from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nimport io\nimport pandas as pd\napp = FastAPI()\n@app.get(\"/get_csv\")\nasync def get_csv():\n    df = pd.DataFrame(dict(col1 = 1, col2 = 2), index=[0])\n    stream = io.StringIO()\n    df.to_csv(stream, index = False)\n    response = StreamingResponse(iter([stream.getvalue()]),\n                                 media_type=\"text/csv\"\n                                )\n    response.headers[\"Content-Disposition\"] = \"attachment; filename=export.csv\"\n    return response",
        "score": 64,
        "is_accepted": true,
        "creation_date": "2020-05-20T06:29:05",
        "author": "Tom Greenwood"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/17985216/simpler-way-to-draw-a-circle-with-tkinter",
    "title": "Simpler way to draw a circle with tkinter?",
    "question_id": 17985216,
    "posted_date": "2013-08-01T00:19:40",
    "answers": [
      {
        "answer_id": 17985217,
        "body": "try:\n    import tkinter as tk\nexcept ImportError:\n    import Tkinter as tk  # Python 2\nroot = tk.Tk()\ncanvas = tk.Canvas(root, width=200, height=200, borderwidth=0, highlightthickness=0,\n                   bg=\"black\")\ncanvas.grid()\ndef _create_circle(self, x, y, r, **kwargs):\n    return self.create_oval(x-r, y-r, x+r, y+r, **kwargs)\ntk.Canvas.create_circle = _create_circle\ndef _create_circle_arc(self, x, y, r, **kwargs):\n    if \"start\" in kwargs and \"end\" in kwargs:\n        kwargs[\"extent\"] = kwargs.pop(\"end\") - kwargs[\"start\"]\n    return self.create_arc(x-r, y-r, x+r, y+r, **kwargs)\ntk.Canvas.create_circle_arc = _create_circle_arc\ncanvas.create_circle(100, 120, 50, fill=\"blue\", outline=\"#DDD\", width=4)\ncanvas.create_circle_arc(100, 120, 48, fill=\"green\", outline=\"\", start=45, end=140)\ncanvas.create_circle_arc(100, 120, 48, fill=\"green\", outline=\"\", start=275, end=305)\ncanvas.create_circle_arc(100, 120, 45, style=\"arc\", outline=\"white\", width=6,\n                         start=270-25, end=270+25)\ncanvas.create_circle(150, 40, 20, fill=\"#BBB\", outline=\"\")\nroot.title(\"Circles and Arcs\")\nroot.mainloop()",
        "score": 56,
        "is_accepted": true,
        "creation_date": "2013-08-01T00:19:40",
        "author": "mgold"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44193823/get-existing-table-using-sqlalchemy-metadata",
    "title": "Get existing table using SQLAlchemy MetaData",
    "question_id": 44193823,
    "posted_date": "2017-05-26T00:48:35",
    "answers": [
      {
        "answer_id": 44205552,
        "body": "from sqlalchemy import (MetaData, Table, Column, Integer, String, Sequence,\n                        create_engine)\nCONN = create_engine('sqlite:///db.sql')\nMETA_DATA = MetaData(bind=CONN, reflect=True)\nUSERS_TABLE = Table(\"users\", META_DATA,\n                    Column(\"id\", Integer, Sequence(\"user_id_seq\"),\n                           primary_key=True),\n                    Column(\"first_name\", String(255)),\n                    Column(\"last_name\", String(255)),\n                    keep_existing=True)\nMETA_DATA.create_all(CONN, checkfirst=True)",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2017-05-26T11:47:56",
        "author": "Azat Ibrakov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63895392/seaborn-is-not-plotting-within-defined-subplots",
    "title": "seaborn is not plotting within defined subplots",
    "question_id": 63895392,
    "posted_date": "2020-09-15T01:01:42",
    "answers": [
      {
        "answer_id": 63895570,
        "body": "import seaborn as sns\nimport matplotlib.pyplot as plt\n# load data\npenguins = sns.load_dataset(\"penguins\", cache=False)\n# display(penguins.head())\n  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex\n0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    MALE\n1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  FEMALE\n2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  FEMALE\n3  Adelie  Torgersen             NaN            NaN                NaN          NaN     NaN\n4  Adelie  Torgersen            36.7           19.3              193.0       3450.0  FEMALE",
        "score": 44,
        "is_accepted": true,
        "creation_date": "2020-09-15T01:20:41",
        "author": "Trenton McKinney"
      },
      {
        "answer_id": 63895570,
        "body": "# create a long dataframe\ndfl = penguins.melt(id_vars='species', value_vars=['bill_length_mm', 'bill_depth_mm'], var_name='bill_size', value_name='vals')\n# display(dfl.head())\n  species       bill_size  vals\n0  Adelie  bill_length_mm  39.1\n1  Adelie   bill_depth_mm  18.7\n2  Adelie  bill_length_mm  39.5\n3  Adelie   bill_depth_mm  17.4\n4  Adelie  bill_length_mm  40.3\n# plot\nsns.displot(data=dfl, x='vals', col='bill_size', kde=True, stat='density', common_bins=False, common_norm=False, height=4, facet_kws={'sharey': False, 'sharex': False})",
        "score": 44,
        "is_accepted": true,
        "creation_date": "2020-09-15T01:20:41",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57628064/automating-python-package-release-process",
    "title": "Automating Python package release process",
    "question_id": 57628064,
    "posted_date": "2019-08-23T10:13:10",
    "answers": [
      {
        "answer_id": 57676367,
        "body": "$ poetry update           # update dependencies, may be skipped\n$ poetry version patch    # bump version\nBumping version from 1.1.2 to 1.1.3\n# finalize git stuff, e.g. add -u, commit -m 'v1.1.3', tag v1.1.3, push\n$ poetry publish --build  # build and publish to PyPI\nBuilding my_django_lib (1.1.3)\n - Building sdist\n - Built my_django_lib-1.1.3.tar.gz\n - Building wheel\n - Built my_django_lib-1.1.3-py3-none-any.whl\nPublishing my_django_lib (1.1.3) to PyPI\n - Uploading my_django_lib-1.1.3-py3-none-any.whl 100%\n - Uploading my_django_lib-1.1.3.tar.gz 100%",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2019-08-27T10:00:14",
        "author": "Arne"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43150687/colorbar-limits-are-not-respecting-set-vmin-vmax-in-plt-contourf-how-can-i-more",
    "title": "Colorbar limits are not respecting set vmin/vmax in plt.contourf. How can I more explicitly set the colorbar limits?",
    "question_id": 43150687,
    "posted_date": "2017-03-31T18:42:22",
    "answers": [
      {
        "answer_id": 55403314,
        "body": "def myfunction():\n\n    def bivariate_normal(X, Y, sigmax=1.0, sigmay=1.0, mux=0.0, muy=0.0, sigmaxy=0.0):\n        \"\"\"copied from here: https://github.com/matplotlib/matplotlib/blob/81e8154dbba54ac1607b21b22984cabf7a6598fa/lib/matplotlib/mlab.py#L1866\"\"\"\n        Xmu = X-mux\n        Ymu = Y-muy\n        rho = sigmaxy/(sigmax*sigmay)\n        z = Xmu**2/sigmax**2 + Ymu**2/sigmay**2 - 2*rho*Xmu*Ymu/(sigmax*sigmay)\n        denom = 2*np.pi*sigmax*sigmay*np.sqrt(1-rho**2)\n        return np.exp(-z/(2*(1-rho**2))) / denom\n\n    delta = 0.025\n    x = np.arange(-3.0, 3.0, delta)\n    y = np.arange(-2.0, 2.0, delta)\n    X, Y = np.meshgrid(x, y)\n    Z1 = bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)\n    Z2 = bivariate_normal(X, Y, 1.5, 0.5, 1, 1)\n    Z = 10.0 * (Z2 - Z1)\n    return X,Y,Z",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2019-03-28T13:08:25",
        "author": "Bastian"
      },
      {
        "answer_id": 55403314,
        "body": "def clippedcolorbar(CS, **kwargs):\n    from matplotlib.cm import ScalarMappable\n    from numpy import arange, floor, ceil\n    fig = CS.ax.get_figure()\n    vmin = CS.get_clim()[0]\n    vmax = CS.get_clim()[1]\n    m = ScalarMappable(cmap=CS.get_cmap())\n    m.set_array(CS.get_array())\n    m.set_clim(CS.get_clim())\n    step = CS.levels[1] - CS.levels[0]\n    cliplower = CS.zmin<vmin\n    clipupper = CS.zmax>vmax\n    noextend = 'extend' in kwargs.keys() and kwargs['extend']=='neither'\n    # set the colorbar boundaries\n    boundaries = arange((floor(vmin/step)-1+1*(cliplower and noextend))*step, (ceil(vmax/step)+1-1*(clipupper and noextend))*step, step)\n    kwargs['boundaries'] = boundaries\n    # if the z-values are outside the colorbar range, add extend marker(s)\n    # This behavior can be disabled by providing extend='neither' to the function call\n    if not('extend' in kwargs.keys()) or kwargs['extend'] in ['min','max']:\n        extend_min = cliplower or ( 'extend' in kwargs.keys() and kwargs['extend']=='min' )\n        extend_max = clipupper or ( 'extend' in kwargs.keys() and kwargs['extend']=='max' )\n        if extend_min and extend_max:\n            kwargs['extend'] = 'both'\n        elif extend_min:\n            kwargs['extend'] = 'min'\n        elif extend_max:\n            kwargs['extend'] = 'max'\n    return fig.colorbar(m, **kwargs)",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2019-03-28T13:08:25",
        "author": "Bastian"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49695990/authenticate-from-linux-to-windows-sql-server-with-pyodbc",
    "title": "Authenticate from Linux to Windows SQL Server with pyodbc",
    "question_id": 49695990,
    "posted_date": "2018-04-06T11:16:01",
    "answers": [
      {
        "answer_id": 58651634,
        "body": "#!/usr/bin/env python\n# minimal example using Kerberos auth\nimport sys\nimport re\nimport pyodbc\ndriver='{ODBC Driver 17 for SQL Server}'\nserver = sys.argv[1]\ndatabase = sys.argv[2]\n# trusted_connection uses kerberos ticket and ignores UID and PASSWORD in connection string\n# https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/using-integrated-authentication?view=sql-server-ver15\ntry:\n    cnxn = pyodbc.connect(driver=driver, server=server, database=database, trusted_connection='yes')\n    cursor = cnxn.cursor()\nexcept pyodbc.Error as ex:\n    msg = ex.args[1]\n    if re.search('No Kerberos', msg):\n        print('You must login using kinit before using this script.')\n        exit(1)\n    else:\n        raise\n# Sample select query\ncursor.execute(\"SELECT @@version;\")\nrow = cursor.fetchone()\nwhile row:\n    print(row[0])\n    row = cursor.fetchone()\nprint('success')",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2019-10-31T17:55:46",
        "author": "benrifkah"
      },
      {
        "answer_id": 58651634,
        "body": "user@localhost:~# kdestroy # make sure there are no active tickets\nkdestroy: No credentials cache found while destroying cache\nuser@localhost:~# python pyodbc_sql_server_test.py tcp:dbserver.example.com mydatabase\nYou must login using kinit before using this script.\nuser@localhost:~# kinit\nPassword for user@DOMAIN.LOCAL:\nuser@localhost:~# python pyodbc_sql_server_test.py tcp:dbserver.example.com mydatabase\nMicrosoft SQL Server 2016 (SP2-GDR) (KB4505220) - 13.0.5101.9 (X64)\n        Jun 15 2019 23:15:58\n        Copyright (c) Microsoft Corporation\n        Enterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: )\nsuccess\nuser@localhost:~#",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2019-10-31T17:55:46",
        "author": "benrifkah"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60422693/weird-indexing-using-numpy",
    "title": "Weird indexing using numpy",
    "question_id": 60422693,
    "posted_date": "2020-02-26T16:16:44",
    "answers": [
      {
        "answer_id": 60423244,
        "body": "x = np.arange(120).reshape(2,3,4,5)\ny = np.array([0,2,4])\n# x looks like:\narray([[[[  0,   1,   2,   3,   4],    -+      =+\n         [  5,   6,   7,   8,   9],     Sheet1  |\n         [ 10,  11,  12,  13,  14],     |       |\n         [ 15,  16,  17,  18,  19]],   -+       |\n                                                Workbook1\n        [[ 20,  21,  22,  23,  24],    -+       |\n         [ 25,  26,  27,  28,  29],     Sheet2  |\n         [ 30,  31,  32,  33,  34],     |       |\n         [ 35,  36,  37,  38,  39]],   -+       |\n                                                |\n        [[ 40,  41,  42,  43,  44],    -+       |\n         [ 45,  46,  47,  48,  49],     Sheet3  |\n         [ 50,  51,  52,  53,  54],     |       |\n         [ 55,  56,  57,  58,  59]]],  -+      =+\n       [[[ 60,  61,  62,  63,  64],\n         [ 65,  66,  67,  68,  69],\n         [ 70,  71,  72,  73,  74],\n         [ 75,  76,  77,  78,  79]],\n        [[ 80,  81,  82,  83,  84],\n         [ 85,  86,  87,  88,  89],\n         [ 90,  91,  92,  93,  94],\n         [ 95,  96,  97,  98,  99]],\n        [[100, 101, 102, 103, 104],\n         [105, 106, 107, 108, 109],\n         [110, 111, 112, 113, 114],\n         [115, 116, 117, 118, 119]]]])",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-02-26T17:00:21",
        "author": "James"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53498226/what-is-the-meaning-of-exclamation-and-question-marks-in-jupyter-notebook",
    "title": "What is the meaning of exclamation and question marks in Jupyter Notebook?",
    "question_id": 53498226,
    "posted_date": "2018-11-27T06:02:34",
    "answers": [
      {
        "answer_id": 53498455,
        "body": "Signature: df.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\nDocstring:\nFill NA/NaN values using the specified method\nParameters\n----------\nvalue : scalar, dict, Series, or DataFrame\n    Value to use to fill holes (e.g. 0), alternately a\n    dict/Series/DataFrame of values specifying which value to use for\n    each index (for a Series) or column (for a DataFrame). (values not\n    in the dict/Series/DataFrame will not be filled). This value cannot\n    be a list.\nmethod : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n    Method to use for filling holes in reindexed Series\n    pad / ffill: propagate last valid observation forward to next valid\n    backfill / bfill: use NEXT valid observation to fill gap\naxis : {0, 1, 'index', 'columns'}\ninplace : boolean, default False\n    If True, fill in place. Note: this will modify any\n    other views on this object, (e.g. a no-copy slice for a column in a\n    DataFrame).\nlimit : int, default None\n    If method is specified, this is the maximum number of consecutive\n    NaN values to forward/backward fill. In other words, if there is\n    a gap with more than this number of consecutive NaNs, it will only\n    be partially filled. If method is not specified, this is the\n    maximum number of entries along the entire axis where NaNs will be\n    filled.\ndowncast : dict, default is None\n    a dict of item->dtype of what to downcast if possible,\n    or the string 'infer' which will try to downcast to an appropriate\n    equal type (e.g. float64 to int64 if possible)\nSee Also\n--------\nreindex, asfreq\nReturns\n-------\nfilled : DataFrame\nFile:      c:\\users\\root\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\nType:      method",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2018-11-27T06:15:48",
        "author": "desertnaut"
      },
      {
        "answer_id": 53498455,
        "body": "Signature: np.argmax(a, axis=None, out=None)\nDocstring:\nReturns the indices of the maximum values along an axis.\nParameters\n----------\na : array_like\n    Input array.\naxis : int, optional\n    By default, the index is into the flattened array, otherwise\n    along the specified axis.\nout : array, optional\n    If provided, the result will be inserted into this array. It should\n    be of the appropriate shape and dtype.\nReturns\n-------\nindex_array : ndarray of ints\n    Array of indices into the array. It has the same shape as `a.shape`\n    with the dimension along `axis` removed.\nSee Also\n--------\nndarray.argmax, argmin\namax : The maximum value along a given axis.\nunravel_index : Convert a flat index into an index tuple.\nNotes\n-----\nIn case of multiple occurrences of the maximum values, the indices\ncorresponding to the first occurrence are returned.\nExamples\n--------\n>>> a = np.arange(6).reshape(2,3)\n>>> a\narray([[0, 1, 2],\n       [3, 4, 5]])\n>>> np.argmax(a)\n5\n>>> np.argmax(a, axis=0)\narray([1, 1, 1])\n>>> np.argmax(a, axis=1)\narray([2, 2])\n>>> b = np.arange(6)\n>>> b[1] = 5\n>>> b\narray([0, 5, 2, 3, 4, 5])\n>>> np.argmax(b) # Only the first occurrence is returned.\n1\nFile:      c:\\users\\root\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\nType:      function",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2018-11-27T06:15:48",
        "author": "desertnaut"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51720909/how-to-get-python-m-venv-to-directly-install-latest-pip-version",
    "title": "How to get &quot;python -m venv&quot; to directly install latest pip version",
    "question_id": 51720909,
    "posted_date": "2018-08-07T03:13:00",
    "answers": [
      {
        "answer_id": 60217751,
        "body": "# in ~/.bashrc or wherever\nfunction ve() {\n    local py=\"python3\"\n    if [ ! -d ./.venv ]; then\n        echo \"creating venv...\"\n        if ! $py -m venv .venv --prompt=$(basename $PWD) --without-pip; then\n            echo \"ERROR: Problem creating venv\" >&2\n            return 1\n        else\n            local whl=$($py -c \"import pathlib, ensurepip; whl = list(pathlib.Path(ensurepip.__path__[0]).glob('_bundled/pip*.whl'))[0]; print(whl)\")\n            echo \"boostrapping pip using $whl\"\n            .venv/bin/python $whl/pip install --upgrade pip setuptools wheel\n            source .venv/bin/activate\n        fi\n    else\n        source .venv/bin/activate\n    fi\n}",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2020-02-13T18:01:17",
        "author": "wim"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10988082/multivariate-polynomial-regression-with-numpy",
    "title": "Multivariate polynomial regression with numpy",
    "question_id": 10988082,
    "posted_date": "2012-06-11T17:55:36",
    "answers": [
      {
        "answer_id": 31467522,
        "body": "import numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n#X is the independent variable (bivariate in this case)\nX = np.array([[0.44, 0.68], [0.99, 0.23]])\n#vector is the dependent data\nvector = np.array([109.85, 155.72])\n#predict is an independent variable for which we'd like to predict the value\npredict= np.array([[0.49, 0.18]])\n#generate a model of polynomial features\npoly = PolynomialFeatures(degree=2)\n#transform the x data for proper fitting (for single variable type it returns,[1,x,x**2])\nX_ = poly.fit_transform(X)\n#transform the prediction to fit the model type\npredict_ = poly.fit_transform(predict)\n#here we can remove polynomial orders we don't want\n#for instance I'm removing the `x` component\nX_ = np.delete(X_,(1),axis=1)\npredict_ = np.delete(predict_,(1),axis=1)\n#generate the regression object\nclf = linear_model.LinearRegression()\n#preform the actual regression\nclf.fit(X_, vector)\nprint(\"X_ = \",X_)\nprint(\"predict_ = \",predict_)\nprint(\"Prediction = \",clf.predict(predict_))",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2015-07-16T22:23:38",
        "author": "David Hoffman"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/30003068/how-to-get-a-list-of-all-indices-of-repeated-elements-in-a-numpy-array",
    "title": "How to get a list of all indices of repeated elements in a numpy array",
    "question_id": 30003068,
    "posted_date": "2015-05-02T09:49:48",
    "answers": [
      {
        "answer_id": 30003565,
        "body": "import numpy as np\n# create a test array\nrecords_array = np.array([1, 2, 3, 1, 1, 3, 4, 3, 2])\n# creates an array of indices, sorted by unique element\nidx_sort = np.argsort(records_array)\n# sorts records array so all unique elements are together\nsorted_records_array = records_array[idx_sort]\n# returns the unique values, the index of the first occurrence of a value, and the count for each element\nvals, idx_start, count = np.unique(sorted_records_array, return_counts=True, return_index=True)\n# splits the indices into separate arrays\nres = np.split(idx_sort, idx_start[1:])\n#filter them with respect to their size, keeping only items occurring more than once\nvals = vals[count > 1]\nres = filter(lambda x: x.size > 1, res)",
        "score": 48,
        "is_accepted": true,
        "creation_date": "2015-05-02T10:41:05",
        "author": "gg349"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69334475/how-to-hint-at-number-types-i-e-subclasses-of-number-not-numbers-themselv",
    "title": "How to hint at number *types* (i.e. subclasses of Number) - not numbers themselves?",
    "question_id": 69334475,
    "posted_date": "2021-09-26T07:31:50",
    "answers": [
      {
        "answer_id": 69383462,
        "body": ">>> # All classes have `object` in their mro\n>>> class Foo: pass\n>>> Foo.__mro__\n(<class '__main__.Foo'>, <class 'object'>)\n>>>\n>>> # Subclasses of a class have that class in their mro\n>>> class IntSubclass(int): pass\n>>> IntSubclass.__mro__\n(<class '__main__.IntSubclass'>, <class 'int'>, <class 'object'>)\n>>> issubclass(IntSubclass, int)\nTrue\n>>>\n>>> # But `Number` is not in the mro of `int`...\n>>> int.__mro__\n(<class 'int'>, <class 'object'>)\n>>> # ...Yet `int` still pretends to be a subclass of `Number`!\n>>> from numbers import Number\n>>> issubclass(int, Number)\nTrue\n>>> #?!?!!??",
        "score": 60,
        "is_accepted": true,
        "creation_date": "2021-09-29T17:20:08",
        "author": "Alex Waygood"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59586879/does-await-in-python-yield-to-the-event-loop",
    "title": "Does `await` in Python yield to the event loop?",
    "question_id": 59586879,
    "posted_date": "2020-01-03T19:26:53",
    "answers": [
      {
        "answer_id": 59780868,
        "body": "@types.coroutine\ndef __sleep0():\n    \"\"\"Skip one event loop run cycle.\n    This is a private helper for 'asyncio.sleep()', used\n    when the 'delay' is set to 0.  It uses a bare 'yield'\n    expression (which Task.__step knows how to handle)\n    instead of creating a Future object.\n    \"\"\"\n    yield\nasync def sleep(delay, result=None, *, loop=None):\n    \"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\n    if delay <= 0:\n        await __sleep0()\n        return result\n    if loop is None:\n        loop = events.get_running_loop()\n    else:\n        warnings.warn(\"The loop argument is deprecated since Python 3.8, \"\n                      \"and scheduled for removal in Python 3.10.\",\n                      DeprecationWarning, stacklevel=2)\n    future = loop.create_future()\n    h = loop.call_later(delay,\n                        futures._set_result_unless_cancelled,\n                        future, result)\n    try:\n        return await future\n    finally:\n        h.cancel()",
        "score": 61,
        "is_accepted": true,
        "creation_date": "2020-01-16T22:39:54",
        "author": "Zach Harris"
      },
      {
        "answer_id": 59780868,
        "body": "import asyncio\nimport types\ndef task_print(s):\n    print(f\"{asyncio.current_task().get_name()}: {s}\")\nasync def other_task(s):\n    task_print(s)\nclass AwaitableCls:\n    def __await__(self):\n        task_print(\"    'Jumped straight into' another `await`; the act of `await awaitable` *itself* doesn't 'pause' anything\")\n        yield\n        task_print(\"    We're back to our awaitable object because that other task completed\")\n        asyncio.create_task(other_task(\"The event loop gets control when `yield` points (from an iterable coroutine) propagate up to the `current_task` through a suitable chain of `await` or `yield from` statements\"))\nasync def coro():\n    task_print(\"  'Jumped straight into' coro; the `await` keyword itself does nothing to 'pause' the current_task\")\n    await AwaitableCls()\n    task_print(\"  'Jumped straight back into' coro; we have another pending task, but leaving an `__await__` doesn't 'pause' the task any more than entering the `__await__` does\")\n@types.coroutine\ndef iterable_coro(context):\n    task_print(f\"`{context} iterable_coro`: pre-yield\")\n    yield None # None or a Future object are the only legitimate yields to the task in asyncio\n    task_print(f\"`{context} iterable_coro`: post-yield\")\nasync def original_task():\n    asyncio.create_task(other_task(\"Aha, but a (suitably unconsumed) *`yield`* DOES 'pause' the current_task allowing the event scheduler to `_wakeup` another task\"))\n    task_print(\"Original task\")\n    await coro()\n    task_print(\"'Jumped straight out of' coro. Leaving a coro, as with leaving/entering any awaitable, doesn't give control to the event loop\")\n    res = await iterable_coro(\"await\")\n    assert res is None\n    asyncio.create_task(other_task(\"This doesn't run until the very end because the generated None following the creation of this task is consumed by the `for` loop\"))\n    for y in iterable_coro(\"for y in\"):\n        task_print(f\"But 'ordinary' `yield` points (those which are consumed by the `current_task` itself) behave as ordinary without relinquishing control at the async/task-level; `y={y}`\")\n    task_print(\"Done with original task\")\nasyncio.get_event_loop().run_until_complete(original_task())",
        "score": 61,
        "is_accepted": true,
        "creation_date": "2020-01-16T22:39:54",
        "author": "Zach Harris"
      },
      {
        "answer_id": 59780868,
        "body": "import types # no asyncio, nor any other loop framework\nasync def f1():\n    print(1)\n    print(await f2(),'= await f2()')\n    return 8\n@types.coroutine\ndef f2():\n    print(2)\n    print((yield 3),'= yield 3')\n    return 7\nclass F3:\n   def __await__(self):\n        print(4)\n        print((yield 5),'= yield 5')\n        print(10)\n        return 11\ntask1 = f1()\ntask2 = F3().__await__()\n\"\"\" You could say calls to send() represent our\n   \"manual task management\" in this script.\n\"\"\"\nprint(task1.send(None), '= task1.send(None)')\nprint(task2.send(None), '= task2.send(None)')\ntry:\n    print(task1.send(6), 'try task1.send(6)')\nexcept StopIteration as e:\n    print(e.value, '= except task1.send(6)')\ntry:\n    print(task2.send(9), 'try task2.send(9)')\nexcept StopIteration as e:\n    print(e.value, '= except task2.send(9)')",
        "score": 61,
        "is_accepted": true,
        "creation_date": "2020-01-16T22:39:54",
        "author": "Zach Harris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58986126/replacing-placeholder-for-tensorflow-v2",
    "title": "Replacing placeholder for tensorflow v2",
    "question_id": 58986126,
    "posted_date": "2019-11-21T20:22:28",
    "answers": [
      {
        "answer_id": 59158900,
        "body": "import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n@tf.function\ndef construct_graph(graph_dict, inputs, outputs):\n    queue = inputs[:]\n    make_dict = {}\n    for key, val in graph_dict.items():\n        if key in inputs:\n            make_dict[key] = tf.placeholder(tf.float32, name=key)\n        else:\n            make_dict[key] = None\n    # Breadth-First search of graph starting from inputs\n    while len(queue) != 0:\n        cur = graph_dict[queue[0]]\n        for outg in cur[\"outgoing\"]:\n            if make_dict[outg[0]]: # If discovered node, do add/multiply operation\n                make_dict[outg[0]] = tf.add(make_dict[outg[0]], tf.multiply(outg[1], make_dict[queue[0]]))\n            else: # If undiscovered node, input is just coming in multiplied and add outgoing to queue\n                make_dict[outg[0]] = tf.multiply(make_dict[queue[0]], outg[1])\n                for outgo in graph_dict[outg[0]][\"outgoing\"]:\n                    queue.append(outgo[0])\n        queue.pop(0)\n    # Returns one data graph for each output\n    return [make_dict[x] for x in outputs]\ndef main():\n    graph_def = {\n        \"B\": {\n            \"incoming\": [],\n            \"outgoing\": [(\"A\", 1.0)]\n        },\n        \"C\": {\n            \"incoming\": [],\n            \"outgoing\": [(\"A\", 1.0)]\n        },\n        \"A\": {\n            \"incoming\": [(\"B\", 2.0), (\"C\", -1.0)],\n            \"outgoing\": [(\"D\", 3.0)]\n        },\n        \"D\": {\n            \"incoming\": [(\"A\", 2.0)],\n            \"outgoing\": []\n        }\n    }\n    outputs = construct_graph(graph_def, [\"B\", \"C\"], [\"A\"])\n    print(outputs)\nif __name__ == \"__main__\":\n    main()",
        "score": 53,
        "is_accepted": true,
        "creation_date": "2019-12-03T09:05:09",
        "author": "AlexisBRENON"
      },
      {
        "answer_id": 59158900,
        "body": "import tensorflow as tf\ndef construct_graph(graph_dict, inputs, outputs):\n    queue = inputs[:]\n    make_dict = {}\n    for key, val in graph_dict.items():\n        if key in inputs:\n            # Use keras.Input instead of placeholders\n            make_dict[key] = tf.keras.Input(name=key, shape=(), dtype=tf.dtypes.float32)\n        else:\n            make_dict[key] = None\n    # Breadth-First search of graph starting from inputs\n    while len(queue) != 0:\n        cur = graph_dict[queue[0]]\n        for outg in cur[\"outgoing\"]:\n            if make_dict[outg[0]] is not None: # If discovered node, do add/multiply operation\n                make_dict[outg[0]] = tf.keras.layers.add([\n                    make_dict[outg[0]],\n                    tf.keras.layers.multiply(\n                        [[outg[1]], make_dict[queue[0]]],\n                    )],\n                )\n            else: # If undiscovered node, input is just coming in multiplied and add outgoing to queue\n                make_dict[outg[0]] = tf.keras.layers.multiply(\n                    [make_dict[queue[0]], [outg[1]]]\n                )\n                for outgo in graph_dict[outg[0]][\"outgoing\"]:\n                    queue.append(outgo[0])\n        queue.pop(0)\n    # Returns one data graph for each output\n    model_inputs = [make_dict[key] for key in inputs]\n    model_outputs = [make_dict[key] for key in outputs]\n    return [tf.keras.Model(inputs=model_inputs, outputs=o) for o in model_outputs]\ndef main():\n    graph_def = {\n        \"B\": {\n            \"incoming\": [],\n            \"outgoing\": [(\"A\", 1.0)]\n        },\n        \"C\": {\n            \"incoming\": [],\n            \"outgoing\": [(\"A\", 1.0)]\n        },\n        \"A\": {\n            \"incoming\": [(\"B\", 2.0), (\"C\", -1.0)],\n            \"outgoing\": [(\"D\", 3.0)]\n        },\n        \"D\": {\n            \"incoming\": [(\"A\", 2.0)],\n            \"outgoing\": []\n        }\n    }\n    outputs = construct_graph(graph_def, [\"B\", \"C\"], [\"A\"])\n    print(\"Builded models:\", outputs)\n    for o in outputs:\n        o.summary(120)\n        print(\"Output:\", o((1.0, 1.0)))\nif __name__ == \"__main__\":\n    main()",
        "score": 53,
        "is_accepted": true,
        "creation_date": "2019-12-03T09:05:09",
        "author": "AlexisBRENON"
      },
      {
        "answer_id": 59158900,
        "body": "Builded models: [<tensorflow.python.keras.engine.training.Model object at 0x7fa0b49f0f50>]\nModel: \"model\"\n________________________________________________________________________________________________________________________\nLayer (type)                           Output Shape               Param #       Connected to\n========================================================================================================================\nB (InputLayer)                         [(None,)]                  0\n________________________________________________________________________________________________________________________\nC (InputLayer)                         [(None,)]                  0\n________________________________________________________________________________________________________________________\ntf_op_layer_mul (TensorFlowOpLayer)    [(None,)]                  0             B[0][0]\n________________________________________________________________________________________________________________________\ntf_op_layer_mul_1 (TensorFlowOpLayer)  [(None,)]                  0             C[0][0]\n________________________________________________________________________________________________________________________\nadd (Add)                              (None,)                    0             tf_op_layer_mul[0][0]\n                                                                                tf_op_layer_mul_1[0][0]\n========================================================================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\n________________________________________________________________________________________________________________________\nOutput: tf.Tensor([2.], shape=(1,), dtype=float32)",
        "score": 53,
        "is_accepted": true,
        "creation_date": "2019-12-03T09:05:09",
        "author": "AlexisBRENON"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29766827/make-axis-ticks-labels-bold-when-using-usetex-true",
    "title": "Make axis ticks labels bold when using usetex=True",
    "question_id": 29766827,
    "posted_date": "2015-04-21T04:29:31",
    "answers": [
      {
        "answer_id": 29772534,
        "body": "import matplotlib.pyplot as plt\nimport numpy as np\ntmpData = np.random.random( 100 )\n# activate latex text rendering\nplt.rc('text', usetex=True)\nplt.rc('axes', linewidth=2)\nplt.rc('font', weight='bold')\nplt.rcParams['text.latex.preamble'] = r'\\usepackage{sfmath} \\boldmath'\n#create figure\nf = plt.figure(figsize=(10,10))\nax = plt.gca()\nplt.plot(np.arange(100), tmpData, label=r'\\textbf{Line 1}', linewidth=2)\nplt.ylabel(r'\\textbf{Y-AXIS}', fontsize=20)\nplt.xlabel(r'\\textbf{X-AXIS}', fontsize=20)\nax.xaxis.set_tick_params(labelsize=20)\nax.yaxis.set_tick_params(labelsize=20)\nplt.legend()",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2015-04-21T08:42:00",
        "author": "tmdavison"
      },
      {
        "answer_id": 29772534,
        "body": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime, timedelta\ntmpData = np.random.random(100)\nbase = datetime(2000, 1, 1)\narr = np.array([base + timedelta(days=i) for i in range(100)])\n# activate latex text rendering\nplt.rc('text', usetex=True)\nplt.rc('axes', linewidth=2)\nplt.rc('font', weight='bold')\nplt.rcParams['text.latex.preamble'] = r'\\usepackage{sfmath} \\boldmath'\n# create figure\nf = plt.figure(figsize=(10, 10))\nax = plt.gca()\nplt.plot(arr, tmpData, label=r'\\textbf{Line 1}', linewidth=2)\nplt.ylabel(r'\\textbf{Y-AXIS}', fontsize=20)\nplt.xlabel(r'\\textbf{X-AXIS}', fontsize=20)\nax.xaxis.set_tick_params(labelsize=20)\nax.yaxis.set_tick_params(labelsize=20)\n# Set x-axis major formatter and locator\nax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%Y'))\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\nplt.legend()",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2015-04-21T08:42:00",
        "author": "tmdavison"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45829353/python-type-checking-in-vs-code",
    "title": "Python type checking in VS Code",
    "question_id": 45829353,
    "posted_date": "2017-08-22T21:40:32",
    "answers": [
      {
        "answer_id": 47196099,
        "body": "{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Python\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"stopOnEntry\": false,\n            \"pythonPath\": \"${config:python.pythonPath}\",\n            \"program\": \"${file}\",\n            \"cwd\": \"${workspaceRoot}\",\n            \"env\": {},\n            \"envFile\": \"${workspaceRoot}/.env\",\n            \"debugOptions\": [\n                \"WaitOnAbnormalExit\",\n                \"WaitOnNormalExit\",\n                \"RedirectOutput\"\n            ]\n        }\n    ]\n}",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2017-11-09T02:21:19",
        "author": "qwabra"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45943160/can-memmap-pandas-series-what-about-a-dataframe",
    "title": "Can memmap pandas series. What about a dataframe?",
    "question_id": 45943160,
    "posted_date": "2017-08-29T11:36:31",
    "answers": [
      {
        "answer_id": 47894784,
        "body": "from pandas.core.internals import BlockManager\nclass BlockManagerUnconsolidated(BlockManager):\n    def __init__(self, *args, **kwargs):\n        BlockManager.__init__(self, *args, **kwargs)\n        self._is_consolidated = False\n        self._known_consolidated = False\n    def _consolidate_inplace(self): pass\n    def _consolidate(self): return self.blocks\ndef df_from_arrays(arrays, columns, index):\n    from pandas.core.internals import make_block\n    def gen():\n        _len = None\n        p = 0\n        for a in arrays:\n            if _len is None:\n                _len = len(a)\n                assert len(index) == _len\n            assert _len == len(a)\n            yield make_block(values=a.reshape((1,_len)), placement=(p,))\n            p += 1\n    blocks = tuple(gen())\n    mgr = BlockManagerUnconsolidated(blocks=blocks, axes=[columns, index])\n    return pd.DataFrame(mgr, copy=False)",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2017-12-19T15:34:45",
        "author": "user48956"
      },
      {
        "answer_id": 47894784,
        "body": "def assert_readonly(iloc):\n    try:\n        iloc[0] = 999 # Should be non-editable\n        raise Exception(\"MUST BE READ ONLY (1)\")\n    except ValueError as e:\n        assert \"read-only\" in e.message\n# Original ndarray\nn = 1000\n_arr = np.arange(0,1000, dtype=float)\n# Convert it to a memmap\nmm = np.memmap(filename, mode='w+', shape=_arr.shape, dtype=_arr.dtype)\nmm[:] = _arr[:]\ndel _arr\nmm.flush()\nmm.flags['WRITEABLE'] = False  # Make immutable!\ndf = df_from_arrays(\n    [mm, mm, mm],\n    columns=['a', 'b', 'c'],\n    index=range(len(mm)))\nassert_read_only(df[\"a\"].iloc)\nassert_read_only(df[\"b\"].iloc)\nassert_read_only(df[\"c\"].iloc)",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2017-12-19T15:34:45",
        "author": "user48956"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63272437/how-can-i-send-a-message-to-someone-with-telegram-api-using-my-own-account",
    "title": "How can I send a message to someone with telegram API using my own account",
    "question_id": 63272437,
    "posted_date": "2020-08-05T15:39:17",
    "answers": [
      {
        "answer_id": 63285858,
        "body": "import logging\nimport argparse\nfrom utils import setup_logging\nfrom telegram.client import Telegram\n\"\"\"\nSends a message to a chat\nUsage:\n    python examples/send_message.py api_id api_hash phone chat_id text\n\"\"\"\nif __name__ == '__main__':\n    setup_logging(level=logging.INFO)\n    parser = argparse.ArgumentParser()\n    parser.add_argument('api_id', help='API id')  # https://my.telegram.org/apps\n    parser.add_argument('api_hash', help='API hash')\n    parser.add_argument('phone', help='Phone')\n    parser.add_argument('chat_id', help='Chat id', type=int)\n    parser.add_argument('text', help='Message text')\n    args = parser.parse_args()\n    tg = Telegram(\n        api_id=args.api_id,\n        api_hash=args.api_hash,\n        phone=args.phone,\n        database_encryption_key='changeme1234',\n    )\n    # you must call login method before others\n    tg.login()\n    # if this is the first run, library needs to preload all chats\n    # otherwise the message will not be sent\n    result = tg.get_chats()\n    # `tdlib` is asynchronous, so `python-telegram` always returns you an `AsyncResult` object.\n    # You can wait for a result with the blocking `wait` method.\n    result.wait()\n    if result.error:\n        print(f'get chats error: {result.error_info}')\n    else:\n        print(f'chats: {result.update}')\n    result = tg.send_message(\n        chat_id=args.chat_id,\n        text=args.text,\n    )\n    result.wait()\n    if result.error:\n        print(f'send message error: {result.error_info}')\n    else:\n        print(f'message has been sent: {result.update}')",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2020-08-06T10:32:18",
        "author": "Pac0"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56567841/django-count-and-sum-annotations-interfere-with-each-other",
    "title": "Django Count and Sum annotations interfere with each other",
    "question_id": 56567841,
    "posted_date": "2019-06-12T13:51:30",
    "answers": [
      {
        "answer_id": 56619484,
        "body": ">>> from sandbox.models import Player\n>>> from django.db.models import Count, Sum\n>>> Player.objects.annotate(weapon_count=Count('unit_set__weapon_set')).values()\n<QuerySet [{'id': 1, 'name': 'player_1', 'weapon_count': 2}]>\n>>> Player.objects.annotate(rarity_sum=Sum('unit_set__rarity')).values()\n<QuerySet [{'id': 1, 'name': 'player_1', 'rarity_sum': 10}]>\n>>> Player.objects.annotate(\n...     weapon_count=Count('unit_set__weapon_set', distinct=True),\n...     rarity_sum=Sum('unit_set__rarity')).values()\n<QuerySet [{'id': 1, 'name': 'player_1', 'weapon_count': 2, 'rarity_sum': 20}]>",
        "score": 58,
        "is_accepted": true,
        "creation_date": "2019-06-16T09:56:00",
        "author": "rktavi"
      },
      {
        "answer_id": 56619484,
        "body": "sqlite> SELECT \"sandbox_player\".\"id\",\n   ...>        \"sandbox_player\".\"name\",\n   ...>        \"sandbox_weapon\".\"id\",\n   ...>        \"sandbox_unit\".\"rarity\"\n   ...> FROM \"sandbox_player\"\n   ...>          LEFT OUTER JOIN \"sandbox_unit\" ON (\"sandbox_player\".\"id\" = \"sandbox_unit\".\"player_id\")\n   ...>          LEFT OUTER JOIN \"sandbox_weapon\" ON (\"sandbox_unit\".\"id\" = \"sandbox_weapon\".\"unit_id\");\nid          name        id          rarity\n----------  ----------  ----------  ----------\n1           player_1    1           10\n1           player_1    2           10",
        "score": 58,
        "is_accepted": true,
        "creation_date": "2019-06-16T09:56:00",
        "author": "rktavi"
      },
      {
        "answer_id": 56619484,
        "body": ">>> from django.db.models import Count, IntegerField, OuterRef, Subquery, Sum\n>>> weapon_count = Player.objects.annotate(weapon_count=Count('unit_set__weapon_set')).filter(pk=OuterRef('pk'))\n>>> rarity_sum = Player.objects.annotate(rarity_sum=Sum('unit_set__rarity')).filter(pk=OuterRef('pk'))\n>>> qs = Player.objects.annotate(\n...     weapon_count=Subquery(weapon_count.values('weapon_count'), output_field=IntegerField()),\n...     rarity_sum=Subquery(rarity_sum.values('rarity_sum'), output_field=IntegerField())\n... )\n>>> qs.values()\n<QuerySet [{'id': 1, 'name': 'player_1', 'weapon_count': 2, 'rarity_sum': 10}]>",
        "score": 58,
        "is_accepted": true,
        "creation_date": "2019-06-16T09:56:00",
        "author": "rktavi"
      },
      {
        "answer_id": 56619484,
        "body": "SELECT \"sandbox_player\".\"id\", \"sandbox_player\".\"name\",\n(\n    SELECT COUNT(U2.\"id\") AS \"weapon_count\"\n    FROM \"sandbox_player\" U0\n    LEFT OUTER JOIN \"sandbox_unit\" U1\n        ON (U0.\"id\" = U1.\"player_id\")\n    LEFT OUTER JOIN \"sandbox_weapon\" U2\n        ON (U1.\"id\" = U2.\"unit_id\")\n    WHERE U0.\"id\" = (\"sandbox_player\".\"id\")\n    GROUP BY U0.\"id\", U0.\"name\"\n) AS \"weapon_count\",\n(\n    SELECT SUM(U1.\"rarity\") AS \"rarity_sum\"\n    FROM \"sandbox_player\" U0\n    LEFT OUTER JOIN \"sandbox_unit\" U1\n        ON (U0.\"id\" = U1.\"player_id\")\n    WHERE U0.\"id\" = (\"sandbox_player\".\"id\")\nGROUP BY U0.\"id\", U0.\"name\") AS \"rarity_sum\"\nFROM \"sandbox_player\"",
        "score": 58,
        "is_accepted": true,
        "creation_date": "2019-06-16T09:56:00",
        "author": "rktavi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66521958/how-to-access-environment-secrets-from-a-github-workflow",
    "title": "How to access environment secrets from a Github workflow?",
    "question_id": 66521958,
    "posted_date": "2021-03-07T17:05:20",
    "answers": [
      {
        "answer_id": 66526312,
        "body": "jobs:\n  publish:\n    environment: CI    # <--- /!\\ Here is the link to the environment\n    needs: build\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/v')\n    steps:\n    - uses: actions/checkout@v2\n    # Some more steps here ...\n    - name: Publish to Test PyPI\n      env:\n        TWINE_USERNAME: \"__token__\"\n        TWINE_PASSWORD: ${{ secrets.TEST_PYPI_API_TOKEN }}\n        TWINE_REPOSITORY_URL: \"https://test.pypi.org/legacy/\"\n      run: |\n        echo KEY: '${TWINE_PASSWORD}'\n        twine check dist/*\n        twine upload --verbose --skip-existing dist/*",
        "score": 65,
        "is_accepted": true,
        "creation_date": "2021-03-08T03:15:35",
        "author": "fchauvel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43618910/pil-drawing-a-semi-transparent-square-overlay-on-image",
    "title": "PIL Drawing a semi-transparent square overlay on image",
    "question_id": 43618910,
    "posted_date": "2017-04-25T15:02:15",
    "answers": [
      {
        "answer_id": 43620169,
        "body": "from PIL import Image, ImageDraw\nfrom io import BytesIO\nfrom urllib.request import urlopen\nTINT_COLOR = (0, 0, 0)  # Black\nTRANSPARENCY = .25  # Degree of transparency, 0-100%\nOPACITY = int(255 * TRANSPARENCY)\nurl = \"https://i.ytimg.com/vi/W4qijIdAPZA/maxresdefault.jpg\"\nwith BytesIO(urlopen(url).read()) as file:\n    img = Image.open(file)\n    img = img.convert(\"RGBA\")\n# Determine extent of the largest possible square centered on the image.\n# and the image's shorter dimension.\nif img.size[0] > img.size[1]:\n    shorter = img.size[1]\n    llx, lly = (img.size[0]-img.size[1]) // 2 , 0\nelse:\n    shorter = img.size[0]\n    llx, lly = 0, (img.size[1]-img.size[0]) // 2\n# Calculate upper point + 1 because second point needs to be just outside the\n# drawn rectangle when drawing rectangles.\nurx, ury = llx+shorter+1, lly+shorter+1\n# Make a blank image the same size as the image for the rectangle, initialized\n# to a fully transparent (0% opaque) version of the tint color, then draw a\n# semi-transparent version of the square on it.\noverlay = Image.new('RGBA', img.size, TINT_COLOR+(0,))\ndraw = ImageDraw.Draw(overlay)  # Create a context for drawing things on it.\ndraw.rectangle(((llx, lly), (urx, ury)), fill=TINT_COLOR+(OPACITY,))\n# Alpha composite these two images together to obtain the desired result.\nimg = Image.alpha_composite(img, overlay)\nimg = img.convert(\"RGB\") # Remove alpha for saving in jpg format.\nimg.save('dark-cat.jpg')\nimg.show()",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2017-04-25T16:15:53",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/31948285/display-data-streamed-from-a-flask-view-as-it-updates",
    "title": "Display data streamed from a Flask view as it updates",
    "question_id": 31948285,
    "posted_date": "2015-08-11T13:30:34",
    "answers": [
      {
        "answer_id": 31951077,
        "body": "<p>This is the latest output: <span id=\"latest\"></span></p>\n<p>This is all the output:</p>\n<ul id=\"output\"></ul>\n<script>\n    var latest = document.getElementById('latest');\n    var output = document.getElementById('output');\n    var xhr = new XMLHttpRequest();\n    xhr.open('GET', '{{ url_for('stream') }}');\n    xhr.send();\n    var position = 0;\n    function handleNewData() {\n        // the response text include the entire response so far\n        // split the messages, then take the messages that haven't been handled yet\n        // position tracks how many messages have been handled\n        // messages end with a newline, so split will always show one extra empty message at the end\n        var messages = xhr.responseText.split('\\n');\n        messages.slice(position, -1).forEach(function(value) {\n            latest.textContent = value;  // update the latest value in place\n            // build and append a new item to a list to log all output\n            var item = document.createElement('li');\n            item.textContent = value;\n            output.appendChild(item);\n        });\n        position = messages.length - 1;\n    }\n    var timer;\n    timer = setInterval(function() {\n        // check the response for new data\n        handleNewData();\n        // stop checking once the response has ended\n        if (xhr.readyState == XMLHttpRequest.DONE) {\n            clearInterval(timer);\n            latest.textContent = 'Done';\n        }\n    }, 1000);\n</script>",
        "score": 37,
        "is_accepted": true,
        "creation_date": "2015-08-11T16:11:07",
        "author": "davidism"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61577643/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread",
    "title": "Python - How to use FastAPI and uvicorn.run without blocking the thread?",
    "question_id": 61577643,
    "posted_date": "2020-05-03T12:08:04",
    "answers": [
      {
        "answer_id": 64521239,
        "body": "import contextlib\nimport time\nimport threading\nimport uvicorn\nclass Server(uvicorn.Server):\n    def install_signal_handlers(self):\n        pass\n    @contextlib.contextmanager\n    def run_in_thread(self):\n        thread = threading.Thread(target=self.run)\n        thread.start()\n        try:\n            while not self.started:\n                time.sleep(1e-3)\n            yield\n        finally:\n            self.should_exit = True\n            thread.join()\nconfig = uvicorn.Config(\"example:app\", host=\"127.0.0.1\", port=5000, log_level=\"info\")\nserver = Server(config=config)\nwith server.run_in_thread():\n    # Server is started.\n    ...\n    # Server will be stopped once code put here is completed\n    ...\n# Server stopped.",
        "score": 46,
        "is_accepted": false,
        "creation_date": "2020-10-25T03:10:40",
        "author": "Elijas Dap\u0161auskas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/46274961/removing-horizontal-lines-in-image-opencv-python-matplotlib",
    "title": "Removing Horizontal Lines in image (OpenCV, Python, Matplotlib)",
    "question_id": 46274961,
    "posted_date": "2017-09-18T04:39:11",
    "answers": [
      {
        "answer_id": 58002605,
        "body": "import cv2\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n# Remove horizontal\nhorizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25,1))\ndetected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\ncnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    cv2.drawContours(image, [c], -1, (255,255,255), 2)\n# Repair image\nrepair_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,6))\nresult = 255 - cv2.morphologyEx(255 - image, cv2.MORPH_CLOSE, repair_kernel, iterations=1)\ncv2.imshow('thresh', thresh)\ncv2.imshow('detected_lines', detected_lines)\ncv2.imshow('image', image)\ncv2.imshow('result', result)\ncv2.waitKey()",
        "score": 54,
        "is_accepted": true,
        "creation_date": "2019-09-18T21:39:52",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58404225/vs-code-python-move-to-next-line-on-run-ctrl-enter",
    "title": "VS Code Python move to next line on run ctrl + enter",
    "question_id": 58404225,
    "posted_date": "2019-10-15T20:34:53",
    "answers": [
      {
        "answer_id": 60585541,
        "body": "###############################\n# 1. Install extension \"macros\" in Visual Code\n#\n# Hit View on top menu\n# Search for extension named \"macros\" (by geddski)\n# Install \"macros\" extension\n#\n###############################\n###############################\n# 2. Add code below to keybindings.json\n#\n# Hit <Ctrl> + <Shift> + <P>\n# Enter in search bar: JSON\n# Select Open keyboard shortcuts\n#\n###############################\n{\n        \"key\": \"ctrl+enter\",\n        \"command\": \"macros.pythonExecSelectionAndCursorDown\",\n        \"when\": \"editorTextFocus && editorLangId == 'python'\"\n    }\n###############################\n# 3. Add code below to settings.json\n#\n# Hit <Ctrl> + <Shift> + <P>\n# Enter in search bar: JSON\n# Select Open settings\n#\n###############################\n\"macros\": {  // Note: this requires macros extension by publisher:\"geddski\"\n        \"pythonExecSelectionAndCursorDown\": [\n            \"python.execSelectionInTerminal\",\n            \"cursorDown\"\n        ]\n    }",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2020-03-08T03:55:56",
        "author": "P.Marres"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41064961/how-to-use-python-in-net-core-application",
    "title": "How to use Python in .NET-Core application?",
    "question_id": 41064961,
    "posted_date": "2016-12-09T11:35:34",
    "answers": [
      {
        "answer_id": 61891763,
        "body": "public class PythonScript\n{\n    private ScriptEngine _engine;\n    public PythonScript()\n    {\n        _engine = Python.CreateEngine();\n    }\n    public TResult RunFromString<TResult>(string code, string variableName)\n    {\n\t\t// for easier debugging write it out to a file and call: _engine.CreateScriptSourceFromFile(filePath);\n        ScriptSource source = _engine.CreateScriptSourceFromString(code, SourceCodeKind.Statements);\n        CompiledCode cc = source.Compile();\n        ScriptScope scope = _engine.CreateScope();\n        cc.Execute(scope);\n        return scope.GetVariable<TResult>(variableName);\n    }\n}",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2020-05-19T09:04:50",
        "author": "James"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58660378/how-use-pytest-to-unit-test-sqlalchemy-orm-classes",
    "title": "How use pytest to unit test sqlalchemy orm classes",
    "question_id": 58660378,
    "posted_date": "2019-11-01T09:52:30",
    "answers": [
      {
        "answer_id": 58662370,
        "body": "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import scoped_session, sessionmaker\n@pytest.fixture(scope='session')\ndef db_engine(request):\n    \"\"\"yields a SQLAlchemy engine which is suppressed after the test session\"\"\"\n    db_url = request.config.getoption(\"--dburl\")\n    engine_ = create_engine(db_url, echo=True)\n    yield engine_\n    engine_.dispose()\n@pytest.fixture(scope='session')\ndef db_session_factory(db_engine):\n    \"\"\"returns a SQLAlchemy scoped session factory\"\"\"\n    return scoped_session(sessionmaker(bind=db_engine))\n@pytest.fixture(scope='function')\ndef db_session(db_session_factory):\n    \"\"\"yields a SQLAlchemy connection which is rollbacked after the test\"\"\"\n    session_ = db_session_factory()\n    yield session_\n    session_.rollback()\n    session_.close()",
        "score": 43,
        "is_accepted": true,
        "creation_date": "2019-11-01T12:06:40",
        "author": "Tryph"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71287550/repeatedly-removing-the-maximum-average-subarray",
    "title": "Repeatedly removing the maximum average subarray",
    "question_id": 71287550,
    "posted_date": "2022-02-27T13:44:56",
    "answers": [
      {
        "answer_id": 71288237,
        "body": "# Lengths of the segments in the upper convex hull\n# of the cumulative sum graph\ndef upperSumHullLengths(arr):\n    if len(arr) < 2:\n        if len(arr) < 1:\n            return []\n        else:\n            return [1]\n\n    hull = [(0, 0),(1, arr[0])]\n    for x in range(2, len(arr)+1):\n        # this has x coordinate x-1\n        prevPoint = hull[len(hull) - 1]\n        # next point in cumulative sum\n        point = (x, prevPoint[1] + arr[x-1])\n        # remove points not on the convex hull\n        while len(hull) >= 2:\n            p0 = hull[len(hull)-2]\n            dx0 = prevPoint[0] - p0[0]\n            dy0 = prevPoint[1] - p0[1]\n            dx1 = x - prevPoint[0]\n            dy1 = point[1] - prevPoint[1]\n            if dy1*dx0 < dy0*dx1:\n                break\n            hull.pop()\n            prevPoint = p0\n        hull.append(point)\n\n    return [hull[i+1][0] - hull[i][0] for i in range(0, len(hull)-1)]\nprint(upperSumHullLengths([  1,   7,   8,   4,   2,   1,   4]))",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2022-02-27T15:28:23",
        "author": "Matt Timmermans"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11645285/why-cprofile-module-doesnt-work-with-unittest",
    "title": "Why cProfile module doesn&#39;t work with unittest?",
    "question_id": 11645285,
    "posted_date": "2012-07-25T04:06:14",
    "answers": [
      {
        "answer_id": 20251400,
        "body": "from pstats import Stats\nimport unittest\nclass TestSplayTree(unittest.TestCase):\n    \"\"\"a simple test\"\"\"\n    def setUp(self):\n        \"\"\"init each test\"\"\"\n        self.testtree = SplayTree (1000000)\n        self.pr = cProfile.Profile()\n        self.pr.enable()\n        print \"\\n<<<---\"\n    def tearDown(self):\n        \"\"\"finish any test\"\"\"\n        p = Stats (self.pr)\n        p.strip_dirs()\n        p.sort_stats ('cumtime')\n        p.print_stats ()\n        print \"\\n--->>>\"\n\n    def xtest1 (self):\n        pass",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2013-11-27T14:29:17",
        "author": "alinsoar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/13756356/different-databases-for-different-apps-in-django",
    "title": "Different databases for different apps in Django",
    "question_id": 13756356,
    "posted_date": "2012-12-06T22:10:38",
    "answers": [
      {
        "answer_id": 13756801,
        "body": "# DB router for app1\nclass App1DBRouter(object):\n        \"\"\"\n    A router to control db operations\n    \"\"\"\n    route_app_labels = {'app1'}\n    db_name = 'db_app1'\n    def db_for_read(self, model, **hints):\n        \"\"\"\n        Attempts to read auth and contenttypes models go to self.db_name.\n        \"\"\"\n        if model._meta.app_label in self.route_app_labels:\n            return self.db_name\n        return None\n    def db_for_write(self, model, **hints):\n        \"\"\"\n        Attempts to write auth and contenttypes models go to self.db_name.\n        \"\"\"\n        if model._meta.app_label in self.route_app_labels:\n            return self.db_name\n        return None\n    def allow_relation(self, obj1, obj2, **hints):\n        \"\"\"\n        Allow relations if a model in the auth or contenttypes apps is\n        involved.\n        \"\"\"\n        if (\n            obj1._meta.app_label in self.route_app_labels or\n            obj2._meta.app_label in self.route_app_labels\n        ):\n           return True\n        return None\n    def allow_migrate(self, db, app_label, model_name=None, **hints):\n        \"\"\"\n        Make sure the auth and contenttypes apps only appear in the\n        self.db_name database.\n        \"\"\"\n        if app_label in self.route_app_labels:\n            return db == self.db_name\n        return None",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2012-12-06T23:10:45",
        "author": "Rohan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60255595/if-i-cache-a-spark-dataframe-and-then-overwrite-the-reference-will-the-original",
    "title": "If I cache a Spark Dataframe and then overwrite the reference, will the original data frame still be cached?",
    "question_id": 60255595,
    "posted_date": "2020-02-16T22:34:20",
    "answers": [
      {
        "answer_id": 65399311,
        "body": ">>> def func():\n...     data = spark.createDataFrame([[1],[2],[3]]).toDF('col1')\n...     data.cache()\n...     data.count()\n...     return data\n...\n>>> sc._jsc.getPersistentRDDs()\n{}\n>>> df = func()\n>>> sc._jsc.getPersistentRDDs()\n{71: JavaObject id=o234}\n>>> df2 = df.filter('col1 != 2')\n>>> del df\n>>> import gc\n>>> gc.collect()\n93\n>>> sc._jvm.System.gc()\n>>> sc._jsc.getPersistentRDDs()\n{71: JavaObject id=o240}\n>>> df2.select('*').explain()\n== Physical Plan ==\n*(1) Filter (isnotnull(col1#174L) AND NOT (col1#174L = 2))\n+- *(1) ColumnarToRow\n   +- InMemoryTableScan [col1#174L], [isnotnull(col1#174L), NOT (col1#174L = 2)]\n         +- InMemoryRelation [col1#174L], StorageLevel(disk, memory, deserialized, 1 replicas)\n               +- *(1) Project [_1#172L AS col1#174L]\n                  +- *(1) Scan ExistingRDD[_1#172L]\n>>> del df2\n>>> gc.collect()\n85\n>>> sc._jvm.System.gc()\n>>> sc._jsc.getPersistentRDDs()\n{71: JavaObject id=o250}",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2020-12-21T15:09:19",
        "author": "mck"
      },
      {
        "answer_id": 65399311,
        "body": ">>> def func():\n...     data = spark.createDataFrame([[1],[2],[3]]).toDF('col1')\n...     data.cache()\n...     data.count()\n...     return data\n...\n>>> sc._jsc.getPersistentRDDs()\n{}\n>>> df = func()\n>>> sc._jsc.getPersistentRDDs()\n{86: JavaObject id=o317}\n>>> df = df.filter('col1 != 2')\n>>> import gc\n>>> gc.collect()\n244\n>>> sc._jvm.System.gc()\n>>> sc._jsc.getPersistentRDDs()\n{86: JavaObject id=o323}\n>>> df.select('*').explain()\n== Physical Plan ==\n*(1) Filter (isnotnull(col1#220L) AND NOT (col1#220L = 2))\n+- *(1) ColumnarToRow\n   +- InMemoryTableScan [col1#220L], [isnotnull(col1#220L), NOT (col1#220L = 2)]\n         +- InMemoryRelation [col1#220L], StorageLevel(disk, memory, deserialized, 1 replicas)\n               +- *(1) Project [_1#218L AS col1#220L]\n                  +- *(1) Scan ExistingRDD[_1#218L]\n>>> del df\n>>> gc.collect()\n85\n>>> sc._jvm.System.gc()\n>>> sc._jsc.getPersistentRDDs()\n{86: JavaObject id=o333}",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2020-12-21T15:09:19",
        "author": "mck"
      },
      {
        "answer_id": 65399311,
        "body": ">>> def func():\n...     data = spark.createDataFrame([[1],[2],[3]]).toDF('col1')\n...     data.cache()\n...     data.count()\n...     return data\n...\n>>> sc._jsc.getPersistentRDDs()\n{}\n>>> df = func()\n>>> sc._jsc.getPersistentRDDs()\n{116: JavaObject id=o398}\n>>> df2 = df.filter('col1 != 2')\n>>> df2.select('*').explain()\n== Physical Plan ==\n*(1) Filter (isnotnull(col1#312L) AND NOT (col1#312L = 2))\n+- *(1) ColumnarToRow\n   +- InMemoryTableScan [col1#312L], [isnotnull(col1#312L), NOT (col1#312L = 2)]\n         +- InMemoryRelation [col1#312L], StorageLevel(disk, memory, deserialized, 1 replicas)\n               +- *(1) Project [_1#310L AS col1#312L]\n                  +- *(1) Scan ExistingRDD[_1#310L]\n>>> df.unpersist()\nDataFrame[col1: bigint]\n>>> sc._jsc.getPersistentRDDs()\n{}\n>>> df2.select('*').explain()\n== Physical Plan ==\n*(1) Project [_1#310L AS col1#312L]\n+- *(1) Filter (isnotnull(_1#310L) AND NOT (_1#310L = 2))\n   +- *(1) Scan ExistingRDD[_1#310L]",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2020-12-21T15:09:19",
        "author": "mck"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55180829/python-if-else-code-style-for-reduced-code-for-rounding-floats",
    "title": "Python if-else code style for reduced code for rounding floats",
    "question_id": 55180829,
    "posted_date": "2019-03-15T06:44:23",
    "answers": [
      {
        "answer_id": 55185849,
        "body": "`\n    if value < -0.95:        ts_folder = ''\n    elif value < -0.85:      ts_folder = r'\\-0.9'\n    elif value < -0.75:      ts_folder = r'\\-0.8'\n    elif value < -0.65:      ts_folder = r'\\-0.7'\n    elif value < -0.55:      ts_folder = r'\\-0.6'\n    elif value < -0.45:      ts_folder = r'\\-0.5'\n    elif value < -0.35:      ts_folder = r'\\-0.4'\n    elif value < -0.25:      ts_folder = r'\\-0.3'\n    elif value < -0.15:      ts_folder = r'\\-0.2'\n    elif value < -0.05:      ts_folder = r'\\-0.1'\n    elif value < 0.05:       ts_folder = r'\\0.0'\n    elif value < 0.15:       ts_folder = r'\\0.1'\n    elif value < 0.25:       ts_folder = r'\\0.2'\n    elif value < 0.35:       ts_folder = r'\\0.3'\n    elif value < 0.45:       ts_folder = r'\\0.4'\n    elif value < 0.55:       ts_folder = r'\\0.5'\n    elif value < 0.65:       ts_folder = r'\\0.6'\n    elif value < 0.75:       ts_folder = r'\\0.7'\n    elif value < 0.85:       ts_folder = r'\\0.8'\n    elif value < 0.95:       ts_folder = r'\\0.9'\n    else:                    ts_folder = ''",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2019-03-15T11:24:47",
        "author": "Martin Bonner supports Monica"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70680363/structural-pattern-matching-using-regex",
    "title": "Structural pattern matching using regex",
    "question_id": 70680363,
    "posted_date": "2022-01-12T05:58:18",
    "answers": [
      {
        "answer_id": 72201246,
        "body": "# noinspection PyPep8Naming\n@dataclass\nclass regex_in:\n    string: str\n    match: re.Match = None\n    def __eq__(self, other: str | re.Pattern):\n        if isinstance(other, str):\n            other = re.compile(other)\n        assert isinstance(other, re.Pattern)\n        # TODO extend for search and match variants\n        self.match = other.fullmatch(self.string)\n        return self.match is not None\n    def __getitem__(self, group):\n        return self.match[group]\n# Note the `as m` in in the case specification\nmatch regex_in(validated_string):\n    case r'\\d(\\d)' as m:\n        print(f'The second digit is {m[1]}')\n        print(f'The whole match is {m.match}')",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2022-05-11T08:41:13",
        "author": "ahoff"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10085996/shutdown-socketserver-serve-forever-in-one-thread-python-application",
    "title": "Shutdown socketserver serve_forever() in one-thread Python application",
    "question_id": 10085996,
    "posted_date": "2012-04-10T05:14:28",
    "answers": [
      {
        "answer_id": 22533929,
        "body": "#!/usr/bin/env python\n# -*- coding: UTF-8 -*-\nimport SimpleHTTPServer\nimport SocketServer\nimport time\nimport thread\nclass MyHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n    def do_POST(self):\n        if self.path.startswith('/kill_server'):\n            print \"Server is going down, run it again manually!\"\n            def kill_me_please(server):\n                server.shutdown()\n            thread.start_new_thread(kill_me_please, (httpd,))\n            self.send_error(500)\nclass MyTCPServer(SocketServer.TCPServer):\n    def server_bind(self):\n        import socket\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.socket.bind(self.server_address)\nserver_address = ('', 8000)\nhttpd = MyTCPServer(server_address, MyHandler)\ntry:\n    httpd.serve_forever()\nexcept KeyboardInterrupt:\n    pass\nhttpd.server_close()",
        "score": 28,
        "is_accepted": false,
        "creation_date": "2014-03-20T09:05:52",
        "author": "dmitry_romanov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61514887/how-to-trigger-a-dag-on-the-success-of-a-another-dag-in-airflow-using-python",
    "title": "How to Trigger a DAG on the success of a another DAG in Airflow using Python?",
    "question_id": 61514887,
    "posted_date": "2020-04-29T22:24:25",
    "answers": [
      {
        "answer_id": 61534071,
        "body": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom airflow.operators.sensors import ExternalTaskSensor\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': datetime(2020, 4, 29),\n}\ndag = DAG('Child_dag', default_args=default_args, schedule_interval='@daily')\n# Use ExternalTaskSensor to listen to the Parent_dag and cook_dinner task\n# when cook_dinner is finished, Child_dag will be triggered\nwait_for_dinner = ExternalTaskSensor(\n    task_id='wait_for_dinner',\n    external_dag_id='Parent_dag',\n    external_task_id='cook_dinner',\n    start_date=datetime(2020, 4, 29),\n    execution_delta=timedelta(hours=1),\n    timeout=3600,\n)\nhave_dinner = DummyOperator(\n    task_id='have_dinner',\n    dag=dag,\n)\nplay_with_food = DummyOperator(\n    task_id='play_with_food',\n    dag=dag,\n)\nwait_for_dinner >> have_dinner\nwait_for_dinner >> play_with_food",
        "score": 40,
        "is_accepted": true,
        "creation_date": "2020-04-30T18:48:49",
        "author": "moon"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60050586/pytorch-change-the-learning-rate-based-on-number-of-epochs",
    "title": "Pytorch Change the learning rate based on number of epochs",
    "question_id": 60050586,
    "posted_date": "2020-02-03T23:28:05",
    "answers": [
      {
        "answer_id": 60051713,
        "body": "Epoch-1 lr: 0.1\nEpoch-2 lr: 0.1\nEpoch-3 lr: 0.1\nEpoch-4 lr: 0.1\nEpoch-5 lr: 0.1\nEpoch-6 lr: 0.010000000000000002\nEpoch-7 lr: 0.010000000000000002\nEpoch-8 lr: 0.010000000000000002\nEpoch-9 lr: 0.010000000000000002\nEpoch-10 lr: 0.010000000000000002\nEpoch-11 lr: 0.0010000000000000002\nEpoch-12 lr: 0.0010000000000000002\nEpoch-13 lr: 0.0010000000000000002\nEpoch-14 lr: 0.0010000000000000002\nEpoch-15 lr: 0.0010000000000000002\nEpoch-16 lr: 0.00010000000000000003\nEpoch-17 lr: 0.00010000000000000003\nEpoch-18 lr: 0.00010000000000000003\nEpoch-19 lr: 0.00010000000000000003\nEpoch-20 lr: 0.00010000000000000003",
        "score": 54,
        "is_accepted": true,
        "creation_date": "2020-02-04T01:24:55",
        "author": "Dishin H Goyani"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56090541/how-to-plot-precision-and-recall-of-multiclass-classifier",
    "title": "How to plot precision and recall of multiclass classifier?",
    "question_id": 56090541,
    "posted_date": "2019-05-11T08:54:41",
    "answers": [
      {
        "answer_id": 56092736,
        "body": "from sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import precision_recall_curve, roc_curve\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nmnist = fetch_openml(\"mnist_784\")\ny = mnist.target\ny = y.astype(np.uint8)\nn_classes = len(set(y))\nY = label_binarize(mnist.target, classes=[*range(n_classes)])\nX_train, X_test, y_train, y_test = train_test_split(mnist.data,\n                                                    Y,\n                                                    random_state = 42)\nclf = OneVsRestClassifier(RandomForestClassifier(n_estimators=50,\n                             max_depth=3,\n                             random_state=0))\nclf.fit(X_train, y_train)\ny_score = clf.predict_proba(X_test)",
        "score": 58,
        "is_accepted": true,
        "creation_date": "2019-05-11T13:31:32",
        "author": "sentence"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53968770/how-to-set-up-local-file-references-in-python-jsonschema-document",
    "title": "How to set up local file references in python-jsonschema document?",
    "question_id": 53968770,
    "posted_date": "2018-12-29T05:39:05",
    "answers": [
      {
        "answer_id": 61632081,
        "body": "import json\nfrom jsonschema import RefResolver, Draft7Validator\naddress=\"\"\"\n{\n  \"$id\": \"https://example.com/schemas/address\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"street_address\": { \"type\": \"string\" },\n    \"city\": { \"type\": \"string\" },\n    \"state\": { \"type\": \"string\" }\n  },\n  \"required\": [\"street_address\", \"city\", \"state\"],\n  \"additionalProperties\": false\n}\n\"\"\"\ncustomer=\"\"\"\n{\n  \"$id\": \"https://example.com/schemas/customer\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"first_name\": { \"type\": \"string\" },\n    \"last_name\": { \"type\": \"string\" },\n    \"shipping_address\": { \"$ref\": \"/schemas/address\" },\n    \"billing_address\": { \"$ref\": \"/schemas/address\" }\n  },\n  \"required\": [\"first_name\", \"last_name\", \"shipping_address\", \"billing_address\"],\n  \"additionalProperties\": false\n}\n\"\"\"\ndata = \"\"\"\n{\n  \"first_name\": \"John\",\n  \"last_name\": \"Doe\",\n  \"shipping_address\": {\n    \"street_address\": \"1600 Pennsylvania Avenue NW\",\n    \"city\": \"Washington\",\n    \"state\": \"DC\"\n  },\n  \"billing_address\": {\n    \"street_address\": \"1st Street SE\",\n    \"city\": \"Washington\",\n    \"state\": \"DC\"\n  }\n}\n\"\"\"\naddress_schema = json.loads(address)\ncustomer_schema = json.loads(customer)\nschema_store = {\n    address_schema['$id'] : address_schema,\n    customer_schema['$id'] : customer_schema,\n}\nresolver = RefResolver.from_schema(customer_schema, store=schema_store)\nvalidator = Draft7Validator(customer_schema, resolver=resolver)\njsonData = json.loads(data)\nvalidator.validate(jsonData)",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2020-05-06T05:46:46",
        "author": "Daniel Schneider"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/40179593/how-to-get-the-coordinates-of-the-maximum-in-xarray",
    "title": "How to get the coordinates of the maximum in xarray?",
    "question_id": 40179593,
    "posted_date": "2016-10-21T10:44:12",
    "answers": [
      {
        "answer_id": 40197248,
        "body": "In [8]: da = xr.DataArray(\n   ...:     np.random.rand(2,3),\n   ...:     dims=list('ab'),\n   ...:     coords=dict(a=list('xy'), b=list('ijk'))\n   ...: )\nIn [14]: da\nOut[14]:\n<xarray.DataArray (a: 2, b: 3)>\narray([[0.63059257, 0.00155463, 0.60763418],\n       [0.19680788, 0.43953352, 0.05602777]])\nCoordinates:\n  * a        (a) <U1 'x' 'y'\n  * b        (b) <U1 'i' 'j' 'k'\nIn [13]: da.idxmax('a')\nOut[13]:\n<xarray.DataArray 'a' (b: 3)>\narray(['x', 'y', 'x'], dtype=object)\nCoordinates:\n  * b        (b) <U1 'i' 'j' 'k'",
        "score": 37,
        "is_accepted": true,
        "creation_date": "2016-10-22T17:28:58",
        "author": "Maximilian"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73599970/how-to-solve-wkhtmltopdf-reported-an-error-exit-with-code-1-due-to-network-err",
    "title": "How to solve &quot;wkhtmltopdf reported an error: Exit with code 1 due to network error: ProtocolUnknownError&quot; in python pdfkit",
    "question_id": 73599970,
    "posted_date": "2022-09-04T09:54:15",
    "answers": [
      {
        "answer_id": 73603802,
        "body": "download_view.py\nimport os\nimport pdfkit\nfrom django.http import FileResponse\nfrom django.template.loader import render_to_string\nfrom paypal.models import Invoice\nfrom website import settings\ndef download_as_pdf_view(request, pk):\n    # create PDF from HTML template file with context.\n    invoice = Invoice.objects.get(pk=pk)\n    context = {\n        # please set your contexts as dict.\n    }\n    _html = render_to_string('paypal/card_invoice_detail.html', context)\n     # remove header\n    _html = _html[_html.find('<body>'):]\n    # create new header\n    new_header = '''<!DOCTYPE html>\n    <html lang=\"ja\">\n    <head>\n    <meta charset=\"utf-8\"/>\n    </head>\n    <style>\n'''\n    # add style from css file. please change to your css file path.\n    css_path = os.path.join(settings.BASE_DIR, 'paypal', 'static', 'paypal', 'css', 'invoice.css')\n    with open(css_path, 'r') as f:\n        new_header += f.read()\n    new_header += '\\n</style>'\n    print(new_header)\n    # add head to html\n    _html = new_header + _html[_html.find('<body>'):]\n    with open('paypal/sample.html', 'w') as f: f.write(_html)  # for debug\n    # convert html to pdf\n    file_name = 'invoice.pdf'\n    pdf_path = os.path.join(settings.BASE_DIR, 'static', 'pdf', file_name)\n    pdfkit.from_string(_html, pdf_path, options={\"enable-local-file-access\": \"\"})\n    return FileResponse(open(pdf_path, 'rb'), filename=file_name, content_type='application/pdf')",
        "score": 45,
        "is_accepted": true,
        "creation_date": "2022-09-04T21:21:27",
        "author": "Nori"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66488807/pytorch-model-input-shape",
    "title": "PyTorch model input shape",
    "question_id": 66488807,
    "posted_date": "2021-03-05T02:59:52",
    "answers": [
      {
        "answer_id": 66562064,
        "body": "class NetWidth(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(16 * 8 * 8, 32)\n        self.fc2 = nn.Linear(32, 2)\n\n    def forward(self, x):\n        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n        out = out.view(-1, 16 * 8 * 8)\n        out = torch.tanh(self.fc1(out))\n        out = self.fc2(out)\n        return out",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2021-03-10T04:44:19",
        "author": "iacob"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48258008/n-and-r-arguments-to-ipythons-timeit-magic",
    "title": "-n and -r arguments to IPython&#39;s %timeit magic",
    "question_id": 48258008,
    "posted_date": "2018-01-15T01:35:55",
    "answers": [
      {
        "answer_id": 59543135,
        "body": ">>> r = %timeit -o ...\n7.46 ns \u00b1 0.0788 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000000 loops each)\n>>> r.loops  # the \"number\" is called \"loops\" on the result\n100000000\n>>> r.repeat\n7\n>>> r.all_runs\n[0.7445439999999905,\n 0.7611092000000212,\n 0.7249667000000102,\n 0.7238135999999997,\n 0.7385598000000186,\n 0.7338551999999936,\n 0.7277425999999991]\n>>> r.best\n7.238135999999997e-09\n>>> r.average\n7.363701571428618e-09\n>>> min(r.all_runs) / r.loops  # calculated best by hand\n7.238135999999997e-09\n>>> from statistics import mean\n>>> mean(r.all_runs) / r.loops  # calculated average by hand\n7.363701571428619e-09",
        "score": 34,
        "is_accepted": false,
        "creation_date": "2019-12-31T05:55:20",
        "author": "MSeifert"
      },
      {
        "answer_id": 59543135,
        "body": "import timeit\nr = timeit.repeat('sum(1 for _ in range(10000))', number=1, repeat=1_000)\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.title('measuring summation of 10_000 1s')\nplt.ylabel('number of measurements')\nplt.xlabel('measured time [s]')\nplt.yscale('log')\nplt.hist(r, bins='auto', color='black', label='measurements')\nplt.tight_layout()\nplt.axvline(np.min(r), c='lime', label='min')\nplt.axvline(np.mean(r), c='red', label='mean')\nplt.axvline(np.median(r), c='blue', label='median')\nplt.legend()",
        "score": 34,
        "is_accepted": false,
        "creation_date": "2019-12-31T05:55:20",
        "author": "MSeifert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/68417319/initialize-python-dataclass-from-dictionary",
    "title": "Initialize Python dataclass from dictionary",
    "question_id": 68417319,
    "posted_date": "2021-07-17T00:10:28",
    "answers": [
      {
        "answer_id": 72164665,
        "body": "from dataclasses import dataclass, fields\nclass DataClassUnpack:\n    classFieldCache = {}\n    @classmethod\n    def instantiate(cls, classToInstantiate, argDict):\n        if classToInstantiate not in cls.classFieldCache:\n            cls.classFieldCache[classToInstantiate] = {f.name for f in fields(classToInstantiate) if f.init}\n        fieldSet = cls.classFieldCache[classToInstantiate]\n        filteredArgDict = {k : v for k, v in argDict.items() if k in fieldSet}\n        return classToInstantiate(**filteredArgDict)\n@dataclass\nclass Req:\n    id: int\n    description: str\nreq = DataClassUnpack.instantiate(Req, {\"id\": 123, \"description\": \"hello\", \"data_a\": \"\"})\nprint(req)\nreq = DataClassUnpack.instantiate(Req, {\"id\": 456, \"description\": \"goodbye\", \"data_a\": \"my\", \"data_b\": \"friend\"})\nprint(req)\n@dataclass\nclass Req2:\n    id: int\n    description: str\n    data_a: str\nreq2 = DataClassUnpack.instantiate(Req2, {\"id\": 123, \"description\": \"hello\", \"data_a\": \"world\"})\nprint(req2)\nprint(\"\\nHere's a peek at the internals of DataClassUnpack:\")\nprint(DataClassUnpack.classFieldCache)",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2022-05-08T15:58:43",
        "author": "constantstranger"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58642528/displaying-of-fastapi-validation-errors-to-end-users",
    "title": "Displaying of FastAPI validation errors to end users",
    "question_id": 58642528,
    "posted_date": "2019-10-31T07:36:38",
    "answers": [
      {
        "answer_id": 72213866,
        "body": "from collections import defaultdict\nfrom fastapi import status\nfrom fastapi.encoders import jsonable_encoder\nfrom fastapi.responses import JSONResponse\n@app.exception_handler(RequestValidationError)\nasync def custom_form_validation_error(request, exc):\n    reformatted_message = defaultdict(list)\n    for pydantic_error in exc.errors():\n        loc, msg = pydantic_error[\"loc\"], pydantic_error[\"msg\"]\n        filtered_loc = loc[1:] if loc[0] in (\"body\", \"query\", \"path\") else loc\n        field_string = \".\".join(filtered_loc)  # nested fields with dot-notation\n        reformatted_message[field_string].append(msg)\n    return JSONResponse(\n        status_code=status.HTTP_400_BAD_REQUEST,\n        content=jsonable_encoder(\n            {\"detail\": \"Invalid request\", \"errors\": reformatted_message}\n        ),\n    )",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2022-05-12T06:21:59",
        "author": "Dariosky"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55301343/how-to-define-the-structure-of-a-sankey-diagram-using-a-pandas-dataframe",
    "title": "How to define the structure of a sankey diagram using a pandas dataframe",
    "question_id": 55301343,
    "posted_date": "2019-03-22T10:04:21",
    "answers": [
      {
        "answer_id": 55355445,
        "body": "import pandas as pd\nimport numpy as np\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nnodes = [\n    ['ID', 'Label', 'Color'],\n    [0,'Remain+No \u2013 28','#F27420'],\n    [1,'Leave+No \u2013 16','#4994CE'],\n    [2,'Remain+Yes \u2013 21','#FABC13'],\n    [3,'Leave+Yes \u2013 14','#7FC241'],\n    [4,'Didn\u2019t vote in at least one referendum \u2013 21','#D3D3D3'],\n    [5,'46 \u2013 No','#8A5988']\n]\nlinks = [\n    ['Source','Target','Value','Link Color'],\n    [0,3,20,'rgba(253, 227, 212, 0.5)'],\n    [0,4,3,'rgba(242, 116, 32, 1)'],\n    [0,2,5,'rgba(253, 227, 212, 0.5)'],\n    [1,5,14,'rgba(219, 233, 246, 0.5)'],\n    [1,3,1,'rgba(73, 148, 206, 1)'],\n    [1,4,1,'rgba(219, 233, 246,0.5)'],\n    [1,2,10,'rgba(8, 233, 246,0.5)'],\n    [1,3,5,'rgba(219, 77, 246,0.5)'],\n    [1,5,12,'rgba(219, 4, 246,0.5)']\n]\nnodes_headers = nodes.pop(0)\nnodes_df = pd.DataFrame(nodes, columns = nodes_headers)\nlinks_headers = links.pop(0)\nlinks_df = pd.DataFrame(links, columns = links_headers)\ndata_trace = dict(\n    type='sankey',\n    domain = dict(\n      x =  [0,1],\n      y =  [0,1]\n    ),\n    orientation = \"h\",\n    valueformat = \".0f\",\n    node = dict(\n      pad = 10,\n      thickness = 30,\n      line = dict(\n        color = \"black\",\n        width = 0\n      ),\n      label =  nodes_df['Label'].dropna(axis=0, how='any'),\n      color = nodes_df['Color']\n    ),\n    link = dict(\n      source = links_df['Source'].dropna(axis=0, how='any'),\n      target = links_df['Target'].dropna(axis=0, how='any'),\n      value = links_df['Value'].dropna(axis=0, how='any'),\n      color = links_df['Link Color'].dropna(axis=0, how='any'),\n  )\n)\nlayout =  dict(\n    title = \"Scottish Referendum Voters who now want Independence\",\n    height = 772,\n    font = dict(\n      size = 10\n    ),\n)\nfig = dict(data=[data_trace], layout=layout)\niplot(fig, validate=False)",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2019-03-26T06:57:10",
        "author": "vurmux"
      },
      {
        "answer_id": 55355445,
        "body": "nodes = [\n    ['ID', 'Label', 'Color'],\n    [0,'Remain+No \u2013 28','#F27420'],\n    [1,'Leave+No \u2013 16','#4994CE'],\n    [2,'Remain+Yes \u2013 21','#FABC13'],\n    [3,'Leave+Yes \u2013 14','#7FC241'],\n    [4,'Didn\u2019t vote in at least one referendum \u2013 21','#D3D3D3'],\n    [5,'46 \u2013 No','#8A5988'],\n    [6,'WAKA1','#8A5988'],\n    [7,'WAKA2','#8A5988'],\n    [8,'WAKA3','#8A5988'],\n    [9,'WAKA4','#8A5988'],\n    [10,'WAKA5','#8A5988'],\n    [11,'WAKA6','#8A5988'],\n\n]\nlinks = [\n    ['Source','Target','Value','Link Color'],\n    [0,3,20,'rgba(253, 227, 212, 0.5)'],\n    [0,4,3,'rgba(242, 116, 32, 1)'],\n    [0,2,5,'rgba(253, 227, 212, 0.5)'],\n    [1,5,14,'rgba(219, 233, 246, 0.5)'],\n    [1,3,1,'rgba(73, 148, 206, 1)'],\n    [1,4,1,'rgba(219, 233, 246,0.5)'],\n    [1,2,10,'rgba(8, 233, 246,0.5)'],\n    [1,3,5,'rgba(219, 77, 246,0.5)'],\n    [1,5,12,'rgba(219, 4, 246,0.5)']\n]",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2019-03-26T06:57:10",
        "author": "vurmux"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/40949746/how-to-display-flashing-message-without-reloading-the-page-in-flask",
    "title": "How to display flashing message without reloading the page in Flask?",
    "question_id": 40949746,
    "posted_date": "2016-12-03T11:08:10",
    "answers": [
      {
        "answer_id": 40951758,
        "body": "@app.route('/', methods=['GET', 'POST'])\ndef index():\n    form = Nameform()\n    if form.validate_on_submit():\n        old_name = session.get('name')\n        if old_name is not None and old_name != form.name.data:\n            flash('Looks like you have changed your name!')\n        session['name'] = form.name.data\n        form.name.data = ''\n        return redirect(url_for('index'))\n    return render_template('index.html', form=form, name=session.get('name'))\n        form = form, name = session.get('name'))",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2016-12-03T14:42:28",
        "author": "boardrider"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69970147/how-do-i-resolve-the-pygraphviz-error-on-mac-os",
    "title": "How do I resolve the pygraphviz error on mac OS?",
    "question_id": 69970147,
    "posted_date": "2021-11-15T01:21:58",
    "answers": [
      {
        "answer_id": 70439868,
        "body": "Collecting pygraphviz\n  Using cached pygraphviz-1.11.zip (120 kB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nBuilding wheels for collected packages: pygraphviz\n  Building wheel for pygraphviz (pyproject.toml) ... done\n  Created wheel for pygraphviz: filename=pygraphviz-1.11-cp311-cp311-macosx_13_0_arm64.whl size=100586 sha256=0d6e56168321d335706a6c6789a006b8d2831bbd32b1cd28bd8fb2238122f73b\n  Stored in directory: .../pip/wheels/c8/03/73/b754941d55845a8b326f6de528bc70e65774838c76effa6d51\nSuccessfully built pygraphviz\nInstalling collected packages: pygraphviz\nSuccessfully installed pygraphviz-1.11",
        "score": 48,
        "is_accepted": false,
        "creation_date": "2021-12-21T13:10:01",
        "author": "DanielM"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/22785849/drawing-multiple-edges-between-two-nodes-with-networkx",
    "title": "Drawing multiple edges between two nodes with networkx",
    "question_id": 22785849,
    "posted_date": "2014-04-01T08:25:37",
    "answers": [
      {
        "answer_id": 70245742,
        "body": "import matplotlib.pyplot as plt\nimport networkx as nx\nG = nx.DiGraph()\nedge_list = [(1, 2, {'w': 'A1'}), (2, 1, {'w': 'A2'}), (2, 3, {'w': 'B'}),\n             (3, 1, {'w': 'C'}),\n             (3, 4, {'w': 'D1'}), (4, 3, {'w': 'D2'}), (1, 5, {'w': 'E1'}),\n             (5, 1, {'w': 'E2'}),\n             (3, 5, {'w': 'F'}), (5, 4, {'w': 'G'})]\nG.add_edges_from(edge_list)\npos = nx.spring_layout(G, seed=5)\nfig, ax = plt.subplots()\nnx.draw_networkx_nodes(G, pos, ax=ax)\nnx.draw_networkx_labels(G, pos, ax=ax)\nfig.savefig(\"1.png\", bbox_inches='tight', pad_inches=0)",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2021-12-06T07:47:04",
        "author": "kcoskun"
      },
      {
        "answer_id": 70245742,
        "body": "import my_networkx as my_nx\nedge_weights = nx.get_edge_attributes(G, 'w')\ncurved_edge_labels = {edge: edge_weights[edge] for edge in curved_edges}\nstraight_edge_labels = {edge: edge_weights[edge] for edge in straight_edges}\nmy_nx.my_draw_networkx_edge_labels(G, pos, ax=ax,\n                                   edge_labels=curved_edge_labels, rotate=False,\n                                   rad=arc_rad)\nnx.draw_networkx_edge_labels(G, pos, ax=ax, edge_labels=straight_edge_labels,\n                             rotate=False)\nfig.savefig(\"3.png\", bbox_inches='tight', pad_inches=0)",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2021-12-06T07:47:04",
        "author": "kcoskun"
      },
      {
        "answer_id": 70245742,
        "body": "def my_draw_networkx_edge_labels(\n    G,\n    pos,\n    edge_labels=None,\n    label_pos=0.5,\n    font_size=10,\n    font_color=\"k\",\n    font_family=\"sans-serif\",\n    font_weight=\"normal\",\n    alpha=None,\n    bbox=None,\n    horizontalalignment=\"center\",\n    verticalalignment=\"center\",\n    ax=None,\n    rotate=True,\n    clip_on=True,\n    rad=0\n):\n    \"\"\"Draw edge labels.\n    Parameters\n    ----------\n    G : graph\n        A networkx graph\n    pos : dictionary\n        A dictionary with nodes as keys and positions as values.\n        Positions should be sequences of length 2.\n    edge_labels : dictionary (default={})\n        Edge labels in a dictionary of labels keyed by edge two-tuple.\n        Only labels for the keys in the dictionary are drawn.\n    label_pos : float (default=0.5)\n        Position of edge label along edge (0=head, 0.5=center, 1=tail)\n    font_size : int (default=10)\n        Font size for text labels\n    font_color : string (default='k' black)\n        Font color string\n    font_weight : string (default='normal')\n        Font weight\n    font_family : string (default='sans-serif')\n        Font family\n    alpha : float or None (default=None)\n        The text transparency\n    bbox : Matplotlib bbox, optional\n        Specify text box properties (e.g. shape, color etc.) for edge labels.\n        Default is {boxstyle='round', ec=(1.0, 1.0, 1.0), fc=(1.0, 1.0, 1.0)}.\n    horizontalalignment : string (default='center')\n        Horizontal alignment {'center', 'right', 'left'}\n    verticalalignment : string (default='center')\n        Vertical alignment {'center', 'top', 'bottom', 'baseline', 'center_baseline'}\n    ax : Matplotlib Axes object, optional\n        Draw the graph in the specified Matplotlib axes.\n    rotate : bool (deafult=True)\n        Rotate edge labels to lie parallel to edges\n    clip_on : bool (default=True)\n        Turn on clipping of edge labels at axis boundaries\n    Returns\n    -------\n    dict\n        `dict` of labels keyed by edge\n    Examples\n    --------\n    >>> G = nx.dodecahedral_graph()\n    >>> edge_labels = nx.draw_networkx_edge_labels(G, pos=nx.spring_layout(G))\n    Also see the NetworkX drawing examples at\n    https://networkx.org/documentation/latest/auto_examples/index.html\n    See Also\n    --------\n    draw\n    draw_networkx\n    draw_networkx_nodes\n    draw_networkx_edges\n    draw_networkx_labels\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    if ax is None:\n        ax = plt.gca()\n    if edge_labels is None:\n        labels = {(u, v): d for u, v, d in G.edges(data=True)}\n    else:\n        labels = edge_labels\n    text_items = {}\n    for (n1, n2), label in labels.items():\n        (x1, y1) = pos[n1]\n        (x2, y2) = pos[n2]\n        (x, y) = (\n            x1 * label_pos + x2 * (1.0 - label_pos),\n            y1 * label_pos + y2 * (1.0 - label_pos),\n        )\n        pos_1 = ax.transData.transform(np.array(pos[n1]))\n        pos_2 = ax.transData.transform(np.array(pos[n2]))\n        linear_mid = 0.5*pos_1 + 0.5*pos_2\n        d_pos = pos_2 - pos_1\n        rotation_matrix = np.array([(0,1), (-1,0)])\n        ctrl_1 = linear_mid + rad*rotation_matrix@d_pos\n        ctrl_mid_1 = 0.5*pos_1 + 0.5*ctrl_1\n        ctrl_mid_2 = 0.5*pos_2 + 0.5*ctrl_1\n        bezier_mid = 0.5*ctrl_mid_1 + 0.5*ctrl_mid_2\n        (x, y) = ax.transData.inverted().transform(bezier_mid)\n        if rotate:\n            # in degrees\n            angle = np.arctan2(y2 - y1, x2 - x1) / (2.0 * np.pi) * 360\n            # make label orientation \"right-side-up\"\n            if angle > 90:\n                angle -= 180\n            if angle < -90:\n                angle += 180\n            # transform data coordinate angle to screen coordinate angle\n            xy = np.array((x, y))\n            trans_angle = ax.transData.transform_angles(\n                np.array((angle,)), xy.reshape((1, 2))\n            )[0]\n        else:\n            trans_angle = 0.0\n        # use default box of white with white border\n        if bbox is None:\n            bbox = dict(boxstyle=\"round\", ec=(1.0, 1.0, 1.0), fc=(1.0, 1.0, 1.0))\n        if not isinstance(label, str):\n            label = str(label)  # this makes \"1\" and 1 labeled the same\n        t = ax.text(\n            x,\n            y,\n            label,\n            size=font_size,\n            color=font_color,\n            family=font_family,\n            weight=font_weight,\n            alpha=alpha,\n            horizontalalignment=horizontalalignment,\n            verticalalignment=verticalalignment,\n            rotation=trans_angle,\n            transform=ax.transData,\n            bbox=bbox,\n            zorder=1,\n            clip_on=clip_on,\n        )\n        text_items[(n1, n2)] = t\n    ax.tick_params(\n        axis=\"both\",\n        which=\"both\",\n        bottom=False,\n        left=False,\n        labelbottom=False,\n        labelleft=False,\n    )\n    return text_items",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2021-12-06T07:47:04",
        "author": "kcoskun"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50443411/how-to-load-a-tflite-model-in-script",
    "title": "How to load a tflite model in script?",
    "question_id": 50443411,
    "posted_date": "2018-05-21T02:48:51",
    "answers": [
      {
        "answer_id": 51986982,
        "body": "import numpy as np\nimport tensorflow as tf\n# Load TFLite model and allocate tensors.\ninterpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\ninterpreter.allocate_tensors()\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n# Test model on random input data.\ninput_shape = input_details[0]['shape']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n# The function `get_tensor()` returns a copy of the tensor data.\n# Use `tensor()` in order to get a pointer to the tensor.\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nprint(output_data)",
        "score": 68,
        "is_accepted": false,
        "creation_date": "2018-08-23T09:30:21",
        "author": "Jing Zhao"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21104664/extract-all-bounding-boxes-using-opencv-python",
    "title": "Extract all bounding boxes using OpenCV Python",
    "question_id": 21104664,
    "posted_date": "2014-01-13T20:39:57",
    "answers": [
      {
        "answer_id": 60068297,
        "body": "import cv2\nimport numpy as np\n# Load image, grayscale, Otsu's threshold\nimage = cv2.imread('1.png')\noriginal = image.copy()\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n# Find contours, obtain bounding box, extract and save ROI\nROI_number = 0\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    x,y,w,h = cv2.boundingRect(c)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n    ROI = original[y:y+h, x:x+w]\n    cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n    ROI_number += 1\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 29,
        "is_accepted": false,
        "creation_date": "2020-02-04T21:41:02",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3114786/python-library-to-extract-epub-information",
    "title": "Python library to extract &#39;epub&#39; information",
    "question_id": 3114786,
    "posted_date": "2010-06-24T20:12:10",
    "answers": [
      {
        "answer_id": 3114929,
        "body": "import zipfile\nfrom lxml import etree\ndef epub_info(fname):\n    def xpath(element, path):\n        return element.xpath(\n            path,\n            namespaces={\n                \"n\": \"urn:oasis:names:tc:opendocument:xmlns:container\",\n                \"pkg\": \"http://www.idpf.org/2007/opf\",\n                \"dc\": \"http://purl.org/dc/elements/1.1/\",\n            },\n        )[0]\n    # prepare to read from the .epub file\n    zip_content = zipfile.ZipFile(fname)\n\n    # find the contents metafile\n    cfname = xpath(\n        etree.fromstring(zip_content.read(\"META-INF/container.xml\")),\n        \"n:rootfiles/n:rootfile/@full-path\",\n    )\n\n    # grab the metadata block from the contents metafile\n    metadata = xpath(\n        etree.fromstring(zip_content.read(cfname)), \"/pkg:package/pkg:metadata\"\n    )\n\n    # repackage the data\n    return {\n        s: xpath(metadata, f\"dc:{s}/text()\")\n        for s in (\"title\", \"language\", \"creator\", \"date\", \"identifier\")\n    }",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2010-06-24T21:07:06",
        "author": "Hugh Bothwell"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61316540/how-to-get-python-fastapi-async-await-functionality-to-work-properly",
    "title": "How to get Python FastAPI async/await functionality to work properly?",
    "question_id": 61316540,
    "posted_date": "2020-04-20T02:43:59",
    "answers": [
      {
        "answer_id": 68113745,
        "body": "from fastapi import FastAPI\nimport time\nimport asyncio\napp = FastAPI()\nasync def my_func_1():\n    \"\"\"\n    my func 1\n    \"\"\"\n    print('Func1 started..!!')\n    await asyncio.sleep(5)\n    print('Func1 ended..!!')\n    return 'a..!!'\nasync def my_func_2():\n    \"\"\"\n    my func 2\n    \"\"\"\n    print('Func2 started..!!')\n    await asyncio.sleep(5)\n    print('Func2 ended..!!')\n    return 'b..!!'\n@app.get(\"/home\")\nasync def root():\n    \"\"\"\n    my home route\n    \"\"\"\n    start = time.time()\n    futures = [my_func_1(), my_func_2()]\n    a,b = await asyncio.gather(*futures)\n    end = time.time()\n    print('It took {} seconds to finish execution.'.format(round(end-start)))\n    return {\n        'a': a,\n        'b': b\n    }",
        "score": 26,
        "is_accepted": false,
        "creation_date": "2021-06-24T06:10:15",
        "author": "Mattia Paterna"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59182827/how-to-get-the-cells-of-a-sudoku-grid-with-opencv",
    "title": "How to get the cells of a sudoku grid with OpenCV?",
    "question_id": 59182827,
    "posted_date": "2019-12-04T13:46:26",
    "answers": [
      {
        "answer_id": 59184973,
        "body": "import cv2\nfrom imutils import contours\nimport numpy as np\n# Load image, grayscale, and adaptive threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nthresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,57,5)\n# Filter out all numbers and noise to isolate only boxes\ncnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area < 1000:\n        cv2.drawContours(thresh, [c], -1, (0,0,0), -1)\n# Fix horizontal and vertical lines\nvertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, vertical_kernel, iterations=9)\nhorizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, horizontal_kernel, iterations=4)\n# Sort by top to bottom and each row by left to right\ninvert = 255 - thresh\ncnts = cv2.findContours(invert, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\n(cnts, _) = contours.sort_contours(cnts, method=\"top-to-bottom\")\nsudoku_rows = []\nrow = []\nfor (i, c) in enumerate(cnts, 1):\n    area = cv2.contourArea(c)\n    if area < 50000:\n        row.append(c)\n        if i % 9 == 0:\n            (cnts, _) = contours.sort_contours(row, method=\"left-to-right\")\n            sudoku_rows.append(cnts)\n            row = []\n# Iterate through each box\nfor row in sudoku_rows:\n    for c in row:\n        mask = np.zeros(image.shape, dtype=np.uint8)\n        cv2.drawContours(mask, [c], -1, (255,255,255), -1)\n        result = cv2.bitwise_and(image, mask)\n        result[mask==0] = 255\n        cv2.imshow('result', result)\n        cv2.waitKey(175)\ncv2.imshow('thresh', thresh)\ncv2.imshow('invert', invert)\ncv2.waitKey()",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2019-12-04T16:35:24",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/27386738/per-transaction-isolation-level-in-django-orm",
    "title": "Per-transaction isolation level in Django ORM",
    "question_id": 27386738,
    "posted_date": "2014-12-09T14:00:14",
    "answers": [
      {
        "answer_id": 37562317,
        "body": "    DATABASES = {\n        'default': {\n            'NAME': 'app_data',\n            'ENGINE': 'django.db.backends.postgresql',\n            'USER': 'postgres_user',\n            'PASSWORD': 's3krit',\n        },\n        'serializable': {\n            'NAME': 'app_data',\n            'ENGINE': 'django.db.backends.postgresql',\n            'USER': 'postgres_user',\n            'PASSWORD': 's3krit',\n            'OPTIONS': {\n                'isolation_level': psycopg2.extensions.ISOLATION_LEVEL_SERIALIZABLE,\n            },\n        },\n    }",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2016-06-01T03:38:23",
        "author": "dhui"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42844636/what-is-the-difference-between-partial-and-partialmethod",
    "title": "What is the difference between partial and partialmethod?",
    "question_id": 42844636,
    "posted_date": "2017-03-16T16:57:32",
    "answers": [
      {
        "answer_id": 58352943,
        "body": "from functools import partialmethod\nclass Live:\n    def __init__(self):\n        self._live = False\n    def set_live(self,state:'bool'):\n        self._live = state\n    def __get_live(self):\n        return self._live\n    def __call__(self):\n        # enable this to be called when the object is made callable.\n        return self.__get_live()\n\n    # partial methods. Freezes the method `set_live` and `set_dead`\n    # with the specific arguments\n    set_alive = partialmethod(set_live, True)\n    set_dead = partialmethod(set_live, False)\nlive = Live() # create object\nprint(live()) # make the object callable. It calls `__call__` under the hood\nlive.set_alive() # Call the partial method\nprint(live())",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-10-12T05:55:53",
        "author": "Eyong Kevin Enowanyo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57737610/puppeteer-fingerprint-simulation",
    "title": "Puppeteer fingerprint simulation",
    "question_id": 57737610,
    "posted_date": "2019-08-31T07:26:44",
    "answers": [
      {
        "answer_id": 57944153,
        "body": "const puppeteer = require('puppeteer');\n(async () => {\n    const browser = await puppeteer.launch({ headless: false });\n    const page = await browser.newPage();\n    await page.evaluateOnNewDocument(() => {\n        const originalFunction = HTMLCanvasElement.prototype.toDataURL;\n        HTMLCanvasElement.prototype.toDataURL = function (type) {\n            if (type === 'image/png' && this.width === 220 && this.height === 30) {\n                // this is likely a fingerprint attempt, return fake fingerprint\n                return 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANwAAAAeCAAAAABiES/iAAACeElEQVRYw+2YzUtUURjGf47OmDPh5AyFomUiEeEmyghXtWsh4dcswlYV2KYWfZh/QRBUVLhTCCJXEgmKUCIkFhJREARBkbkyKBlTRmUC82lxZ7z3TjM4whwXwz2ry3vO87znx33Pey4XFfHAg/PgPDgPzoPz4Dy4rFIKscSkAfmnsUY+iTfXFhxue4Zm4QpfaKbg8k+EsZNsGG6iNVzRMrkZeRPmjp6eCgcae5f+3wJIgtWLldG+DUnfzoail1etaVsEa1f2lUqw2hPd3T7nCrkMtlkQ24YDwP8+FZkI+gY3uq2cTcu54GIA/dJCDUAnSE4RdAESdALUxZ0hl4E5OMs49iE528E5a+cj5YFhDVI3vLA2c4K+zLXpvR37tNRDs3STg1OJqXqQSwS14wlJUD+VeHWAW86Qy8BwQ5Ek/WK/JBgqC72UTvJakmY5lAvurTRPSDrMmKRRcIvgeUo2KmmEI86Qy8DwmVu/ezQIBCSBLzwjKZhujv5cZZmUNkAq57ekRXCLYDG12pre5Qy5DAzDXbPfIOB/JqmCzNafCZd+dMA5RfZxdsBlNTAMF+FJfD2eSvSI0iGpmXe5GnbG3qyyHAO3yCZxlGV2uBLWDcJVMZKc7UrnfIBvQI+pHpxbS34ZaNkK7gYN0yvTDSCXyCZxNJTscFFe/DUH1w3QvpnzPiUPdTXfsvxZDdBGmeQU2SQd9lWQHS5m9J6Ln4/suZCwc96D25qM1formq5/3ApOX1uDkZ7P7JXkENkkK5eqQm3flRtuvitSYgCucKOf0zv01bazcG3Tyz8GKukvSjjrlB3/U5Rw42dqAo29yypKOO8figeX1/gH+zX9JqfOeUwAAAAASUVORK5CYII=';\n            }\n            // otherwise, just use the original function\n            return originalFunction.apply(this, arguments);\n        };\n    });\n    await page.goto('https://browserleaks.com/canvas');\n})();",
        "score": 26,
        "is_accepted": false,
        "creation_date": "2019-09-15T08:35:21",
        "author": "Thomas Dondorf"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/31768031/plotting-points-on-the-surface-of-a-sphere",
    "title": "Plotting points on the surface of a sphere",
    "question_id": 31768031,
    "posted_date": "2015-08-01T22:27:22",
    "answers": [
      {
        "answer_id": 31775938,
        "body": "   0.000000000000000\t90.000000000000000    -0.055226399197273\n 180.000000000000000\t90.000000000000000    -0.055226399197273\n  90.000000000000000\t90.000000000000000    -0.055226399197273\n -90.000000000000000\t90.000000000000000    -0.055226399197273\n  90.000000000000000\t 0.000000000000000    -0.055226399197273\n  90.000000000000000   180.000000000000000    -0.055226399197273\n  45.000000000000000\t54.735610317245346     0.004450274607445\n  45.000000000000000   125.264389682754654     0.004450274607445\n -45.000000000000000\t54.735610317245346     0.004450274607445\n -45.000000000000000   125.264389682754654     0.004450274607445\n 135.000000000000000\t54.735610317245346     0.004450274607445\n 135.000000000000000   125.264389682754654     0.004450274607445\n-135.000000000000000\t54.735610317245346     0.004450274607445\n-135.000000000000000   125.264389682754654     0.004450274607445\n  45.000000000000000\t39.440090784780402     0.004496841067921\n  45.000000000000000   140.559909215219591     0.004496841067921\n -45.000000000000000\t39.440090784780402     0.004496841067921\n -45.000000000000000   140.559909215219591     0.004496841067921\n 135.000000000000000\t39.440090784780402     0.004496841067921\n 135.000000000000000   140.559909215219591     0.004496841067921\n-135.000000000000000\t39.440090784780402     0.004496841067921\n-135.000000000000000   140.559909215219591     0.004496841067921\n  59.815442273124063\t63.307345060625650     0.004496841067921\n -59.815442273124063\t63.307345060625650     0.004496841067921\n  59.815442273124063   116.692654939374364     0.004496841067921\n -59.815442273124063   116.692654939374364     0.004496841067921\n 120.184557726875937\t63.307345060625650     0.004496841067921\n-120.184557726875937\t63.307345060625650     0.004496841067921\n 120.184557726875937   116.692654939374364     0.004496841067921\n-120.184557726875937   116.692654939374364     0.004496841067921\n  30.184557726875941\t63.307345060625650     0.004496841067921\n 149.815442273124063\t63.307345060625650     0.004496841067921\n  30.184557726875941   116.692654939374364     0.004496841067921\n 149.815442273124063   116.692654939374364     0.004496841067921\n -30.184557726875941\t63.307345060625650     0.004496841067921\n-149.815442273124063\t63.307345060625650     0.004496841067921\n -30.184557726875941   116.692654939374364     0.004496841067921\n-149.815442273124063   116.692654939374364     0.004496841067921\n  45.000000000000000\t20.881794557261646     0.005049153450479\n  45.000000000000000   159.118205442738343     0.005049153450479\n -45.000000000000000\t20.881794557261646     0.005049153450479\n -45.000000000000000   159.118205442738343     0.005049153450479\n 135.000000000000000\t20.881794557261646     0.005049153450479\n 135.000000000000000   159.118205442738343     0.005049153450479\n-135.000000000000000\t20.881794557261646     0.005049153450479\n-135.000000000000000   159.118205442738343     0.005049153450479\n  74.903220296612005\t75.401622829462283     0.005049153450479\n -74.903220296612005\t75.401622829462283     0.005049153450479\n  74.903220296612005   104.598377170537717     0.005049153450479\n -74.903220296612005   104.598377170537717     0.005049153450479\n 105.096779703387995\t75.401622829462283     0.005049153450479\n-105.096779703387995\t75.401622829462283     0.005049153450479\n 105.096779703387995   104.598377170537717     0.005049153450479\n-105.096779703387995   104.598377170537717     0.005049153450479\n  15.096779703387996\t75.401622829462283     0.005049153450479\n 164.903220296612034\t75.401622829462283     0.005049153450479\n  15.096779703387996   104.598377170537717     0.005049153450479\n 164.903220296612034   104.598377170537717     0.005049153450479\n -15.096779703387996\t75.401622829462283     0.005049153450479\n-164.903220296612034\t75.401622829462283     0.005049153450479\n -15.096779703387996   104.598377170537717     0.005049153450479\n-164.903220296612034   104.598377170537717     0.005049153450479\n  45.000000000000000\t80.891636123006165     0.003976408018052\n  45.000000000000000\t99.108363876993835     0.003976408018052\n -45.000000000000000\t80.891636123006165     0.003976408018052\n -45.000000000000000\t99.108363876993835     0.003976408018052\n 135.000000000000000\t80.891636123006165     0.003976408018052\n 135.000000000000000\t99.108363876993835     0.003976408018052\n-135.000000000000000\t80.891636123006165     0.003976408018052\n-135.000000000000000\t99.108363876993835     0.003976408018052\n  12.774805990014807\t45.717979481517574     0.003976408018052\n -12.774805990014807\t45.717979481517574     0.003976408018052\n  12.774805990014807   134.282020518482426     0.003976408018052\n -12.774805990014807   134.282020518482426     0.003976408018052\n 167.225194009985188\t45.717979481517574     0.003976408018052\n-167.225194009985188\t45.717979481517574     0.003976408018052\n 167.225194009985188   134.282020518482426     0.003976408018052\n-167.225194009985188   134.282020518482426     0.003976408018052\n  77.225194009985188\t45.717979481517574     0.003976408018052\n 102.774805990014812\t45.717979481517574     0.003976408018052\n  77.225194009985188   134.282020518482426     0.003976408018052\n 102.774805990014812   134.282020518482426     0.003976408018052\n -77.225194009985188\t45.717979481517574     0.003976408018052\n-102.774805990014812\t45.717979481517574     0.003976408018052\n -77.225194009985188   134.282020518482426     0.003976408018052\n-102.774805990014812   134.282020518482426     0.003976408018052\n  45.000000000000000\t68.685581154790029     0.004401400650381\n  45.000000000000000   111.314418845209985     0.004401400650381\n -45.000000000000000\t68.685581154790029     0.004401400650381\n -45.000000000000000   111.314418845209985     0.004401400650381\n 135.000000000000000\t68.685581154790029     0.004401400650381\n 135.000000000000000   111.314418845209985     0.004401400650381\n-135.000000000000000\t68.685581154790029     0.004401400650381\n-135.000000000000000   111.314418845209985     0.004401400650381\n  28.889424740291254\t48.796111385350962     0.004401400650381\n -28.889424740291254\t48.796111385350962     0.004401400650381\n  28.889424740291254   131.203888614649060     0.004401400650381\n -28.889424740291254   131.203888614649060     0.004401400650381\n 151.110575259708753\t48.796111385350962     0.004401400650381\n-151.110575259708753\t48.796111385350962     0.004401400650381\n 151.110575259708753   131.203888614649060     0.004401400650381\n-151.110575259708753   131.203888614649060     0.004401400650381\n  61.110575259708753\t48.796111385350962     0.004401400650381\n 118.889424740291247\t48.796111385350962     0.004401400650381\n  61.110575259708753   131.203888614649060     0.004401400650381\n 118.889424740291247   131.203888614649060     0.004401400650381\n -61.110575259708753\t48.796111385350962     0.004401400650381\n-118.889424740291247\t48.796111385350962     0.004401400650381\n -61.110575259708753   131.203888614649060     0.004401400650381\n-118.889424740291247   131.203888614649060     0.004401400650381\n  45.000000000000000\t 3.274152069216487     0.017245443505444\n  45.000000000000000   176.725847930783516     0.017245443505444\n -45.000000000000000\t 3.274152069216487     0.017245443505444\n -45.000000000000000   176.725847930783516     0.017245443505444\n 135.000000000000000\t 3.274152069216487     0.017245443505444\n 135.000000000000000   176.725847930783516     0.017245443505444\n-135.000000000000000\t 3.274152069216487     0.017245443505444\n-135.000000000000000   176.725847930783516     0.017245443505444\n  87.683564415961172\t87.685455250362111     0.017245443505444\n -87.683564415961172\t87.685455250362111     0.017245443505444\n  87.683564415961172\t92.314544749637903     0.017245443505444\n -87.683564415961172\t92.314544749637903     0.017245443505444\n  92.316435584038842\t87.685455250362111     0.017245443505444\n -92.316435584038842\t87.685455250362111     0.017245443505444\n  92.316435584038842\t92.314544749637903     0.017245443505444\n -92.316435584038842\t92.314544749637903     0.017245443505444\n   2.316435584038771\t87.685455250362111     0.017245443505444\n 177.683564415961257\t87.685455250362111     0.017245443505444\n   2.316435584038771\t92.314544749637903     0.017245443505444\n 177.683564415961257\t92.314544749637903     0.017245443505444\n  -2.316435584038771\t87.685455250362111     0.017245443505444\n-177.683564415961257\t87.685455250362111     0.017245443505444\n  -2.316435584038771\t92.314544749637903     0.017245443505444\n-177.683564415961257\t92.314544749637903     0.017245443505444\n  54.381587934584054\t90.000000000000000     0.004231083095357\n -54.381587934584054\t90.000000000000000     0.004231083095357\n 125.618412065415953\t90.000000000000000     0.004231083095357\n-125.618412065415953\t90.000000000000000     0.004231083095357\n  35.618412065415953\t90.000000000000000     0.004231083095357\n -35.618412065415953\t90.000000000000000     0.004231083095357\n 144.381587934584047\t90.000000000000000     0.004231083095357\n-144.381587934584047\t90.000000000000000     0.004231083095357\n   0.000000000000000\t35.618412065415953     0.004231083095357\n   0.000000000000000   144.381587934584047     0.004231083095357\n 180.000000000000000\t35.618412065415953     0.004231083095357\n 180.000000000000000   144.381587934584047     0.004231083095357\n   0.000000000000000\t54.381587934584054     0.004231083095357\n   0.000000000000000   125.618412065415953     0.004231083095357\n 180.000000000000000\t54.381587934584054     0.004231083095357\n 180.000000000000000   125.618412065415953     0.004231083095357\n  90.000000000000000\t35.618412065415953     0.004231083095357\n  90.000000000000000   144.381587934584047     0.004231083095357\n -90.000000000000000\t35.618412065415953     0.004231083095357\n -90.000000000000000   144.381587934584047     0.004231083095357\n  90.000000000000000\t54.381587934584054     0.004231083095357\n  90.000000000000000   125.618412065415953     0.004231083095357\n -90.000000000000000\t54.381587934584054     0.004231083095357\n -90.000000000000000   125.618412065415953     0.004231083095357\n  69.231820019013028\t90.000000000000000     0.005198069864064\n -69.231820019013028\t90.000000000000000     0.005198069864064\n 110.768179980986986\t90.000000000000000     0.005198069864064\n-110.768179980986986\t90.000000000000000     0.005198069864064\n  20.768179980986979\t90.000000000000000     0.005198069864064\n -20.768179980986979\t90.000000000000000     0.005198069864064\n 159.231820019013014\t90.000000000000000     0.005198069864064\n-159.231820019013014\t90.000000000000000     0.005198069864064\n   0.000000000000000\t20.768179980986979     0.005198069864064\n   0.000000000000000   159.231820019013014     0.005198069864064\n 180.000000000000000\t20.768179980986979     0.005198069864064\n 180.000000000000000   159.231820019013014     0.005198069864064\n   0.000000000000000\t69.231820019013028     0.005198069864064\n   0.000000000000000   110.768179980986986     0.005198069864064\n 180.000000000000000\t69.231820019013028     0.005198069864064\n 180.000000000000000   110.768179980986986     0.005198069864064\n  90.000000000000000\t20.768179980986979     0.005198069864064\n  90.000000000000000   159.231820019013014     0.005198069864064\n -90.000000000000000\t20.768179980986979     0.005198069864064\n -90.000000000000000   159.231820019013014     0.005198069864064\n  90.000000000000000\t69.231820019013028     0.005198069864064\n  90.000000000000000   110.768179980986986     0.005198069864064\n -90.000000000000000\t69.231820019013028     0.005198069864064\n -90.000000000000000   110.768179980986986     0.005198069864064\n  64.963704081332708\t32.473856655655446     0.004695720972569\n  64.963704081332708   147.526143344344547     0.004695720972569\n -64.963704081332708\t32.473856655655446     0.004695720972569\n -64.963704081332708   147.526143344344547     0.004695720972569\n 115.036295918667292\t32.473856655655446     0.004695720972569\n 115.036295918667292   147.526143344344547     0.004695720972569\n-115.036295918667292\t32.473856655655446     0.004695720972569\n-115.036295918667292   147.526143344344547     0.004695720972569\n  74.926112157973748\t60.891424466952714     0.004695720972569\n  74.926112157973748   119.108575533047286     0.004695720972569\n -74.926112157973748\t60.891424466952714     0.004695720972569\n -74.926112157973748   119.108575533047286     0.004695720972569\n 105.073887842026252\t60.891424466952714     0.004695720972569\n 105.073887842026252   119.108575533047286     0.004695720972569\n-105.073887842026252\t60.891424466952714     0.004695720972569\n-105.073887842026252   119.108575533047286     0.004695720972569\n  25.036295918667289\t32.473856655655446     0.004695720972569\n  25.036295918667289   147.526143344344547     0.004695720972569\n -25.036295918667289\t32.473856655655446     0.004695720972569\n -25.036295918667289   147.526143344344547     0.004695720972569\n 154.963704081332708\t32.473856655655446     0.004695720972569\n 154.963704081332708   147.526143344344547     0.004695720972569\n-154.963704081332708\t32.473856655655446     0.004695720972569\n-154.963704081332708   147.526143344344547     0.004695720972569\n  60.030959593932515\t76.866650451671518     0.004695720972569\n  60.030959593932515   103.133349548328482     0.004695720972569\n -60.030959593932515\t76.866650451671518     0.004695720972569\n -60.030959593932515   103.133349548328482     0.004695720972569\n 119.969040406067492\t76.866650451671518     0.004695720972569\n 119.969040406067492   103.133349548328482     0.004695720972569\n-119.969040406067492\t76.866650451671518     0.004695720972569\n-119.969040406067492   103.133349548328482     0.004695720972569\n  15.073887842026251\t60.891424466952714     0.004695720972569\n  15.073887842026251   119.108575533047286     0.004695720972569\n -15.073887842026251\t60.891424466952714     0.004695720972569\n -15.073887842026251   119.108575533047286     0.004695720972569\n 164.926112157973762\t60.891424466952714     0.004695720972569\n 164.926112157973762   119.108575533047286     0.004695720972569\n-164.926112157973762\t60.891424466952714     0.004695720972569\n-164.926112157973762   119.108575533047286     0.004695720972569\n  29.969040406067499\t76.866650451671518     0.004695720972569\n  29.969040406067499   103.133349548328482     0.004695720972569\n -29.969040406067499\t76.866650451671518     0.004695720972569\n -29.969040406067499   103.133349548328482     0.004695720972569\n 150.030959593932522\t76.866650451671518     0.004695720972569\n 150.030959593932522   103.133349548328482     0.004695720972569\n-150.030959593932522\t76.866650451671518     0.004695720972569\n-150.030959593932522   103.133349548328482     0.004695720972569",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2015-08-02T15:49:19",
        "author": "Amy Teegarden"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44404349/pyqt-showing-video-stream-from-opencv",
    "title": "PyQt showing video stream from opencv",
    "question_id": 44404349,
    "posted_date": "2017-06-07T01:39:40",
    "answers": [
      {
        "answer_id": 44404713,
        "body": "import cv2\nimport sys\nfrom PyQt5.QtWidgets import  QWidget, QLabel, QApplication\nfrom PyQt5.QtCore import QThread, Qt, pyqtSignal, pyqtSlot\nfrom PyQt5.QtGui import QImage, QPixmap\n\nclass Thread(QThread):\n    changePixmap = pyqtSignal(QImage)\n    def run(self):\n        cap = cv2.VideoCapture(0)\n        while True:\n            ret, frame = cap.read()\n            if ret:\n                # https://stackoverflow.com/a/55468544/6622587\n                rgbImage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                h, w, ch = rgbImage.shape\n                bytesPerLine = ch * w\n                convertToQtFormat = QImage(rgbImage.data, w, h, bytesPerLine, QImage.Format_RGB888)\n                p = convertToQtFormat.scaled(640, 480, Qt.KeepAspectRatio)\n                self.changePixmap.emit(p)\nclass App(QWidget):\n    def __init__(self):\n        super().__init__()\n        [...]\n        self.initUI()\n    @pyqtSlot(QImage)\n    def setImage(self, image):\n        self.label.setPixmap(QPixmap.fromImage(image))\n    def initUI(self):\n        self.setWindowTitle(self.title)\n        self.setGeometry(self.left, self.top, self.width, self.height)\n        self.resize(1800, 1200)\n        # create a label\n        self.label = QLabel(self)\n        self.label.move(280, 120)\n        self.label.resize(640, 480)\n        th = Thread(self)\n        th.changePixmap.connect(self.setImage)\n        th.start()\n        self.show()",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2017-06-07T02:05:29",
        "author": "eyllanesc"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64116781/how-do-i-automerge-dependabot-updates-config-version-2",
    "title": "How do I automerge dependabot updates (config version 2)?",
    "question_id": 64116781,
    "posted_date": "2020-09-29T05:31:42",
    "answers": [
      {
        "answer_id": 68365564,
        "body": "name: Dependabot auto-approve\non: pull_request_target\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  dependabot:\n    runs-on: ubuntu-latest\n    if: ${{ github.actor == 'dependabot[bot]' }}\n    steps:\n      - name: Dependabot metadata\n        id: metadata\n        uses: dependabot/fetch-metadata@v1.1.1\n        with:\n          github-token: \"${{ secrets.GITHUB_TOKEN }}\"\n      - name: Enable auto-merge for Dependabot PRs\n        if: ${{contains(steps.metadata.outputs.dependency-names, 'my-dependency') && steps.metadata.outputs.update-type == 'version-update:semver-patch'}}\n        run: gh pr merge --auto --merge \"$PR_URL\"\n        env:\n          PR_URL: ${{github.event.pull_request.html_url}}\n          GITHUB_TOKEN: ${{secrets.GITHUB_TOKEN}}",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2021-07-13T11:42:22",
        "author": "kojiro"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61706535/keras-validation-loss-and-accuracy-stuck-at-0",
    "title": "Keras - Validation Loss and Accuracy stuck at 0",
    "question_id": 61706535,
    "posted_date": "2020-05-09T22:46:16",
    "answers": [
      {
        "answer_id": 61707324,
        "body": "model.fit(X_train, y_train, validation_data=[X_train.to_numpy(), y_train.to_numpy()],\nepochs=10, batch_size=64)\nEpoch 1/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.7898 - accuracy: 0.6087 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 2/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.6500 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 3/10\n8/8 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6500 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 4/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6716 - accuracy: 0.6370 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 5/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.6326 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 6/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.6326 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 7/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.6522 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 8/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.6109 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 9/10\n8/8 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.6717 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\nEpoch 10/10\n8/8 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.6652 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2020-05-10T00:49:21",
        "author": "Zabir Al Nazi Nabil"
      },
      {
        "answer_id": 61707324,
        "body": "...\n...\n        # Run validation.\n        if validation_data and self._should_eval(epoch, validation_freq):\n          val_x, val_y, val_sample_weight = (\n              data_adapter.unpack_x_y_sample_weight(validation_data))\n          val_logs = self.evaluate(\n              x=val_x,\n              y=val_y,\n              sample_weight=val_sample_weight,\n              batch_size=validation_batch_size or batch_size,\n              steps=validation_steps,\n              callbacks=callbacks,\n              max_queue_size=max_queue_size,\n              workers=workers,\n              use_multiprocessing=use_multiprocessing,\n              return_dict=True)\n          val_logs = {'val_' + name: val for name, val in val_logs.items()}\n          epoch_logs.update(val_logs)",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2020-05-10T00:49:21",
        "author": "Zabir Al Nazi Nabil"
      },
      {
        "answer_id": 61707324,
        "body": "model.fit(X_train, y_train, validation_data=(X_train.to_numpy(), y_train.to_numpy()),\nepochs=10, batch_size=64)\nEpoch 1/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.5832 - accuracy: 0.6696 - val_loss: 0.6892 - val_accuracy: 0.6674\nEpoch 2/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.6385 - accuracy: 0.6804 - val_loss: 0.8984 - val_accuracy: 0.5565\nEpoch 3/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.6822 - accuracy: 0.6391 - val_loss: 0.6556 - val_accuracy: 0.6739\nEpoch 4/10\n8/8 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.6609 - val_loss: 1.0691 - val_accuracy: 0.5630\nEpoch 5/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.7048 - accuracy: 0.6239 - val_loss: 0.6474 - val_accuracy: 0.6326\nEpoch 6/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6500 - val_loss: 0.6659 - val_accuracy: 0.6043\nEpoch 7/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.5796 - accuracy: 0.6913 - val_loss: 0.6891 - val_accuracy: 0.6435\nEpoch 8/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.6891 - val_loss: 0.5307 - val_accuracy: 0.7152\nEpoch 9/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.5571 - accuracy: 0.7000 - val_loss: 0.5465 - val_accuracy: 0.6957\nEpoch 10/10\n8/8 [==============================] - 0s 7ms/step - loss: 0.7133 - accuracy: 0.6283 - val_loss: 0.7046 - val_accuracy: 0.6413",
        "score": 39,
        "is_accepted": true,
        "creation_date": "2020-05-10T00:49:21",
        "author": "Zabir Al Nazi Nabil"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50308812/is-it-possible-to-limit-the-number-of-coroutines-running-corcurrently-in-asyncio",
    "title": "Is it possible to limit the number of coroutines running corcurrently in asyncio?",
    "question_id": 50308812,
    "posted_date": "2018-05-12T13:14:06",
    "answers": [
      {
        "answer_id": 60004447,
        "body": "import asyncio\nasync def semaphore_gather(num, coros, return_exceptions=False):\n    semaphore = asyncio.Semaphore(num)\n    async def _wrap_coro(coro):\n        async with semaphore:\n            return await coro\n    return await asyncio.gather(\n        *(_wrap_coro(coro) for coro in coros), return_exceptions=return_exceptions\n    )\n# async def a():\n#     return 1\n# print(asyncio.run(semaphore_gather(10, [a() for _ in range(100)])))\n# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-01-31T07:59:43",
        "author": "ddelange"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71938799/python-asyncio-create-task-really-need-to-keep-a-reference",
    "title": "Python asyncio.create_task() - really need to keep a reference?",
    "question_id": 71938799,
    "posted_date": "2022-04-20T07:25:43",
    "answers": [
      {
        "answer_id": 76823668,
        "body": "import asyncio\nimport gc\nasync def coro1():\n    while True:\n        print(\"just printing...\")\n        await asyncio.sleep(1)\n        gc.collect()\nasync def coro2():\n    loop = asyncio.get_running_loop()\n    f = loop.create_future()\n    print(\"inside coro2 - going to wait for future\")\n    await f\n    print(\"inside coro2 - future resolved\")\nasync def main():\n    t1 = asyncio.create_task(coro1()) # This task has a reference.\n    asyncio.create_task(coro2())      # This task doesn't.\n    await asyncio.sleep(5)\nasyncio.run(main())",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2023-08-02T17:31:41",
        "author": "S.B"
      },
      {
        "answer_id": 76823668,
        "body": "import asyncio\nimport socket\nimport gc\nasync def echo(connection, loop):\n    while data := await loop.sock_recv(connection, 512):\n        gc.collect()\n        await loop.sock_sendall(connection, data)\nasync def listen_for_connections(server_socket, loop):\n    while True:\n        gc.collect()\n        client_socket, client_address = await loop.sock_accept(server_socket)\n        client_socket.setblocking(False)\n        print(f\"received a connection from {client_address}\")\n        asyncio.create_task(echo(client_socket, loop))  # no reference to this task\nasync def main():\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_address = (\"127.0.0.1\", 8000)\n    server_socket.setblocking(False)\n    server_socket.bind(server_address)\n    server_socket.listen()\n    await listen_for_connections(server_socket, asyncio.get_running_loop())\nasyncio.run(main())",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2023-08-02T17:31:41",
        "author": "S.B"
      },
      {
        "answer_id": 76823668,
        "body": "async def sleep(delay, result=None):\n    \"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\n    if delay <= 0:\n        await __sleep0()\n        return result\n    ### Reaching this line means the `delay` is a positive integer\n    loop = events.get_running_loop()\n    future = loop.create_future()\n    h = loop.call_later(delay,        # <------------\n                        futures._set_result_unless_cancelled,\n                        future, result)\n    try:\n        return await future\n    finally:\n        h.cancel()",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2023-08-02T17:31:41",
        "author": "S.B"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64234214/how-to-generate-a-blob-signed-url-in-google-cloud-run",
    "title": "How to generate a Blob signed url in Google Cloud Run?",
    "question_id": 64234214,
    "posted_date": "2020-10-06T17:43:38",
    "answers": [
      {
        "answer_id": 64245028,
        "body": "def sign_url():\n    from google.cloud import storage\n    from datetime import datetime, timedelta\n    import google.auth\n    credentials, project_id = google.auth.default()\n    # Perform a refresh request to get the access token of the current credentials (Else, it's None)\n    from google.auth.transport import requests\n    r = requests.Request()\n    credentials.refresh(r)\n    client = storage.Client()\n    bucket = client.get_bucket('EXAMPLE_BUCKET')\n    blob = bucket.get_blob('libraries/image_1.png')\n    expires = datetime.now() + timedelta(seconds=86400)\n    # In case of user credential use, define manually the service account to use (for development purpose only)\n    service_account_email = \"YOUR DEV SERVICE ACCOUNT\"\n    # If you use a service account credential, you can use the embedded email\n    if hasattr(credentials, \"service_account_email\"):\n        service_account_email = credentials.service_account_email\n    url = blob.generate_signed_url(expiration=expires,service_account_email=service_account_email, access_token=credentials.token)\n    return url, 200",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2020-10-07T09:27:37",
        "author": "guillaume blaquiere"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62398231/building-docs-fails-due-to-missing-pandoc",
    "title": "Building docs fails due to missing pandoc",
    "question_id": 62398231,
    "posted_date": "2020-06-15T18:46:43",
    "answers": [
      {
        "answer_id": 71585691,
        "body": "from inspect import getsourcefile\n# Get path to directory containing this file, conf.py.\nDOCS_DIRECTORY = os.path.dirname(os.path.abspath(getsourcefile(lambda: 0)))\ndef ensure_pandoc_installed(_):\n    import pypandoc\n    # Download pandoc if necessary. If pandoc is already installed and on\n    # the PATH, the installed version will be used. Otherwise, we will\n    # download a copy of pandoc into docs/bin/ and add that to our PATH.\n    pandoc_dir = os.path.join(DOCS_DIRECTORY, \"bin\")\n    # Add dir containing pandoc binary to the PATH environment variable\n    if pandoc_dir not in os.environ[\"PATH\"].split(os.pathsep):\n        os.environ[\"PATH\"] += os.pathsep + pandoc_dir\n    pypandoc.ensure_pandoc_installed(\n        quiet=True,\n        targetfolder=pandoc_dir,\n        delete_installer=True,\n    )\ndef setup(app):\n    app.connect(\"builder-inited\", ensure_pandoc_installed)",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2022-03-23T06:36:10",
        "author": "scottclowe"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58562928/how-do-i-update-a-python-virtual-environment-with-venv-in-python-3-3-to-use",
    "title": "How do I update a Python virtual environment with `venv` (in Python 3.3+) to use a newer version of Python?",
    "question_id": 58562928,
    "posted_date": "2019-10-25T13:10:53",
    "answers": [
      {
        "answer_id": 58563033,
        "body": "python -m venv --help\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n            [--upgrade] [--without-pip] [--prompt PROMPT]\n            ENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories.\npositional arguments:\n  ENV_DIR               A directory to create the environment in.\noptional arguments:\n  -h, --help            show this help message and exit\n  --system-site-packages\n                        Give the virtual environment access to the system\n                        site-packages dir.\n  --symlinks            Try to use symlinks rather than copies, when symlinks\n                        are not the default for the platform.\n  --copies              Try to use copies rather than symlinks, even when\n                        symlinks are the default for the platform.\n  --clear               Delete the contents of the environment directory if it\n                        already exists, before environment creation.\n  --upgrade             Upgrade the environment directory to use this version\n                        of Python, assuming Python has been upgraded in-place.\n  --without-pip         Skips installing or upgrading pip in the virtual\n                        environment (pip is bootstrapped by default)\n  --prompt PROMPT       Provides an alternative prompt prefix for this\n                        environment.",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2019-10-25T13:19:51",
        "author": "RMPR"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56656493/what-is-the-difference-between-anaconda-prompt-and-anaconda-powershell-prompt",
    "title": "What is the difference between Anaconda Prompt and Anaconda Powershell Prompt?",
    "question_id": 56656493,
    "posted_date": "2019-06-18T16:18:49",
    "answers": [
      {
        "answer_id": 61766951,
        "body": "> $PSVersionTable\nName                           Value\n----                           -----\nPSVersion                      5.1.18362.752\nPSEdition                      Desktop\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0...}\nBuildVersion                   10.0.18362.752\nCLRVersion                     4.0.30319.42000\nWSManStackVersion              3.0\nPSRemotingProtocolVersion      2.3\nSerializationVersion           1.1.0.1\n> $env:PATH\nC:\\Users\\user-name\\anaconda3;C:\\Users\\user-name\\anaconda3\\Library\\mingw-w64\\bin;...",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2020-05-13T01:17:14",
        "author": "YaOzI"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/28680896/how-can-i-get-the-3rd-friday-of-a-month-in-python",
    "title": "How can I get the 3rd Friday of a month in Python?",
    "question_id": 28680896,
    "posted_date": "2015-02-23T13:36:45",
    "answers": [
      {
        "answer_id": 61215390,
        "body": "import pandas as pd\npd.date_range('2017-12-02','2020-08-31',freq='WOM-3FRI')\nOutput:\nDatetimeIndex(['2017-12-15', '2018-01-19', '2018-02-16', '2018-03-16',\n               '2018-04-20', '2018-05-18', '2018-06-15', '2018-07-20',\n               '2018-08-17', '2018-09-21', '2018-10-19', '2018-11-16',\n               '2018-12-21', '2019-01-18', '2019-02-15', '2019-03-15',\n               '2019-04-19', '2019-05-17', '2019-06-21', '2019-07-19',\n               '2019-08-16', '2019-09-20', '2019-10-18', '2019-11-15',\n               '2019-12-20', '2020-01-17', '2020-02-21', '2020-03-20',\n               '2020-04-17', '2020-05-15', '2020-06-19', '2020-07-17',\n               '2020-08-21'],\n              dtype='datetime64[ns]', freq='WOM-3FRI')",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2020-04-14T15:11:47",
        "author": "J Chow"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69796358/repeating-triangle-pattern-in-python",
    "title": "Repeating triangle pattern in Python",
    "question_id": 69796358,
    "posted_date": "2021-11-01T07:33:41",
    "answers": [
      {
        "answer_id": 69796943,
        "body": "                        *\n                       ***\n                      *****\n                     *******\n                 *      *      *\n                ***    ***    ***\n               *****  *****  *****\n              *********************\n          *      *      *      *      *\n         ***    ***    ***    ***    ***\n        *****  *****  *****  *****  *****\n       ***********************************\n   *      *      *      *      *      *      *\n  ***    ***    ***    ***    ***    ***    ***\n *****  *****  *****  *****  *****  *****  *****\n*************************************************",
        "score": 55,
        "is_accepted": true,
        "creation_date": "2021-11-01T08:28:18",
        "author": "Troll"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67887138/how-to-install-packages-in-airflow-docker-compose",
    "title": "How to install packages in Airflow (docker-compose)?",
    "question_id": 67887138,
    "posted_date": "2021-06-08T08:38:58",
    "answers": [
      {
        "answer_id": 67890645,
        "body": "version: '3'\nx-airflow-common:\n  &airflow-common\n  build: .\n  # REPLACED # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.1.0}\n  environment:\n    &airflow-common-env\n    AIRFLOW__CORE__EXECUTOR: CeleryExecutor\n    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow\n    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow\n    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0\n    AIRFLOW__CORE__FERNET_KEY: ''\n    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'\n    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'\n    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'\n  volumes:\n    - ./dags:/opt/airflow/dags\n    - ./logs:/opt/airflow/logs\n    - ./plugins:/opt/airflow/plugins\n  user: \"${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}\"\n  depends_on:\n    redis:\n      condition: service_healthy\n    postgres:\n      condition: service_healthy\n# ...",
        "score": 54,
        "is_accepted": false,
        "creation_date": "2021-06-08T12:05:43",
        "author": "Makrushin Evgenii"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55169952/delete-all-items-dynamodb-using-python",
    "title": "delete all items DynamoDB using Python",
    "question_id": 55169952,
    "posted_date": "2019-03-14T14:46:22",
    "answers": [
      {
        "answer_id": 61641766,
        "body": "import boto3\ndynamo = boto3.resource('dynamodb')\ndef truncateTable(tableName):\n    table = dynamo.Table(tableName)\n\n    #get the table keys\n    tableKeyNames = [key.get(\"AttributeName\") for key in table.key_schema]\n    #Only retrieve the keys for each item in the table (minimize data transfer)\n    projectionExpression = \", \".join('#' + key for key in tableKeyNames)\n    expressionAttrNames = {'#'+key: key for key in tableKeyNames}\n\n    counter = 0\n    page = table.scan(ProjectionExpression=projectionExpression, ExpressionAttributeNames=expressionAttrNames)\n    with table.batch_writer() as batch:\n        while page[\"Count\"] > 0:\n            counter += page[\"Count\"]\n            # Delete items in batches\n            for itemKeys in page[\"Items\"]:\n                batch.delete_item(Key=itemKeys)\n            # Fetch the next page\n            if 'LastEvaluatedKey' in page:\n                page = table.scan(\n                    ProjectionExpression=projectionExpression, ExpressionAttributeNames=expressionAttrNames,\n                    ExclusiveStartKey=page['LastEvaluatedKey'])\n            else:\n                break\n    print(f\"Deleted {counter}\")\n\ntruncateTable(\"YOUR_TABLE_NAME\")",
        "score": 39,
        "is_accepted": false,
        "creation_date": "2020-05-06T13:46:40",
        "author": "Ethan Harris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62994795/how-to-secure-fastapi-api-endpoint-with-jwt-token-based-authorization",
    "title": "How to secure fastapi API endpoint with JWT Token based authorization?",
    "question_id": 62994795,
    "posted_date": "2020-07-20T07:52:09",
    "answers": [
      {
        "answer_id": 65999655,
        "body": "# dependency.py script\nfrom jose import jwt\nfrom jose.exceptions import JOSEError\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPAuthorizationCredentials, HTTPBearer\nsecurity = HTTPBearer()\nasync def has_access(credentials: HTTPAuthorizationCredentials= Depends(security)):\n    \"\"\"\n        Function that is used to validate the token in the case that it requires it\n    \"\"\"\n    token = credentials.credentials\n    try:\n        payload = jwt.decode(token, key='secret', options={\"verify_signature\": False,\n                                                           \"verify_aud\": False,\n                                                           \"verify_iss\": False})\n        print(\"payload => \", payload)\n    except JOSEError as e:  # catches any exception\n        raise HTTPException(\n            status_code=401,\n            detail=str(e))",
        "score": 47,
        "is_accepted": false,
        "creation_date": "2021-02-01T15:25:05",
        "author": "onofricamila"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59330863/cant-import-dll-module-in-python",
    "title": "Can&#39;t import dll module in Python",
    "question_id": 59330863,
    "posted_date": "2019-12-13T18:06:08",
    "answers": [
      {
        "answer_id": 59333711,
        "body": "    #!/usr/bin/env python\n    import argparse\n    import ctypes as cts\n    import os\n    import sys\n    DLL_NAME = \"./dll00.{:s}\".format(\"dll\" if sys.platform[:3].lower() == \"win\" else \"so\")\n    METH_ADDLLDIR = \"a\"\n    METH_PATH = \"p\"\n    METHS = (\n        METH_ADDLLDIR,\n        METH_PATH,\n    )\n    def parse_args(*argv):\n        parser = argparse.ArgumentParser(description=\"Python .dll search path (Win) example\")\n        parser.add_argument(\"--path\", \"-p\", choices=METHS)\n        parser.add_argument(\"--winmode\", \"-w\", type=int)\n        args, unk = parser.parse_known_args()\n        if unk:\n            print(\"Warning: Ignoring unknown arguments: {:}\".format(unk))\n        return args.path, args.winmode\n    def main(*argv):\n        meth, wmod = parse_args()\n        print(\"PATH (original): {:}\\n\".format(os.environ.get(\"PATH\")))\n        print(\"Using winmode={:}\".format(wmod))\n        if meth is not None:\n            subdir = os.path.join(os.path.abspath(os.path.dirname(__file__)), \"subdir00\")\n            if meth == METH_ADDLLDIR:\n                add_dll_directory = getattr(os, \"add_dll_directory\", None)\n                if add_dll_directory:\n                    os.add_dll_directory(subdir)\n                    print(\"Using AddDllDirectory()\\n\")\n            elif meth == METH_PATH:\n                os.environ[\"PATH\"] = os.pathsep.join((os.environ.get(\"PATH\", \"\"), subdir))\n                print(\"Using %PATH%\\n\")\n        dll00 = cts.CDLL(DLL_NAME, winmode=wmod)\n        print(\"Dll: {:}\".format(dll00))\n        if False:  # No need to actually call the function\n            dll00Func00 = dll00.dll00Func00\n            dll00Func00.argtypes = ()\n            dll00Func00.restype = cts.c_int\n            res = dll00Func00()\n            print(\"\\n{0:s} returned: {1:d}\".format(dll00Func00.__name__, res))\n    if __name__ == \"__main__\":\n        print(\"Python {:s} {:03d}bit on {:s}\\n\".format(\" \".join(elem.strip() for elem in sys.version.split(\"\\n\")),\n                                                       64 if sys.maxsize > 0x100000000 else 32, sys.platform))\n        rc = main(*sys.argv[1:])\n        print(\"\\nDone.\\n\")\n        sys.exit(rc)",
        "score": 29,
        "is_accepted": false,
        "creation_date": "2019-12-14T04:03:34",
        "author": "CristiFati"
      },
      {
        "answer_id": 59333711,
        "body": ">    [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackOverflow\\q059330863]> sopr.bat\n>    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n>\n>    [prompt]> \"c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64 > nul\n>\n>    [prompt]> tree /a /f\n>    Folder PATH listing for volume SSD0-WORK\n>    Volume serial number is AE9E-72AC\n>    E:.\n>    |   code00.py\n>    |   dll00.c\n>    |   dll01.c\n>    |   test.bat\n>    |\n>    \\---subdir00\n>\n>    [prompt]> :: Build .dlls\n>    [prompt]> cl /nologo /DDLL /MD dll01.c  /link /NOLOGO /DLL /OUT:subdir00\\dll01.dll\n>    dll01.c\n>       Creating library subdir00\\dll01.lib and object subdir00\\dll01.exp\n>\n>    [prompt]>\n>    [prompt]> cl /nologo /DDLL /MD dll00.c  /link /NOLOGO /DLL /OUT:dll00.dll subdir00\\dll01.lib\n>    dll00.c\n>       Creating library dll00.lib and object dll00.exp\n>\n>    [prompt]>\n>    [prompt]> tree /a /f\n>    Folder PATH listing for volume SSD0-WORK\n>    Volume serial number is AE9E-72AC\n>    E:.\n>    |   code00.py\n>    |   dll00.c\n>    |   dll00.dll\n>    |   dll00.exp\n>    |   dll00.lib\n>    |   dll00.obj\n>    |   dll01.c\n>    |   dll01.obj\n>    |   test.bat\n>    |\n>    \\---subdir00\n>            dll01.dll\n>            dll01.exp\n>            dll01.lib\n>\n>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -h\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    usage: code00.py [-h] [--path {a,p}] [--winmode WINMODE]\n>\n>    Python .dll search path (Win) example\n>\n>    options:\n>      -h, --help            show this help message and exit\n>      --path {a,p}, -p {a,p}\n>      --winmode WINMODE, -w WINMODE\n>\n>    [prompt]>\n>    [prompt]> :: Going through combinations. When an argument is not passed, its default value is None\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=None\n>    Traceback (most recent call last):\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 57, in <module>\n>        rc = main(*sys.argv[1:])\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 44, in main\n>        dll00 = cts.CDLL(DLL_NAME, winmode=wmod)\n>      File \"c:\\Install\\pc064\\Python\\Python\\03.10\\lib\\ctypes\\__init__.py\", line 374, in __init__\n>        self._handle = _dlopen(self._name, mode)\n>    FileNotFoundError: Could not find module 'e:\\Work\\Dev\\StackOverflow\\q059330863\\dll00.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -w 0\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=0\n>    Traceback (most recent call last):\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 57, in <module>\n>        rc = main(*sys.argv[1:])\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 44, in main\n>        dll00 = cts.CDLL(DLL_NAME, winmode=wmod)\n>      File \"c:\\Install\\pc064\\Python\\Python\\03.10\\lib\\ctypes\\__init__.py\", line 374, in __init__\n>        self._handle = _dlopen(self._name, mode)\n>    FileNotFoundError: Could not find module './dll00.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n>\n>    [prompt]>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -p a\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=None\n>    Using AddDllDirectory()\n>\n>    Dll: <CDLL 'e:\\Work\\Dev\\StackOverflow\\q059330863\\dll00.dll', handle 7ffe6aaf0000 at 0x1f896d9ffd0>\n>\n>    Done.\n>\n>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -p a -w 0\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=0\n>    Using AddDllDirectory()\n>\n>    Traceback (most recent call last):\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 57, in <module>\n>        rc = main(*sys.argv[1:])\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 44, in main\n>        dll00 = cts.CDLL(DLL_NAME, winmode=wmod)\n>      File \"c:\\Install\\pc064\\Python\\Python\\03.10\\lib\\ctypes\\__init__.py\", line 374, in __init__\n>        self._handle = _dlopen(self._name, mode)\n>    FileNotFoundError: Could not find module './dll00.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n>\n>    [prompt]>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -p p\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=None\n>    Using %PATH%\n>\n>    Traceback (most recent call last):\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 57, in <module>\n>        rc = main(*sys.argv[1:])\n>      File \"e:\\Work\\Dev\\StackOverflow\\q059330863\\code00.py\", line 44, in main\n>        dll00 = cts.CDLL(DLL_NAME, winmode=wmod)\n>      File \"c:\\Install\\pc064\\Python\\Python\\03.10\\lib\\ctypes\\__init__.py\", line 374, in __init__\n>        self._handle = _dlopen(self._name, mode)\n>    FileNotFoundError: Could not find module 'e:\\Work\\Dev\\StackOverflow\\q059330863\\dll00.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n>\n>    [prompt]>\n>    [prompt]> \"e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\\python.exe\" code00.py -p p -w 0\n>    Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] 064bit on win32\n>\n>    PATH (original): c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\VCPackages;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\MSBuild\\Current\\bin\\Roslyn;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4\n>    .8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.22000.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\Tools\\;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\dotnet\\;C:\\Users\\cfati\\AppData\\Local\\Programs\\Python\\Launcher\\;e:\\Work\\Dev\\Utils\\current\\Win;e:\\Work\\Dev\\VEnvs\\py_pc064_03.09_test0\\Scripts;C:\\Us\n>    ers\\cfati\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\cfati\\.dotnet\\tools;;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;c:\\Install\\pc032\\Microsoft\\VisualStudioCommunity\\2019\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\n>\n>    Using winmode=0\n>    Using %PATH%\n>\n>    Dll: <CDLL './dll00.dll', handle 7ffe6aaf0000 at 0x142a7a73cd0>\n>\n>    Done.\n>",
        "score": 29,
        "is_accepted": false,
        "creation_date": "2019-12-14T04:03:34",
        "author": "CristiFati"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29967487/get-progress-back-from-shutil-file-copy-thread",
    "title": "Get progress back from shutil file copy thread",
    "question_id": 29967487,
    "posted_date": "2015-04-30T08:13:09",
    "answers": [
      {
        "answer_id": 29967714,
        "body": "import os\nimport shutil\ndef copyfileobj(fsrc, fdst, callback, length=0):\n    try:\n        # check for optimisation opportunity\n        if \"b\" in fsrc.mode and \"b\" in fdst.mode and fsrc.readinto:\n            return _copyfileobj_readinto(fsrc, fdst, callback, length)\n    except AttributeError:\n        # one or both file objects do not support a .mode or .readinto attribute\n        pass\n    if not length:\n        length = shutil.COPY_BUFSIZE\n\n    fsrc_read = fsrc.read\n    fdst_write = fdst.write\n    copied = 0\n    while True:\n        buf = fsrc_read(length)\n        if not buf:\n            break\n        fdst_write(buf)\n        copied += len(buf)\n        callback(copied)\n# differs from shutil.COPY_BUFSIZE on platforms != Windows\nREADINTO_BUFSIZE = 1024 * 1024\ndef _copyfileobj_readinto(fsrc, fdst, callback, length=0):\n    \"\"\"readinto()/memoryview() based variant of copyfileobj().\n    *fsrc* must support readinto() method and both files must be\n    open in binary mode.\n    \"\"\"\n    fsrc_readinto = fsrc.readinto\n    fdst_write = fdst.write\n    if not length:\n        try:\n            file_size = os.stat(fsrc.fileno()).st_size\n        except OSError:\n            file_size = READINTO_BUFSIZE\n        length = min(file_size, READINTO_BUFSIZE)\n    copied = 0\n    with memoryview(bytearray(length)) as mv:\n        while True:\n            n = fsrc_readinto(mv)\n            if not n:\n                break\n            elif n < length:\n                with mv[:n] as smv:\n                    fdst.write(smv)\n            else:\n                fdst_write(mv)\n            copied += n\n            callback(copied)",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2015-04-30T08:24:37",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4699605/why-doesn-t-sqlite-require-a-commit-call-to-save-data",
    "title": "Why doesn\u2019t SQLite require a commit() call to save data?",
    "question_id": 4699605,
    "posted_date": "2011-01-15T07:36:08",
    "answers": [
      {
        "answer_id": 48391535,
        "body": "import sqlite3\nconnection = sqlite3.connect(':memory:', isolation_level='DEFERRED')\n# No transaction is explicitly initiated here by a start transaction statement.\nassert connection.in_transaction is False\nstatements = []\nconnection.set_trace_callback(statements.append)\ncursor = connection.cursor()\n# Transaction 1 is implicitly initiated here.\ncursor.execute('CREATE TABLE t (i INT)')\n# Transaction 1 is implicitly committed here.\n# Transaction 2 is explicitly initiated here by a start transaction statement.\ncursor.execute('INSERT INTO t VALUES (?)', (1,))\ncursor.execute('CREATE TABLE u (j INT)')\ncursor.execute('INSERT INTO u VALUES (?)', (2,))\ncursor.close()\nconnection.close()\n# Transaction 2 is implicitly rolled back here.\nassert statements == [\n    'CREATE TABLE t (i INT)',\n    'BEGIN DEFERRED',\n    'INSERT INTO t VALUES (1)',\n    'CREATE TABLE u (j INT)',\n    'INSERT INTO u VALUES (2)',\n]",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2018-01-22T17:51:01",
        "author": "G&#233;ry Ogam"
      },
      {
        "answer_id": 48391535,
        "body": "import sqlite3\nconnection = sqlite3.connect(':memory:', autocommit=False)\n# Transaction 1 is explicitly initiated here by a start transaction statement.\nassert connection.in_transaction is True\nstatements = []\nconnection.set_trace_callback(statements.append)\ncursor = connection.cursor()\ncursor.execute('CREATE TABLE t (i INT)')\ncursor.execute('INSERT INTO t VALUES (?)', (1,))\ncursor.execute('CREATE TABLE u (j INT)')\ncursor.execute('INSERT INTO u VALUES (?)', (2,))\ncursor.close()\nconnection.close()\n# Transaction 1 is explicitly rolled back here by a rollback statement.\nassert statements == [\n    'CREATE TABLE t (i INT)',\n    'INSERT INTO t VALUES (1)',\n    'CREATE TABLE u (j INT)',\n    'INSERT INTO u VALUES (2)',\n    'ROLLBACK',\n]",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2018-01-22T17:51:01",
        "author": "G&#233;ry Ogam"
      },
      {
        "answer_id": 48391535,
        "body": "import sqlite3\nconnection = sqlite3.connect(':memory:', isolation_level=None)\n# No transaction is explicitly initiated here by a start transaction statement.\nassert connection.in_transaction is False\nstatements = []\nconnection.set_trace_callback(statements.append)\ncursor = connection.cursor()\n# Transaction 1 is implicitly initiated here.\ncursor.execute('CREATE TABLE t (i INT)')\n# Transaction 1 is implicitly committed here.\n# Transaction 2 is implicitly initiated here.\ncursor.execute('INSERT INTO t VALUES (?)', (1,))\n# Transaction 2 is implicitly committed here.\n# Transaction 3 is implicitly initiated here.\ncursor.execute('CREATE TABLE u (j INT)')\n# Transaction 3 is implicitly committed here.\n# Transaction 4 is implicitly initiated here.\ncursor.execute('INSERT INTO u VALUES (?)', (2,))\n# Transaction 4 is implicitly committed here.\ncursor.close()\nconnection.close()\nassert statements == [\n    'CREATE TABLE t (i INT)',\n    'INSERT INTO t VALUES (1)',\n    'CREATE TABLE u (j INT)',\n    'INSERT INTO u VALUES (2)',\n]",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2018-01-22T17:51:01",
        "author": "G&#233;ry Ogam"
      },
      {
        "answer_id": 48391535,
        "body": "import sqlite3\nconnection = sqlite3.connect(':memory:', autocommit=True)\n# No transaction is explicitly initiated here by a start transaction statement.\nassert connection.in_transaction is False\nstatements = []\nconnection.set_trace_callback(statements.append)\ncursor = connection.cursor()\n# Transaction 1 is implicitly initiated here.\ncursor.execute('CREATE TABLE t (i INT)')\n# Transaction 1 is implicitly committed here.\n# Transaction 2 is implicitly initiated here.\ncursor.execute('INSERT INTO t VALUES (?)', (1,))\n# Transaction 2 is implicitly committed here.\n# Transaction 3 is implicitly initiated here.\ncursor.execute('CREATE TABLE u (j INT)')\n# Transaction 3 is implicitly committed here.\n# Transaction 4 is implicitly initiated here.\ncursor.execute('INSERT INTO u VALUES (?)', (2,))\n# Transaction 4 is implicitly committed here.\ncursor.close()\nconnection.close()\nassert statements == [\n    'CREATE TABLE t (i INT)',\n    'INSERT INTO t VALUES (1)',\n    'CREATE TABLE u (j INT)',\n    'INSERT INTO u VALUES (2)',\n]",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2018-01-22T17:51:01",
        "author": "G&#233;ry Ogam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model",
    "title": "Add dense layer on top of Huggingface BERT model",
    "question_id": 64156202,
    "posted_date": "2020-10-01T09:16:01",
    "answers": [
      {
        "answer_id": 64156912,
        "body": "from transformers import BertModel\nclass CustomBERTModel(nn.Module):\n    def __init__(self):\n          super(CustomBERTModel, self).__init__()\n          self.bert = BertModel.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\n          ### New layers:\n          self.linear1 = nn.Linear(768, 256)\n          self.linear2 = nn.Linear(256, 3) ## 3 is the number of classes in this example\n    def forward(self, ids, mask):\n          sequence_output, pooled_output = self.bert(\n               ids,\n               attention_mask=mask)\n          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n          linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n          linear2_output = self.linear2(linear1_output)\n          return linear2_output\ntokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\nmodel = CustomBERTModel() # You can pass the parameters if required to have more flexible model\nmodel.to(torch.device(\"cpu\")) ## can be gpu\ncriterion = nn.CrossEntropyLoss() ## If required define your own criterion\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\nfor epoch in epochs:\n    for batch in data_loader: ## If you have a DataLoader()  object to get the data.\n        data = batch[0]\n        targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n\n        optimizer.zero_grad()\n        encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        outputs = F.log_softmax(outputs, dim=1)\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2020-10-01T09:56:28",
        "author": "Ashwin Geet D&#39;Sa"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44467828/what-techniques-can-be-used-to-measure-performance-of-pandas-numpy-solutions",
    "title": "What techniques can be used to measure performance of pandas/numpy solutions",
    "question_id": 44467828,
    "posted_date": "2017-06-09T19:12:54",
    "answers": [
      {
        "answer_id": 56398618,
        "body": "           sum_pd    sum_fc    sum_nb\n16       0.000796  0.000515  0.000502\n32       0.000702  0.000453  0.000454\n64       0.000702  0.000454  0.000456\n128      0.000711  0.000456  0.000458\n256      0.000714  0.000461  0.000462\n512      0.000728  0.000471  0.000473\n1024     0.000746  0.000512  0.000513\n2048     0.000825  0.000515  0.000514\n4096     0.000902  0.000609  0.000640\n8192     0.001056  0.000731  0.000755\n16384    0.001381  0.001012  0.000936\n32768    0.001885  0.001465  0.001328\n65536    0.003404  0.002957  0.002585\n131072   0.008076  0.005668  0.005159\n262144   0.015532  0.011059  0.010988\n524288   0.032517  0.023336  0.018608\n1048576  0.055144  0.040367  0.035487\n2097152  0.112333  0.080407  0.072154",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-05-31T12:20:31",
        "author": "MSeifert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76322463/how-to-initialize-a-global-object-or-variable-and-reuse-it-in-every-fastapi-endp",
    "title": "How to initialize a global object or variable and reuse it in every FastAPI endpoint?",
    "question_id": 76322463,
    "posted_date": "2023-05-24T06:20:42",
    "answers": [
      {
        "answer_id": 76322910,
        "body": "from fastapi import FastAPI, Request\nfrom contextlib import asynccontextmanager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    ''' Run at startup\n        Initialize the Client and add it to app.state\n    '''\n    app.state.n_client = NotificationClient()\n    yield\n    ''' Run on shutdown\n        Close the connection\n        Clear variables and release the resources\n    '''\n    app.state.n_client.close()\napp = FastAPI(lifespan=lifespan)\n@app.get('/')\nasync def main(request: Request):\n    n_client = request.app.state.n_client\n    # ...",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2023-05-24T07:10:25",
        "author": "Chris"
      },
      {
        "answer_id": 76322910,
        "body": "from fastapi import FastAPI, Request\nfrom contextlib import asynccontextmanager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    ''' Run at startup\n        Initialize the Client and add it to request.state\n    '''\n    n_client = NotificationClient()\n    yield {'n_client': n_client}\n    ''' Run on shutdown\n        Close the connection\n        Clear variables and release the resources\n    '''\n    n_client.close()\napp = FastAPI(lifespan=lifespan)\n@app.get('/')\nasync def main(request: Request):\n    n_client = request.state.n_client\n    # ...",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2023-05-24T07:10:25",
        "author": "Chris"
      },
      {
        "answer_id": 76322910,
        "body": "from fastapi import FastAPI, Request\nfrom contextlib import asynccontextmanager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    yield {\"data\": {\"val\": 1}}\n    #yield {\"val\": 1}  # changes to `val` would not take effect globally\napp = FastAPI(lifespan=lifespan)\n@app.get('/set')\nasync def set(request: Request):\n    #request.state.val = 2  # changes to `val` would not take effect globally\n    request.state.data[\"val\"] = 2\n    return request.state\n@app.get(\"/get\")\nasync def get(request: Request):\n    return request.state",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2023-05-24T07:10:25",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63492123/how-do-add-an-assembled-field-to-a-pydantic-model",
    "title": "How do add an assembled field to a Pydantic model",
    "question_id": 63492123,
    "posted_date": "2020-08-19T13:29:49",
    "answers": [
      {
        "answer_id": 63493377,
        "body": "`python\nfrom typing import Optional\nfrom pydantic import BaseModel, validator\nclass UserDB(BaseModel):\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\nclass User_1(BaseModel):\n    location: str  # for a change\n    full_name: Optional[str] = None\n    def __init__(self, user_db: UserDB, **data):\n        super().__init__(full_name=f\"{user_db.first_name} {user_db.last_name}\", **data)\nuser_db = UserDB(first_name=\"John\", last_name=\"Stark\")\nuser = User_1(user_db, location=\"Mars\")\nprint(user)\nclass User_2(BaseModel):\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    full_name: Optional[str] = None\n    @validator('full_name', always=True)\n    def ab(cls, v, values) -> str:\n        return f\"{values['first_name']} {values['last_name']}\"\nuser = User_2(**user_db.dict())\nprint(user)",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-08-19T15:00:18",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74605279/python-3-11-worse-optimized-than-3-10",
    "title": "Python 3.11 worse optimized than 3.10?",
    "question_id": 74605279,
    "posted_date": "2022-11-28T13:52:43",
    "answers": [
      {
        "answer_id": 74607850,
        "body": "CPython 3.10 loop:\n        >>   28 FOR_ITER                 6 (to 42)\n             30 STORE_NAME               4 (_)\n  6          32 LOAD_NAME                1 (a)\n             34 LOAD_CONST               2 ('a')\n             36 INPLACE_ADD                             <----------\n             38 STORE_NAME               1 (a)\n             40 JUMP_ABSOLUTE           14 (to 28)\nCPython 3.11 loop:\n        >>   66 FOR_ITER                 7 (to 82)\n             68 STORE_NAME               4 (_)\n  6          70 LOAD_NAME                1 (a)\n             72 LOAD_CONST               2 ('a')\n             74 BINARY_OP               13 (+=)         <----------\n             78 STORE_NAME               1 (a)\n             80 JUMP_BACKWARD            8 (to 66)",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2022-11-28T19:17:42",
        "author": "J&#233;r&#244;me Richard"
      },
      {
        "answer_id": 74607850,
        "body": "        // In CPython 3.10.8\n        case TARGET(INPLACE_ADD): {\n            PyObject *right = POP();\n            PyObject *left = TOP();\n            PyObject *sum;\n            if (PyUnicode_CheckExact(left) && PyUnicode_CheckExact(right)) {\n                sum = unicode_concatenate(tstate, left, right, f, next_instr); // <-----\n                /* unicode_concatenate consumed the ref to left */\n            }\n            else {\n                sum = PyNumber_InPlaceAdd(left, right);\n                Py_DECREF(left);\n            }\n            Py_DECREF(right);\n            SET_TOP(sum);\n            if (sum == NULL)\n                goto error;\n            DISPATCH();\n        }\n//----------------------------------------------------------------------------\n        // In CPython 3.11.0\n        TARGET(BINARY_OP_ADD_UNICODE) {\n            assert(cframe.use_tracing == 0);\n            PyObject *left = SECOND();\n            PyObject *right = TOP();\n            DEOPT_IF(!PyUnicode_CheckExact(left), BINARY_OP);\n            DEOPT_IF(Py_TYPE(right) != Py_TYPE(left), BINARY_OP);\n            STAT_INC(BINARY_OP, hit);\n            PyObject *res = PyUnicode_Concat(left, right); // <-----\n            STACK_SHRINK(1);\n            SET_TOP(res);\n            _Py_DECREF_SPECIALIZED(left, _PyUnicode_ExactDealloc);\n            _Py_DECREF_SPECIALIZED(right, _PyUnicode_ExactDealloc);\n            if (TOP() == NULL) {\n                goto error;\n            }\n            JUMPBY(INLINE_CACHE_ENTRIES_BINARY_OP);\n            DISPATCH();\n        }",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2022-11-28T19:17:42",
        "author": "J&#233;r&#244;me Richard"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55481355/python-abstract-class-shall-force-derived-classes-to-initialize-variable-in-in",
    "title": "Python abstract class shall force derived classes to initialize variable in __init__",
    "question_id": 55481355,
    "posted_date": "2019-04-02T14:27:49",
    "answers": [
      {
        "answer_id": 55571677,
        "body": "from abc import ABCMeta, abstractmethod\n# our version of ABCMeta with required attributes\nclass MyMeta(ABCMeta):\n    required_attributes = []\n    def __call__(self, *args, **kwargs):\n        obj = super(MyMeta, self).__call__(*args, **kwargs)\n        for attr_name in obj.required_attributes:\n            if not getattr(obj, attr_name):\n                raise ValueError('required attribute (%s) not set' % attr_name)\n        return obj\n# similar to the above example, but inheriting MyMeta now\nclass Quadrature(object, metaclass=MyMeta):\n    required_attributes = ['xyz', 'weights']\n    @abstractmethod\n    def __init__(self, order):\n        pass\nclass QuadratureWhichWorks(Quadrature):\n    # This shall work because we initialize xyz and weights in __init__\n    def __init__(self,order):\n        self.xyz = 123\n        self.weights = 456\nq = QuadratureWhichWorks('foo')\nclass QuadratureWhichShallNotWork(Quadrature):\n    def __init__(self, order):\n        self.xyz = 123\nq2 = QuadratureWhichShallNotWork('bar')",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-04-08T06:48:01",
        "author": "Andrew F"
      },
      {
        "answer_id": 55571677,
        "body": ">>> class Joker(object):\n>>>     # a class attribute\n>>>     setup = 'Wenn ist das Nunst\u00fcck git und Slotermeyer?'\n>>>\n>>>     # a read-only property\n>>>     @property\n>>>     def warning(self):\n>>>         return 'Joke Warfare is explicitly banned bythe Geneva Conventions'\n>>>\n>>>     def __init__(self):\n>>>         self.punchline = 'Ja! Beiherhund das Oder die Flipperwaldt gersput!'\n>>> j = Joker()\n>>> # we can access the class attribute via class or instance\n>>> Joker.setup == j.setup\n>>> # we can get the property but cannot set it\n>>> j.warning\n'Joke Warfare is explicitly banned bythe Geneva Conventions'\n>>> j.warning = 'Totally safe joke...'\nAttributeError: cant set attribute\n>>> # instance attribute set in __init__ is only accessible to that instance\n>>> j.punchline != Joker.punchline\nAttributeError: type object 'Joker' has no attribute 'punchline'",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-04-08T06:48:01",
        "author": "Andrew F"
      },
      {
        "answer_id": 55571677,
        "body": ">>> from abc import ABCMeta, abstractmethod\n>>> class Quadrature(object, metaclass=ABCMeta):\n>>>\n>>>     @property\n>>>     @abstractmethod\n>>>     def xyz(self):\n>>>         pass\n>>>\n>>>     @property\n>>>     @abstractmethod\n>>>     def weights(self):\n>>>         pass\n>>>\n>>>     @abstractmethod\n>>>     def __init__(self, order):\n>>>         pass\n>>>\n>>>     def someStupidFunctionDefinedHere(self, n):\n>>>         return self.xyz+self.weights+n\n>>>\n>>>\n>>> class QuadratureWhichWorks(Quadrature):\n>>>     # This shall work because we initialize xyz and weights in __init__\n>>>     def __init__(self,order):\n>>>         self._xyz = 123\n>>>         self._weights = 456\n>>>\n>>>     @property\n>>>     def xyz(self):\n>>>         return self._xyz\n>>>\n>>>     @property\n>>>     def weights(self):\n>>>         return self._weights\n>>>\n>>> q = QuadratureWhichWorks('foo')\n>>> q.xyz\n123\n>>> q.weights\n456",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-04-08T06:48:01",
        "author": "Andrew F"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42697933/colormap-with-maximum-distinguishable-colours",
    "title": "Colormap with maximum distinguishable colours",
    "question_id": 42697933,
    "posted_date": "2017-03-09T09:30:05",
    "answers": [
      {
        "answer_id": 59998512,
        "body": "import math\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.cm import hsv\ndef generate_colormap(number_of_distinct_colors: int = 80):\n    if number_of_distinct_colors == 0:\n        number_of_distinct_colors = 80\n    number_of_shades = 7\n    number_of_distinct_colors_with_multiply_of_shades = int(math.ceil(number_of_distinct_colors / number_of_shades) * number_of_shades)\n    # Create an array with uniformly drawn floats taken from <0, 1) partition\n    linearly_distributed_nums = np.arange(number_of_distinct_colors_with_multiply_of_shades) / number_of_distinct_colors_with_multiply_of_shades\n    # We are going to reorganise monotonically growing numbers in such way that there will be single array with saw-like pattern\n    #     but each saw tooth is slightly higher than the one before\n    # First divide linearly_distributed_nums into number_of_shades sub-arrays containing linearly distributed numbers\n    arr_by_shade_rows = linearly_distributed_nums.reshape(number_of_shades, number_of_distinct_colors_with_multiply_of_shades // number_of_shades)\n    # Transpose the above matrix (columns become rows) - as a result each row contains saw tooth with values slightly higher than row above\n    arr_by_shade_columns = arr_by_shade_rows.T\n    # Keep number of saw teeth for later\n    number_of_partitions = arr_by_shade_columns.shape[0]\n    # Flatten the above matrix - join each row into single array\n    nums_distributed_like_rising_saw = arr_by_shade_columns.reshape(-1)\n    # HSV colour map is cyclic (https://matplotlib.org/tutorials/colors/colormaps.html#cyclic), we'll use this property\n    initial_cm = hsv(nums_distributed_like_rising_saw)\n    lower_partitions_half = number_of_partitions // 2\n    upper_partitions_half = number_of_partitions - lower_partitions_half\n    # Modify lower half in such way that colours towards beginning of partition are darker\n    # First colours are affected more, colours closer to the middle are affected less\n    lower_half = lower_partitions_half * number_of_shades\n    for i in range(3):\n        initial_cm[0:lower_half, i] *= np.arange(0.2, 1, 0.8/lower_half)\n    # Modify second half in such way that colours towards end of partition are less intense and brighter\n    # Colours closer to the middle are affected less, colours closer to the end are affected more\n    for i in range(3):\n        for j in range(upper_partitions_half):\n            modifier = np.ones(number_of_shades) - initial_cm[lower_half + j * number_of_shades: lower_half + (j + 1) * number_of_shades, i]\n            modifier = j * modifier / upper_partitions_half\n            initial_cm[lower_half + j * number_of_shades: lower_half + (j + 1) * number_of_shades, i] += modifier\n    return ListedColormap(initial_cm)",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-01-31T00:47:22",
        "author": "Greg0ry"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/24872527/combine-word-document-using-python-docx",
    "title": "combine word document using python docx",
    "question_id": 24872527,
    "posted_date": "2014-07-21T14:52:42",
    "answers": [
      {
        "answer_id": 54735397,
        "body": "#Importing the required packages\nfrom docxcompose.composer import Composer\nfrom docx import Document as Document_compose\n#filename_master is name of the file you want to merge the docx file into\nmaster = Document_compose(filename_master)\ncomposer = Composer(master)\n#filename_second_docx is the name of the second docx file\ndoc2 = Document_compose(filename_second_docx)\n#append the doc2 into the master using composer.append function\ncomposer.append(doc2)\n#Save the combined docx with a name\ncomposer.save(\"combined.docx\")",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2019-02-17T11:49:06",
        "author": "Shashank Shekhar Shukla"
      },
      {
        "answer_id": 54735397,
        "body": "#Filename_master is the name of the file you want to merge all the document into\n#files_list is a list containing all the filename of the docx file to be merged\ndef combine_all_docx(filename_master,files_list):\n    number_of_sections=len(files_list)\n    master = Document_compose(filename_master)\n    composer = Composer(master)\n    for i in range(0, number_of_sections):\n        doc_temp = Document_compose(files_list[i])\n        composer.append(doc_temp)\n    composer.save(\"combined_file.docx\")\n#For Example\n#filename_master=\"file1.docx\"\n#files_list=[\"file2.docx\",\"file3.docx\",\"file4.docx\",file5.docx\"]\n#Calling the function\n#combine_all_docx(filename_master,files_list)\n#This function will combine all the document in the array files_list into the file1.docx and save the merged document into combined_file.docx",
        "score": 40,
        "is_accepted": false,
        "creation_date": "2019-02-17T11:49:06",
        "author": "Shashank Shekhar Shukla"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54653356/case-when-function-from-r-to-python",
    "title": "case_when function from R to Python",
    "question_id": 54653356,
    "posted_date": "2019-02-12T10:20:56",
    "answers": [
      {
        "answer_id": 54653448,
        "body": "conditions = [\n    (df[\"age\"].lt(10)),\n    (df[\"age\"].ge(10) & df[\"age\"].lt(20)),\n    (df[\"age\"].ge(20) & df[\"age\"].lt(30)),\n    (df[\"age\"].ge(30) & df[\"age\"].lt(50)),\n    (df[\"age\"].ge(50)),\n]\nchoices = [\"baby\", \"kid\", \"young\", \"mature\", \"grandpa\"]\ndf[\"elderly\"] = np.select(conditions, choices)\n# Results in:\n#      name  age  preTestScore  postTestScore  elderly\n#  0  Jason   42             4             25   mature\n#  1  Molly   52            24             94  grandpa\n#  2   Tina   36            31             57   mature\n#  3   Jake   24             2             62    young\n#  4    Amy   73             3             70  grandpa",
        "score": 43,
        "is_accepted": true,
        "creation_date": "2019-02-12T10:25:50",
        "author": "Alex"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71514124/find-near-duplicate-and-faked-images",
    "title": "Find near duplicate and faked images",
    "question_id": 71514124,
    "posted_date": "2022-03-17T10:32:30",
    "answers": [
      {
        "answer_id": 71567609,
        "body": "from sentence_transformers import SentenceTransformer, util\nfrom PIL import Image\nimport glob\nimport os\n# Load the OpenAI CLIP Model\nprint('Loading CLIP Model...')\nmodel = SentenceTransformer('clip-ViT-B-32')\n# Next we compute the embeddings\n# To encode an image, you can use the following code:\n# from PIL import Image\n# encoded_image = model.encode(Image.open(filepath))\nimage_names = list(glob.glob('./*.jpg'))\nprint(\"Images:\", len(image_names))\nencoded_image = model.encode([Image.open(filepath) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n# Now we run the clustering algorithm. This function compares images aganist\n# all other images and returns a list with the pairs that have the highest\n# cosine similarity score\nprocessed_images = util.paraphrase_mining_embeddings(encoded_image)\nNUM_SIMILAR_IMAGES = 10\n# =================\n# DUPLICATES\n# =================\nprint('Finding duplicate images...')\n# Filter list for duplicates. Results are triplets (score, image_id1, image_id2) and is scorted in decreasing order\n# A duplicate image will have a score of 1.00\nduplicates = [image for image in processed_images if image[0] >= 1]\n# Output the top X duplicate images\nfor score, image_id1, image_id2 in duplicates[0:NUM_SIMILAR_IMAGES]:\n    print(\"\\nScore: {:.3f}%\".format(score * 100))\n    print(image_names[image_id1])\n    print(image_names[image_id2])\n# =================\n# NEAR DUPLICATES\n# =================\nprint('Finding near duplicate images...')\n# Use a threshold parameter to identify two images as similar. By setting the threshold lower,\n# you will get larger clusters which have less similar images in it. Threshold 0 - 1.00\n# A threshold of 1.00 means the two images are exactly the same. Since we are finding near\n# duplicate images, we can set it at 0.99 or any number 0 < X < 1.00.\nthreshold = 0.99\nnear_duplicates = [image for image in processed_images if image[0] < threshold]\nfor score, image_id1, image_id2 in near_duplicates[0:NUM_SIMILAR_IMAGES]:\n    print(\"\\nScore: {:.3f}%\".format(score * 100))\n    print(image_names[image_id1])\n    print(image_names[image_id2])",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2022-03-22T02:11:52",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65575796/why-does-the-flask-bool-query-parameter-always-evaluate-to-true",
    "title": "Why does the Flask bool query parameter always evaluate to true?",
    "question_id": 65575796,
    "posted_date": "2021-01-05T03:59:19",
    "answers": [
      {
        "answer_id": 68856594,
        "body": "$ curl -XGET http://localhost:5000/test?fullInfo=false\n{\"full_info\":false}\n$ curl -XGET http://localhost:5000/test?fullInfo=adasdasd\n{\"full_info\":false}\n$ curl -XGET http://localhost:5000/test?fullInfo=11431423\n{\"full_info\":false}\n$ curl -XGET http://localhost:5000/test?fullInfo=\n{\"full_info\":false}\n$ curl -XGET http://localhost:5000/test?fullInfo=true\n{\"full_info\":true}\n$ curl -XGET http://localhost:5000/test?fullInfo=TRUE\n{\"full_info\":true}\n$ curl -XGET http://localhost:5000/test\n{\"full_info\":false}",
        "score": 51,
        "is_accepted": true,
        "creation_date": "2021-08-19T23:10:49",
        "author": "Gino Mempin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65465555/how-to-use-values-from-list-as-pydantic-validator",
    "title": "How to use values from list as pydantic validator?",
    "question_id": 65465555,
    "posted_date": "2020-12-27T07:08:51",
    "answers": [
      {
        "answer_id": 67400431,
        "body": ">>> uf = UserForm(fruits=['apple','banana'],name='hello')\n>>> uf\nUserForm(fruits=[<Fruit.APPLE: 'apple'>, <Fruit.BANANA: 'banana'>], name='hello')\n>>> af = UserForm(fruits=['monkey','apple'],name='hello')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"pydantic/main.py\", line 400, in pydantic.main.BaseModel.__init__\npydantic.error_wrappers.ValidationError: 1 validation error for UserForm\nfruits -> 0\n  value is not a valid enumeration member; permitted: 'apple', 'banana', 'melon' (type=type_error.enum; enum_values=[<Fruit.APPLE: 'apple'>, <Fruit.BANANA: 'banana'>, <Fruit.MELON: 'melon'>])\n>>>",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2021-05-05T07:31:10",
        "author": "aahnik"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43434020/black-and-white-boxplots-in-seaborn",
    "title": "Black and white boxplots in Seaborn",
    "question_id": 43434020,
    "posted_date": "2017-04-16T01:26:09",
    "answers": [
      {
        "answer_id": 65529178,
        "body": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n_to_plot = pd.DataFrame(\n    {\n     0: np.random.normal(0, 1, 100),\n     1: np.random.normal(0, 2, 100),\n     2: np.random.normal(-1, 1, 100),\n     3: np.random.normal(-2, 2, 100)\n     }\n).melt()\nPROPS = {\n    'boxprops':{'facecolor':'none', 'edgecolor':'red'},\n    'medianprops':{'color':'green'},\n    'whiskerprops':{'color':'blue'},\n    'capprops':{'color':'magenta'}\n}\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.boxplot(x='variable',y='value',\n            data=_to_plot,\n            showfliers=False,\n            linewidth=1,\n            ax=ax,\n            **PROPS)",
        "score": 34,
        "is_accepted": false,
        "creation_date": "2021-01-01T06:12:17",
        "author": "fffrost"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4066202/resizing-pictures-in-pil-in-tkinter",
    "title": "Resizing pictures in PIL in Tkinter",
    "question_id": 4066202,
    "posted_date": "2010-10-31T21:54:01",
    "answers": [
      {
        "answer_id": 4066264,
        "body": "im_temp = Image.open(Image_Location)\nim_temp = im_temp.resize((250, 250), Image.ANTIALIAS)\nim_temp.save(\"ArtWrk.ppm\", \"ppm\") ## The only reason I included this was to convert\n## The image into a format that Tkinter woulden't complain about\nself.photo = PhotoImage(file=\"ArtWrk.ppm\") ## Open the image as a tkinter.PhotoImage class()\nself.Artwork.destroy() ## Erase the last drawn picture (in the program the picture I used was changing)\nself.Artwork = Label(self.frame, image=self.photo) ## Sets the image too the label\nself.Artwork.photo = self.photo ## Make the image actually display (If I don't include this it won't display an image)\nself.Artwork.pack() ## Repack the image",
        "score": 46,
        "is_accepted": true,
        "creation_date": "2010-10-31T22:10:58",
        "author": "Joshkunz"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/385572/typecasting-in-python",
    "title": "Typecasting in Python",
    "question_id": 385572,
    "posted_date": "2008-12-21T23:35:18",
    "answers": [
      {
        "answer_id": 385583,
        "body": "s8 = (i + 2**7) % 2**8 - 2**7      # convert to signed 8-bit\nu8 = i % 2**8                      # convert to unsigned 8-bit\ns16 = (i + 2**15) % 2**16 - 2**15  # convert to signed 16-bit\nu16 = i % 2**16                    # convert to unsigned 16-bit\ns32 = (i + 2**31) % 2**32 - 2**31  # convert to signed 32-bit\nu32 = i % 2**32                    # convert to unsigned 32-bit\ns64 = (i + 2**63) % 2**64 - 2**63  # convert to signed 64-bit\nu64 = i % 2**64                    # convert to unsigned 64-bit",
        "score": 46,
        "is_accepted": true,
        "creation_date": "2008-12-21T23:44:48",
        "author": "Adam Rosenfield"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56206038/how-to-loop-through-paginated-api-using-python",
    "title": "How to loop through paginated API using python",
    "question_id": 56206038,
    "posted_date": "2019-05-19T04:29:49",
    "answers": [
      {
        "answer_id": 56206136,
        "body": "import requests #to make TMDB API calls\n#Discover API url filtered to movies >= 2004 and containing Drama genre_ID: 18\ndiscover_api_url = 'https://api.themoviedb.org/3/discover/movie?\napi_key=['my api key']&language=en-US&sort_by=popularity.desc&include_adult=false&include_video=false&primary_release_year=>%3D2004&with_genres=18'\nmost_popular_films = []\nnew_results = True\npage = 1\nwhile new_results:\n    discover_api = requests.get(discover_api_url + f\"&page={page}\").json()\n    new_results = discover_api.get(\"results\", [])\n    most_popular_films.extend(new_results)\n    page += 1\n#printing movie_id and movie_title by popularity desc\nfor i, film in enumerate(most_popular_films):\n    print(i, film['id'], film['title'])",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2019-05-19T04:42:43",
        "author": "AdamGold"
      },
      {
        "answer_id": 56206136,
        "body": "import requests #to make TMDB API calls\n#Discover API url filtered to movies >= 2004 and containing Drama genre_ID: 18\ndiscover_api_url = 'https://api.themoviedb.org/3/discover/movie?\napi_key=['my api key']&language=en-US&sort_by=popularity.desc&include_adult=false&include_video=false&primary_release_year=>%3D2004&with_genres=18'\ndiscover_api = requests.get(discover_api_url).json()\nmost_popular_films = discover_api[\"results\"]\nfor page in range(2, discover_api[\"total_pages\"]+1):\n    discover_api = requests.get(discover_api_url + f\"&page={page}\").json()\n    most_popular_films.extend(discover_api[\"results\"])\n#printing movie_id and movie_title by popularity desc\nfor i, film in enumerate(most_popular_films):\n    print(i, film['id'], film['title'])",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2019-05-19T04:42:43",
        "author": "AdamGold"
      },
      {
        "answer_id": 56206136,
        "body": "import requests #to make TMDB API calls\n#Discover API url filtered to movies >= 2004 and containing Drama genre_ID: 18\ndiscover_api = 'https://api.themoviedb.org/3/discover/movie?\napi_key=['my api key']&language=en-US&sort_by=popularity.desc&include_adult=false&include_video=false&primary_release_year=>%3D2004&with_genres=18'\ndiscover_api = requests.get(discover_api).json()\nmost_popular_films = discover_api[\"results\"]\nwhile discover_api[\"next_url\"]:\n    discover_api = requests.get(discover_api[\"next_url\"]).json()\n    most_popular_films.extend(discover_api[\"results\"])\n#printing movie_id and movie_title by popularity desc\nfor i, film in enumerate(most_popular_films):\n    print(i, film['id'], film['title'])",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2019-05-19T04:42:43",
        "author": "AdamGold"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45425896/install-tensorflow-with-specific-version-on-anaconda",
    "title": "Install TensorFlow with specific version on Anaconda",
    "question_id": 45425896,
    "posted_date": "2017-07-31T17:55:20",
    "answers": [
      {
        "answer_id": 61068145,
        "body": "Loading channels: done\n# Name                       Version           Build  Channel\ntensorflow-gpu                 1.4.1               0  pkgs/main\ntensorflow-gpu                 1.5.0               0  pkgs/main\ntensorflow-gpu                 1.6.0               0  pkgs/main\ntensorflow-gpu                 1.7.0               0  pkgs/main\ntensorflow-gpu                 1.8.0      h7b35bdc_0  pkgs/main\ntensorflow-gpu                 1.9.0      hf154084_0  pkgs/main\ntensorflow-gpu                1.10.0      hf154084_0  pkgs/main\ntensorflow-gpu                1.11.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                1.12.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                1.13.1      h0d30ee6_0  pkgs/main\ntensorflow-gpu                1.14.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                1.15.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                 2.0.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                 2.1.0      h0d30ee6_0  pkgs/main\ntensorflow-gpu                 2.2.0      h0d30ee6_0  pkgs/main",
        "score": 32,
        "is_accepted": false,
        "creation_date": "2020-04-06T16:10:32",
        "author": "adamconkey"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63105799/understanding-python-contextvars",
    "title": "Understanding Python contextvars",
    "question_id": 63105799,
    "posted_date": "2020-07-26T17:19:01",
    "answers": [
      {
        "answer_id": 63131230,
        "body": "`\nimport asyncio\nimport contextvars\n# declare context var\ncurrent_request_id_ctx = contextvars.ContextVar('')\ncurrent_request_id_global = ''\nasync def some_inner_coroutine():\n    global current_request_id_global\n    # simulate some async work\n    await asyncio.sleep(0.1)\n    # get value\n    print('Processed inner coroutine of request: {}'.format(current_request_id_ctx.get()))\n    if current_request_id_global != current_request_id_ctx.get():\n        print(f\"ERROR! global var={current_request_id_global}\")\nasync def some_outer_coroutine(req_id):\n    global current_request_id_global\n    # set value\n    current_request_id_ctx.set(req_id)\n    current_request_id_global = req_id\n    await some_inner_coroutine()\n    # get value\n    print('Processed outer coroutine of request: {}\\n'.format(current_request_id_ctx.get()))\nasync def main():\n    tasks = []\n    for req_id in range(1, 10000):\n        tasks.append(asyncio.create_task(some_outer_coroutine(req_id)))\n    await asyncio.gather(*tasks)\nif __name__ == '__main__':\n    asyncio.run(main())",
        "score": 47,
        "is_accepted": true,
        "creation_date": "2020-07-28T05:38:50",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/1408272/get-file-creation-time-with-python-on-linux",
    "title": "Get file creation time with Python on linux",
    "question_id": 1408272,
    "posted_date": "2009-09-10T19:35:39",
    "answers": [
      {
        "answer_id": 1408281,
        "body": "> 3.1)  How do I find the creation time of a file?\n>\n>       You can't - it isn't stored anywhere.  Files have a last-modified\n>       time (shown by \"ls -l\"), a last-accessed time (shown by \"ls -lu\")\n>       and an inode change time (shown by \"ls -lc\"). The latter is often\n>       referred to as the \"creation time\" - even in some man pages -\n>       but that's wrong; it's also set by such operations as mv, ln,\n>       chmod, chown and chgrp.\n>\n>       The man page for \"stat(2)\" discusses this.\n>",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2009-09-10T19:38:21",
        "author": "SingleNegationElimination"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67921192/5bad-argument-in-function-rectangle-cant-parse-pt1-sequence-item-wit",
    "title": "(-5:Bad argument) in function &#39;rectangle&#39; - Can&#39;t parse &#39;pt1&#39;. Sequence item with index 0 has a wrong type",
    "question_id": 67921192,
    "posted_date": "2021-06-10T08:30:53",
    "answers": [
      {
        "answer_id": 67921334,
        "body": "Traceback (most recent call last):\n  File \"C:/Users/User/Desktop/temp.py\", line 9, in <module>\n    cv2.rectangle(img, c1, c2, (255, 0, 0), -1)\ncv2.error: OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2",
        "score": 42,
        "is_accepted": true,
        "creation_date": "2021-06-10T08:41:38",
        "author": "Red"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62280161/saving-keras-models-with-custom-layers",
    "title": "Saving Keras models with Custom Layers",
    "question_id": 62280161,
    "posted_date": "2020-06-09T06:12:33",
    "answers": [
      {
        "answer_id": 65010554,
        "body": "import tensorflow as tf\n@tf.keras.utils.register_keras_serializable()\nclass CustomLayer(tf.keras.layers.Layer):\n    def __init__(self, k, **kwargs):\n        self.k = k\n        super(CustomLayer, self).__init__(**kwargs)\n    def get_config(self):\n        config = super().get_config()\n        config[\"k\"] = self.k\n        return config\n    def call(self, input):\n        return tf.multiply(input, 2)\ndef main():\n    model = tf.keras.models.Sequential(\n        [\n            tf.keras.Input(name='input_layer', shape=(10,)),\n            CustomLayer(10, name='custom_layer'),\n            tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')\n        ]\n    )\n    print(\"SUMMARY OF THE MODEL CREATED\")\n    print(\"-\" * 60)\n    print(model.summary())\n    model.save('model.h5')\n    del model\n    print()\n    print()\n    model = tf.keras.models.load_model('model.h5')\n    print(\"SUMMARY OF THE MODEL LOADED\")\n    print(\"-\" * 60)\n    print(model.summary())\nif __name__ == \"__main__\":\n    main()",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2020-11-25T13:17:16",
        "author": "M. Perier--Dulhoste"
      },
      {
        "answer_id": 65010554,
        "body": "SUMMARY OF THE MODEL CREATED\n------------------------------------------------------------\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\ncustom_layer (CustomLayer)   (None, 10)                0\n_________________________________________________________________\noutput_layer (Dense)         (None, 1)                 11\n=================================================================\nTotal params: 11\nTrainable params: 11\nNon-trainable params: 0\n_________________________________________________________________\nNone\nWARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\nSUMMARY OF THE MODEL LOADED\n------------------------------------------------------------\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\ncustom_layer (CustomLayer)   (None, 10)                0\n_________________________________________________________________\noutput_layer (Dense)         (None, 1)                 11\n=================================================================\nTotal params: 11\nTrainable params: 11\nNon-trainable params: 0\n_________________________________________________________________\nNone",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2020-11-25T13:17:16",
        "author": "M. Perier--Dulhoste"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/795190/how-to-perform-common-post-initialization-tasks-in-inherited-classes",
    "title": "How to perform common post-initialization tasks in inherited classes?",
    "question_id": 795190,
    "posted_date": "2009-04-27T16:38:03",
    "answers": [
      {
        "answer_id": 69791256,
        "body": "class PostInitCaller(type):\n    def __call__(cls, *args, **kwargs):\n        obj = type.__call__(cls, *args, **kwargs)\n        obj.__post_init__()\n        return obj\nclass BaseClass(metaclass=PostInitCaller):\n    def __init__(self):\n        print('base __init__')\n        self.common1()\n    def common1(self):\n        print('common 1')\n    def finalizeInitialization(self):\n        print('finalizeInitialization [common2]')\n    def __post_init__(self): # this is called at the end of __init__\n        self.finalizeInitialization()\nclass Subclass1(BaseClass):\n    def __init__(self):\n        super().__init__()\n        self.specific()\n    def specific(self):\n        print('specific')\ns = Subclass1()",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2021-10-31T19:06:30",
        "author": "Cam.Davidson.Pilon"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48996494/send-http-request-through-specific-network-interface",
    "title": "Send http request through specific network interface",
    "question_id": 48996494,
    "posted_date": "2018-02-26T15:22:29",
    "answers": [
      {
        "answer_id": 61581069,
        "body": "import requests\ndef session_for_src_addr(addr: str) -> requests.Session:\n    \"\"\"\n    Create `Session` which will bind to the specified local address\n    rather than auto-selecting it.\n    \"\"\"\n    session = requests.Session()\n    for prefix in ('http://', 'https://'):\n        session.get_adapter(prefix).init_poolmanager(\n            # those are default values from HTTPAdapter's constructor\n            connections=requests.adapters.DEFAULT_POOLSIZE,\n            maxsize=requests.adapters.DEFAULT_POOLSIZE,\n            # This should be a tuple of (address, port). Port 0 means auto-selection.\n            source_address=(addr, 0),\n        )\n    return session\n# usage example:\ns = session_for_src_addr('192.168.1.12')\ns.get('https://httpbin.org/ip')",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2020-05-03T16:19:35",
        "author": "MarSoft"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42771110/fastest-way-to-left-cycle-a-numpy-array-like-pop-push-for-a-queue",
    "title": "Fastest way to left-cycle a numpy array (like pop, push for a queue)",
    "question_id": 42771110,
    "posted_date": "2017-03-13T14:42:29",
    "answers": [
      {
        "answer_id": 66406793,
        "body": "# benchmark_circular_buffer.py\nimport numpy as np\n# all operations are O(1) and don't require copying the array\n# except to_array which has to copy the array and is O(n)\nclass RecordingQueue1D:\n    def __init__(self, object: object, maxlen: int):\n        #allocate the memory we need ahead of time\n        self.max_length: int = maxlen\n        self.queue_tail: int = maxlen - 1\n        o_len = len(object)\n        if (o_len == maxlen):\n            self.rec_queue = np.array(object, dtype=np.int64)\n        elif (o_len > maxlen):\n            self.rec_queue = np.array(object[o_len-maxlen:], dtype=np.int64)\n        else:\n            self.rec_queue = np.append(np.array(object, dtype=np.int64), np.zeros(maxlen-o_len, dtype=np.int64))\n            self.queue_tail = o_len - 1\n    def to_array(self) -> np.array:\n        head = (self.queue_tail + 1) % self.max_length\n        return np.roll(self.rec_queue, -head) # this will force a copy\n    def enqueue(self, new_data: np.array) -> None:\n        # move tail pointer forward then insert at the tail of the queue\n        # to enforce max length of recording\n        self.queue_tail = (self.queue_tail + 1) % self.max_length\n        self.rec_queue[self.queue_tail] = new_data\n    def peek(self) -> int:\n        queue_head = (self.queue_tail + 1) % self.max_length\n        return self.rec_queue[queue_head]\n    def replace_item_at(self, index: int, new_value: int):\n        loc = (self.queue_tail + 1 + index) % self.max_length\n        self.rec_queue[loc] = new_val\n    def item_at(self, index: int) -> int:\n        # the item we want will be at head + index\n        loc = (self.queue_tail + 1 + index) % self.max_length\n        return self.rec_queue[loc]\n    def __repr__(self):\n        return \"tail: \" + str(self.queue_tail) + \"\\narray: \" + str(self.rec_queue)\n    def __str__(self):\n        return \"tail: \" + str(self.queue_tail) + \"\\narray: \" + str(self.rec_queue)\n        # return str(self.to_array())\nrnd_arr = np.random.randint(0, 1e6, 10**8)\nnew_val = -100\nslice_arr = rnd_arr.copy()\nc_buf_arr = RecordingQueue1D(rnd_arr.copy(), len(rnd_arr))\n# Test speed for queuing new a new item\n# swapping items 100 and 1000\n# swapping items 10000 and 100000\ndef slice_and_copy():\n    slice_arr[:-1] = slice_arr[1:]\n    slice_arr[-1] = new_val\n    old = slice_arr[100]\n    slice_arr[100] = slice_arr[1000]\n    old = slice_arr[10000]\n    slice_arr[10000] = slice_arr[100000]\ndef circular_buffer():\n    c_buf_arr.enqueue(new_val)\n    old = c_buf_arr.item_at(100)\n    slice_arr[100] = slice_arr[1000]\n    old = slice_arr[10000]\n    slice_arr[10000] = slice_arr[100000]\n# lets add copying the array to a new numpy.array\n# this will take O(N) time for the circular buffer because we use numpy.roll()\n# which copies the array.\ndef slice_and_copy_assignemnt():\n    slice_and_copy()\n    my_throwaway_arr = slice_arr.copy()\n    return my_throwaway_arr\ndef circular_buffer_assignment():\n    circular_buffer()\n    my_throwaway_arr = c_buf_arr.to_array().copy()\n    return my_throwaway_arr\n# test using\n# python -m timeit -s \"import benchmark_circular_buffer as bcb\" \"bcb.slice_and_copy()\"\n# python -m timeit -s \"import benchmark_circular_buffer as bcb\" \"bcb.circular_buffer()\"\n# python -m timeit -r 5 -n 4 -s \"import benchmark_circular_buffer as bcb\" \"bcb.slice_and_copy_assignemnt()\"\n# python -m timeit -r 5 -n 4 -s \"import benchmark_circular_buffer as bcb\" \"bcb.circular_buffer_assignment()\"",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2021-02-28T02:27:46",
        "author": "L Co"
      },
      {
        "answer_id": 66406793,
        "body": "(thermal_venv) PS X:\\win10\\repos\\thermal> python -m timeit -s \"import benchmark_circular_buffer as bcb\" \"bcb.slice_and_copy()\"\n10 loops, best of 5: 36.7 msec per loop\n(thermal_venv) PS X:\\win10\\repos\\thermal> python -m timeit -s \"import benchmark_circular_buffer as bcb\" \"bcb.circular_buffer()\"\n200000 loops, best of 5: 1.04 usec per loop\n(thermal_venv) PS X:\\win10\\repos\\thermal> python -m timeit -s \"import benchmark_circular_buffer as bcb\" \"bcb.slice_and_copy_assignemnt()\"\n2 loops, best of 5: 166 msec per loop\n(thermal_venv) PS X:\\win10\\repos\\thermal> python -m timeit -r 5 -n 4 -s \"import benchmark_circular_buffer as bcb\" \"bcb.slice_and_copy_assignemnt()\"\n4 loops, best of 5: 159 msec per loop\n(thermal_venv) PS X:\\win10\\repos\\thermal> python -m timeit -r 5 -n 4 -s \"import benchmark_circular_buffer as bcb\" \"bcb.circular_buffer_assignment()\"\n4 loops, best of 5: 511 msec per loop",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2021-02-28T02:27:46",
        "author": "L Co"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49581104/sklearn-gridsearchcv-not-using-sample-weight-in-score-function",
    "title": "sklearn GridSearchCV not using sample_weight in score function",
    "question_id": 49581104,
    "posted_date": "2018-03-30T16:35:37",
    "answers": [
      {
        "answer_id": 49598597,
        "body": "import numpy as np\nfrom sklearn import set_config\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import GridSearchCV, RepeatedKFold\nfrom sklearn.metrics import make_scorer\nset_config(enable_metadata_routing=True)\nif __name__ == \"__main__\":\n    RANDOM_STATE = 1337\n    X, y = load_iris(return_X_y=True)\n    sample_weight = np.array([1 + 100 * (i % 25) for i in range(len(X))])\n    search_params = {\"max_features\": [1, 2, 3, 4]}\n    cv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=RANDOM_STATE)\n    rfc_weighted = RandomForestClassifier(\n        n_estimators=256,\n        criterion=\"entropy\",\n        warm_start=False,\n        n_jobs=1,\n        random_state=RANDOM_STATE,\n    ).set_fit_request(sample_weight=True)\n    rfc_unweighted = RandomForestClassifier(\n        n_estimators=256,\n        criterion=\"entropy\",\n        warm_start=False,\n        n_jobs=1,\n        random_state=RANDOM_STATE,\n    ).set_fit_request(sample_weight=False)\n    scorer_weighted = make_scorer(\n        log_loss, greater_is_better=False, needs_proba=True, needs_threshold=False\n    ).set_score_request(sample_weight=True)\n    scorer_unweighted = make_scorer(\n        log_loss, greater_is_better=False, needs_proba=True, needs_threshold=False\n    ).set_score_request(sample_weight=False)\n    for rfc, rfc_is_weighted in zip([rfc_weighted, rfc_unweighted], [True, False]):\n        for scorer, scorer_is_weighted in zip(\n            [scorer_weighted, scorer_unweighted], [True, False]\n        ):\n            grid_clf = GridSearchCV(\n                estimator=rfc,\n                scoring=scorer,\n                cv=cv,\n                param_grid=search_params,\n                refit=True,\n                return_train_score=False,\n            )\n            if rfc_is_weighted or scorer_is_weighted:\n                grid_clf.fit(X, y, sample_weight=sample_weight)\n            else:\n                grid_clf.fit(X, y)\n            print(\n                \"This is the best out-of-sample score using GridSearchCV with \"\n                f\"(is scorer weighted: {scorer_is_weighted}), (is rfc weighted: \"\n                f\"{rfc_is_weighted}): {-grid_clf.best_score_}\"\n            )",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2018-04-01T09:31:42",
        "author": "adrin"
      },
      {
        "answer_id": 49598597,
        "body": "This is the best out-of-sample score using GridSearchCV with (is scorer weighted: True), (is rfc weighted: True): 0.09180030568650309\nThis is the best out-of-sample score using GridSearchCV with (is scorer weighted: False), (is rfc weighted: True): 0.1225297422810374\nThis is the best out-of-sample score using GridSearchCV with (is scorer weighted: True), (is rfc weighted: False): 0.09064253271691491\nThis is the best out-of-sample score using GridSearchCV with (is scorer weighted: False), (is rfc weighted: False): 0.12187958644498716",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2018-04-01T09:31:42",
        "author": "adrin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15857838/modify-object-in-python-multiprocessing",
    "title": "Modify object in python multiprocessing",
    "question_id": 15857838,
    "posted_date": "2013-04-06T21:15:59",
    "answers": [
      {
        "answer_id": 15858559,
        "body": "import numpy as np\nimport multiprocessing as mp\nclass Tester:\n    num = 0.0\n    name = 'none'\n    def __init__(self,tnum=num, tname=name):\n        self.num  = tnum\n        self.name = tname\n    def __str__(self):\n        return '%f %s' % (self.num, self.name)\ndef mod(test, nn, out_queue):\n    print test.num\n    test.num = np.random.randn()\n    print test.num\n    test.name = nn\n    out_queue.put(test)\nif __name__ == '__main__':\n    num = 10\n    out_queue = mp.Queue()\n    tests = np.empty(num, dtype=object)\n    for it in range(num):\n        tests[it] = Tester(tnum=it*1.0)\n\n\n    print '\\n'\n    workers = [ mp.Process(target=mod, args=(test, 'some', out_queue) ) for test in tests ]\n\n    for work in workers: work.start()\n\n    for work in workers: work.join()\n\n    res_lst = []\n    for j in range(len(workers)):\n        res_lst.append(out_queue.get())\n\n    for test in res_lst: print test",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2013-04-06T23:24:43",
        "author": "tacaswell"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57193597/mocking-a-sqlalchemy-session-for-pytest",
    "title": "Mocking a Sqlalchemy session for pytest",
    "question_id": 57193597,
    "posted_date": "2019-07-24T22:44:17",
    "answers": [
      {
        "answer_id": 57204195,
        "body": "import typing\nfrom flask import jsonify\nclass LegendsPostService:\n    def __init__(self, json_args, _session=None) -> None:\n        self.json_args = json_args\n        self.session = _session or db.session\n    def _get_legends(self) -> Legend:\n        return schemas.Legends(many=True).load(self.json_args)\n    def post(self) -> typing.List[typing.Dict[str, typing.Any]]:\n        legends = self._get_legends()\n        for legend in legends:\n            self.session.add(legend)\n        self.session.commit()\n        return schemas.Legends(many=True).dump(legends)\ndef post(cls):\n    service = LegendsPostService(json_args=request.get_json())\n    service.post()\n    return jsonify({'message': 'legends saved'})",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2019-07-25T10:19:23",
        "author": "Stephen Fuhry"
      },
      {
        "answer_id": 57204195,
        "body": "from factory.alchemy import SQLAlchemyModelFactory\nclass ModelFactory(SQLAlchemyModelFactory):\n    class Meta:\n        abstract = True\n        sqlalchemy_session = db.session\n# setup your factory for Legends:\nclass LegendsFactory(ModelFactory):\n    logo_url = factory.Faker('image_url')\n    class Meta(ModelFactory.Meta):\n        model = Legends\nfrom unittest.mock import MagicMock, patch\n# neither of these tests even need a database connection!\n# so you should be able to write HUNDREDS of similar tests\n# and you should be able to run hundreds of them in seconds (not minutes)\ndef test_LegendsPostService_can_init():\n    session = MagicMock()\n    service = LegendsPostService(json_args={'foo': 'bar'}, _session=session)\n    assert service.session is session\n    assert service.json_args['foo'] == 'bar'\ndef test_LegendsPostService_can_post():\n    session = MagicMock()\n    service = LegendsPostService(json_args={'foo': 'bar'}, _session=session)\n    # let's make some fake Legends for our service!\n    legends = LegendsFactory.build_batch(2)\n    with patch.object(service, '_get_legends') as _get_legends:\n        _get_legends.return_value = legends\n        legends_post_json = service.post()\n    # look, Ma! No database connection!\n    assert legends_post_json[0]['image_url'] == legends[0].image_url",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2019-07-25T10:19:23",
        "author": "Stephen Fuhry"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/10625865/how-does-pyarg-parsetupleandkeywords-work",
    "title": "How does PyArg_ParseTupleAndKeywords work?",
    "question_id": 10625865,
    "posted_date": "2012-05-16T16:03:57",
    "answers": [
      {
        "answer_id": 42193379,
        "body": "static PyObject *keywords(PyObject *self, PyObject *args, PyObject *kwargs)\n{\n    char *a;\n    char *b;\n    char *foo = NULL;\n    char *bar = NULL;\n    char *baz = NULL;\n    // Note how \"a\" and \"b\" are included in this\n    // even though they aren't supposed to be in kwargs like in python\n    static char *kwlist[] = {\"a\", \"b\", \"foo\", \"bar\", \"baz\", NULL};\n    if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"ss|sss\", kwlist,\n                                     &a, &b, &foo, &bar, &baz))\n    {\n        return NULL;\n    }\n    printf(\"a is %s\\n\", a);\n    printf(\"b is %s\\n\", b);\n    printf(\"foo is %s\\n\", foo);\n    printf(\"bar is %s\\n\", bar);\n    printf(\"baz is %s\\n\", baz);\n    Py_RETURN_NONE;\n}\n// ...\nstatic PyMethodDef SpamMethods[] =\n{\n    // ...\n    {\"keywords\", (PyCFunction) keywords, METH_VARARGS | METH_KEYWORDS, \"practice kwargs\"},\n    {NULL, NULL, 0, NULL}\n    // ...\n}",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2017-02-12T16:19:07",
        "author": "Matthew Moisen"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55912363/how-to-analyze-dependency-tree-for-conda",
    "title": "How to analyze dependency tree for conda",
    "question_id": 55912363,
    "posted_date": "2019-04-29T20:19:47",
    "answers": [
      {
        "answer_id": 57010879,
        "body": "# version\n$ conda-tree --version\nconda-tree 0.0.4\n# packages that no other package depends on\n$ conda-tree leaves\n['samtools','bcftools',...]\n# dependencies of a specific package\n$ conda-tree depends samtools\n['curl', 'xz', 'libgcc', 'zlib']\n# which packages depend on a specific package\n$ conda-tree whoneeds xz\n['samtools', 'bcftools', 'htslib', 'python']\n# dependency cycles\n$ conda-tree cycles\npip -> python -> pip\npip -> wheel -> python -> pip\n# query a different conda prefix/env\n$ conda-tree -p /conda/envs/trinity leaves\n['trinity']\n# query by name\n$ conda-tree -n trinity leaves\n['trinity']",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2019-07-12T12:33:04",
        "author": "pareyesv"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64901945/how-to-send-a-progress-of-operation-in-a-fastapi-app",
    "title": "How to send a progress of operation in a FastAPI app?",
    "question_id": 64901945,
    "posted_date": "2020-11-18T16:51:08",
    "answers": [
      {
        "answer_id": 64910966,
        "body": "import asyncio\nfrom http import HTTPStatus\nfrom fastapi import BackgroundTasks\nfrom typing import Dict, List\nfrom uuid import UUID, uuid4\nimport uvicorn\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nclass Job(BaseModel):\n    uid: UUID = Field(default_factory=uuid4)\n    status: str = \"in_progress\"\n    progress: int = 0\n    result: int = None\napp = FastAPI()\njobs: Dict[UUID, Job] = {}  # Dict as job storage\nasync def long_task(queue: asyncio.Queue, param: int):\n    for i in range(1, param):  # do work and return our progress\n        await asyncio.sleep(1)\n        await queue.put(i)\n    await queue.put(None)\nasync def start_new_task(uid: UUID, param: int) -> None:\n    queue = asyncio.Queue()\n    task = asyncio.create_task(long_task(queue, param))\n    while progress := await queue.get():  # monitor task progress\n        jobs[uid].progress = progress\n    jobs[uid].status = \"complete\"\n@app.post(\"/new_task/{param}\", status_code=HTTPStatus.ACCEPTED)\nasync def task_handler(background_tasks: BackgroundTasks, param: int):\n    new_task = Job()\n    jobs[new_task.uid] = new_task\n    background_tasks.add_task(start_new_task, new_task.uid, param)\n    return new_task\n@app.get(\"/task/{uid}/status\")\nasync def status_handler(uid: UUID):\n    return jobs[uid]",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2020-11-19T06:41:34",
        "author": "alex_noname"
      },
      {
        "answer_id": 64910966,
        "body": "import time\nfrom http import HTTPStatus\nfrom fastapi import BackgroundTasks, UploadFile, File\nfrom typing import Dict, List\nfrom uuid import UUID, uuid4\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nclass Job(BaseModel):\n    uid: UUID = Field(default_factory=uuid4)\n    status: str = \"in_progress\"\n    processed_files: List[str] = Field(default_factory=list)\napp = FastAPI()\njobs: Dict[UUID, Job] = {}\ndef process_files(task_id: UUID, files: List[UploadFile]):\n    for i in files:\n        time.sleep(5)  # pretend long task\n        # ...\n        # do a lot of operations on each file\n        # then append the processed file to a list\n        # ...\n        jobs[task_id].processed_files.append(i.filename)\n    jobs[task_id].status = \"completed\"\n@app.post('/work/test', status_code=HTTPStatus.ACCEPTED)\nasync def work(background_tasks: BackgroundTasks, files: List[UploadFile] = File(...)):\n    new_task = Job()\n    jobs[new_task.uid] = new_task\n    background_tasks.add_task(process_files, new_task.uid, files)\n    return new_task\n@app.get(\"/work/{uid}/status\")\nasync def status_handler(uid: UUID):\n    return jobs[uid]",
        "score": 19,
        "is_accepted": false,
        "creation_date": "2020-11-19T06:41:34",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71031816/how-do-you-properly-reuse-an-httpx-asyncclient-within-a-fastapi-application",
    "title": "how do you properly reuse an httpx.AsyncClient within a FastAPI application?",
    "question_id": 71031816,
    "posted_date": "2022-02-08T04:56:02",
    "answers": [
      {
        "answer_id": 74397436,
        "body": "import logging\nfrom fastapi import FastAPI\nimport httpx\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)-9s %(asctime)s - %(name)s - %(message)s\")\nLOGGER = logging.getLogger(__name__)\nclass HTTPXClientWrapper:\n    async_client = None\n    def start(self):\n        \"\"\" Instantiate the client. Call from the FastAPI startup hook.\"\"\"\n        self.async_client = httpx.AsyncClient()\n        LOGGER.info(f'httpx AsyncClient instantiated. Id {id(self.async_client)}')\n    async def stop(self):\n        \"\"\" Gracefully shutdown. Call from FastAPI shutdown hook.\"\"\"\n        LOGGER.info(f'httpx async_client.is_closed(): {self.async_client.is_closed} - Now close it. Id (will be unchanged): {id(self.async_client)}')\n        await self.async_client.aclose()\n        LOGGER.info(f'httpx async_client.is_closed(): {self.async_client.is_closed}. Id (will be unchanged): {id(self.async_client)}')\n        self.async_client = None\n        LOGGER.info('httpx AsyncClient closed')\n    def __call__(self):\n        \"\"\" Calling the instantiated HTTPXClientWrapper returns the wrapped singleton.\"\"\"\n        # Ensure we don't use it if not started / running\n        assert self.async_client is not None\n        LOGGER.info(f'httpx async_client.is_closed(): {self.async_client.is_closed}. Id (will be unchanged): {id(self.async_client)}')\n        return self.async_client\nhttpx_client_wrapper = HTTPXClientWrapper()\napp = FastAPI()\n@app.get('/test-call-external')\nasync def call_external_api(url: str = 'https://stackoverflow.com'):\n    async_client = httpx_client_wrapper()\n    res = await async_client.get(url)\n    result = res.text\n    return {\n        'result': result,\n        'status': res.status_code\n    }\n@app.on_event(\"startup\")\nasync def startup_event():\n    httpx_client_wrapper.start()\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    await httpx_client_wrapper.stop()\nif __name__ == '__main__':\n    import uvicorn\n    LOGGER.info(f'starting...')\n    uvicorn.run(f\"{__name__}:app\", host=\"127.0.0.1\", port=8000)",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2022-11-10T21:31:04",
        "author": "Ben"
      },
      {
        "answer_id": 74401249,
        "body": "from fastapi import FastAPI, Depends\nimport httpx\napp = FastAPI()\nasync def get_client():\n    # create a new client for each request\n    async with httpx.AsyncClient() as client:\n        # yield the client to the endpoint function\n        yield client\n        # close the client when the request is done\n@app.get(\"/foo\")\nasync def foo(client: httpx.AsyncClient = Depends(get_client)):\n    # use the client to make some http requests, e.g.,\n    response = await client.get(\"http://example.it\")\n    return response.json()",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2022-11-11T05:37:12",
        "author": "PaulvdBoor"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16673778/python-regex-match-in-multiline-but-still-want-to-get-the-line-number",
    "title": "python regex, match in multiline, but still want to get the line number",
    "question_id": 16673778,
    "posted_date": "2013-05-21T11:28:38",
    "answers": [
      {
        "answer_id": 45142535,
        "body": "def finditer_with_line_numbers(pattern, string, flags=0):\n    \"\"\"\n    A version of ``re.finditer`` that returns ``(match, line_number)`` pairs.\n    \"\"\"\n    import re\n    matches = list(re.finditer(pattern, string, flags))\n    if matches:\n        end = matches[-1].start()\n        # -1 so a failed `rfind` maps to the first line.\n        newline_table = {-1: 0}\n        for i, m in enumerate(re.finditer(\"\\\\n\", string), 1):\n            # Don't find newlines past our last match.\n            offset = m.start()\n            if offset > end:\n                break\n            newline_table[offset] = i\n        # Failing to find the newline is OK, -1 maps to 0.\n        for m in matches:\n            newline_offset = string.rfind(\"\\n\", 0, m.start())\n            line_number = newline_table[newline_offset]\n            yield (m, line_number)",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2017-07-17T07:02:07",
        "author": "ideasman42"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/24418449/pretty-output-with-pyyaml",
    "title": "pretty output with pyyaml",
    "question_id": 24418449,
    "posted_date": "2014-06-25T16:59:09",
    "answers": [
      {
        "answer_id": 31005595,
        "body": "import sys\nimport ruamel.yaml\nfrom pathlib import Path\nLT = ruamel.yaml.scalarstring.LiteralScalarString\nfile_org = Path('org.yaml')\nfile_plain = Path('plain.yaml')\nfile_block = Path('block.yaml')\ndef normalise(d):\n    if isinstance(d, dict):\n        for k, v in d.items():\n             d[k] = normalise(v)\n        return d\n    if isinstance(d, list):\n        for idx, elem in enumerate(d):\n            d[idx] = normalise(elem)\n        return d\n    if not isinstance(d, str):\n        return d\n    if '\\n' in d:\n        if isinstance(d, LT):\n            return d     # already a block style literal scalar\n        return LT(d)\n    return str(d)\nyaml = ruamel.yaml.YAML()\nfor fn in [file_org, file_plain, file_block]:\n    data = normalise(yaml.load(file_org))\n    yaml.dump(data, fn)\nassert file_org.read_bytes() == file_plain.read_bytes()\nassert file_org.read_bytes() == file_block.read_bytes()\nprint(file_block.read_text())",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2015-06-23T10:27:49",
        "author": "Anthon"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65184035/alembic-ignore-specific-tables",
    "title": "Alembic ignore specific tables",
    "question_id": 65184035,
    "posted_date": "2020-12-07T09:55:24",
    "answers": [
      {
        "answer_id": 65259433,
        "body": "def run_migrations_online():\n    ...\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n            # THE FOLLOWING LINE WAS MISSING FROM MY ORIGINAL CODE\n            include_object=include_object, # <----------------------- THIS!\n        )\n    ...",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-12-11T17:23:21",
        "author": "Yaakov Bressler"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51772493/understanding-output-from-statsmodels-grangercausalitytests",
    "title": "Understanding output from statsmodels grangercausalitytests",
    "question_id": 51772493,
    "posted_date": "2018-08-09T13:04:40",
    "answers": [
      {
        "answer_id": 59635707,
        "body": "Granger Causality\nnumber of lags (no zero) 1\nssr based F test:         F=19.8998 , p=0.0000  , df_denom=221, df_num=1\nssr based chi2 test:   chi2=20.1700 , p=0.0000  , df=1\nlikelihood ratio test: chi2=19.3129 , p=0.0000  , df=1\nparameter F test:         F=19.8998 , p=0.0000  , df_denom=221, df_num=1\nGranger Causality\nnumber of lags (no zero) 25\nssr based F test:         F=6.9970  , p=0.0000  , df_denom=149, df_num=25\nssr based chi2 test:   chi2=234.7975, p=0.0000  , df=25\nlikelihood ratio test: chi2=155.3126, p=0.0000  , df=25\nparameter F test:         F=6.9970  , p=0.0000  , df_denom=149, df_num=25",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2020-01-07T15:36:12",
        "author": "rsmith49"
      },
      {
        "answer_id": 59635707,
        "body": "Granger Causality\nnumber of lags (no zero) 1\nssr based F test:         F=0.1279  , p=0.7210  , df_denom=219, df_num=1\nssr based chi2 test:   chi2=0.1297  , p=0.7188  , df=1\nlikelihood ratio test: chi2=0.1296  , p=0.7188  , df=1\nparameter F test:         F=0.1279  , p=0.7210  , df_denom=219, df_num=1\nGranger Causality\nnumber of lags (no zero) 25\nssr based F test:         F=6.2471  , p=0.0000  , df_denom=147, df_num=25\nssr based chi2 test:   chi2=210.3621, p=0.0000  , df=25\nlikelihood ratio test: chi2=143.3297, p=0.0000  , df=25\nparameter F test:         F=6.2471  , p=0.0000  , df_denom=147, df_num=25",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2020-01-07T15:36:12",
        "author": "rsmith49"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74057367/how-to-get-rid-of-the-in-place-futurewarning-when-setting-an-entire-column-from",
    "title": "How to get rid of the in place FutureWarning when setting an entire column from an array?",
    "question_id": 74057367,
    "posted_date": "2022-10-13T10:19:55",
    "answers": [
      {
        "answer_id": 74193599,
        "body": "import numpy as np\nimport pandas as pd\nimport warnings\ndf = pd.DataFrame({\"price\": [11.1, 12.2]}, index=[\"book1\", \"book2\"])\noriginal_prices = df[\"price\"]\nnew_prices = np.array([98, 99])\nwith warnings.catch_warnings():\n    # Setting values in-place is fine, ignore the warning in Pandas >= 1.5.0\n    # This can be removed, if Pandas 1.5.0 does not need to be supported any longer.\n    # See also: https://stackoverflow.com/q/74057367/859591\n    warnings.filterwarnings(\n        \"ignore\",\n        category=FutureWarning,\n        message=(\n            \".*will attempt to set the values inplace instead of always setting a new array. \"\n            \"To retain the old behavior, use either.*\"\n        ),\n    )\n    df.iloc[:, 0] = new_prices\ndf.iloc[:, 0]",
        "score": 8,
        "is_accepted": true,
        "creation_date": "2022-10-25T07:47:51",
        "author": "lumbric"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55105045/python-invalid-base64-encoded-string-number-of-data-characters-5-cannot-be-1",
    "title": "python: Invalid base64-encoded string: number of data characters (5) cannot be 1 more than a multiple of 4",
    "question_id": 55105045,
    "posted_date": "2019-03-11T11:17:00",
    "answers": [
      {
        "answer_id": 55106160,
        "body": ">>> import base64\n>>> import os\n>>> from cryptography.fernet import Fernet\n>>> from cryptography.hazmat.backends import default_backend\n>>> from cryptography.hazmat.primitives import hashes\n>>> from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n>>> password = b\"password\"\n>>> hkdf = HKDF(\n...     algorithm=hashes.SHA256(),  # You can swap this out for hashes.MD5()\n...     length=32,\n...     salt=None,    # You may be able to remove this line but I'm unable to test\n...     info=None,    # You may also be able to remove this line\n...     backend=default_backend()\n... )\n>>> key = base64.urlsafe_b64encode(hkdf.derive(password))\n>>> f = Fernet(key)\n>>> token = f.encrypt(b\"Secret message!\")\n>>> token\nb'...'\n>>> f.decrypt(token)  # Process the key in the exact same manner to decode an encoded message\nb'Secret message!'",
        "score": 7,
        "is_accepted": false,
        "creation_date": "2019-03-11T12:17:59",
        "author": "Will T"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53581589/matplotlib-can-i-use-a-secondary-font-for-missing-glyphs",
    "title": "matplotlib: Can I use a secondary font for missing glyphs?",
    "question_id": 53581589,
    "posted_date": "2018-12-02T10:15:05",
    "answers": [
      {
        "answer_id": 57442775,
        "body": "import matplotlib.pyplot as plt\nfrom matplotlib.textpath import TextPath\nfrom fontTools.ttLib import TTFont\nfig = plt.figure()\nplt.axis([0, 8, 0, 6])\nt = u'abcde\u2665'\nplt.text(4.5, 4, 'DejaVu Sans:', horizontalalignment='right')\nplt.text(5, 4, t, {'family':'DejaVu Sans'})\nplt.text(4.5, 3, 'Noto Sans:', horizontalalignment='right')\nplt.text(5, 3, t, {'family':'Noto Sans'})\nplt.text(4.5, 2, 'Noto Sans Symbols2:', horizontalalignment='right')\nplt.text(5, 2, t, {'family':'Noto Sans Symbols2'})\ndef doesContain(fontPath, unicode_char):  # Helper function, the only issue being it takes font paths instead of names\n    font = TTFont(fontPath)  # Use helper library to go through all characters\n    for cmap in font['cmap'].tables:\n        if cmap.isUnicode():\n            if ord(unicode_char) in cmap.cmap:  # If the character table contains our character return True\n                return True\n    # Otherwise, return False.\n    return False\n\ndef renderText(x, y, text, fontSize, fallback_list, spacingSize):\n    xPosNow = x\n\n    for char in text:  # For each character...\n        fontId = 0\n        while not doesContain(fallback_list[fontId]['path'], char):  # find a font that works\n            if fontId < len(fallback_list) - 1:\n                fontId += 1\n            else:  # Or just go with the first font, if nothing seems to match\n                fontId = 0\n                break\n        print(fontId)\n\n        t = plt.text(xPosNow, y, char, {'family':fallback_list[fontId]['name']})\n        r = fig.canvas.get_renderer()\n        xPosNow += t.get_window_extent(renderer=r).width/100 + spacingSize",
        "score": 9,
        "is_accepted": true,
        "creation_date": "2019-08-10T09:55:17",
        "author": "Geza Kerecsenyi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44603119/how-to-display-a-pandas-data-frame-with-pyqt5-pyside2",
    "title": "How to display a Pandas data frame with PyQt5/PySide2",
    "question_id": 44603119,
    "posted_date": "2017-06-17T05:47:51",
    "answers": [
      {
        "answer_id": 44605011,
        "body": "class DataFrameModel(QtCore.QAbstractTableModel):\n    DtypeRole = QtCore.Qt.UserRole + 1000\n    ValueRole = QtCore.Qt.UserRole + 1001\n    def __init__(self, df=pd.DataFrame(), parent=None):\n        super(DataFrameModel, self).__init__(parent)\n        self._dataframe = df\n    def setDataFrame(self, dataframe):\n        self.beginResetModel()\n        self._dataframe = dataframe.copy()\n        self.endResetModel()\n    def dataFrame(self):\n        return self._dataframe\n    dataFrame = QtCore.pyqtProperty(pd.DataFrame, fget=dataFrame, fset=setDataFrame)\n    @QtCore.pyqtSlot(int, QtCore.Qt.Orientation, result=str)\n    def headerData(self, section: int, orientation: QtCore.Qt.Orientation, role: int = QtCore.Qt.DisplayRole):\n        if role == QtCore.Qt.DisplayRole:\n            if orientation == QtCore.Qt.Horizontal:\n                return self._dataframe.columns[section]\n            else:\n                return str(self._dataframe.index[section])\n        return QtCore.QVariant()\n    def rowCount(self, parent=QtCore.QModelIndex()):\n        if parent.isValid():\n            return 0\n        return len(self._dataframe.index)\n    def columnCount(self, parent=QtCore.QModelIndex()):\n        if parent.isValid():\n            return 0\n        return self._dataframe.columns.size\n    def data(self, index, role=QtCore.Qt.DisplayRole):\n        if not index.isValid() or not (0 <= index.row() < self.rowCount() \\\n            and 0 <= index.column() < self.columnCount()):\n            return QtCore.QVariant()\n        row = self._dataframe.index[index.row()]\n        col = self._dataframe.columns[index.column()]\n        dt = self._dataframe[col].dtype\n        val = self._dataframe.iloc[row][col]\n        if role == QtCore.Qt.DisplayRole:\n            return str(val)\n        elif role == DataFrameModel.ValueRole:\n            return val\n        if role == DataFrameModel.DtypeRole:\n            return dt\n        return QtCore.QVariant()\n    def roleNames(self):\n        roles = {\n            QtCore.Qt.DisplayRole: b'display',\n            DataFrameModel.DtypeRole: b'dtype',\n            DataFrameModel.ValueRole: b'value'\n        }\n        return roles",
        "score": 82,
        "is_accepted": true,
        "creation_date": "2017-06-17T09:09:43",
        "author": "eyllanesc"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53995171/anaconda-conda-error-argument-command-invalid-choice-when-trying-to-update-pa",
    "title": "anaconda conda: error: argument command: invalid choice when trying to update packages",
    "question_id": 53995171,
    "posted_date": "2019-01-01T06:49:07",
    "answers": [
      {
        "answer_id": 77077188,
        "body": "no change     /opt/homebrew/anaconda3/condabin/conda\nno change     /opt/homebrew/anaconda3/bin/conda\nno change     /opt/homebrew/anaconda3/bin/conda-env\nno change     /opt/homebrew/anaconda3/bin/activate\nno change     /opt/homebrew/anaconda3/bin/deactivate\nno change     /opt/homebrew/anaconda3/etc/profile.d/conda.sh\nno change     /opt/homebrew/anaconda3/etc/fish/conf.d/conda.fish\nno change     /opt/homebrew/anaconda3/shell/condabin/Conda.psm1\nno change     /opt/homebrew/anaconda3/shell/condabin/conda-hook.ps1\nno change     /opt/homebrew/anaconda3/lib/python3.11/site-packages/xontrib/conda.xsh\nno change     /opt/homebrew/anaconda3/etc/profile.d/conda.csh\nmodified /Users/<username>/.zshrc # <--- ADDITONAL CHANGES",
        "score": 45,
        "is_accepted": false,
        "creation_date": "2023-09-10T13:17:30",
        "author": "Webia1"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55099243/python3-dataclass-with-kwargsasterisk",
    "title": "python3 dataclass with **kwargs(asterisk)",
    "question_id": 55099243,
    "posted_date": "2019-03-11T05:56:00",
    "answers": [
      {
        "answer_id": 55101438,
        "body": "from dataclasses import dataclass\nfrom inspect import signature\n@dataclass\nclass Container:\n    user_id: int\n    body: str\n    @classmethod\n    def from_kwargs(cls, **kwargs):\n        # fetch the constructor's signature\n        cls_fields = {field for field in signature(cls).parameters}\n        # split the kwargs into native ones and new ones\n        native_args, new_args = {}, {}\n        for name, val in kwargs.items():\n            if name in cls_fields:\n                native_args[name] = val\n            else:\n                new_args[name] = val\n        # use the native ones to create the class ...\n        ret = cls(**native_args)\n        # ... and add the new ones by hand\n        for new_name, new_val in new_args.items():\n            setattr(ret, new_name, new_val)\n        return ret",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2019-03-11T08:01:15",
        "author": "Arne"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11782147/python-opencv-contour-tree-hierarchy-structure",
    "title": "Python OpenCV Contour Tree Hierarchy Structure",
    "question_id": 11782147,
    "posted_date": "2012-08-02T12:48:18",
    "answers": [
      {
        "answer_id": 71891581,
        "body": "0:\t[ 6 -1  1 -1]\t18:\t[19 -1 -1 17]\n1:\t[ 2 -1 -1  0]\t19:\t[20 18 -1 17]\n2:\t[ 3  1 -1  0]\t20:\t[21 19 -1 17]\n3:\t[ 4  2 -1  0]\t21:\t[22 20 -1 17]\n4:\t[ 5  3 -1  0]\t22:\t[-1 21 -1 17]\n5:\t[-1  4 -1  0]\t23:\t[27 17 24 -1]\n6:\t[11  0  7 -1]\t24:\t[25 -1 -1 23]\n7:\t[ 8 -1 -1  6]\t25:\t[26 24 -1 23]\n8:\t[ 9  7 -1  6]\t26:\t[-1 25 -1 23]\n9:\t[10  8 -1  6]\t27:\t[32 23 28 -1]\n10:\t[-1  9 -1  6]\t28:\t[29 -1 -1 27]\n11:\t[17  6 12 -1]\t29:\t[30 28 -1 27]\n12:\t[15 -1 13 11]\t30:\t[31 29 -1 27]\n13:\t[14 -1 -1 12]\t31:\t[-1 30 -1 27]\n14:\t[-1 13 -1 12]\t32:\t[-1 27 33 -1]\n15:\t[16 12 -1 11]\t33:\t[34 -1 -1 32]\n16:\t[-1 15 -1 11]\t34:\t[35 33 -1 32]\n17:\t[23 11 18 -1]\t35:\t[-1 34 -1 32]",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2022-04-16T02:21:33",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76734333/pydantic-v2-field-validator-values-argument-equivalent",
    "title": "Pydantic V2 - @field_validator `values` argument equivalent",
    "question_id": 76734333,
    "posted_date": "2023-07-20T19:53:19",
    "answers": [
      {
        "answer_id": 76736483,
        "body": "from typing import Any\nfrom pydantic import BaseModel, ValidationError, validator\nclass UserModel(BaseModel):\n    ...\n    password1: str\n    password2: str\n    @validator(\"password2\")\n    def passwords_match(cls, v: str, values: dict[str, Any]) -> str:\n        if \"password1\" in values and v != values[\"password1\"]:\n            raise ValueError(\"passwords do not match\")\n        return v\ntry:\n    UserModel(password1=\"abc\", password2=\"xyz\")\nexcept ValidationError as err:\n    print(err.json(indent=4))",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2023-07-21T04:50:12",
        "author": "Daniil Fajnberg"
      },
      {
        "answer_id": 76736483,
        "body": "from pydantic import BaseModel, ValidationError, ValidationInfo, field_validator\nclass UserModel(BaseModel):\n    ...\n    password1: str\n    password2: str\n    @field_validator(\"password2\")\n    def passwords_match(cls, v: str, info: ValidationInfo) -> str:\n        if \"password1\" in info.data and v != info.data[\"password1\"]:\n            raise ValueError(\"passwords do not match\")\n        return v\ntry:\n    UserModel(password1=\"abc\", password2=\"xyz\")\nexcept ValidationError as err:\n    print(err.json(indent=4))",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2023-07-21T04:50:12",
        "author": "Daniil Fajnberg"
      },
      {
        "answer_id": 76736483,
        "body": "from typing import Annotated\nfrom pydantic import AfterValidator, BaseModel, ValidationError, ValidationInfo\ndef ensure_passwords_match(v: str, info: ValidationInfo) -> str:\n    if \"password1\" in info.data and v != info.data[\"password1\"]:\n        raise ValueError(\"passwords do not match\")\n    return v\nclass UserModel(BaseModel):\n    ...\n    password1: str\n    password2: Annotated[str, AfterValidator(ensure_passwords_match)]\ntry:\n    UserModel(password1=\"abc\", password2=\"xyz\")\nexcept ValidationError as err:\n    print(err.json(indent=4))",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2023-07-21T04:50:12",
        "author": "Daniil Fajnberg"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64501193/fastapi-how-to-use-httpexception-in-responses",
    "title": "FastAPI - How to use HTTPException in responses?",
    "question_id": 64501193,
    "posted_date": "2020-10-23T09:45:08",
    "answers": [
      {
        "answer_id": 64505982,
        "body": "from fastapi import FastAPI\nfrom fastapi.exceptions import HTTPException\nfrom pydantic import BaseModel\nclass Dummy(BaseModel):\n    name: str\nclass HTTPError(BaseModel):\n    detail: str\n    class Config:\n        schema_extra = {\n            \"example\": {\"detail\": \"HTTPException raised.\"},\n        }\napp = FastAPI()\n@app.get(\n    \"/test\",\n    responses={\n        200: {\"model\": Dummy},\n        409: {\n            \"model\": HTTPError,\n            \"description\": \"This endpoint always raises an error\",\n        },\n    },\n)\ndef raises_error():\n    raise HTTPException(409, detail=\"Error raised\")",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2020-10-23T15:09:30",
        "author": "Yagiz Degirmenci"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51525691/realtime-offline-speech-recognition-in-python",
    "title": "Realtime offline speech recognition in Python",
    "question_id": 51525691,
    "posted_date": "2018-07-25T14:41:14",
    "answers": [
      {
        "answer_id": 73304153,
        "body": "    from vosk import Model, KaldiRecognizer\n    import pyaudio\n\n    model = Model(r\"C:\\\\Users\\User\\Desktop\\python practice\\ai\\vosk-model-small-en-us-0.15\")\n    recognizer = KaldiRecognizer(model, 16000)\n\n    mic = pyaudio.PyAudio()\n    stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192)\n    stream.start_stream()\n\n    while True:\n        data = stream.read(4096)\n\n\n        if recognizer.AcceptWaveform(data):\n            text = recognizer.Result()\n            print(f\"' {text[14:-3]} '\")",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2022-08-10T05:50:43",
        "author": "Buddhi ashen"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29800749/delaunay-triangulation-of-points-from-2d-surface-in-3d-with-python",
    "title": "Delaunay Triangulation of points from 2D surface in 3D with python?",
    "question_id": 29800749,
    "posted_date": "2015-04-22T10:28:51",
    "answers": [
      {
        "answer_id": 30305576,
        "body": "from matplotlib import path as mpath\nfrom mayavi import mlab\nimport numpy as np\ndef make_star(amplitude=1.0, rotation=0.0):\n    \"\"\" Make a star shape\n    \"\"\"\n    t = np.linspace(0, 2*np.pi, 6) + rotation\n    star = np.zeros((12, 2))\n    star[::2] = np.c_[np.cos(t), np.sin(t)]\n    star[1::2] = 0.5*np.c_[np.cos(t + np.pi / 5), np.sin(t + np.pi / 5)]\n    return amplitude * star\ndef make_stars(n_stars=51, z_diff=0.05):\n    \"\"\" Make `2*n_stars-1` stars stacked in 3D\n    \"\"\"\n    amps = np.linspace(0.25, 1, n_stars)\n    amps = np.r_[amps, amps[:-1][::-1]]\n    rots = np.linspace(0, 2*np.pi, len(amps))\n    zamps = np.linspace\n    stars = []\n    for i, (amp, rot) in enumerate(zip(amps, rots)):\n        star = make_star(amplitude=amp, rotation=rot)\n        height = i*z_diff\n        z = np.full(len(star), height)\n        star3d = np.c_[star, z]\n        stars.append(star3d)\n    return stars\ndef polygon_to_boolean(points, xvals, yvals):\n    \"\"\" Convert `points` to a boolean indicator mask\n    over the specified domain\n    \"\"\"\n    x, y = np.meshgrid(xvals, yvals)\n    xy = np.c_[x.flatten(), y.flatten()]\n    mask = mpath.Path(points).contains_points(xy).reshape(x.shape)\n    return x, y, mask\ndef plot_contours(stars):\n    \"\"\" Plot a list of stars in 3D\n    \"\"\"\n    n = len(stars)\n    for i, star in enumerate(stars):\n        x, y, z = star.T\n        mlab.plot3d(*star.T)\n        #ax.plot3D(x, y, z, '-o', c=(0, 1-i/n, i/n))\n        #ax.set_xlim(-1, 1)\n        #ax.set_ylim(-1, 1)\n    mlab.show()\nif __name__ == '__main__':\n    # Make and plot the 2D contours\n    stars3d = make_stars()\n    plot_contours(stars3d)\n    xvals = np.linspace(-1, 1, 101)\n    yvals = np.linspace(-1, 1, 101)\n    volume = np.dstack([\n        polygon_to_boolean(star[:,:2], xvals, yvals)[-1]\n        for star in stars3d\n    ]).astype(float)\n    mlab.contour3d(volume, contours=[0.5])\n    mlab.show()",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2015-05-18T10:14:21",
        "author": "Matt Hancock"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37094419/python-requests-retry-request-after-re-authentication",
    "title": "Python Requests - retry request after re-authentication",
    "question_id": 37094419,
    "posted_date": "2016-05-07T18:38:23",
    "answers": [
      {
        "answer_id": 69226185,
        "body": "session = requests.Session()\nsession.headers.update({\"Authorization\": f\"Bearer deliberate-wrong-token\"})\ndef refresh_token(r, *args, **kwargs):\n    if r.status_code == 401:\n        logger.info(\"Fetching new token as the previous token expired\")\n        token = get_token()\n        session.headers.update({\"Authorization\": f\"Bearer {token}\"})\n        r.request.headers[\"Authorization\"] = session.headers[\"Authorization\"]\n        return session.send(r.request, verify=False)\nsession.hooks['response'].append(refresh_token)",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2021-09-17T11:45:35",
        "author": "Yesh"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53290302/how-to-handle-optional-arguments-in-logging-format-strings",
    "title": "How to handle optional arguments in logging format strings?",
    "question_id": 53290302,
    "posted_date": "2018-11-13T17:13:27",
    "answers": [
      {
        "answer_id": 64686328,
        "body": "import logging\nimport re\nclass CustomFormatter(logging.Formatter):\n    def format(self, record: logging.LogRecord) -> str:\n        arg_pattern = re.compile(r'%\\((\\w+)\\)')\n        arg_names = [x.group(1) for x in arg_pattern.finditer(self._fmt)]\n        for field in arg_names:\n            if field not in record.__dict__:\n                record.__dict__[field] = None\n        return super().format(record)\nlogger = logging.getLogger(__name__)\nhandler = logging.StreamHandler()\nformatter = CustomFormatter('{\"message\": \"%(message)s\", \"user\": \"%(user)s\"}')\nhandler.setFormatter(formatter)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(handler)\nlogger.info('hi')\nlogger.info('hi', extra={\"user\": \"asmith\"})",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-11-04T14:13:33",
        "author": "Christopher Peisert"
      },
      {
        "answer_id": 64686328,
        "body": "import logging\nclass ExtraFormatter(logging.Formatter):\n    def format(self, record: logging.LogRecord) -> str:\n        default_attrs = logging.LogRecord(None, None, None, None, None, None, None).__dict__.keys()\n        extras = set(record.__dict__.keys()) - default_attrs\n        log_items = ['\"message\": \"%(message)s\"']\n        for attr in extras:\n            log_items.append(f'\"{attr}\": \"%({attr})s\"')\n        format_str = f'{{{\", \".join(log_items)}}}'\n        self._style._fmt = format_str\n        return super().format(record)\nlogger = logging.getLogger(__name__)\nhandler = logging.StreamHandler()\nformatter = ExtraFormatter()\nhandler.setFormatter(formatter)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(handler)\nlogger.info('hi')\nlogger.info('hi', extra={\"user\": \"asmith\", \"number\": \"42\"})",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-11-04T14:13:33",
        "author": "Christopher Peisert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63110848/how-do-i-send-list-of-dictionary-as-body-parameter-together-with-files-in-fastap",
    "title": "How do I send list of dictionary as Body parameter together with Files in FastAPI?",
    "question_id": 63110848,
    "posted_date": "2020-07-27T03:45:43",
    "answers": [
      {
        "answer_id": 71439821,
        "body": "from fastapi import FastAPI, File, UploadFile, Body, status\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nimport json\napp = FastAPI()\nclass DataModelOut(BaseModel):\n    message: str = None\n    id: str = None\n    input_data: dict = None\n    result: List[dict] = []\n    statusCode: int\n\n\nclass DataModelIn(BaseModel):\n    countryId: str\n    policyDetails: List[dict]\n    leaveTypeId: str\n    branchIds: List[str]\n    cityIds: List[str]\n\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate_to_json\n    @classmethod\n    def validate_to_json(cls, value):\n        if isinstance(value, str):\n            return cls(**json.loads(value))\n        return value\n\n@app.post('/', response_model=DataModelOut)\ndef create_policy_details(data: DataModelIn = Body(...), files: Optional[List[UploadFile]] = File(None)):\n    print('Files received: ', [f.filename for f in files])\n    return {'input_data':data, 'statusCode': status.HTTP_201_CREATED}",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2022-03-11T09:12:50",
        "author": "Chris"
      },
      {
        "answer_id": 71439821,
        "body": "from fastapi import FastAPI, File, UploadFile, Body, status\nfrom pydantic import BaseModel, model_validator\nfrom typing import Optional, List\nimport json\napp = FastAPI()\nclass DataModelOut(BaseModel):\n    message: str = None\n    id: str = None\n    input_data: dict = None\n    result: List[dict] = []\n    statusCode: int\n\n\nclass DataModelIn(BaseModel):\n    countryId: str\n    policyDetails: List[dict]\n    leaveTypeId: str\n    branchIds: List[str]\n    cityIds: List[str]\n    @model_validator(mode='before')\n    @classmethod\n    def validate_to_json(cls, value):\n        if isinstance(value, str):\n            return cls(**json.loads(value))\n        return value\n\n@app.post('/', response_model=DataModelOut)\ndef create_policy_details(data: DataModelIn = Body(...), files: List[UploadFile] = File(...)):\n    print('Files received: ', [f.filename for f in files])\n    return {'input_data': data.model_dump(), 'statusCode': status.HTTP_201_CREATED}",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2022-03-11T09:12:50",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54358287/pass-and-use-input-parameters-to-a-lambda-task-from-a-step-function",
    "title": "Pass and use input (parameters) to a lambda task from a step function",
    "question_id": 54358287,
    "posted_date": "2019-01-24T21:43:04",
    "answers": [
      {
        "answer_id": 59663223,
        "body": "{\n  \"Comment\": \"A Hello World example of the Amazon States Language using an AWS Lambda function\",\n  \"StartAt\": \"HelloWorld\",\n  \"States\": {\n    \"HelloWorld\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:ap-southeast-2:XXXXXXX:function:fields_sync\",\n      \"Next\": \"HelloWorld2\"\n    },\n    \"HelloWorld2\": {\n      \"Type\": \"Task\",\n      \"InputPath\": \"$\",\n      \"ResultPath\": \"$.taskresult\"\n      \"Resource\": \"arn:aws:lambda:ap-southeast-2:XXXXXXX:function:fields_sync_2\",\n      \"End\": true\n    }\n  }\n}",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2020-01-09T06:42:25",
        "author": "N.Nonkovic"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6567724/set-minor-tick-label-spacing-on-a-log-axis-and-change-colorbar-tick-label-size",
    "title": "Set minor tick label spacing on a log axis, and change colorbar tick label size",
    "question_id": 6567724,
    "posted_date": "2011-07-04T01:50:13",
    "answers": [
      {
        "answer_id": 6568248,
        "body": "import numpy as np\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\nx = np.arange(10,3000,100)\ny = np.arange(10,3000,100)\nX,Y = np.meshgrid(x,y)\nZ = np.random.random(X.shape)*8000000\nsurf = ax.contourf(X,Y,Z, 8, cmap=plt.cm.jet)\nax.set_ylabel('Log Frequency (Hz)')\nax.set_xlabel('Log Frequency (Hz)')\nax.set_xscale('log')\nax.set_yscale('log')\nax.xaxis.set_minor_formatter(plt.FormatStrFormatter('%d'))\n# defining custom minor tick locations:\nax.xaxis.set_minor_locator(plt.FixedLocator([50,500,2000]))\nax.yaxis.set_ticks_position('left')\nax.xaxis.set_ticks_position('bottom')\nax.tick_params(axis='both',reset=False,which='both',length=8,width=2)\ncbar = fig.colorbar(surf, shrink=0.5, aspect=20, fraction=.12,pad=.02)\ncbar.set_label('Activation',size=18)\n# access to cbar tick labels:\ncbar.ax.tick_params(labelsize=5)\nplt.show()",
        "score": 159,
        "is_accepted": true,
        "creation_date": "2011-07-04T02:55:48",
        "author": "Paul"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72854116/selenium-attributeerror-webdriver-object-has-no-attribute-find-element-by-cs",
    "title": "Selenium AttributeError: &#39;WebDriver&#39; object has no attribute &#39;find_element_by_css_selector&#39;",
    "question_id": 72854116,
    "posted_date": "2022-07-04T04:56:10",
    "answers": [
      {
        "answer_id": 73816390,
        "body": ".find_element_by_class_name(\n.find_element(By.CLASS_NAME,\n.find_element_by_css_selector(\n.find_element(By.CSS_SELECTOR,\n.find_element_by_id(\n.find_element(By.ID,\n.find_element_by_link_text(\n.find_element(By.LINK_TEXT,\n.find_element_by_name(\n.find_element(By.NAME,\n.find_element_by_partial_link_text(\n.find_element(By.PARTIAL_LINK_TEXT,\n.find_element_by_tag_name(\n.find_element(By.TAG_NAME,\n.find_element_by_xpath(\n.find_element(By.XPATH,\n.find_elements_by_class_name(\n.find_elements(By.CLASS_NAME,\n.find_elements_by_css_selector(\n.find_elements(By.CSS_SELECTOR,\n.find_elements_by_id(\n.find_elements(By.ID,\n.find_elements_by_link_text(\n.find_elements(By.LINK_TEXT,\n.find_elements_by_name(\n.find_elements(By.NAME,\n.find_elements_by_partial_link_text(\n.find_elements(By.PARTIAL_LINK_TEXT,\n.find_elements_by_tag_name(\n.find_elements(By.TAG_NAME,\n.find_elements_by_xpath(\n.find_elements(By.XPATH,",
        "score": 35,
        "is_accepted": false,
        "creation_date": "2022-09-22T10:26:58",
        "author": "Pikamander2"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45440900/throttling-async-functions-in-python-asyncio",
    "title": "Throttling Async Functions in Python Asyncio",
    "question_id": 45440900,
    "posted_date": "2017-08-01T10:41:01",
    "answers": [
      {
        "answer_id": 45502319,
        "body": "import asyncio\nfrom contextlib import AbstractAsyncContextManager\nfrom functools import partial\nfrom heapq import heappop, heappush\nfrom itertools import count\nfrom types import TracebackType\nfrom typing import List, Optional, Tuple, Type\nclass AsyncLimiter(AbstractAsyncContextManager):\n    \"\"\"A leaky bucket rate limiter.\n    This is an :ref:`asynchronous context manager <async-context-managers>`;\n    when used with :keyword:`async with`, entering the context acquires\n    capacity::\n        limiter = AsyncLimiter(10)\n        for foo in bar:\n            async with limiter:\n                # process foo elements at 10 items per minute\n    :param max_rate: Allow up to `max_rate` / `time_period` acquisitions before\n       blocking.\n    :param time_period: duration, in seconds, of the time period in which to\n       limit the rate. Note that up to `max_rate` acquisitions are allowed\n       within this time period in a burst.\n    \"\"\"\n    __slots__ = (\n        \"max_rate\",\n        \"time_period\",\n        \"_rate_per_sec\",\n        \"_level\",\n        \"_last_check\",\n        \"_event_loop\",\n        \"_waiters\",\n        \"_next_count\",\n        \"_waker_handle\",\n    )\n    max_rate: float  #: The configured `max_rate` value for this limiter.\n    time_period: float  #: The configured `time_period` value for this limiter.\n    def __init__(self, max_rate: float, time_period: float = 60) -> None:\n        self.max_rate = max_rate\n        self.time_period = time_period\n        self._rate_per_sec = max_rate / time_period\n        self._level = 0.0\n        self._last_check = 0.0\n        # timer until next waiter can resume\n        self._waker_handle: asyncio.TimerHandle | None = None\n        # min-heap with (amount requested, order, future) for waiting tasks\n        self._waiters: List[Tuple[float, int, \"asyncio.Future[None]\"]] = []\n        # counter used to order waiting tasks\n        self._next_count = partial(next, count())\n    @property\n    def _loop(self) -> asyncio.AbstractEventLoop:\n        self._event_loop: asyncio.AbstractEventLoop\n        try:\n            loop = self._event_loop\n        except AttributeError:\n            loop = self._event_loop = asyncio.get_running_loop()\n        return loop\n    def _leak(self) -> None:\n        \"\"\"Drip out capacity from the bucket.\"\"\"\n        now = self._loop.time()\n        if self._level:\n            # drip out enough level for the elapsed time since\n            # we last checked\n            elapsed = now - self._last_check\n            decrement = elapsed * self._rate_per_sec\n            self._level = max(self._level - decrement, 0)\n        self._last_check = now\n    def has_capacity(self, amount: float = 1) -> bool:\n        \"\"\"Check if there is enough capacity remaining in the limiter\n        :param amount: How much capacity you need to be available.\n        \"\"\"\n        self._leak()\n        return self._level + amount <= self.max_rate\n    async def acquire(self, amount: float = 1) -> None:\n        \"\"\"Acquire capacity in the limiter.\n        If the limit has been reached, blocks until enough capacity has been\n        freed before returning.\n        :param amount: How much capacity you need to be available.\n        :exception: Raises :exc:`ValueError` if `amount` is greater than\n           :attr:`max_rate`.\n        \"\"\"\n        if amount > self.max_rate:\n            raise ValueError(\"Can't acquire more than the maximum capacity\")\n        loop = self._loop\n        while not self.has_capacity(amount):\n            # Add a future to the _waiters heapq to be notified when capacity\n            # has come up. The future callback uses call_soon so other tasks\n            # are checked *after* completing capacity acquisition in this task.\n            fut = loop.create_future()\n            fut.add_done_callback(partial(loop.call_soon, self._wake_next))\n            heappush(self._waiters, (amount, self._next_count(), fut))\n            self._wake_next()\n            await fut\n        self._level += amount\n        # reset the waker to account for the new, lower level.\n        self._wake_next()\n        return None\n    def _wake_next(self, *_args: object) -> None:\n        \"\"\"Wake the next waiting future or set a timer\"\"\"\n        # clear timer and any cancelled futures at the top of the heap\n        heap, handle, self._waker_handle = self._waiters, self._waker_handle, None\n        if handle is not None:\n            handle.cancel()\n        while heap and heap[0][-1].done():\n            heappop(heap)\n        if not heap:\n            # nothing left waiting\n            return\n        amount, _, fut = heap[0]\n        self._leak()\n        needed = amount - self.max_rate + self._level\n        if needed <= 0:\n            heappop(heap)\n            fut.set_result(None)\n            # fut.set_result triggers another _wake_next call\n            return\n        wake_next_at = self._last_check + (1 / self._rate_per_sec * needed)\n        self._waker_handle = self._loop.call_at(wake_next_at, self._wake_next)\n    def __repr__(self) -> str:  # pragma: no cover\n        args = f\"max_rate={self.max_rate!r}, time_period={self.time_period!r}\"\n        state = f\"level: {self._level:f}, waiters: {len(self._waiters)}\"\n        if (handle := self._waker_handle) and not handle.cancelled():\n            microseconds = int((handle.when() - self._loop.time()) * 10**6)\n            if microseconds > 0:\n                state += f\", waking in {microseconds} \\N{MICRO SIGN}s\"\n        return f\"<AsyncLimiter({args}) at {id(self):#x} [{state}]>\"\n    async def __aenter__(self) -> None:\n        await self.acquire()\n        return None\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        return None",
        "score": 74,
        "is_accepted": true,
        "creation_date": "2017-08-04T04:52:14",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69774921/im-using-wsl-how-i-upgrade-python-to-the-last-version-through-the-console",
    "title": "I&#39;m using WSL how I upgrade Python to the last version through the console?",
    "question_id": 69774921,
    "posted_date": "2021-10-29T17:25:13",
    "answers": [
      {
        "answer_id": 74072190,
        "body": "# Update package lists{\nsudo apt update\n# Install dependent libraries:\nsudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libsqlite3-dev libreadline-dev libffi-dev curl libbz2-dev\n# Download Python binary package:\nwget https://www.python.org/ftp/python/3.10.8/Python-3.10.8.tgz\n# Unzip the package:\ntar -xzf Python-3.10.8.tgz\n# Execute configure script\ncd Python-3.10.8\n./configure --enable-optimizations\n# Build Python 3.10\nmake -j 2\n# Install Python 3.10\nsudo make install\n# Verify the installation\npython3.10",
        "score": 50,
        "is_accepted": false,
        "creation_date": "2022-10-14T12:32:13",
        "author": "Chami Mohammed"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43367805/pandas-read-excel-multiple-tables-on-the-same-sheet",
    "title": "pandas read_excel multiple tables on the same sheet",
    "question_id": 43367805,
    "posted_date": "2017-04-12T07:05:12",
    "answers": [
      {
        "answer_id": 57930609,
        "body": "def parse_excel_sheet(file, sheet_name=0, threshold=5):\n    '''parses multiple tables from an excel sheet into multiple data frame objects. Returns [dfs, df_mds], where dfs is a list of data frames and df_mds their potential associated metadata'''\n    xl = pd.ExcelFile(file)\n    entire_sheet = xl.parse(sheet_name=sheet_name)\n    # count the number of non-Nan cells in each row and then the change in that number between adjacent rows\n    n_values = np.logical_not(entire_sheet.isnull()).sum(axis=1)\n    n_values_deltas = n_values[1:] - n_values[:-1].values\n    # define the beginnings and ends of tables using delta in n_values\n    table_beginnings = n_values_deltas > threshold\n    table_beginnings = table_beginnings[table_beginnings].index\n    table_endings = n_values_deltas < -threshold\n    table_endings = table_endings[table_endings].index\n    if len(table_beginnings) < len(table_endings) or len(table_beginnings) > len(table_endings)+1:\n        raise BaseException('Could not detect equal number of beginnings and ends')\n    # look for metadata before the beginnings of tables\n    md_beginnings = []\n    for start in table_beginnings:\n        md_start = n_values.iloc[:start][n_values==0].index[-1] + 1\n        md_beginnings.append(md_start)\n    # make data frames\n    dfs = []\n    df_mds = []\n    for ind in range(len(table_beginnings)):\n        start = table_beginnings[ind]+1\n        if ind < len(table_endings):\n            stop = table_endings[ind]\n        else:\n            stop = entire_sheet.shape[0]\n        df = xl.parse(sheet_name=sheet_name, skiprows=start, nrows=stop-start)\n        dfs.append(df)\n        md = xl.parse(sheet_name=sheet_name, skiprows=md_beginnings[ind], nrows=start-md_beginnings[ind]-1).dropna(axis=1)\n        df_mds.append(md)\n    return dfs, df_mds",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2019-09-13T17:37:05",
        "author": "Rotem"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62287001/how-to-overlay-two-plots-in-same-figure-in-plotly-create-pareto-chart-in-plotl",
    "title": "How to overlay two plots in same figure in plotly ( Create Pareto chart in plotly )?",
    "question_id": 62287001,
    "posted_date": "2020-06-09T12:10:08",
    "answers": [
      {
        "answer_id": 62287397,
        "body": "import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\ntrace1 = go.Bar(\n    x=df[cat],\n    y=df[num],\n    name=num,\n    marker=dict(\n        color='rgb(34,163,192)'\n               )\n)\ntrace2 = go.Scatter(\n    x=df[cat],\n    y=df['cumulative_perc'],\n    name='Cumulative Percentage',\n    yaxis='y2'\n)\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\nfig.add_trace(trace1)\nfig.add_trace(trace2,secondary_y=True)\nfig['layout'].update(height = 600, width = 800, title = title,xaxis=dict(\n      tickangle=-90\n    ))\niplot(fig)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2020-06-09T12:29:04",
        "author": "BhishanPoudel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49851280/showing-a-simple-matplotlib-plot-in-plotly-dash",
    "title": "Showing a simple matplotlib plot in plotly Dash",
    "question_id": 49851280,
    "posted_date": "2018-04-16T03:00:50",
    "answers": [
      {
        "answer_id": 56932297,
        "body": "import io\nimport base64\n...\n\napp.layout = html.Div(children=[\n    ...,\n    html.Img(id='example') # img element\n])\n@app.callback(\n    dash.dependencies.Output('example', 'src'), # src attribute\n    [dash.dependencies.Input('n_points', 'value')]\n)\ndef update_figure(n_points):\n    #create some matplotlib graph\n    x = np.random.rand(n_points)\n    y = np.random.rand(n_points)\n    buf = io.BytesIO() # in-memory files\n    plt.scatter(x, y)\n    plt.savefig(buf, format = \"png\")\n    plt.close()\n    data = base64.b64encode(buf.getbuffer()).decode(\"utf8\") # encode to html elements\n    buf.close()\n    return \"data:image/png;base64,{}\".format(data)",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-07-08T05:47:25",
        "author": "simplyPTA"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42147776/producing-2d-perlin-noise-with-numpy",
    "title": "Producing 2D perlin noise with numpy",
    "question_id": 42147776,
    "posted_date": "2017-02-09T17:05:56",
    "answers": [
      {
        "answer_id": 42154921,
        "body": "import numpy as np\nimport matplotlib.pyplot as plt\ndef perlin(x, y, seed=0):\n    # permutation table\n    np.random.seed(seed)\n    p = np.arange(256, dtype=int)\n    np.random.shuffle(p)\n    p = np.stack([p, p]).flatten()\n    # coordinates of the top-left\n    xi, yi = x.astype(int), y.astype(int)\n    # internal coordinates\n    xf, yf = x - xi, y - yi\n    # fade factors\n    u, v = fade(xf), fade(yf)\n    # noise components\n    n00 = gradient(p[p[xi] + yi], xf, yf)\n    n01 = gradient(p[p[xi] + yi + 1], xf, yf - 1)\n    n11 = gradient(p[p[xi + 1] + yi + 1], xf - 1, yf - 1)\n    n10 = gradient(p[p[xi + 1] + yi], xf - 1, yf)\n    # combine noises\n    x1 = lerp(n00, n10, u)\n    x2 = lerp(n01, n11, u)  # FIX1: I was using n10 instead of n01\n    return lerp(x1, x2, v)  # FIX2: I also had to reverse x1 and x2 here\ndef lerp(a, b, x):\n    \"linear interpolation\"\n    return a + x * (b - a)\ndef fade(t):\n    \"6t^5 - 15t^4 + 10t^3\"\n    return 6 * t**5 - 15 * t**4 + 10 * t**3\ndef gradient(h, x, y):\n    \"grad converts h to the right gradient vector and return the dot product with (x,y)\"\n    vectors = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]])\n    g = vectors[h % 4]\n    return g[:, :, 0] * x + g[:, :, 1] * y\n# EDIT : generating noise at multiple frequencies and adding them up\np = np.zeros((100,100))\nfor i in range(4):\n    freq = 2**i\n    lin = np.linspace(0, freq, 100, endpoint=False)\n    x, y = np.meshgrid(lin, lin)  # FIX3: I thought I had to invert x and y here but it was a mistake\n    p = perlin(x, y, seed=87) / freq + p\nplt.imshow(p, origin='upper')",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2017-02-10T03:40:36",
        "author": "tgirod"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63560005/draw-curved-lines-to-connect-points-in-matplotlib",
    "title": "Draw curved lines to connect points in matplotlib",
    "question_id": 63560005,
    "posted_date": "2020-08-24T07:20:41",
    "answers": [
      {
        "answer_id": 63561363,
        "body": "import matplotlib.pyplot as plt\nfrom matplotlib.path import Path\nimport matplotlib.patches as patches\nimport numpy as np\nn_teams = 4\nn_weeks = 4\nt = np.array([[1, 2, 4, 3],\n              [4, 3, 3, 2],\n              [3, 4, 1, 4],\n              [2, 1, 2, 1]])\nfig, ax = plt.subplots(figsize=(10, 4), facecolor='#1b1b1b')\nax.set_facecolor('#1b1b1b')\nindent = 0.8\nfor tj in t:\n    ax.scatter(np.arange(len(tj)), tj, marker='o', color='#4F535C', s=100, zorder=3)\n    # create bezier curves\n    verts = [(i + d, tij) for i, tij in enumerate(tj) for d in (-indent, 0, indent)][1:-1]\n    codes = [Path.MOVETO] + [Path.CURVE4] * (len(verts) - 1)\n    path = Path(verts, codes)\n    patch = patches.PathPatch(path, facecolor='none', lw=2, edgecolor='#4F535C')\n    ax.add_patch(patch)\nax.set_xticks([])\nax.set_yticks([])\nax.autoscale() # sets the xlim and ylim for the added patches\nplt.show()",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2020-08-24T08:47:07",
        "author": "JohanC"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51556996/do-a-dry-run-of-an-alembic-upgrade",
    "title": "Do a dry-run of an Alembic upgrade",
    "question_id": 51556996,
    "posted_date": "2018-07-27T07:26:40",
    "answers": [
      {
        "answer_id": 59704406,
        "body": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection, target_metadata=target_metadata\n        )\n        with context.begin_transaction():\n            context.run_migrations()",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2020-01-12T08:43:22",
        "author": "Mark Amery"
      },
      {
        "answer_id": 59704406,
        "body": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n        # Ensure the context will create a transaction\n        # for backends that don't normally use transactional DDL.\n        # Note that ROLLBACK will not roll back DDL structures\n        # on databases such as MySQL, as well as with the SQLite\n        # Python driver's default settings.\n        transactional_ddl=True,\n    )\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection, target_metadata=target_metadata\n        )\n        with context.begin_transaction() as transaction:\n            context.run_migrations()\n            if 'dry-run' in context.get_x_argument():\n                print('Dry-run succeeded; now rolling back transaction...')\n                transaction.rollback()",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2020-01-12T08:43:22",
        "author": "Mark Amery"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/724924/how-to-make-pdb-recognize-that-the-source-has-changed-between-runs",
    "title": "How to make pdb recognize that the source has changed between runs?",
    "question_id": 724924,
    "posted_date": "2009-04-07T06:09:09",
    "answers": [
      {
        "answer_id": 23207689,
        "body": "# pdbs.py -\tPDB support\nfrom __future__ import print_function\ndef r():\n    \"\"\"Reload all non-system modules, to reload stuff on pbd restart. \"\"\"\n    import importlib\n    import sys\n    # This is likely to be OS-specific\n    SYS_PREFIX = '/usr/lib'\n    for k, v in list(sys.modules.items()):\n        if (\n            k == \"__main__\" or\n            k.startswith(\"pdb\") or\n            not getattr(v, \"__file__\", None)\n            or v.__file__.startswith(SYS_PREFIX)\n        ):\n            continue\n        print(\"reloading %s [%s]\" % (k, v.__file__), file=sys.stderr)\n        importlib.reload(v)",
        "score": 7,
        "is_accepted": false,
        "creation_date": "2014-04-21T19:22:56",
        "author": "pourhaus"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62376164/how-to-change-max-iter-in-optimize-function-used-by-sklearn-gaussian-process-reg",
    "title": "How to change max_iter in optimize function used by sklearn gaussian process regression?",
    "question_id": 62376164,
    "posted_date": "2020-06-14T13:45:56",
    "answers": [
      {
        "answer_id": 62380182,
        "body": "from functools import partial\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nimport scipy.optimize\nclass MyGPR(GaussianProcessRegressor):\n    def __init__(self, *args, max_iter=15000, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._max_iter = max_iter\n    def _constrained_optimization(self, obj_func, initial_theta, bounds):\n        def new_optimizer(obj_func, initial_theta, bounds):\n            return scipy.optimize.minimize(\n                obj_func,\n                initial_theta,\n                method=\"L-BFGS-B\",\n                jac=True,\n                bounds=bounds,\n                max_iter=self._max_iter,\n            )\n        self.optimizer = new_optimizer\n        return super()._constrained_optimization(obj_func, initial_theta, bounds)",
        "score": 7,
        "is_accepted": true,
        "creation_date": "2020-06-14T21:45:28",
        "author": "bnaecker"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/38000993/how-can-i-get-my-assertions-in-pytest-to-stop-being-abbreviated-with-ellipsis",
    "title": "How can I get my assertions in pytest to stop being abbreviated with ellipsis?",
    "question_id": 38000993,
    "posted_date": "2016-06-23T16:15:19",
    "answers": [
      {
        "answer_id": 64073841,
        "body": "========================================================== FAILURES ===========================================================\n______________________________________________ test_truncated_exception_message _______________________________________________\n    def test_truncated_exception_message():\n        with raises(Exception) as exception_info:\n            raise ValueError(\"a\"*1024)\n\n        exception_str = str(exception_info.value)\n>       assert problem_function(\"a\"*1024, exception_str)\nE       AssertionError: assert False\nE        +  where False = problem_function(('a' * 1024), 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\nexception_info = <ExceptionInfo ValueError('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa') tblen=1>\nexception_str = 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\naaaaa'\nbeartype_test/unit/pep/p484/test_p484.py:39: AssertionError",
        "score": 9,
        "is_accepted": true,
        "creation_date": "2020-09-26T00:18:31",
        "author": "Cecil Curry"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72779926/gunicorn-cuda-cannot-re-initialize-cuda-in-forked-subprocess",
    "title": "GUnicorn + CUDA: Cannot re-initialize CUDA in forked subprocess",
    "question_id": 72779926,
    "posted_date": "2022-06-27T21:53:38",
    "answers": [
      {
        "answer_id": 75308606,
        "body": "import time\nimport torch\nimport torch.multiprocessing as mp\ndef f(q):\n    y = q.get()\n    y[0] = 1000\ndef g(q):\n    x = torch.zeros(1).cuda()\n    x.share_memory_()\n    q.put(x)\n    q.put(x)\n    while True:\n        time.sleep(1)  # this process must live as long as x is in use\nif __name__ == '__main__':\n    queue = mp.Queue()\n    pf = mp.Process(target=f, args=(queue,), daemon=True)\n    pf.start()\n    pg = mp.Process(target=g, args=(queue,), daemon=True)\n    pg.start()\n    pf.join()\n    x = queue.get()\n    print(\"x =\", x.item())  # Prints x = 1000.0",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2023-02-01T05:14:57",
        "author": "Green \u7eff\u8272"
      },
      {
        "answer_id": 75308606,
        "body": "import logging\nimport os\nfrom torch.multiprocessing.reductions import ForkingPickler\nimport zmq\ndef request_model(zmq_url: str):\n    logging.info(\"Connecting\")\n    context = zmq.Context()\n    with context.socket(zmq.REQ) as socket:\n        socket.connect(zmq_url)\n        logging.info(\"Sending request\")\n        socket.send(ForkingPickler.dumps(os.getpid()))\n        logging.info(\"Waiting for a response\")\n        model = ForkingPickler.loads(socket.recv())\n    logging.info(\"Got response from object server\")\n    return model",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2023-02-01T05:14:57",
        "author": "Green \u7eff\u8272"
      },
      {
        "answer_id": 75308606,
        "body": "from argparse import ArgumentParser\nimport logging\nimport torch\nfrom torch.multiprocessing.reductions import ForkingPickler\nimport zmq\ndef load_model():\n    model = torch.nn.Linear(10000, 50000)\n    model.cuda()\n    model.share_memory()\n    counter = torch.zeros(1).cuda()\n    counter.share_memory_()\n    return model, counter\ndef share_object(obj, url):\n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    socket.bind(url)\n    while True:\n        logging.info(\"Waiting for requests on %s\", url)\n        message = socket.recv()\n        logging.info(\"Got a message from %d\", ForkingPickler.loads(message))\n        socket.send(ForkingPickler.dumps(obj))\nif __name__ == '__main__':\n    parser = ArgumentParser(description=\"Serve model\")\n    parser.add_argument(\"--listen-address\", default=\"tcp://127.0.0.1:5555\")\n    args = parser.parse_args()\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Loading model\")\n    model = load_model()\n    share_object(model, args.listen_address)",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2023-02-01T05:14:57",
        "author": "Green \u7eff\u8272"
      },
      {
        "answer_id": 75308606,
        "body": "$ python server.py &\nINFO:root:Waiting for requests on tcp://127.0.0.1:5555\n$ gunicorn -c config.py app:app\n[2023-02-01 16:45:34 +0800] [24113] [INFO] Starting gunicorn 20.1.0\n[2023-02-01 16:45:34 +0800] [24113] [INFO] Listening at: http://127.0.0.1:8080 (24113)\n[2023-02-01 16:45:34 +0800] [24113] [INFO] Using worker: sync\n[2023-02-01 16:45:34 +0800] [24186] [INFO] Booting worker with pid: 24186\nINFO:root:Connecting\nINFO:root:Sending request\nINFO:root:Waiting for a response\nINFO:root:Got response from object server",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2023-02-01T05:14:57",
        "author": "Green \u7eff\u8272"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43292197/can-python-implement-dependent-types",
    "title": "Can Python implement dependent types?",
    "question_id": 43292197,
    "posted_date": "2017-04-08T05:10:30",
    "answers": [
      {
        "answer_id": 60014630,
        "body": "class Integer:\n    def __init__(self, value):\n        self.value = int(value)\n        self.set_class()\n\n    def set_class(self):\n        if self.value < 10:\n            self.__class__ = LessThanTen\n        else:\n            self.__class__ = TenOrMore\n\n    def add(self, value):\n        self.value += int(value)\n        self.set_class()\n\nclass TenOrMore(Integer):\n    def __init__(self):\n        pass\n        raise ValueError(\"Use Integer()\")\n\nclass LessThanTen(Integer):\n    def __init__(self):\n        raise ValueError(\"Use Integer()\")",
        "score": 5,
        "is_accepted": false,
        "creation_date": "2020-02-01T01:33:46",
        "author": "David Slater"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52558519/bluez-profile-registration",
    "title": "Bluez Profile Registration",
    "question_id": 52558519,
    "posted_date": "2018-09-28T11:30:04",
    "answers": [
      {
        "answer_id": 62881439,
        "body": "\"\"\"\nBluetooth HID keyboard emulator DBUS Service\nOriginal idea taken from:\nhttp://yetanotherpointlesstechblog.blogspot.com/2016/04/emulating-bluetooth-keyboard-with.html\nMoved to Python 3 and tested with BlueZ 5.43\nUpdates documented at:\nhttps://gist.github.com/ukBaz/a47e71e7b87fbc851b27cde7d1c0fcf0\n\"\"\"\nimport os\nimport sys\nimport dbus\nimport dbus.service\nimport socket\nfrom gi.repository import GLib\nfrom dbus.mainloop.glib import DBusGMainLoop\nclass HumanInterfaceDeviceProfile(dbus.service.Object):\n    \"\"\"\n    BlueZ D-Bus Profile for HID\n    \"\"\"\n    fd = -1\n    @dbus.service.method('org.bluez.Profile1',\n                         in_signature='', out_signature='')\n    def Release(self):\n            print('Release')\n            mainloop.quit()\n    @dbus.service.method('org.bluez.Profile1',\n                         in_signature='oha{sv}', out_signature='')\n    def NewConnection(self, path, fd, properties):\n            self.fd = fd.take()\n            print('NewConnection({}, {})'.format(path, self.fd))\n            for key in properties.keys():\n                    if key == 'Version' or key == 'Features':\n                            print('  {} = 0x{:04x}'.format(key,\n                                                           properties[key]))\n                    else:\n                            print('  {} = {}'.format(key, properties[key]))\n    @dbus.service.method('org.bluez.Profile1',\n                         in_signature='o', out_signature='')\n    def RequestDisconnection(self, path):\n            print('RequestDisconnection {}'.format(path))\n            if self.fd > 0:\n                    os.close(self.fd)\n                    self.fd = -1\nclass BTKbDevice:\n    \"\"\"\n    create a bluetooth device to emulate a HID keyboard\n    \"\"\"\n    MY_DEV_NAME = 'BT_HID_Keyboard'\n    # Service port - must match port configured in SDP record\n    P_CTRL = 17\n    # Service port - must match port configured in SDP record#Interrrupt port\n    P_INTR = 19\n    # BlueZ dbus\n    PROFILE_DBUS_PATH = '/bluez/yaptb/btkb_profile'\n    ADAPTER_IFACE = 'org.bluez.Adapter1'\n    DEVICE_INTERFACE = 'org.bluez.Device1'\n    DBUS_PROP_IFACE = 'org.freedesktop.DBus.Properties'\n    DBUS_OM_IFACE = 'org.freedesktop.DBus.ObjectManager'\n    # file path of the sdp record to laod\n    install_dir  = os.path.dirname(os.path.realpath(__file__))\n    SDP_RECORD_PATH = os.path.join(install_dir,\n                                   'sdp_record.xml')\n    # UUID for HID service (1124)\n    # https://www.bluetooth.com/specifications/assigned-numbers/service-discovery\n    UUID = '00001124-0000-1000-8000-00805f9b34fb'\n    def __init__(self, hci=0):\n        self.scontrol = None\n        self.ccontrol = None  # Socket object for control\n        self.sinterrupt = None\n        self.cinterrupt = None  # Socket object for interrupt\n        self.dev_path = '/org/bluez/hci{}'.format(hci)\n        print('Setting up BT device')\n        self.bus = dbus.SystemBus()\n        self.adapter_methods = dbus.Interface(\n            self.bus.get_object('org.bluez',\n                                self.dev_path),\n            self.ADAPTER_IFACE)\n        self.adapter_property = dbus.Interface(\n            self.bus.get_object('org.bluez',\n                                self.dev_path),\n            self.DBUS_PROP_IFACE)\n        self.bus.add_signal_receiver(self.interfaces_added,\n                                     dbus_interface=self.DBUS_OM_IFACE,\n                                     signal_name='InterfacesAdded')\n        self.bus.add_signal_receiver(self._properties_changed,\n                                     dbus_interface=self.DBUS_PROP_IFACE,\n                                     signal_name='PropertiesChanged',\n                                     arg0=self.DEVICE_INTERFACE,\n                                     path_keyword='path')\n        print('Configuring for name {}'.format(BTKbDevice.MY_DEV_NAME))\n        self.config_hid_profile()\n        # set the Bluetooth device configuration\n        self.alias = BTKbDevice.MY_DEV_NAME\n        self.discoverabletimeout = 0\n        self.discoverable = True\n    def interfaces_added(self):\n        pass\n    def _properties_changed(self, interface, changed, invalidated, path):\n        if self.on_disconnect is not None:\n            if 'Connected' in changed:\n                if not changed['Connected']:\n                    self.on_disconnect()\n    def on_disconnect(self):\n        print('The client has been disconnect')\n        self.listen()\n    @property\n    def address(self):\n        \"\"\"Return the adapter MAC address.\"\"\"\n        return self.adapter_property.Get(self.ADAPTER_IFACE,\n                                         'Address')\n    @property\n    def powered(self):\n        \"\"\"\n        power state of the Adapter.\n        \"\"\"\n        return self.adapter_property.Get(self.ADAPTER_IFACE, 'Powered')\n    @powered.setter\n    def powered(self, new_state):\n        self.adapter_property.Set(self.ADAPTER_IFACE, 'Powered', new_state)\n    @property\n    def alias(self):\n        return self.adapter_property.Get(self.ADAPTER_IFACE,\n                                         'Alias')\n    @alias.setter\n    def alias(self, new_alias):\n        self.adapter_property.Set(self.ADAPTER_IFACE,\n                                  'Alias',\n                                  new_alias)\n    @property\n    def discoverabletimeout(self):\n        \"\"\"Discoverable timeout of the Adapter.\"\"\"\n        return self.adapter_props.Get(self.ADAPTER_IFACE,\n                                      'DiscoverableTimeout')\n    @discoverabletimeout.setter\n    def discoverabletimeout(self, new_timeout):\n        self.adapter_property.Set(self.ADAPTER_IFACE,\n                                  'DiscoverableTimeout',\n                                  dbus.UInt32(new_timeout))\n    @property\n    def discoverable(self):\n        \"\"\"Discoverable state of the Adapter.\"\"\"\n        return self.adapter_props.Get(\n            self.ADAPTER_INTERFACE, 'Discoverable')\n    @discoverable.setter\n    def discoverable(self, new_state):\n        self.adapter_property.Set(self.ADAPTER_IFACE,\n                                  'Discoverable',\n                                  new_state)\n    def config_hid_profile(self):\n        \"\"\"\n        Setup and register HID Profile\n        \"\"\"\n        print('Configuring Bluez Profile')\n        service_record = self.read_sdp_service_record()\n        opts = {\n            'Role': 'server',\n            'RequireAuthentication': False,\n            'RequireAuthorization': False,\n            'AutoConnect': True,\n            'ServiceRecord': service_record,\n        }\n        manager = dbus.Interface(self.bus.get_object('org.bluez',\n                                                     '/org/bluez'),\n                                 'org.bluez.ProfileManager1')\n        HumanInterfaceDeviceProfile(self.bus,\n                                    BTKbDevice.PROFILE_DBUS_PATH)\n        manager.RegisterProfile(BTKbDevice.PROFILE_DBUS_PATH,\n                                BTKbDevice.UUID,\n                                opts)\n        print('Profile registered ')\n    @staticmethod\n    def read_sdp_service_record():\n        \"\"\"\n        Read and return SDP record from a file\n        :return: (string) SDP record\n        \"\"\"\n        print('Reading service record')\n        try:\n            fh = open(BTKbDevice.SDP_RECORD_PATH, 'r')\n        except OSError:\n            sys.exit('Could not open the sdp record. Exiting...')\n        return fh.read()\n    def listen(self):\n        \"\"\"\n        Listen for connections coming from HID client\n        \"\"\"\n        print('Waiting for connections')\n        self.scontrol = socket.socket(socket.AF_BLUETOOTH,\n                                      socket.SOCK_SEQPACKET,\n                                      socket.BTPROTO_L2CAP)\n        self.scontrol.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.sinterrupt = socket.socket(socket.AF_BLUETOOTH,\n                                        socket.SOCK_SEQPACKET,\n                                        socket.BTPROTO_L2CAP)\n        self.sinterrupt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.scontrol.bind((self.address, self.P_CTRL))\n        self.sinterrupt.bind((self.address, self.P_INTR))\n        # Start listening on the server sockets\n        self.scontrol.listen(1)  # Limit of 1 connection\n        self.sinterrupt.listen(1)\n        self.ccontrol, cinfo = self.scontrol.accept()\n        print('{} connected on the control socket'.format(cinfo[0]))\n        self.cinterrupt, cinfo = self.sinterrupt.accept()\n        print('{} connected on the interrupt channel'.format(cinfo[0]))\n    def send(self, msg):\n        \"\"\"\n        Send HID message\n        :param msg: (bytes) HID packet to send\n        \"\"\"\n        self.cinterrupt.send(bytes(bytearray(msg)))\nclass BTKbService(dbus.service.Object):\n    \"\"\"\n    Setup of a D-Bus service to recieve HID messages from other\n    processes.\n    Send the recieved HID messages to the Bluetooth HID server to send\n    \"\"\"\n    def __init__(self):\n        print('Setting up service')\n        bus_name = dbus.service.BusName('org.yaptb.btkbservice',\n                                        bus=dbus.SystemBus())\n        dbus.service.Object.__init__(self, bus_name, '/org/yaptb/btkbservice')\n        # create and setup our device\n        self.device = BTKbDevice()\n        # start listening for socket connections\n        self.device.listen()\n    @dbus.service.method('org.yaptb.btkbservice',\n                         in_signature='ay')\n    def send_keys(self, cmd):\n        self.device.send(cmd)\nif __name__ == '__main__':\n    # The sockets require root permission\n    if not os.geteuid() == 0:\n        sys.exit('Only root can run this script')\n    DBusGMainLoop(set_as_default=True)\n    myservice = BTKbService()\n    mainloop = GLib.MainLoop()\n    mainloop.run()",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2020-07-13T13:48:55",
        "author": "ukBaz"
      },
      {
        "answer_id": 62881439,
        "body": "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<record>\n\t<attribute id=\"0x0001\">\n\t\t<sequence>\n\t\t\t<uuid value=\"0x1124\" />\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0004\">\n\t\t<sequence>\n\t\t\t<sequence>\n\t\t\t\t<uuid value=\"0x0100\" />\n\t\t\t\t<uint16 value=\"0x0011\" />\n\t\t\t</sequence>\n\t\t\t<sequence>\n\t\t\t\t<uuid value=\"0x0011\" />\n\t\t\t</sequence>\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0005\">\n\t\t<sequence>\n\t\t\t<uuid value=\"0x1002\" />\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0006\">\n\t\t<sequence>\n\t\t\t<uint16 value=\"0x656e\" />\n\t\t\t<uint16 value=\"0x006a\" />\n\t\t\t<uint16 value=\"0x0100\" />\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0009\">\n\t\t<sequence>\n\t\t\t<sequence>\n\t\t\t\t<uuid value=\"0x1124\" />\n\t\t\t\t<uint16 value=\"0x0100\" />\n\t\t\t</sequence>\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x000d\">\n\t\t<sequence>\n\t\t\t<sequence>\n\t\t\t\t<sequence>\n\t\t\t\t\t<uuid value=\"0x0100\" />\n\t\t\t\t\t<uint16 value=\"0x0013\" />\n\t\t\t\t</sequence>\n\t\t\t\t<sequence>\n\t\t\t\t\t<uuid value=\"0x0011\" />\n\t\t\t\t</sequence>\n\t\t\t</sequence>\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0100\">\n\t\t<text value=\"Raspberry Pi Virtual Keyboard\" />\n\t</attribute>\n\t<attribute id=\"0x0101\">\n\t\t<text value=\"USB > BT Keyboard\" />\n\t</attribute>\n\t<attribute id=\"0x0102\">\n\t\t<text value=\"Raspberry Pi\" />\n\t</attribute>\n\t<attribute id=\"0x0200\">\n\t\t<uint16 value=\"0x0100\" />\n\t</attribute>\n\t<attribute id=\"0x0201\">\n\t\t<uint16 value=\"0x0111\" />\n\t</attribute>\n\t<attribute id=\"0x0202\">\n\t\t<uint8 value=\"0x40\" />\n\t</attribute>\n\t<attribute id=\"0x0203\">\n\t\t<uint8 value=\"0x00\" />\n\t</attribute>\n\t<attribute id=\"0x0204\">\n\t\t<boolean value=\"false\" />\n\t</attribute>\n\t<attribute id=\"0x0205\">\n\t\t<boolean value=\"false\" />\n\t</attribute>\n\t<attribute id=\"0x0206\">\n\t\t<sequence>\n\t\t\t<sequence>\n\t\t\t\t<uint8 value=\"0x22\" />\n\t\t\t\t<text encoding=\"hex\" value=\"05010906a101850175019508050719e029e715002501810295017508810395057501050819012905910295017503910395067508150026ff000507190029ff8100c0050c0901a1018503150025017501950b0a23020a21020ab10109b809b609cd09b509e209ea09e9093081029501750d8103c0\" />\n\t\t\t</sequence>\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x0207\">\n\t\t<sequence>\n\t\t\t<sequence>\n\t\t\t\t<uint16 value=\"0x0409\" />\n\t\t\t\t<uint16 value=\"0x0100\" />\n\t\t\t</sequence>\n\t\t</sequence>\n\t</attribute>\n\t<attribute id=\"0x020b\">\n\t\t<uint16 value=\"0x0100\" />\n\t</attribute>\n\t<attribute id=\"0x020c\">\n\t\t<uint16 value=\"0x0c80\" />\n\t</attribute>\n\t<attribute id=\"0x020d\">\n\t\t<boolean value=\"true\" />\n\t</attribute>\n\t<attribute id=\"0x020e\">\n\t\t<boolean value=\"false\" />\n\t</attribute>\n\t<attribute id=\"0x020f\">\n\t\t<uint16 value=\"0x0640\" />\n\t</attribute>\n\t<attribute id=\"0x0210\">\n\t\t<uint16 value=\"0x0320\" />\n\t</attribute>\n</record>",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2020-07-13T13:48:55",
        "author": "ukBaz"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62759748/downloading-data-from-a-shared-google-drive-link-in-google-colab",
    "title": "Downloading data from a shared google drive link in google colab",
    "question_id": 62759748,
    "posted_date": "2020-07-06T11:51:58",
    "answers": [
      {
        "answer_id": 62767559,
        "body": "# Install the PyDrive wrapper & import libraries.\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n# Authenticate and create the PyDrive client.\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\nfile_id = '1cUaIEd9-MLJHFGjLz5QziNvfBtYygplX'\ndownloaded = drive.CreateFile({'id':file_id})\ndownloaded.FetchMetadata(fetch_all=True)\ndownloaded.GetContentFile(downloaded.metadata['title'])",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2020-07-06T23:09:03",
        "author": "korakot"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/19227724/check-if-a-function-uses-classmethod",
    "title": "Check if a function uses @classmethod",
    "question_id": 19227724,
    "posted_date": "2013-10-07T10:40:55",
    "answers": [
      {
        "answer_id": 19228282,
        "body": ">>> class notclassmethod:\n...     def __init__(self, f):\n...         self.f = f\n...     def __get__(self, _, typ=None):\n...         return self.f.__get__(typ, typ)\n...\n>>> class Base:\n...     @classmethod\n...     def base_cm(cls): pass\n...     @notclassmethod\n...     def base_ncm(cls): pass\n...     def base_m(self): pass\n...\n>>> class Derived(Base):\n...     @classmethod\n...     def derived_cm(cls): pass\n...     @notclassmethod\n...     def derived_ncm(cls): pass\n...     def derived_m(self): pass\n...\n>>> inspect.ismethod(Derived.base_cm) and Derived.base_cm.__self__ is Derived\nTrue\n>>> inspect.ismethod(Derived.base_ncm) and Derived.base_ncm.__self__ is Derived\nTrue\n>>> inspect.ismethod(Derived.base_m) and Derived.base_m.__self__ is Derived\nFalse\n>>> inspect.ismethod(Derived.derived_cm) and Derived.derived_cm.__self__ is Derived\nTrue\n>>> inspect.ismethod(Derived.derived_ncm) and Derived.derived_ncm.__self__ is Derived\nTrue\n>>> inspect.ismethod(Derived.derived_m) and Derived.derived_m.__self__ is Derived\nFalse\n>>> isclassmethod(Derived.base_cm)\nTrue\n>>> isclassmethod(Derived.base_ncm)\nFalse\n>>> isclassmethod(Derived.base_m)\nFalse\n>>> isclassmethod(Derived.derived_cm)\nTrue\n>>> isclassmethod(Derived.derived_ncm)\nFalse\n>>> isclassmethod(Derived.derived_m)\nFalse",
        "score": 40,
        "is_accepted": true,
        "creation_date": "2013-10-07T11:05:28",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52795561/flattening-nested-json-in-pandas-data-frame",
    "title": "flattening nested Json in pandas data frame",
    "question_id": 52795561,
    "posted_date": "2018-10-13T13:33:23",
    "answers": [
      {
        "answer_id": 57334325,
        "body": "def flatten_json(nested_json, exclude=['']):\n    \"\"\"Flatten json object with nested keys into a single level.\n        Args:\n            nested_json: A nested json object.\n            exclude: Keys to exclude from output.\n        Returns:\n            The flattened json object if successful, None otherwise.\n    \"\"\"\n    out = {}\n    def flatten(x, name='', exclude=exclude):\n        if type(x) is dict:\n            for a in x:\n                if a not in exclude: flatten(x[a], name + a + '_')\n        elif type(x) is list:\n            i = 0\n            for a in x:\n                flatten(a, name + str(i) + '_')\n                i += 1\n        else:\n            out[name[:-1]] = x\n    flatten(nested_json)\n    return out",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2019-08-02T19:11:13",
        "author": "rrcal"
      },
      {
        "answer_id": 57334325,
        "body": "this_dict = {'events': [\n  {'id': 142896214,\n   'playerId': 37831,\n   'teamId': 3157,\n   'matchId': 2214569,\n   'matchPeriod': '1H',\n   'eventSec': 0.8935539999999946,\n   'eventId': 8,\n   'eventName': 'Pass',\n   'subEventId': 85,\n   'subEventName': 'Simple pass',\n   'positions': [{'x': 51, 'y': 49}, {'x': 40, 'y': 53}],\n   'tags': [{'id': 1801, 'tag': {'label': 'accurate'}}]},\n {'id': 142896214,\n   'playerId': 37831,\n   'teamId': 3157,\n   'matchId': 2214569,\n   'matchPeriod': '1H',\n   'eventSec': 0.8935539999999946,\n   'eventId': 8,\n   'eventName': 'Pass',\n   'subEventId': 85,\n   'subEventName': 'Simple pass',\n   'positions': [{'x': 51, 'y': 49}, {'x': 40, 'y': 53},{'x': 51, 'y': 49}],\n   'tags': [{'id': 1801, 'tag': {'label': 'accurate'}}]}\n]}",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2019-08-02T19:11:13",
        "author": "rrcal"
      },
      {
        "answer_id": 57334325,
        "body": "pd.DataFrame([flatten_json(x) for x in this_dict['events']])\nOut[1]:\n          id  playerId  teamId  matchId matchPeriod  eventSec  eventId  \\\n0  142896214     37831    3157  2214569          1H  0.893554        8\n1  142896214     37831    3157  2214569          1H  0.893554        8\n  eventName  subEventId subEventName  positions_0_x  positions_0_y  \\\n0      Pass          85  Simple pass             51             49\n1      Pass          85  Simple pass             51             49\n   positions_1_x  positions_1_y  tags_0_id tags_0_tag_label  positions_2_x  \\\n0             40             53       1801         accurate            NaN\n1             40             53       1801         accurate           51.0\n   positions_2_y\n0            NaN\n1           49.0",
        "score": 41,
        "is_accepted": true,
        "creation_date": "2019-08-02T19:11:13",
        "author": "rrcal"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16024677/generate-correlated-data-in-python-3-3",
    "title": "Generate correlated data in Python (3.3)",
    "question_id": 16024677,
    "posted_date": "2013-04-15T17:05:54",
    "answers": [
      {
        "answer_id": 16026231,
        "body": "import numpy as np\nimport matplotlib.pyplot as plt\nnum_samples = 400\n# The desired mean values of the sample.\nmu = np.array([5.0, 0.0, 10.0])\n# The desired covariance matrix.\nr = np.array([\n        [  3.40, -2.75, -2.00],\n        [ -2.75,  5.50,  1.50],\n        [ -2.00,  1.50,  1.25]\n    ])\n# Generate the random samples.\nrng = np.random.default_rng()\ny = rng.multivariate_normal(mu, r, size=num_samples)\n# Plot various projections of the samples.\nplt.subplot(2,2,1)\nplt.plot(y[:,0], y[:,1], 'b.', alpha=0.25)\nplt.plot(mu[0], mu[1], 'ro', ms=3.5)\nplt.ylabel('y[1]')\nplt.axis('equal')\nplt.grid(True)\nplt.subplot(2,2,3)\nplt.plot(y[:,0], y[:,2], 'b.', alpha=0.25)\nplt.plot(mu[0], mu[2], 'ro', ms=3.5)\nplt.xlabel('y[0]')\nplt.ylabel('y[2]')\nplt.axis('equal')\nplt.grid(True)\nplt.subplot(2,2,4)\nplt.plot(y[:,1], y[:,2], 'b.', alpha=0.25)\nplt.plot(mu[1], mu[2], 'ro', ms=3.5)\nplt.xlabel('y[1]')\nplt.axis('equal')\nplt.grid(True)\nplt.show()",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2013-04-15T19:20:07",
        "author": "Warren Weckesser"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69183922/playwright-auto-scroll-to-bottom-of-infinite-scroll-page",
    "title": "Playwright auto-scroll to bottom of infinite-scroll page",
    "question_id": 69183922,
    "posted_date": "2021-09-14T16:02:57",
    "answers": [
      {
        "answer_id": 69193325,
        "body": "page.evaluate(\n    \"\"\"\n    var intervalID = setInterval(function () {\n        var scrollingElement = (document.scrollingElement || document.body);\n        scrollingElement.scrollTop = scrollingElement.scrollHeight;\n    }, 200);\n    \"\"\"\n)\nprev_height = None\nwhile True:\n    curr_height = page.evaluate('(window.innerHeight + window.scrollY)')\n    if not prev_height:\n        prev_height = curr_height\n        time.sleep(1)\n    elif prev_height == curr_height:\n        page.evaluate('clearInterval(intervalID)')\n        break\n    else:\n        prev_height = curr_height\n        time.sleep(1)",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2021-09-15T08:39:45",
        "author": "alex_bits"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4040605/does-anyone-have-good-examples-of-using-mutagen-to-write-to-files",
    "title": "Does anyone have good examples of using mutagen to write to files?",
    "question_id": 4040605,
    "posted_date": "2010-10-28T03:13:03",
    "answers": [
      {
        "answer_id": 14040318,
        "body": "from pathlib import Path\nfrom mutagen.mp3 import HeaderNotFoundError\nfrom mutagen.id3 import Encoding, ID3NoHeaderError, ID3, TIT2, TALB, TPE1, TPE2, COMM, TCOM, TCON, TDRC, TRCK\n# Read the ID3 tag or create one if not present\naudio_path = Path('/path/to/Music/audio.mp3')\nwith audio_path.open(mode='rb') as fib:\n    try:\n        tags = ID3(fib)\n        print(f'BEFORE:\\n\\n{tags.pprint()}')\n    except (ID3NoHeaderError, HeaderNotFoundError):\n        print(\"Adding ID3 header..\")\n        tags = ID3(audio_path)\n    tags[\"TIT2\"] = TIT2(encoding=Encoding.UTF16BE, text='mutagen Title')\n    tags[\"TALB\"] = TALB(encoding=Encoding.UTF16BE, text='mutagen Album Name 2025')\n    tags[\"TPE2\"] = TPE2(encoding=Encoding.UTF16BE, text='mutagen Band')\n    tags[\"COMM\"] = COMM(encoding=Encoding.UTF16BE, lang='eng', desc='desc', text='mutagen comment')\n    tags[\"TPE1\"] = TPE1(encoding=Encoding.UTF16BE, text='mutagen Artist')\n    tags[\"TCOM\"] = TCOM(encoding=Encoding.UTF16BE, text='mutagen Composer')\n    tags[\"TCON\"] = TCON(encoding=Encoding.UTF16BE, text='mutagen Genre')\n    tags[\"TDRC\"] = TDRC(encoding=Encoding.UTF16BE, text='2010')\n    tags[\"TRCK\"] = TRCK(encoding=Encoding.UTF16BE, text='track_number')\n    tags.save(audio_path)\n    print(f'\\n\\nAFTER:\\n\\n{tags.pprint()}')",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2012-12-26T07:02:58",
        "author": "ccpizza"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44374215/how-do-i-specify-url-resolution-in-pythons-requests-library-in-a-similar-fashio",
    "title": "How do I specify URL resolution in python&#39;s requests library in a similar fashion to curl&#39;s --resolve flag?",
    "question_id": 44374215,
    "posted_date": "2017-06-05T13:16:13",
    "answers": [
      {
        "answer_id": 60751327,
        "body": "import socket\ndns_cache = {}\n# Capture a dict of hostname and their IPs to override with\ndef override_dns(domain, ip):\n    dns_cache[domain] = ip\nprv_getaddrinfo = socket.getaddrinfo\n# Override default socket.getaddrinfo() and pass ip instead of host\n# if override is detected\ndef new_getaddrinfo(*args):\n    if args[0] in dns_cache:\n        print(\"Forcing FQDN: {} to IP: {}\".format(args[0], dns_cache[args[0]]))\n        return prv_getaddrinfo(dns_cache[args[0]], *args[1:])\n    else:\n        return prv_getaddrinfo(*args)\nsocket.getaddrinfo = new_getaddrinfo",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2020-03-19T01:21:56",
        "author": "dhul.takker"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48673402/how-can-i-standardize-only-numeric-variables-in-an-sklearn-pipeline",
    "title": "How can I standardize only numeric variables in an sklearn pipeline?",
    "question_id": 48673402,
    "posted_date": "2018-02-07T16:18:02",
    "answers": [
      {
        "answer_id": 48673850,
        "body": "# Author: Pedro Morales <part.morales@gmail.com>\n#\n# License: BSD 3 clause\nimport numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nnp.random.seed(0)\n# Load data from https://www.openml.org/d/40945\nX, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2018-02-07T16:50:44",
        "author": "MaxU - stand with Ukraine"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54181163/fasttext-embeddings-sentence-vectors",
    "title": "fastText embeddings sentence vectors?",
    "question_id": 54181163,
    "posted_date": "2019-01-14T07:01:48",
    "answers": [
      {
        "answer_id": 56289476,
        "body": "def l2_norm(x):\n   return np.sqrt(np.sum(x**2))\ndef div_norm(x):\n   norm_value = l2_norm(x)\n   if norm_value > 0:\n       return x * ( 1.0 / norm_value)\n   else:\n       return x\n# Getting word vectors for 'one' and 'two'.\none = model.get_word_vector('yksi')\ntwo = model.get_word_vector('kaksi')\neos = model.get_word_vector('\\n')\n# Getting the sentence vector for the sentence \"one two\" in Finnish.\none_two = model.get_sentence_vector('yksi kaksi')\none_two_avg = (div_norm(one) + div_norm(two) + div_norm(eos)) / 3",
        "score": 31,
        "is_accepted": false,
        "creation_date": "2019-05-24T05:16:39",
        "author": "malioboro"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43009566/skip-forbidden-parameter-combinations-when-using-gridsearchcv",
    "title": "Skip forbidden parameter combinations when using GridSearchCV",
    "question_id": 43009566,
    "posted_date": "2017-03-24T17:37:51",
    "answers": [
      {
        "answer_id": 43010440,
        "body": "from sklearn import svm, datasets\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.exceptions import FitFailedWarning, ConvergenceWarning\nfrom sklearn.model_selection import GridSearchCV\nwith ignore_warnings(category=[ConvergenceWarning, FitFailedWarning]):\n    iris = datasets.load_iris()\n    parameters = {'dual':[True, False], 'penalty' : ['l1', 'l2'], \\\n                 'loss': ['hinge', 'squared_hinge']}\n    svc = svm.LinearSVC()\n    clf = GridSearchCV(svc, parameters, error_score=0.0)\n    clf.fit(iris.data, iris.target)",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2017-03-24T18:56:22",
        "author": "crypdick"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/33151463/how-to-bin-time-in-a-pandas-dataframe",
    "title": "How to bin time in a pandas dataframe",
    "question_id": 33151463,
    "posted_date": "2015-10-15T10:39:42",
    "answers": [
      {
        "answer_id": 64015335,
        "body": "import pandas as pd\nimport numpy as np  # for test data\nimport random  # for test data\n# setup a sample dataframe; creates 1.5 months of hourly observations\nnp.random.seed(365)\nrandom.seed(365)\ndata = {'date': pd.bdate_range('2020-09-21', freq='h', periods=1100).tolist(),\n        'x': np.random.randint(10, size=(1100))}\ndf = pd.DataFrame(data)\n# the date column of the sample data is already in a datetime format\n# if the date column is not a datetime, then uncomment the following line\n# df.date= pd.to_datetime(df.date)\n# define the bins\nbins = [0, 6, 12, 18, 24]\n# add custom labels if desired\nlabels = ['00:00-05:59', '06:00-11:59', '12:00-17:59', '18:00-23:59']\n# add the bins to the dataframe\ndf['Time Bin'] = pd.cut(df.date.dt.hour, bins, labels=labels, right=False)",
        "score": 21,
        "is_accepted": false,
        "creation_date": "2020-09-22T14:02:14",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/66602480/fastapi-uvicorn-not-logging-errors",
    "title": "FastAPI uvicorn not logging errors",
    "question_id": 66602480,
    "posted_date": "2021-03-12T10:10:12",
    "answers": [
      {
        "answer_id": 66610100,
        "body": "config = {}\n# this is default (site-packages\\uvicorn\\main.py)\nconfig['log_config'] = \"{\n   \"version\":1,\n   \"disable_existing_loggers\":true,\n   \"formatters\":{\n      \"default\":{\n         \"()\":\"uvicorn.logging.DefaultFormatter\",\n         \"fmt\":\"%(levelprefix)s %(message)s\",\n         \"use_colors\":\"None\"\n      },\n      \"access\":{\n         \"()\":\"uvicorn.logging.AccessFormatter\",\n         \"fmt\":\"%(levelprefix)s %(client_addr)s - \\\"%(request_line)s\\\" %(status_code)s\"\n      }\n   },\n   \"handlers\":{\n      \"default\":{\n         \"formatter\":\"default\",\n         \"class\":\"logging.StreamHandler\",\n         \"stream\":\"ext://sys.stderr\"\n      },\n      \"access\":{\n         \"formatter\":\"access\",\n         \"class\":\"logging.StreamHandler\",\n         \"stream\":\"ext://sys.stdout\"\n      }\n   },\n   \"loggers\":{\n      \"uvicorn\":{\n         \"handlers\":[\n            \"default\"\n         ],\n         \"level\":\"INFO\"\n      },\n      \"uvicorn.error\":{\n         \"level\":\"INFO\",\n         \"handlers\":[\n            \"default\"\n         ],\n         \"propagate\":true\n      },\n      \"uvicorn.access\":{\n         \"handlers\":[\n            \"access\"\n         ],\n         \"level\":\"INFO\",\n         \"propagate\":false\n      }\n   }\n}\n# add your handler to it (in my case, I'm working with quart, but you can do this with Flask etc. as well, they're all the same)\nconfig['log_config']['loggers']['quart'] =\n{\n   \"handlers\":[\n      \"default\"\n   ],\n   \"level\":\"INFO\"\n}",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2021-03-12T23:17:05",
        "author": "TheClockTwister"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65362524/in-json-created-from-a-pydantic-basemodel-exclude-optional-if-not-set",
    "title": "In JSON created from a pydantic.BaseModel exclude Optional if not set",
    "question_id": 65362524,
    "posted_date": "2020-12-18T13:59:14",
    "answers": [
      {
        "answer_id": 65363852,
        "body": "from pydantic import BaseModel\nfrom typing import Optional\nfrom pydantic.json import pydantic_encoder\nimport json\nclass Foo(BaseModel):\n    x: int\n    y: int = 42\n    z: Optional[int]\ndef exclude_optional_dict(model: BaseModel):\n    return {**model.dict(exclude_unset=True), **model.dict(exclude_none=True)}\ndef exclude_optional_json(model: BaseModel):\n    return json.dumps(exclude_optional_dict(model), default=pydantic_encoder)\n\nprint(exclude_optional_json(Foo(x=3)))  # {\"x\": 3, \"y\": 42}\nprint(exclude_optional_json(Foo(x=3, z=None)))  # {\"x\": 3, \"z\": null, \"y\": 42}\nprint(exclude_optional_json(Foo(x=3, z=77)))  # {\"x\": 3, \"z\": 77, \"y\": 42}",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2020-12-18T16:00:08",
        "author": "alex_noname"
      },
      {
        "answer_id": 65363852,
        "body": "def union(source, destination):\n    for key, value in source.items():\n        if isinstance(value, dict):\n            node = destination.setdefault(key, {})\n            union(value, node)\n        else:\n            destination[key] = value\n    return destination\ndef exclude_optional_dict(model: BaseModel):\n    return union(model.dict(exclude_unset=True), model.dict(exclude_none=True))\nclass Foo(BaseModel):\n    x: int\n    y: int = 42\n    z: Optional[int]\nclass Bar(BaseModel):\n    a: int\n    b: int = 52\n    c: Optional[int]\n    d: Foo\nprint(exclude_optional_json(Bar(a=4, d=Foo(x=3))))\nprint(exclude_optional_json(Bar(a=4, c=None, d=Foo(x=3, z=None))))\nprint(exclude_optional_json(Bar(a=4, c=78, d=Foo(x=3, z=77))))",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2020-12-18T16:00:08",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67733566/how-to-use-pipenv-on-mac",
    "title": "How to use pipenv on mac?",
    "question_id": 67733566,
    "posted_date": "2021-05-28T01:56:08",
    "answers": [
      {
        "answer_id": 67738782,
        "body": "   eval \"$(brew shellenv)\"\n\n   # Set your preferred python version.\n   # If you just want the latest release, you don't need to\n   # specify anything more than the major version number.\n   export PYENV_VERSION=3\n\n   # Tell pyenv where to keep your python installations.\n   export PYENV_ROOT=~/.pyenv\n\n   # Tell pipx where to install executables.\n   # pipx is like brew, but for python.\n   export PIPX_BIN_DIR=~/.local/bin\n\n   # -U eliminates duplicates.\n   export -U PATH path\n   path=(\n     $PIPX_BIN_DIR\n     $PYENV_ROOT/{bin,shims}\n     $path\n   )\n\n   # Installs/updates pipenv and all of its dependencies.\n   pybake() {\n     # If any commands fail, exit the function.\n     setopt LOCAL_OPTIONS ERR_RETURN\n\n     install-or-upgrade() {\n       if command -v $1 &>/dev/null; then\n         print -n \"upgrade $1\"\n       else\n         print -n \"install $1\"\n       fi\n     }\n\n     # Store the command to unfunction in a trap\n     trap \"unfunction install-or-upgrade\" EXIT\n\n     brew $(install-or-upgrade pyenv)\n     pyenv install --skip-existing $PYENV_VERSION\n     pip install --upgrade pip\n\n     # --user installs to ~/.local/bin\n     pip install --upgrade --user pipx\n\n     pipx $(install-or-upgrade pipenv)\n   }",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2021-05-28T08:23:20",
        "author": "Marlon Richert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/20208562/homepage-login-form-django",
    "title": "homepage login form Django",
    "question_id": 20208562,
    "posted_date": "2013-11-25T23:32:46",
    "answers": [
      {
        "answer_id": 20210318,
        "body": "{% extends \"base.html\" %}\n{% block head %}\n  <title>Login</title>\n{% endblock %}\n{% block body %}\n  {% if form.errors %}\n    <p>Your username and password didn't match. Please try again.</p>\n  {% endif %}\n\n  <form method=\"post\" action=\"{% url 'django.contrib.auth.views.login' %}\">\n    {% csrf_token %}\n    <table>\n      <tr>\n        <td>{{ form.username.label_tag }}</td>\n        <td>{{ form.username }}</td>\n      </tr>\n      <tr>\n        <td>{{ form.password.label_tag }}</td>\n        <td>{{ form.password }}</td>\n      </tr>\n    </table>\n\n    <input type=\"submit\" value=\"login\" />\n    <input type=\"hidden\" name=\"next\" value=\"{{ next }}\" />\n  </form>\n{% endblock %}",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2013-11-26T01:50:12",
        "author": "Peter DeGlopper"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60883696/k-fold-cross-validation-using-dataloaders-in-pytorch",
    "title": "k-fold cross validation using DataLoaders in PyTorch",
    "question_id": 60883696,
    "posted_date": "2020-03-27T05:59:34",
    "answers": [
      {
        "answer_id": 64386444,
        "body": "# define a cross validation function\ndef crossvalid(model=None,criterion=None,optimizer=None,dataset=None,k_fold=5):\n\n    train_score = pd.Series()\n    val_score = pd.Series()\n\n    total_size = len(dataset)\n    fraction = 1/k_fold\n    seg = int(total_size * fraction)\n    # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset\n    # index: [trll,trlr],[vall,valr],[trrl,trrr]\n    for i in range(k_fold):\n        trll = 0\n        trlr = i * seg\n        vall = trlr\n        valr = i * seg + seg\n        trrl = valr\n        trrr = total_size\n        # msg\n#         print(\"train indices: [%d,%d),[%d,%d), test indices: [%d,%d)\"\n#               % (trll,trlr,trrl,trrr,vall,valr))\n\n        train_left_indices = list(range(trll,trlr))\n        train_right_indices = list(range(trrl,trrr))\n\n        train_indices = train_left_indices + train_right_indices\n        val_indices = list(range(vall,valr))\n\n        train_set = torch.utils.data.dataset.Subset(dataset,train_indices)\n        val_set = torch.utils.data.dataset.Subset(dataset,val_indices)\n\n#         print(len(train_set),len(val_set))\n#         print()\n\n        train_loader = torch.utils.data.DataLoader(train_set, batch_size=50,\n                                          shuffle=True, num_workers=4)\n        val_loader = torch.utils.data.DataLoader(val_set, batch_size=50,\n                                          shuffle=True, num_workers=4)\n        train_acc = train(res_model,criterion,optimizer,train_loader,epoch=1)\n        train_score.at[i] = train_acc\n        val_acc = valid(res_model,criterion,optimizer,val_loader)\n        val_score.at[i] = val_acc\n\n    return train_score,val_score\n\ntrain_score,val_score = crossvalid(res_model,criterion,optimizer,dataset=tiny_dataset)",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2020-10-16T05:24:55",
        "author": "Skipper"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58992252/how-to-enforce-dataclass-fields-types",
    "title": "How to enforce dataclass fields&#39; types?",
    "question_id": 58992252,
    "posted_date": "2019-11-22T05:26:45",
    "answers": [
      {
        "answer_id": 58992994,
        "body": "import dataclasses\n@dataclasses.dataclass()\nclass Parent:\n    def __post_init__(self):\n        for (name, field_type) in self.__annotations__.items():\n            if not isinstance(self.__dict__[name], field_type):\n                current_type = type(self.__dict__[name])\n                raise TypeError(f\"The field `{name}` was assigned by `{current_type}` instead of `{field_type}`\")\n        print(\"Check is passed successfully\")\n@dataclasses.dataclass()\nclass MyClass(Parent):\n    value: str\nobj1 = MyClass(value=\"1\")\nobj2 = MyClass(value=1)",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2019-11-22T06:08:38",
        "author": "MartenCatcher"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/26824019/are-sessions-needed-for-python-social-auth",
    "title": "Are sessions needed for python-social-auth",
    "question_id": 26824019,
    "posted_date": "2014-11-08T20:33:59",
    "answers": [
      {
        "answer_id": 28225087,
        "body": "/**\n * This function gets called after successfully getting the access_token from Facebook's API.\n */\nfunction successLoginFbFn(response) {\n    var deferred = $q.defer();\n    $http.post('/api/v1/auth/facebook/', {\n        \"access_token\": response.authResponse.accessToken,\n        \"backend\": \"facebook\"\n    }).success(function(response, status, headers, config) {\n        // Success\n        if (response.token) {\n            // Save the token to localStorage and redirect the user to the front-page.\n            Authentication.setToken(response.token);\n            window.location = '/';\n        }\n        deferred.resolve(response, status, headers, config);\n    }).error(function(response, status, headers, config) {\n        // Error\n        console.error('Authentication error.');\n        deferred.reject(response, status, headers, config);\n    });\n}",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2015-01-29T16:37:32",
        "author": "Carlos Perea"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52104682/rendering-a-pandas-dataframe-as-html-with-same-styling-as-jupyter-notebook",
    "title": "Rendering a pandas dataframe as HTML with same styling as Jupyter Notebook",
    "question_id": 52104682,
    "posted_date": "2018-08-30T16:11:20",
    "answers": [
      {
        "answer_id": 62716643,
        "body": "def getTableHTML(df):\n\n    \"\"\"\n    From https://stackoverflow.com/a/49687866/2007153\n\n    Get a Jupyter like html of pandas dataframe\n\n    \"\"\"\n    styles = [\n        #table properties\n        dict(selector=\" \",\n             props=[(\"margin\",\"0\"),\n                    (\"font-family\",'\"Helvetica\", \"Arial\", sans-serif'),\n                    (\"border-collapse\", \"collapse\"),\n                    (\"border\",\"none\"),\n    #                 (\"border\", \"2px solid #ccf\")\n                       ]),\n        #header color - optional\n    #     dict(selector=\"thead\",\n    #          props=[(\"background-color\",\"#cc8484\")\n    #                ]),\n        #background shading\n        dict(selector=\"tbody tr:nth-child(even)\",\n             props=[(\"background-color\", \"#fff\")]),\n        dict(selector=\"tbody tr:nth-child(odd)\",\n             props=[(\"background-color\", \"#eee\")]),\n        #cell spacing\n        dict(selector=\"td\",\n             props=[(\"padding\", \".5em\")]),\n        #header cell properties\n        dict(selector=\"th\",\n             props=[(\"font-size\", \"100%\"),\n                    (\"text-align\", \"center\")]),\n    ]\n    return (df.style.set_table_styles(styles)).render()",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2020-07-03T09:39:36",
        "author": "DougR"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62413698/how-to-use-refresh-token-with-fastapi",
    "title": "How to use refresh token with fastapi?",
    "question_id": 62413698,
    "posted_date": "2020-06-16T12:54:01",
    "answers": [
      {
        "answer_id": 65365634,
        "body": "from fastapi import FastAPI, Depends, HTTPException\nfrom fastapi_jwt_auth import AuthJWT\nfrom pydantic import BaseModel\napp = FastAPI()\nclass User(BaseModel):\n    email: str\n    password: str\nclass Settings(BaseModel):\n    authjwt_secret_key: str = \"secret\"\n@AuthJWT.load_config\ndef get_config():\n    return Settings()\n@app.post('/login')\ndef login(user: User, Authorize: AuthJWT = Depends()):\n    if user.email != \"test@test.com\" or user.password != \"test\":\n        raise HTTPException(status_code=401,detail=\"Incorrect email or password\")\n    access_token = Authorize.create_access_token(subject=user.email)\n    refresh_token = Authorize.create_refresh_token(subject=user.email)\n    return {\"access_token\": access_token, \"refresh_token\": refresh_token}",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-12-18T19:43:30",
        "author": "metro2012"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45882401/how-to-deal-with-userwarning-converting-sparse-indexedslices-to-a-dense-tensor",
    "title": "How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape",
    "question_id": 45882401,
    "posted_date": "2017-08-25T09:19:42",
    "answers": [
      {
        "answer_id": 45917500,
        "body": "# Flatten batch elements to rank-2 tensor where 1st max_length rows belong to first batch element and so forth\nall_timesteps = tf.reshape(raw_output, [-1, n_dim])  # (batch_size*max_length, n_dim)\n# Indices to last element of each sequence.\n# Index to first element is the sequence order number times max sequence length.\n# Index to last element is the index to first element plus sequence length.\nrow_inds = tf.range(0, batch_size) * max_length + (seq_len - 1)\n# Creating a vector of 0s and 1s that will specify what timesteps to choose.\npartitions = tf.reduce_sum(tf.one_hot(row_inds, tf.shape(all_timesteps)[0], dtype='int32'), 0)\n# Selecting the elements we want to choose.\nlast_timesteps = tf.dynamic_partition(all_timesteps, partitions, 2)  # (batch_size, n_dim)\nlast_timesteps = last_timesteps[1]",
        "score": 13,
        "is_accepted": true,
        "creation_date": "2017-08-28T07:05:49",
        "author": "ryuzakinho"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56112506/pylint-protection-against-self-assignment",
    "title": "pylint protection against self-assignment",
    "question_id": 56112506,
    "posted_date": "2019-05-13T08:35:52",
    "answers": [
      {
        "answer_id": 56151088,
        "body": "from pylint.checkers import BaseChecker\nfrom pylint.interfaces import IAstroidChecker\nclass SelfAssignChecker(BaseChecker):\n    __implements__ = IAstroidChecker\n    name = 'self-assign-returns'\n    priority = -1\n    msgs = {\n        'W5555': (\n            'Self assignment (%s).',\n            'self-assign',\n            'useless assignment.'\n        ),\n    }\n    def visit_assign(self, node):\n        names = []\n        for child in node.get_children():\n            if not hasattr(child, 'name'):\n                return\n            if child.name not in names:\n                names.append(child.name)\n            else:\n                self.add_message(\"self-assign\", node=node, args=child.name)\ndef register(linter):\n    linter.register_checker(SelfAssignChecker(linter))",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2019-05-15T09:54:37",
        "author": "Chocorean"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63316840/django-3-1-streaminghttpresponse-with-an-async-generator",
    "title": "Django 3.1: StreamingHttpResponse with an async generator",
    "question_id": 63316840,
    "posted_date": "2020-08-08T11:02:02",
    "answers": [
      {
        "answer_id": 63452601,
        "body": "import asyncio\n# By design asyncio does not allow its event loop to be nested.\n# Trying to do so will give the error \"RuntimeError: This event loop is already running\".\n# This library solves that problem.\nimport nest_asyncio\nfrom django.http.response import StreamingHttpResponse\nclass AsyncStreamingHttpResponse(StreamingHttpResponse):\n    def __init__(self, streaming_content=(), *args, **kwargs):\n        sync_streaming_content = self.get_sync_iterator(streaming_content)\n        super().__init__(streaming_content=sync_streaming_content, *args, **kwargs)\n    @staticmethod\n    async def convert_async_iterable(stream):\n        \"\"\"Accepts async_generator and async_iterator\"\"\"\n        return iter([chunk async for chunk in stream])\n    def get_sync_iterator(self, async_iterable):\n        nest_asyncio.apply()\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        result = loop.run_until_complete(self.convert_async_iterable(async_iterable))\n        return result",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2020-08-17T10:08:34",
        "author": "wowkin2"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55801796/how-can-we-create-data-columns-in-dash-table-dynamically-using-callback-with-a-f",
    "title": "How can we create data columns in Dash Table dynamically using callback with a function providing the dataframe",
    "question_id": 55801796,
    "posted_date": "2019-04-22T18:15:18",
    "answers": [
      {
        "answer_id": 55840601,
        "body": "html.Div(\n        id = 'tableDiv',\n        className = 'tableDiv'\n    )\n...\n  @app.callback([Output('tableDiv', 'children')]\n          [Input('submit', 'n_clicks')],\n          [State('ID', 'value'),  State('pattern_desc', 'value'),\n        State('file_path', 'value')])\n   def update_table(n_clicks, ID, pattern_desc, file_path):\n         df = someFunc(ID, pattern_desc, file_path)\n    mycolumns = [{'name': i, 'id': i} for i in df.columns]\n        return html.Div([\n                dt.DataTable(\n            id='table',\n            columns=mycolumns,\n            data=df.to_dict(\"rows\")\n         )\n        ])",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2019-04-24T21:27:37",
        "author": "miked"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3586046/fastest-way-to-take-a-screenshot-with-python-on-windows",
    "title": "Fastest way to take a screenshot with python on windows",
    "question_id": 3586046,
    "posted_date": "2010-08-27T12:03:31",
    "answers": [
      {
        "answer_id": 3586280,
        "body": "import win32gui\nimport win32ui\nimport win32con\nw = 1920 # set this\nh = 1080 # set this\nbmpfilenamename = \"out.bmp\" #set this\nhwnd = win32gui.FindWindow(None, windowname)\nwDC = win32gui.GetWindowDC(hwnd)\ndcObj=win32ui.CreateDCFromHandle(wDC)\ncDC=dcObj.CreateCompatibleDC()\ndataBitMap = win32ui.CreateBitmap()\ndataBitMap.CreateCompatibleBitmap(dcObj, w, h)\ncDC.SelectObject(dataBitMap)\ncDC.BitBlt((0,0),(w, h) , dcObj, (0,0), win32con.SRCCOPY)\ndataBitMap.SaveBitmapFile(cDC, bmpfilenamename)\n# Free Resources\ndcObj.DeleteDC()\ncDC.DeleteDC()\nwin32gui.ReleaseDC(hwnd, wDC)\nwin32gui.DeleteObject(dataBitMap.GetHandle())",
        "score": 43,
        "is_accepted": true,
        "creation_date": "2010-08-27T12:33:00",
        "author": "pyfunc"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58321991/is-it-possible-to-change-pytests-assert-statement-behaviour-in-python",
    "title": "Is it possible to change PyTest&#39;s assert statement behaviour in Python",
    "question_id": 58321991,
    "posted_date": "2019-10-10T07:35:53",
    "answers": [
      {
        "answer_id": 58491381,
        "body": "$ pytest test_foo.py -s --pdb --pdbcls=demo.custom_pdb:CustomPdb\n[ ... ]\n    def test_ham():\n>       assert 42 == 17\nE       assert 42 == 17\ntest_foo.py:2: AssertionError\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nSorry, not interested in this failure\nF\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    def test_spam():\n>       int(\"Vikings\")\nE       ValueError: invalid literal for int() with base 10: 'Vikings'\ntest_foo.py:4: ValueError\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n> /.../test_foo.py(4)test_spam()\n-> int(\"Vikings\")\n(Pdb)",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2019-10-21T13:28:16",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 58491381,
        "body": "import pytest\n@pytest.hookimpl(trylast=True)\ndef pytest_configure(config):\n    # unregister returns the unregistered plugin\n    pdbinvoke = config.pluginmanager.unregister(name=\"pdbinvoke\")\n    if pdbinvoke is None:\n        # no --pdb switch used, no debugging requested\n        return\n    # get the terminalreporter too, to write to the console\n    tr = config.pluginmanager.getplugin(\"terminalreporter\")\n    # create or own plugin\n    plugin = ExceptionFilter(pdbinvoke, tr)\n    # register our plugin, pytest will then start calling our plugin hooks\n    config.pluginmanager.register(plugin, \"exception_filter\")\nclass ExceptionFilter:\n    def __init__(self, pdbinvoke, terminalreporter):\n        # provide the same functionality as pdbinvoke\n        self.pytest_internalerror = pdbinvoke.pytest_internalerror\n        self.orig_exception_interact = pdbinvoke.pytest_exception_interact\n        self.tr = terminalreporter\n    def pytest_exception_interact(self, node, call, report):\n        if not call.excinfo. errisinstance(ValueError):\n            self.tr.write_line(\"Sorry, not interested!\")\n            return\n        return self.orig_exception_interact(node, call, report)",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2019-10-21T13:28:16",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 58491381,
        "body": "$ pytest demo/test_foo.py --pdb --pdbcls=IPython.core.debugger:Pdb\n[ ... ]\ndemo/test_foo.py F\nSorry, not interested!\ndemo/test_foo.py F\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    def test_spam():\n>       int(\"Vikings\")\nE       ValueError: invalid literal for int() with base 10: 'Vikings'\ndemo/test_foo.py:4: ValueError\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n> /.../demo/test_foo.py(4)test_spam()\n      1 def test_ham():\n      2     assert 42 == 17\n      3 def test_spam():\n----> 4     int(\"Vikings\")\nipdb>",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2019-10-21T13:28:16",
        "author": "Martijn Pieters"
      },
      {
        "answer_id": 58491381,
        "body": "$ pytest -r a demo/test_foo.py\n============================= test session starts =============================\nplatform darwin -- Python 3.8.0, pytest-3.10.0, py-1.7.0, pluggy-0.8.0\nrootdir: ..., inifile:\ncollected 2 items\ndemo/test_foo.py sF                                                      [100%]\n=================================== FAILURES ===================================\n__________________________________ test_spam ___________________________________\n    def test_spam():\n>       int(\"Vikings\")\nE       ValueError: invalid literal for int() with base 10: 'Vikings'\ndemo/test_foo.py:4: ValueError\n=========================== short test summary info ============================\nFAIL demo/test_foo.py::test_spam\nSKIP [1] .../demo/conftest.py:12: [NOTRUN] ignoring everything but ValueError\n===================== 1 failed, 1 skipped in 0.07 seconds ======================",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2019-10-21T13:28:16",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/2318288/how-to-use-custom-png-image-marker-with-plot",
    "title": "How to use custom png image marker with plot?",
    "question_id": 2318288,
    "posted_date": "2010-02-23T08:07:27",
    "answers": [
      {
        "answer_id": 2320099,
        "body": "import matplotlib.pyplot as plt\nfrom matplotlib import image\n# constant\ndpi = 72\npath = 'smile.png'\n# read in our png file\nim = image.imread(path)\nimage_size = im.shape[1], im.shape[0]\nfig = plt.figure(dpi=dpi)\nax = fig.add_subplot(111)\n# plot our line with transparent markers, and markersize the size of our image\nline, = ax.plot((1,2,3,4),(1,2,3,4),\"bo\",mfc=\"None\",mec=\"None\",markersize=image_size[0] * (dpi/ 96))\n# we need to make the frame transparent so the image can be seen\n# only in trunk can you put the image on top of the plot, see this link:\n# http://www.mail-archive.com/matplotlib-users@lists.sourceforge.net/msg14534.html\nax.patch.set_alpha(0)\nax.set_xlim((0,5))\nax.set_ylim((0,5))\n# translate point positions to pixel positions\n# figimage needs pixels not points\nline._transform_path()\npath, affine = line._transformed_path.get_transformed_points_and_affine()\npath = affine.transform_path(path)\nfor pixelPoint in path.vertices:\n    # place image at point, centering it\n    fig.figimage(im,pixelPoint[0]-image_size[0]/2,pixelPoint[1]-image_size[1]/2,origin=\"upper\")\nplt.show()",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2010-02-23T12:04:06",
        "author": "Mark"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69954587/no-blas-lapack-libraries-found-when-installing-scipy",
    "title": "No BLAS/LAPACK libraries found when installing SciPy",
    "question_id": 69954587,
    "posted_date": "2021-11-13T08:14:00",
    "answers": [
      {
        "answer_id": 70880741,
        "body": "# Install lapack and openblas from Homebrew\nbrew install openblas lapack\n# Tell Numpy installer where to find lapack\nexport LDFLAGS=\"-L/usr/local/opt/lapack/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/lapack/include\"\nexport PKG_CONFIG_PATH=\"/usr/local/opt/lapack/lib/pkgconfig\"\n# See https://github.com/scipy/scipy/issues/12935\nexport CFLAGS=-Wno-error=implicit-function-declaration\n# The location may vary - use find command to find this on your local /usr/local/opt\nexport LAPACK=/usr/local/opt/lapack/lib/liblapack.dylib\nexport BLAS=/usr/local/opt/openblas/lib/libopenblasp-r0.3.19.dylib",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2022-01-27T09:56:34",
        "author": "Mikko Ohtamaa"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/38839402/how-to-use-assert-frame-equal-in-unittest",
    "title": "how to use assert_frame_equal in unittest",
    "question_id": 38839402,
    "posted_date": "2016-08-08T18:24:54",
    "answers": [
      {
        "answer_id": 54344148,
        "body": "import unittest\nimport pandas as pd\nimport pandas.testing as pd_testing\nclass TestSplitWeight(unittest.TestCase):\n    def assertDataframeEqual(self, a, b, msg):\n        try:\n            pd_testing.assert_frame_equal(a, b)\n        except AssertionError as e:\n            raise self.failureException(msg) from e\n    def setUp(self):\n        self.addTypeEqualityFunc(pd.DataFrame, self.assertDataframeEqual)\n    def test_allZero(self):\n        self.assertEqual(pd.DataFrame([0,0,0,0]), pd.DataFrame([0,0,0,0]))",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2019-01-24T05:14:11",
        "author": "L&#233;o Germond"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55525195/do-i-have-to-do-one-hot-encoding-separately-for-train-and-test-dataset",
    "title": "Do I have to do one-hot-encoding separately for train and test dataset?",
    "question_id": 55525195,
    "posted_date": "2019-04-04T17:29:53",
    "answers": [
      {
        "answer_id": 55525814,
        "body": "import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n### Correct\ntrain = pd.DataFrame(['A', 'B', 'A', 'C'])\ntest = pd.DataFrame(['B', 'A', 'D'])\nenc = OneHotEncoder(handle_unknown = 'ignore')\nenc.fit(train)\nenc.transform(train).toarray()\n#array([[1., 0., 0.],\n#       [0., 1., 0.],\n#       [1., 0., 0.],\n#       [0., 0., 1.]])\nenc.transform(test).toarray()\n#array([[0., 1., 0.],\n#       [1., 0., 0.],\n#       [0., 0., 0.]])\n### Incorrect\nfull = pd.concat((train, test))\nenc = OneHotEncoder(handle_unknown = 'ignore')\nenc.fit(full)\nenc.transform(train).toarray()\n#array([[1., 0., 0., 0.],\n#       [0., 1., 0., 0.],\n#       [1., 0., 0., 0.],\n#       [0., 0., 1., 0.]])\nenc.transform(test).toarray()\n#array([[0., 1., 0., 0.],\n#       [1., 0., 0., 0.],\n#       [0., 0., 0., 1.]])",
        "score": 42,
        "is_accepted": true,
        "creation_date": "2019-04-04T18:27:45",
        "author": "mickey"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/20847727/python-inheritance-versus-composition",
    "title": "Python: Inheritance versus Composition",
    "question_id": 20847727,
    "posted_date": "2013-12-30T16:16:48",
    "answers": [
      {
        "answer_id": 34832643,
        "body": "class Person:\n    def __init__(self, firstname, lastname):\n        self.firstname = firstname\n        self.lastname = lastname\n    def get_name(self):\n        return f\"{self.firstname} {self.lastname}\"\nclass Parent(Person):\n    def __init__(self, firstname, lastname):\n        super().__init__(firstname, lastname)\n        self.kids = []\n    def havechild(self, firstname):\n        print(self.firstname, \"is having a child\")\n        self.kids.append(Child(self, firstname))\nclass Child(Person):\n    def __init__(self, parent, firstname):\n        super().__init__(firstname, parent.lastname)\n        self.parent = parent",
        "score": 37,
        "is_accepted": false,
        "creation_date": "2016-01-16T17:03:24",
        "author": "Borys Serebrov"
      },
      {
        "answer_id": 34832643,
        "body": "from collections import defaultdict\nclass Person:\n    def __init__(self, firstname, lastname):\n        self.firstname = firstname\n        self.lastname = lastname\n    def get_name(self):\n        return f\"{self.firstname} {self.lastname}\"\nclass FamilyRegistry(object):\n    def __init__(self):\n        self.kids = defaultdict(list)\n    def register_birth(self, parent, child_name):\n        print(parent.firstname, \"is having a child\")\n        child = Person(child_name, parent.lastname)\n        self.kids[parent.lastname].append(child)\n        return child\n    def print_children(self, person):\n        children = self.kids[person.lastname]\n        if len(children) == 0:\n            print(\"{} has no children\" % person.get_name())\n            return\n        for child in children:\n            print(child.get_name())",
        "score": 37,
        "is_accepted": false,
        "creation_date": "2016-01-16T17:03:24",
        "author": "Borys Serebrov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/24063788/python3-singledispatch-in-class-how-to-dispatch-self-type",
    "title": "python3: singledispatch in class, how to dispatch self type",
    "question_id": 24063788,
    "posted_date": "2014-06-05T11:06:55",
    "answers": [
      {
        "answer_id": 24064102,
        "body": "from functools import singledispatch, update_wrapper\n# Python 3.8 singledispatchmethod, backported\nclass singledispatchmethod:\n    \"\"\"Single-dispatch generic method descriptor.\n    Supports wrapping existing descriptors and handles non-descriptor\n    callables as instance methods.\n    \"\"\"\n    def __init__(self, func):\n        if not callable(func) and not hasattr(func, \"__get__\"):\n            raise TypeError(f\"{func!r} is not callable or a descriptor\")\n        self.dispatcher = singledispatch(func)\n        self.func = func\n    def register(self, cls, method=None):\n        \"\"\"generic_method.register(cls, func) -> func\n        Registers a new implementation for the given *cls* on a *generic_method*.\n        \"\"\"\n        return self.dispatcher.register(cls, func=method)\n    def __get__(self, obj, cls):\n        def _method(*args, **kwargs):\n            method = self.dispatcher.dispatch(args[0].__class__)\n            return method.__get__(obj, cls)(*args, **kwargs)\n        _method.__isabstractmethod__ = self.__isabstractmethod__\n        _method.register = self.register\n        update_wrapper(_method, self.func)\n        return _method\n    @property\n    def __isabstractmethod__(self):\n        return getattr(self.func, '__isabstractmethod__', False)",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2014-06-05T11:21:20",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/68893521/simple-example-of-pandas-extensionarray",
    "title": "Simple example of Pandas ExtensionArray",
    "question_id": 68893521,
    "posted_date": "2021-08-23T09:24:39",
    "answers": [
      {
        "answer_id": 68972163,
        "body": "from __future__ import annotations\nimport operator\nimport re\nfrom typing import Any, Sequence\nimport numpy as np\nimport pandas as pd\n@pd.api.extensions.register_extension_dtype\nclass AngleDtype(pd.core.dtypes.dtypes.PandasExtensionDtype):\n    \"\"\"\n    An ExtensionDtype for unit-aware angular data.\n    \"\"\"\n    # Required for all parameterized dtypes\n    _metadata = ('unit',)\n    _match = re.compile(r'(A|a)ngle\\[(?P<unit>.+)\\]')\n    def __init__(self, unit=None):\n        if unit is None:\n            unit = 'rad'\n        if unit not in ['rad', 'deg']:\n            msg = f\"'{type(self).__name__}' only supports 'rad' and 'deg' units\"\n            raise ValueError(msg)\n        self._unit = unit\n    def __str__(self) -> str:\n        return f'angle[{self.unit}]'\n    # TestDtypeTests\n    def __hash__(self) -> int:\n        return hash(str(self))\n    # TestDtypeTests\n    def __eq__(self, other: Any) -> bool:\n        if isinstance(other, str):\n            return self.name == other\n        else:\n            return isinstance(other, type(self)) and self.unit == other.unit\n    # Required for pickle compat (see GH26067)\n    def __setstate__(self, state) -> None:\n        self._unit = state['unit']\n    # Required for all ExtensionDtype subclasses\n    @classmethod\n    def construct_array_type(cls):\n        \"\"\"\n        Return the array type associated with this dtype.\n        \"\"\"\n        return AngleArray\n    # Recommended for parameterized dtypes\n    @classmethod\n    def construct_from_string(cls, string: str) -> AngleDtype:\n        \"\"\"\n        Construct an AngleDtype from a string.\n        Example\n        -------\n        >>> AngleDtype.construct_from_string('angle[deg]')\n        angle['deg']\n        \"\"\"\n        if not isinstance(string, str):\n            msg = f\"'construct_from_string' expects a string, got {type(string)}\"\n            raise TypeError(msg)\n        msg = f\"Cannot construct a '{cls.__name__}' from '{string}'\"\n        match = cls._match.match(string)\n        if match:\n            d = match.groupdict()\n            try:\n                return cls(unit=d['unit'])\n            except (KeyError, TypeError, ValueError) as err:\n                raise TypeError(msg) from err\n        else:\n            raise TypeError(msg)\n    # Required for all ExtensionDtype subclasses\n    @property\n    def type(self):\n        \"\"\"\n        The scalar type for the array (e.g., int).\n        \"\"\"\n        return np.generic\n    # Required for all ExtensionDtype subclasses\n    @property\n    def name(self) -> str:\n        \"\"\"\n        A string representation of the dtype.\n        \"\"\"\n        return str(self)\n    @property\n    def unit(self) -> str:\n        \"\"\"\n        The angle unit.\n        \"\"\"\n        return self._unit",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2021-08-29T06:52:02",
        "author": "tdy"
      },
      {
        "answer_id": 68972163,
        "body": "class AngleArray(pd.api.extensions.ExtensionArray):\n    \"\"\"\n    An ExtensionArray for unit-aware angular data.\n    \"\"\"\n    # Include `copy` param for TestInterfaceTests\n    def __init__(self, data, unit='rad', copy: bool=False):\n        self._data = np.array(data, copy=copy)\n        self._unit = unit\n    # Required for all ExtensionArray subclasses\n    def __getitem__(self, index: int) -> AngleArray | Any:\n        \"\"\"\n        Select a subset of self.\n        \"\"\"\n        if isinstance(index, int):\n            return self._data[index]\n        else:\n            # Check index for TestGetitemTests\n            index = pd.core.indexers.check_array_indexer(self, index)\n            return type(self)(self._data[index])\n    # TestSetitemTests\n    def __setitem__(self, index: int, value: np.generic) -> None:\n        \"\"\"\n        Set one or more values in-place.\n        \"\"\"\n        # Check index for TestSetitemTests\n        index = pd.core.indexers.check_array_indexer(self, index)\n        # Upcast to value's type (if needed) for TestMethodsTests\n        if self._data.dtype < type(value):\n            self._data = self._data.astype(type(value))\n        # TODO: Validate value for TestSetitemTests\n        # value = self._validate_setitem_value(value)\n        self._data[index] = value\n    # Required for all ExtensionArray subclasses\n    def __len__(self) -> int:\n        \"\"\"\n        Length of this array.\n        \"\"\"\n        return len(self._data)\n    # TestUnaryOpsTests\n    def __invert__(self) -> AngleArray:\n        \"\"\"\n        Element-wise inverse of this array.\n        \"\"\"\n        data = ~self._data\n        return type(self)(data, unit=self.dtype.unit)\n    def _ensure_same_units(self, other) -> AngleArray:\n        \"\"\"\n        Helper method to ensure `self` and `other` have the same units.\n        \"\"\"\n        if isinstance(other, type(self)) and self.dtype.unit != other.dtype.unit:\n            return other.asunit(self.dtype.unit)\n        else:\n            return other\n    def _apply_operator(self, op, other, recast=False) -> np.ndarray | AngleArray:\n        \"\"\"\n        Helper method to apply an operator `op` between `self` and `other`.\n        Some ops require the result to be recast into AngleArray:\n        * Comparison ops: recast=False\n        * Arithmetic ops: recast=True\n        \"\"\"\n        f = operator.attrgetter(op)\n        data, other = np.array(self), np.array(self._ensure_same_units(other))\n        result = f(data)(other)\n        return result if not recast else type(self)(result, unit=self.dtype.unit)\n    def _apply_operator_if_not_series(self, op, other, recast=False) -> np.ndarray | AngleArray:\n        \"\"\"\n        Wraps _apply_operator only if `other` is not Series/DataFrame.\n\n        Some ops should return NotImplemented if `other` is a Series/DataFrame:\n        https://github.com/pandas-dev/pandas/blob/e7e7b40722e421ef7e519c645d851452c70a7b7c/pandas/tests/extension/base/ops.py#L115\n        \"\"\"\n        if isinstance(other, (pd.Series, pd.DataFrame)):\n            return NotImplemented\n        else:\n            return self._apply_operator(op, other, recast=recast)\n    # Required for all ExtensionArray subclasses\n    @pd.core.ops.unpack_zerodim_and_defer('__eq__')\n    def __eq__(self, other):\n        return self._apply_operator('__eq__', other, recast=False)\n    # TestComparisonOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__ne__')\n    def __ne__(self, other):\n        return self._apply_operator('__ne__', other, recast=False)\n    # TestComparisonOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__lt__')\n    def __lt__(self, other):\n        return self._apply_operator('__lt__', other, recast=False)\n    # TestComparisonOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__gt__')\n    def __gt__(self, other):\n        return self._apply_operator('__gt__', other, recast=False)\n    # TestComparisonOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__le__')\n    def __le__(self, other):\n        return self._apply_operator('__le__', other, recast=False)\n    # TestComparisonOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__ge__')\n    def __ge__(self, other):\n        return self._apply_operator('__ge__', other, recast=False)\n\n    # TestArithmeticOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__add__')\n    def __add__(self, other) -> AngleArray:\n        return self._apply_operator_if_not_series('__add__', other, recast=True)\n    # TestArithmeticOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__sub__')\n    def __sub__(self, other) -> AngleArray:\n        return self._apply_operator_if_not_series('__sub__', other, recast=True)\n    # TestArithmeticOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__mul__')\n    def __mul__(self, other) -> AngleArray:\n        return self._apply_operator_if_not_series('__mul__', other, recast=True)\n    # TestArithmeticOpsTests\n    @pd.core.ops.unpack_zerodim_and_defer('__truediv__')\n    def __truediv__(self, other) -> AngleArray:\n        return self._apply_operator_if_not_series('__truediv__', other, recast=True)\n    # Required for all ExtensionArray subclasses\n    @classmethod\n    def _from_sequence(cls, data, dtype=None, copy: bool=False):\n        \"\"\"\n        Construct a new AngleArray from a sequence of scalars.\n        \"\"\"\n        if dtype is None:\n            dtype = AngleDtype()\n        if not isinstance(dtype, AngleDtype):\n            msg = f\"'{cls.__name__}' only supports 'AngleDtype' dtype\"\n            raise ValueError(msg)\n        else:\n            return cls(data, unit=dtype.unit, copy=copy)\n    # TestParsingTests\n    @classmethod\n    def _from_sequence_of_strings(cls, strings, *, dtype=None, copy: bool=False) -> AngleArray:\n        \"\"\"\n        Construct a new AngleArray from a sequence of strings.\n        \"\"\"\n        scalars = pd.to_numeric(strings, errors='raise')\n        return cls._from_sequence(scalars, dtype=dtype, copy=copy)\n    # Required for all ExtensionArray subclasses\n    @classmethod\n    def _from_factorized(cls, uniques: np.ndarray, original: AngleArray):\n        \"\"\"\n        Reconstruct an AngleArray after factorization.\n        \"\"\"\n        return cls(uniques, unit=original.dtype.unit)\n    # Required for all ExtensionArray subclasses\n    @classmethod\n    def _concat_same_type(cls, to_concat: Sequence[AngleArray]) -> AngleArray:\n        \"\"\"\n        Concatenate multiple AngleArrays.\n        \"\"\"\n        # ensure same units\n        counts = pd.value_counts([array.dtype.unit for array in to_concat])\n        unit = counts.index[0]\n        if counts.size > 1:\n            to_concat = [a.asunit(unit) for a in to_concat]\n        return cls(np.concatenate(to_concat), unit=unit)\n    # Required for all ExtensionArray subclasses\n    @property\n    def dtype(self):\n        \"\"\"\n        An instance of AngleDtype.\n        \"\"\"\n        return AngleDtype(self._unit)\n    # Required for all ExtensionArray subclasses\n    @property\n    def nbytes(self) -> int:\n        \"\"\"\n        The number of bytes needed to store this object in memory.\n        \"\"\"\n        return self._data.nbytes\n    @property\n    def unit(self):\n        return self.dtype.unit\n    # Test*ReduceTests\n    def all(self) -> bool:\n        return all(self)\n    def any(self) -> bool:  # Test*ReduceTests\n        return any(self)\n    def sum(self) -> np.generic:  # Test*ReduceTests\n        return self._data.sum()\n    def mean(self) -> np.generic:  # Test*ReduceTests\n        return self._data.mean()\n    def max(self) -> np.generic:  # Test*ReduceTests\n        return self._data.max()\n    def min(self) -> np.generic:  # Test*ReduceTests\n        return self._data.min()\n    def prod(self) -> np.generic:  # Test*ReduceTests\n        return self._data.prod()\n    def std(self) -> np.generic:  # Test*ReduceTests\n        return pd.Series(self._data).std()\n    def var(self) -> np.generic:  # Test*ReduceTests\n        return pd.Series(self._data).var()\n    def median(self) -> np.generic:  # Test*ReduceTests\n        return np.median(self._data)\n    def skew(self) -> np.generic:  # Test*ReduceTests\n        return pd.Series(self._data).skew()\n    def kurt(self) -> np.generic:  # Test*ReduceTests\n        return pd.Series(self._data).kurt()\n    # Test*ReduceTests\n    def _reduce(self, name: str, *, skipna: bool=True, **kwargs):\n        \"\"\"\n        Return a scalar result of performing the reduction operation.\n        \"\"\"\n        f = operator.attrgetter(name)\n        return f(self)()\n    # Required for all ExtensionArray subclasses\n    def isna(self):\n        \"\"\"\n        A 1-D array indicating if each value is missing.\n        \"\"\"\n        return pd.isnull(self._data)\n    # Required for all ExtensionArray subclasses\n    def copy(self):\n        \"\"\"\n        Return a copy of the array.\n        \"\"\"\n        copied = self._data.copy()\n        return type(self)(copied, unit=self.unit)\n    # Required for all ExtensionArray subclasses\n    def take(self, indices, allow_fill=False, fill_value=None):\n        \"\"\"\n        Take elements from an array.\n        \"\"\"\n        if allow_fill and fill_value is None:\n            fill_value = self.dtype.na_value\n        result = pd.core.algorithms.take(self._data, indices, allow_fill=allow_fill,\n                                         fill_value=fill_value)\n        return self._from_sequence(result)\n    # TestMethodsTests\n    def value_counts(self, dropna: bool=True):\n        \"\"\"\n        Return a Series containing descending counts of unique values (excludes NA values by default).\n        \"\"\"\n        return pd.core.algorithms.value_counts(self._data, dropna=dropna)\n    def asunit(self, unit: str) -> AngleArray:\n        \"\"\"\n        Cast to an AngleDtype unit.\n        \"\"\"\n        if unit not in ['rad', 'deg']:\n            msg = f\"'{type(self.dtype).__name__}' only supports 'rad' and 'deg' units\"\n            raise ValueError(msg)\n        elif self.dtype.unit == unit:\n            return self\n        else:\n            rad2deg = self.dtype.unit == 'rad' and unit == 'deg'\n            data = np.rad2deg(self._data) if rad2deg else np.deg2rad(self._data)\n            return type(self)(data, unit)",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2021-08-29T06:52:02",
        "author": "tdy"
      },
      {
        "answer_id": 68972163,
        "body": "import operator\nimport numpy as np\nfrom pandas import Series\nimport pytest\nfrom pandas.tests.extension.base.casting import BaseCastingTests  # noqa\nfrom pandas.tests.extension.base.constructors import BaseConstructorsTests  # noqa\nfrom pandas.tests.extension.base.dtype import BaseDtypeTests  # noqa\nfrom pandas.tests.extension.base.getitem import BaseGetitemTests  # noqa\nfrom pandas.tests.extension.base.groupby import BaseGroupbyTests  # noqa\nfrom pandas.tests.extension.base.interface import BaseInterfaceTests  # noqa\nfrom pandas.tests.extension.base.io import BaseParsingTests  # noqa\nfrom pandas.tests.extension.base.methods import BaseMethodsTests  # noqa\nfrom pandas.tests.extension.base.missing import BaseMissingTests  # noqa\nfrom pandas.tests.extension.base.ops import (  # noqa\n    BaseArithmeticOpsTests,\n    BaseComparisonOpsTests,\n    BaseOpsUtil,\n    BaseUnaryOpsTests,\n)\nfrom pandas.tests.extension.base.printing import BasePrintingTests  # noqa\nfrom pandas.tests.extension.base.reduce import (  # noqa\n    BaseBooleanReduceTests,\n    BaseNoReduceTests,\n    BaseNumericReduceTests,\n)\nfrom pandas.tests.extension.base.reshaping import BaseReshapingTests  # noqa\nfrom pandas.tests.extension.base.setitem import BaseSetitemTests  # noqa\nfrom extension import AngleDtype, AngleArray\n@pytest.fixture\ndef dtype():\n    \"\"\"\n    A fixture providing the ExtensionDtype to validate.\n    \"\"\"\n    return AngleDtype()\n@pytest.fixture\ndef data():\n    \"\"\"\n    Length-100 array for this type.\n    * data[0] and data[1] should both be non missing\n    * data[0] and data[1] should not be equal\n    \"\"\"\n    return AngleArray(np.arange(100))\n@pytest.fixture\ndef data_for_twos():\n    \"\"\"\n    Length-100 array in which all the elements are two.\n    \"\"\"\n    return AngleArray(np.array([2] * 100))\n@pytest.fixture\ndef data_missing():\n    \"\"\"\n    Length-2 array with [NA, Valid].\n    \"\"\"\n    return AngleArray(np.array([np.nan, 2]))\n@pytest.fixture(params=['data', 'data_missing'])\ndef all_data(request, data, data_missing):\n    \"\"\"\n    Parameterized fixture giving 'data' and 'data_missing'.\n    \"\"\"\n    if request.param == 'data':\n        return data\n    elif request.param == 'data_missing':\n        return data_missing\n@pytest.fixture\ndef data_repeated(data):\n    \"\"\"\n    Generate many datasets.\n    Parameters\n    ----------\n    data : fixture implementing `data`\n    Returns\n    -------\n    Callable[[int], Generator]:\n        A callable that takes a `count` argument and\n        returns a generator yielding `count` datasets.\n    \"\"\"\n    def gen(count):\n        for _ in range(count):\n            yield data\n    return gen\n@pytest.fixture\ndef data_for_sorting():\n    \"\"\"\n    Length-3 array with a known sort order.\n    This should be three items [B, C, A] with A < B < C.\n    \"\"\"\n    return AngleArray(np.array([2, 3, 1]))\n@pytest.fixture\ndef data_missing_for_sorting():\n    \"\"\"\n    Length-3 array with a known sort order.\n    This should be three items [B, NA, A] with A < B and NA missing.\n    \"\"\"\n    return AngleArray(np.array([2, np.nan, 1]))\n@pytest.fixture\ndef na_cmp():\n    \"\"\"\n    Binary operator for comparing NA values.\n    Should return a function of two arguments that returns\n    True if both arguments are (scalar) NA for your type.\n    By default, uses ``operator.is_``.\n    \"\"\"\n    return lambda a, b: np.array_equal(a, b, equal_nan=True)\n@pytest.fixture\ndef na_value():\n    \"\"\"\n    The scalar missing value for this type. Default 'None'.\n    \"\"\"\n    return np.nan\n@pytest.fixture\ndef data_for_grouping():\n    \"\"\"\n    Data for factorization, grouping, and unique tests.\n    Expected to be like [B, B, NA, NA, A, A, B, C] where A < B < C and NA is missing.\n    \"\"\"\n    return AngleArray(np.array([2, 2, np.nan, np.nan, 1, 1, 2, 3]))\n@pytest.fixture(params=[True, False])\ndef box_in_series(request):\n    \"\"\"\n    Whether to box the data in a Series.\n    \"\"\"\n    return request.param\n@pytest.fixture(\n    params=[\n        lambda x: 1,\n        lambda x: [1] * len(x),\n        lambda x: Series([1] * len(x)),\n        lambda x: x,\n    ],\n    ids=['scalar', 'list', 'series', 'object'],\n)\ndef groupby_apply_operator(request):\n    \"\"\"\n    Functions to test groupby.apply().\n    \"\"\"\n    return request.param\n@pytest.fixture(params=[True, False])\ndef as_frame(request):\n    \"\"\"\n    Boolean fixture to support Series and Series.to_frame() comparison testing.\n    \"\"\"\n    return request.param\n@pytest.fixture(params=[True, False])\ndef as_series(request):\n    \"\"\"\n    Boolean fixture to support arr and Series(arr) comparison testing.\n    \"\"\"\n    return request.param\n@pytest.fixture(params=[True, False])\ndef use_numpy(request):\n    \"\"\"\n    Boolean fixture to support comparison testing of ExtensionDtype array    and numpy array.\n    \"\"\"\n    return request.param\n@pytest.fixture(params=['ffill', 'bfill'])\ndef fillna_method(request):\n    \"\"\"\n    Parameterized fixture giving method parameters 'ffill' and 'bfill' for\n    Series.fillna(method=<method>) testing.\n    \"\"\"\n    return request.param\n@pytest.fixture(params=[True, False])\ndef as_array(request):\n    \"\"\"\n    Boolean fixture to support ExtensionDtype _from_sequence method testing.\n    \"\"\"\n    return request.param\n@pytest.fixture(params=[None, lambda x: x])\ndef sort_by_key(request):\n    \"\"\"\n    Simple fixture for testing keys in sorting methods.\n    Tests None (no key) and the identity key.\n    \"\"\"\n    return request.param\n# TODO: Finish implementing all operators\n_all_arithmetic_operators = [\n    '__add__',\n    #  '__radd__',\n    '__sub__',\n    #  '__rsub__',\n    '__mul__',\n    #  '__rmul__',\n    #  '__floordiv__',\n    #  '__rfloordiv__',\n    '__truediv__',\n    #  '__rtruediv__',\n    #  '__pow__',\n    #  '__rpow__',\n    #  '__mod__',\n    #  '__rmod__',\n]\n@pytest.fixture(params=_all_arithmetic_operators)\ndef all_arithmetic_operators(request):\n    \"\"\"\n    Fixture for dunder names for common arithmetic operations.\n    \"\"\"\n    return request.param\n_all_numeric_reductions = [\n    'sum',\n    'max',\n    'min',\n    'mean',\n    'prod',\n    'std',\n    'var',\n    'median',\n    'kurt',\n    'skew',\n]\n@pytest.fixture(params=_all_numeric_reductions)\ndef all_numeric_reductions(request):\n    \"\"\"\n    Fixture for numeric reduction names.\n    \"\"\"\n    return request.param\n_all_boolean_reductions = ['all', 'any']\n@pytest.fixture(params=_all_boolean_reductions)\ndef all_boolean_reductions(request):\n    \"\"\"\n    Fixture for boolean reduction names.\n    \"\"\"\n    return request.param\n_all_reductions = _all_numeric_reductions + _all_boolean_reductions\n@pytest.fixture(params=_all_reductions)\ndef all_reductions(request):\n    \"\"\"\n    Fixture for all (boolean + numeric) reduction names.\n    \"\"\"\n    return request.param\n_all_compare_operators = [\n    '__eq__',\n    '__ne__',\n    '__le__',\n    '__lt__',\n    '__ge__',\n    '__gt__',\n]\n@pytest.fixture(params=_all_compare_operators)\ndef all_compare_operators(request):\n    \"\"\"\n    Fixture for dunder names for common compare operations:\n    * >=\n    * >\n    * ==\n    * !=\n    * <\n    * <=\n    \"\"\"\n    return request.param\nclass TestCastingTests(BaseCastingTests):\n    pass\nclass TestConstructorsTests(BaseConstructorsTests):\n    pass\nclass TestDtypeTests(BaseDtypeTests):\n    pass\nclass TestGetitemTests(BaseGetitemTests):\n    pass\nclass TestGroupbyTests(BaseGroupbyTests):\n    pass\nclass TestInterfaceTests(BaseInterfaceTests):\n    pass\nclass TestParsingTests(BaseParsingTests):\n    pass\nclass TestMethodsTests(BaseMethodsTests):\n    pass\nclass TestMissingTests(BaseMissingTests):\n    pass\nclass TestArithmeticOpsTests(BaseArithmeticOpsTests):\n    series_scalar_exc = None\n    frame_scalar_exc = None\n    series_array_exc = None\n    divmod_exc = TypeError  # TODO: Implement divmod\nclass TestComparisonOpsTests(BaseComparisonOpsTests):\n    # See pint-pandas test suite\n    def _compare_other(self, s, data, op_name, other):\n        op = self.get_op_from_name(op_name)\n        result = op(s, other)\n        expected = op(s.to_numpy(), other)\n        assert (result == expected).all()\nclass TestOpsUtil(BaseOpsUtil):\n    pass\nclass TestUnaryOpsTests(BaseUnaryOpsTests):\n    pass\nclass TestPrintingTests(BasePrintingTests):\n    pass\nclass TestBooleanReduceTests(BaseBooleanReduceTests):\n    pass\nclass TestNumericReduceTests(BaseNumericReduceTests):\n    pass\n# AFAICT NoReduce and Boolean+NumericReduce are mutually exclusive\n# class TestNoReduceTests(BaseNoReduceTests):\n    # pass\nclass TestReshapingTests(BaseReshapingTests):\n    pass\nclass TestSetitemTests(BaseSetitemTests):\n    pass",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2021-08-29T06:52:02",
        "author": "tdy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64303607/python-asyncio-how-to-read-stdin-and-write-to-stdout",
    "title": "python asyncio how to read StdIn and write to StdOut?",
    "question_id": 64303607,
    "posted_date": "2020-10-11T07:43:29",
    "answers": [
      {
        "answer_id": 64317899,
        "body": "`\nimport asyncio\nimport sys\nasync def connect_stdin_stdout():\n    loop = asyncio.get_event_loop()\n    reader = asyncio.StreamReader()\n    protocol = asyncio.StreamReaderProtocol(reader)\n    await loop.connect_read_pipe(lambda: protocol, sys.stdin)\n    w_transport, w_protocol = await loop.connect_write_pipe(asyncio.streams.FlowControlMixin, sys.stdout)\n    writer = asyncio.StreamWriter(w_transport, w_protocol, reader, loop)\n    return reader, writer\nasync def main():\n    reader, writer = await connect_stdin_stdout()\n    while True:\n        res = await reader.read(100)\n        if not res:\n            break\n        writer.write(res)\n        await writer.drain()\nif __name__ == \"__main__\":\n    asyncio.run(main())",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2020-10-12T08:26:45",
        "author": "alex_noname"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39788591/python-simplehttpserver-to-receive-files",
    "title": "Python SimpleHTTPServer to receive files",
    "question_id": 39788591,
    "posted_date": "2016-09-30T05:50:19",
    "answers": [
      {
        "answer_id": 58255859,
        "body": "#!/usr/env python3\nimport http.server\nimport socketserver\nimport io\nimport cgi\n# Change this to serve on a different port\nPORT = 44444\nclass CustomHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):\n    def do_POST(self):\n        r, info = self.deal_post_data()\n        print(r, info, \"by: \", self.client_address)\n        f = io.BytesIO()\n        if r:\n            f.write(b\"Success\\n\")\n        else:\n            f.write(b\"Failed\\n\")\n        length = f.tell()\n        f.seek(0)\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/plain\")\n        self.send_header(\"Content-Length\", str(length))\n        self.end_headers()\n        if f:\n            self.copyfile(f, self.wfile)\n            f.close()\n    def deal_post_data(self):\n        ctype, pdict = cgi.parse_header(self.headers['Content-Type'])\n        pdict['boundary'] = bytes(pdict['boundary'], \"utf-8\")\n        pdict['CONTENT-LENGTH'] = int(self.headers['Content-Length'])\n        if ctype == 'multipart/form-data':\n            form = cgi.FieldStorage( fp=self.rfile, headers=self.headers, environ={'REQUEST_METHOD':'POST', 'CONTENT_TYPE':self.headers['Content-Type'], })\n            print (type(form))\n            try:\n                if isinstance(form[\"file\"], list):\n                    for record in form[\"file\"]:\n                        open(\"./%s\"%record.filename, \"wb\").write(record.file.read())\n                else:\n                    open(\"./%s\"%form[\"file\"].filename, \"wb\").write(form[\"file\"].file.read())\n            except IOError:\n                    return (False, \"Can't create file to write, do you have permission to write?\")\n        return (True, \"Files uploaded\")\nHandler = CustomHTTPRequestHandler\nwith socketserver.TCPServer((\"\", PORT), Handler) as httpd:\n    print(\"serving at port\", PORT)\n    httpd.serve_forever()",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2019-10-06T05:20:02",
        "author": "smidgey"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55776571/how-to-split-a-date-column-into-separate-day-month-year-column-in-pandas",
    "title": "How to split a date column into separate day , month ,year column in pandas",
    "question_id": 55776571,
    "posted_date": "2019-04-20T14:33:22",
    "answers": [
      {
        "answer_id": 55776634,
        "body": "df['day'] = df.index.day\ndf['month'] = df.index.month\ndf['year'] = df.index.year\nprint(df)\n                 Dewptm  Fog   Humidity    Pressurem      Tempm     Wspdm  \\\ndatetime_utc\n1996-11-01    11.666667  0.0  52.916667 -2659.666667  22.333333  2.466667\n1996-11-02    10.458333  0.0  48.625000  1009.833333  22.916667  8.028571\n1996-11-03    12.041667  0.0  55.958333  1010.500000  21.791667  4.804545\n1996-11-04    10.222222  0.0  48.055556  1011.333333  22.722222  1.964706\n              Rainfall  day  month  year\ndatetime_utc\n1996-11-01           0    1     11  1996\n1996-11-02           0    2     11  1996\n1996-11-03           0    3     11  1996\n1996-11-04           0    4     11  1996",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2019-04-20T14:40:58",
        "author": "Erfan"
      },
      {
        "answer_id": 55776634,
        "body": "# Reset our index so datetime_utc becomes a column\ndf.reset_index(inplace=True)\n# Create new columns\ndf['day'] = df['datetime_utc'].dt.day\ndf['month'] = df['datetime_utc'].dt.month\ndf['year'] = df['datetime_utc'].dt.year\nprint(df)\n  datetime_utc     Dewptm  Fog   Humidity    Pressurem      Tempm     Wspdm  \\\n0   1996-11-01  11.666667  0.0  52.916667 -2659.666667  22.333333  2.466667\n1   1996-11-02  10.458333  0.0  48.625000  1009.833333  22.916667  8.028571\n2   1996-11-03  12.041667  0.0  55.958333  1010.500000  21.791667  4.804545\n3   1996-11-04  10.222222  0.0  48.055556  1011.333333  22.722222  1.964706\n   Rainfall  day  month  year\n0         0    1     11  1996\n1         0    2     11  1996\n2         0    3     11  1996\n3         0    4     11  1996",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2019-04-20T14:40:58",
        "author": "Erfan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59681461/read-a-big-mbox-file-with-python",
    "title": "Read a big .mbox file with Python",
    "question_id": 59681461,
    "posted_date": "2020-01-10T07:13:19",
    "answers": [
      {
        "answer_id": 59682472,
        "body": "#!/usr/bin/env python3\nimport email\nfrom email.policy import default\nclass MboxReader:\n    def __init__(self, filename):\n        self.handle = open(filename, 'rb')\n        assert self.handle.readline().startswith(b'From ')\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.handle.close()\n    def __iter__(self):\n        return iter(self.__next__())\n    def __next__(self):\n        lines = []\n        while True:\n            line = self.handle.readline()\n            if line == b'' or line.startswith(b'From '):\n                yield email.message_from_bytes(b''.join(lines), policy=default)\n                if line == b'':\n                    break\n                lines = []\n                continue\n            lines.append(line)",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2020-01-10T08:17:34",
        "author": "tripleee"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55466089/image-processing-algorithm-improvement-for-real-time-fedex-logo-detector",
    "title": "Image Processing: Algorithm Improvement for Real-Time FedEx Logo Detector",
    "question_id": 55466089,
    "posted_date": "2019-04-01T22:26:51",
    "answers": [
      {
        "answer_id": 56694901,
        "body": "import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nlogo = cv2.imread('logo.jpg', 0) # query Image\nimg = cv2.imread('main2.jpg',0)  # target Image\n# Create the sift object\nsift = cv2.xfeatures2d.SIFT_create(700)\n# Find keypoints and descriptors directly\nkp1, des1 = sift.detectAndCompute(img, None)\nkp2, des2 = sift.detectAndCompute(logo,None)\n# FLANN parameters\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks=50)   # or pass empty dictionary\nflann = cv2.FlannBasedMatcher(index_params,search_params)\nmatches = flann.knnMatch(des1,des2,k=2)\n# Need to draw only good matches, so create a mask\nmatchesMask = [[0,0] for i in range(len(matches))]\n# ratio test as per Lowe's paper\nfor i,(m,n) in enumerate(matches):\n    if m.distance < 0.7*n.distance:\n        matchesMask[i]=[1,0]\n# Draw lines\ndraw_params = dict(matchColor = (0,255,0),\n                   singlePointColor = (255,0,0),\n                   matchesMask = matchesMask,\n                   flags = 0)\n# Display the matches\nimg3 = cv2.drawMatchesKnn(img,kp1,logo,kp2,matches,None,**draw_params)\nplt.imshow(img3, )\nplt.show()",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-06-20T19:04:39",
        "author": "Carl H"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56131308/create-an-abstract-enum-class",
    "title": "Create an abstract Enum class",
    "question_id": 56131308,
    "posted_date": "2019-05-14T09:11:08",
    "answers": [
      {
        "answer_id": 56135108,
        "body": "from abc import abstractmethod, ABC, ABCMeta\nfrom enum import auto, Flag, EnumMeta\nclass ABCEnumMeta(ABCMeta, EnumMeta):\n    def __new__(mcls, *args, **kw):\n        abstract_enum_cls = super().__new__(mcls, *args, **kw)\n        # Only check abstractions if members were defined.\n        if abstract_enum_cls._member_map_:\n            try:  # Handle existence of undefined abstract methods.\n                absmethods = list(abstract_enum_cls.__abstractmethods__)\n                if absmethods:\n                    missing = ', '.join(f'{method!r}' for method in absmethods)\n                    plural = 's' if len(absmethods) > 1 else ''\n                    raise TypeError(\n                       f\"cannot instantiate abstract class {abstract_enum_cls.__name__!r}\"\n                       f\" with abstract method{plural} {missing}\")\n            except AttributeError:\n                pass\n        return abstract_enum_cls\nclass TranslateableFlag(Flag, metaclass=ABCEnumMeta):\n    @classmethod\n    @abstractmethod\n    def base(cls):\n        pass\n    def translate(self):\n        base = self.base()\n        if self in base:\n            return base[self]\n        else:\n            ret = []\n            for basic in base:\n                if basic in self:\n                    ret.append(base[basic])\n            return \" | \".join(ret)\nclass Students1(TranslateableFlag):\n    ALICE = auto()\n    BOB = auto()\n    CHARLIE = auto()\n    ALL = ALICE | BOB | CHARLIE\n    @classmethod\n    def base(cls):\n        return {Students1.ALICE: \"Alice\", Students1.BOB: \"Bob\",\n                Students1.CHARLIE: \"Charlie\"}\n# Abstract method not defined - should raise TypeError.\nclass Students2(TranslateableFlag):\n    ALICE = auto()\n    BOB = auto()\n    CHARLIE = auto()\n    ALL = ALICE | BOB | CHARLIE\n#    @classmethod\n#    def base(cls):\n#        ...",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2019-05-14T12:49:10",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76771761/why-does-llama-index-still-require-an-openai-key-when-using-hugging-face-local-e",
    "title": "Why does llama-index still require an OpenAI key when using Hugging Face local embedding model?",
    "question_id": 76771761,
    "posted_date": "2023-07-26T09:19:46",
    "answers": [
      {
        "answer_id": 76781752,
        "body": "from pathlib import Path\nimport gradio as gr\nimport sys\nimport logging\nimport os\nfrom llama_index.llms import HuggingFaceLLM\nfrom llama_index.prompts.prompts import SimpleInputPrompt\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\nfrom llama_index import SimpleDirectoryReader, VectorStoreIndex, ServiceContext, load_index_from_storage, StorageContext\nstorage_path = \"storage\"\ndocs_path=\"docs\"\nprint(storage_path)\nmax_input_size = 4096\nnum_outputs = 512\n#max_chunk_overlap = 20\nchunk_overlap_ratio = 0.1\nchunk_size_limit = 600\nsystem_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n- StableLM will refuse to participate in anything that could harm a human.\n\"\"\"\n# This will wrap the default prompts that are internal to llama-index\nquery_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")\nllm = HuggingFaceLLM(\n    context_window=4096,\n    max_new_tokens=256,\n    generate_kwargs={\"temperature\": 0.7, \"do_sample\": False},\n    system_prompt=system_prompt,\n    query_wrapper_prompt=query_wrapper_prompt,\n    tokenizer_name=\"StabilityAI/stablelm-tuned-alpha-3b\",\n    model_name=\"StabilityAI/stablelm-tuned-alpha-3b\",\n    device_map=\"auto\",\n    stopping_ids=[50278, 50279, 50277, 1, 0],\n    tokenizer_kwargs={\"max_length\": 4096},\n    # uncomment this if using CUDA to reduce memory usage\n    # model_kwargs={\"torch_dtype\": torch.float16}\n)\nservice_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm, embed_model=\"local\")\ndocuments = SimpleDirectoryReader(docs_path).load_data()\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\ndef chatbot(input_text):\n    query_engine = index.as_query_engine()\n    response = query_engine.query(input_text)\n    print(response.source_nodes)\n    relevant_files=[]\n    for node_with_score in response.source_nodes:\n        print(node_with_score)\n        print(node_with_score.node)\n        print(node_with_score.node.metadata)\n        print(node_with_score.node.metadata['file_name'])\n        file = node_with_score.node.metadata['file_name']\n        print( file )\n        # Resolve the full file path for the downloading\n        full_file_path = Path( docs_path, file ).resolve()\n        # See if it's already in the array\n        if full_file_path not in relevant_files:\n            relevant_files.append( full_file_path ) # Add it\n    print( relevant_files )\n    return response.response, relevant_files\niface = gr.Interface(fn=chatbot,\n                     inputs=gr.components.Textbox(lines=7, label=\"Enter your text\"),\n                     outputs=[\n                        gr.components.Textbox(label=\"Response\"),\n                        gr.components.File(label=\"Relevant Files\")\n                        ],\n                     title=\"Custom-trained AI Chatbot\",\n                     allow_flagging=\"never\")\niface.launch(share=False)",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2023-07-27T12:29:39",
        "author": "Mikey A. Leonetti"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59955328/how-to-profile-flask-endpoint",
    "title": "How to profile flask endpoint?",
    "question_id": 59955328,
    "posted_date": "2020-01-28T13:57:59",
    "answers": [
      {
        "answer_id": 69758397,
        "body": "* Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\nbegin\nend\n--------------------------------------------------------------------------------\nPATH: '/'\n         298 function calls in 2.992 seconds\n   Ordered by: internal time, call count\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    2.969    2.969    2.969    2.969 {built-in method time.sleep}\n        1    0.002    0.002    0.011    0.011 /usr/local/lib/python3.7/site-packages/flask/app.py:1955(finalize_request)\n        1    0.002    0.002    0.008    0.008 /usr/local/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py:173(__init__)\n       35    0.002    0.000    0.002    0.000 {built-in method builtins.isinstance}\n        4    0.001    0.000    0.001    0.000 /usr/local/lib/python3.7/site-packages/werkzeug/datastructures.py:910(_unicodify_header_value)\n        2    0.001    0.000    0.003    0.002 /usr/local/lib/python3.7/site-packages/werkzeug/datastructures.py:1298(__setitem__)\n        1    0.001    0.001    0.001    0.001 /usr/local/lib/python3.7/site-packages/werkzeug/datastructures.py:960(__getitem__)\n        6    0.001    0.000    0.001    0.000 /usr/local/lib/python3.7/site-packages/werkzeug/_compat.py:210(to_unicode)\n        2    0.000    0.000    0.002    0.001 /usr/local/lib/python3.7/site-packages/werkzeug/datastructures.py:1212(set)\n        4    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n        1    0.000    0.000    0.002    0.002 /usr/local/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py:341(set_data)\n       10    0.000    0.000    0.001    0.000 /usr/local/lib/python3.7/site-packages/werkzeug/local.py:70(__getattr__)\n        8    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n        1    0.000    0.000    0.008    0.008 /usr/local/lib/python3.7/site-packages/flask/app.py:2029(make_response)\n        1    0.000    0.000    0.004    0.004 /usr/local/lib/python3.7/site-packages/werkzeug/routing.py:1551(bind_to_environ)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.7/site-packages/werkzeug/_internal.py:67(_get_environ)\n        1    0.000    0.000    0.001    0.001 /usr/local/lib/python3.7/site-packages/werkzeug/routing.py:1674(__init__)\n[snipped for berevity]",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2021-10-28T13:15:27",
        "author": "v25"
      },
      {
        "answer_id": 69758397,
        "body": "* Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\nbegin\nend\n--------------------------------------------------------------------------------\nPATH: '/'\n         300 function calls in 3.016 seconds\n   Ordered by: internal time, call count\n   List reduced from 131 to 2 due to restriction <'/code/app.py'>\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000    3.007    3.007 /code/app.py:12(index)\n        1    0.000    0.000    2.002    2.002 /code/app.py:9(slower)\n--------------------------------------------------------------------------------",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2021-10-28T13:15:27",
        "author": "v25"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55565760/anaconda-python-site-packages-subfolders-with-tilde-in-name-what-are-they",
    "title": "Anaconda/Python site-packages subfolders with tilde in name - what are they?",
    "question_id": 55565760,
    "posted_date": "2019-04-07T23:13:55",
    "answers": [
      {
        "answer_id": 57488427,
        "body": "class AdjacentTempDirectory(TempDirectory):\n    \"\"\"Helper class that creates a temporary directory adjacent to a real one.\n    Attributes:\n        original\n            The original directory to create a temp directory for.\n        path\n            After calling create() or entering, contains the full\n            path to the temporary directory.\n        delete\n            Whether the directory should be deleted when exiting\n            (when used as a contextmanager)\n    \"\"\"\n    # The characters that may be used to name the temp directory\n    # We always prepend a ~ and then rotate through these until\n    # a usable name is found.\n    # pkg_resources raises a different error for .dist-info folder\n    # with leading '-' and invalid metadata\n    LEADING_CHARS = \"-~.=%0123456789\"\n    ...",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2019-08-14T01:04:47",
        "author": "Leo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57874226/valueerror-view-limit-minimum-35738-3640567-is-less-than-1-and-is-an-invalid-m",
    "title": "ValueError: view limit minimum -35738.3640567 is less than 1 and is an invalid Matplotlib date value",
    "question_id": 57874226,
    "posted_date": "2019-09-10T11:45:52",
    "answers": [
      {
        "answer_id": 57874353,
        "body": "import pandas as pd\nimport matplotlib.pyplot as plt\n# given the following data\ndata = {'datetime': ['2018-05-15', '2018-05-16', '2018-05-17', '2018-05-18', '2018-05-21', '2018-05-22', '2018-05-23', '2018-05-24', '2018-05-25', '2018-05-29'],\n        'price': [1079.22998, 1081.77002, 1078.589966, 1066.359985, 1079.579956, 1069.72998, 1079.689941, 1079.23999, 1075.660034, 1060.319946]}\ndf_google = pd.DataFrame(data)\n# convert the datetime column to a datetime type and assign it back to the column\ndf_google.datetime = pd.to_datetime(df_google.datetime)\n# display(df_google.head())\n     datetime        price\n0  2018-05-15  1079.229980\n1  2018-05-16  1081.770020\n2  2018-05-17  1078.589966\n3  2018-05-18  1066.359985\n4  2018-05-21  1079.579956\n5  2018-05-22  1069.729980\n6  2018-05-23  1079.689941\n7  2018-05-24  1079.239990\n8  2018-05-25  1075.660034\n9  2018-05-29  1060.319946",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2019-09-10T11:52:55",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63427037/package-python3-7-is-not-available",
    "title": "Package Python3.7 is not available",
    "question_id": 63427037,
    "posted_date": "2020-08-15T10:19:14",
    "answers": [
      {
        "answer_id": 63428617,
        "body": "apt-get update\napt-get install -y build-essential openssl openssl-dev* wget curl\nwget https://www.python.org/ftp/python/3.7.8/Python-3.7.8.tgz\ntar -xvf Python-3.7.8.tgz\ncd Python-3.7.8\n./configure --enable-shared\nmake\nmake test\nmake install\n# Steps from here are to enable other libraries in linux to\n# access the shared python libraries.\ncd /usr/local/lib/\ncp libpython3.so /usr/lib64/\ncp libpython3.so /usr/lib\ncp libpython3.7m.so.1.0 /usr/lib64/\ncp libpython3.7m.so.1.0 /usr/lib/\ncd /usr/lib64\nln -s libpython3.7m.so.1.0 libpython3.7m.so\ncd /usr/lib\nln -s libpython3.7m.so.1.0 libpython3.7m.so",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2020-08-15T12:56:36",
        "author": "Kaustubh Desai"
      },
      {
        "answer_id": 63428617,
        "body": "(testvirtual) root@fe794c7ff15e:~# pip install flask\nCollecting flask\n  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 94 kB 404 kB/s\nCollecting Jinja2>=2.10.1\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125 kB 10.4 MB/s\nCollecting click>=5.1\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 82 kB 165 kB/s\nCollecting Werkzeug>=0.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 298 kB 11.9 MB/s\nCollecting itsdangerous>=0.24\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\nCollecting MarkupSafe>=0.23\n  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\nInstalling collected packages: MarkupSafe, Jinja2, click, Werkzeug, itsdangerous, flask\nSuccessfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2020-08-15T12:56:36",
        "author": "Kaustubh Desai"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18679264/how-to-use-malloc-and-free-with-python-ctypes",
    "title": "How to use malloc and free with python ctypes?",
    "question_id": 18679264,
    "posted_date": "2013-09-07T20:39:30",
    "answers": [
      {
        "answer_id": 18679558,
        "body": "import ctypes as ct\nclass Example(ct.Structure):\n    _fields_ = (('data', ct.POINTER(ct.c_char)),\n                ('len', ct.c_int),\n                ('doubles', ct.POINTER(ct.c_double)),\n                ('count', ct.c_int))\n    def __init__(self, length, count):\n        self.data = ct.create_string_buffer(length)\n        self.len = length\n        self.doubles = (ct.c_double * count)()\n        self.count = count\n    def __repr__(self):\n        '''Return string describing how to print an Example object.\n        '''\n        # Note that slicing a pointer to a specific\n        # length returns a list of if its objects.\n        return (f'Example({ct.string_at(self.data)}, {self.doubles[:self.count]}')\nclass Dll:\n    def __init__(self):\n        self.dll = ct.CDLL('./test')\n        self.dll.func.argtypes = ct.POINTER(Example),\n        self.dll.func.restype = None\n    def func(self, ex):\n        self.dll.func(ct.byref(ex))\nd = Dll()\ne = Example(20, 5)\nprint('before:', e)\nd.func(e)\nprint('after:', e)",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2013-09-07T21:33:00",
        "author": "Mark Tolonen"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48078051/duplicate-log-entries-with-google-cloud-stackdriver-logging-of-python-code-on-ku",
    "title": "Duplicate log entries with Google Cloud Stackdriver logging of Python code on Kubernetes Engine",
    "question_id": 48078051,
    "posted_date": "2018-01-03T08:08:31",
    "answers": [
      {
        "answer_id": 71299619,
        "body": "import google.cloud.logging\nimport logging\ndef is_cloud_handler(handler: logging.Handler) -> bool:\n    \"\"\"\n    is_cloud_handler\n    Returns True or False depending on whether the input is a\n    google-cloud-logging handler class\n    \"\"\"\n    accepted_handlers = (\n        google.cloud.logging.handlers.StructuredLogHandler,\n        google.cloud.logging.handlers.CloudLoggingHandler,\n        google.cloud.logging.handlers.ContainerEngineHandler,\n        google.cloud.logging.handlers.AppEngineHandler,\n    )\n    return isinstance(handler, accepted_handlers)\ndef set_up_logging():\n    # here we assume you'll be using the basic logging methods\n    # logging.info, logging.warn etc. which invoke the root logger\n    client = google.cloud.logging.Client()\n    client.setup_logging()\n    root_logger = logging.getLogger()\n    root_logger.handlers = [h for h in root_logger.handlers if is_cloud_handler(h)]",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2022-02-28T13:42:04",
        "author": "Paddy Alton"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64083104/making-python-generator-via-c20-coroutines",
    "title": "Making python generator via c++20 coroutines",
    "question_id": 64083104,
    "posted_date": "2020-09-26T18:32:53",
    "answers": [
      {
        "answer_id": 64083986,
        "body": "#include <coroutine>\n#include <exception>\n#include <string>\n#include <iostream>\nstruct generator_input {};\ntemplate <typename OutputType, typename InputType>\nstruct generator {\n    struct promise_type;\n    using coro_handle = std::coroutine_handle<promise_type>;\n    struct passthru_value\n    {\n        InputType &ret_;\n        bool await_ready() {return true;}\n        void await_suspend(coro_handle) {}\n        InputType &await_resume() { return ret_; }\n    };\n    struct promise_type {\n        OutputType current_value;\n        InputType input_value;\n        auto get_return_object() { return generator{coro_handle::from_promise(*this)}; }\n        auto initial_suspend() { return std::suspend_always{}; }\n        auto final_suspend() { return std::suspend_always{}; }\n        void unhandled_exception() { std::terminate(); }\n        auto yield_value(OutputType value) {\n            current_value = value;\n            return std::suspend_always{};\n        }\n        void return_void() {}\n        auto await_transform(generator_input)\n        {\n            return passthru_value{input_value};\n        }\n    };\n    bool next() { return coro ? (coro.resume(), !coro.done()) : false; }\n    OutputType value() { return coro.promise().current_value; }\n    void send(const InputType &input)\n    {\n        coro.promise().input_value = input;\n    }\n    void send(InputType &&input)\n    {\n        coro.promise().input_value = std::move(input);\n    }\n    generator(generator const & rhs) = delete;\n    generator(generator &&rhs)\n        :coro(rhs.coro)\n    {\n        rhs.coro = nullptr;\n    }\n    ~generator() {\n        if (coro)\n            coro.destroy();\n    }\nprivate:\n    generator(coro_handle h) : coro(h) {}\n    coro_handle coro;\n};\ngenerator<char, std::string> hello(){\n    auto word = co_await generator_input{};\n    for(auto &ch: word){\n        co_yield ch;\n    }\n}\nint main(int, char**)\n{\n    auto test = hello();\n    test.send(\"hello world\");\n    while(test.next())\n    {\n        std::cout << test.value() << ' ';\n    }\n}",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2020-09-26T21:33:59",
        "author": "Nicol Bolas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58585019/understanding-gradient-policy-deriving",
    "title": "Understanding Gradient Policy Deriving",
    "question_id": 58585019,
    "posted_date": "2019-10-27T22:06:23",
    "answers": [
      {
        "answer_id": 58843880,
        "body": "import gym\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nNUM_EPISODES = 5000\nLEARNING_RATE = 0.0001\nGAMMA = 0.99\n# noinspection PyMethodMayBeStatic\nclass Agent:\n    def __init__(self):\n        self.poly = PolynomialFeatures(1)\n        self.w = np.random.randn(5, 1) * 0.01\n    # Our policy that maps state to action parameterized by w\n    # noinspection PyShadowingNames\n    def policy(self, state):\n        z = np.sum(state.dot(self.w))\n        return self.sigmoid(z)\n    def sigmoid(self, x):\n        s = 1 / (1 + np.exp(-x))\n        return s\n    def sigmoid_grad(self, sig_x):\n        return sig_x * (1 - sig_x)\n    def grad(self, probs, action, state):\n        grad = state.T.dot(probs - action)\n        return -grad\n    def update_with(self, grads, rewards):\n        if len(grads) < 50:\n            return\n        for i in range(len(grads)):\n            # Loop through everything that happened in the episode\n            # and update towards the log policy gradient times **FUTURE** reward\n            total_grad_effect = 0\n            for t, r in enumerate(rewards[i:]):\n                total_grad_effect += r * (GAMMA ** r)\n            self.w += LEARNING_RATE * grads[i] * total_grad_effect\ndef main(argv):\n    env = gym.make('CartPole-v0')\n    np.random.seed(1)\n    agent = Agent()\n    complete_scores = []\n    for e in range(NUM_EPISODES):\n        state = env.reset()[None, :]\n        state = agent.poly.fit_transform(state)\n        rewards = []\n        grads = []\n        score = 0\n        while True:\n            probs = agent.policy(state)\n            action_space = env.action_space.n\n            action = np.random.choice(action_space, p=[1 - probs, probs])\n            next_state, reward, done, _ = env.step(action)\n            next_state = next_state[None, :]\n            next_state = agent.poly.fit_transform(next_state.reshape(1, 4))\n            grad = agent.grad(probs, action, state)\n            grads.append(grad)\n            rewards.append(reward)\n            score += reward\n            state = next_state\n            if done:\n                break\n        agent.update_with(grads, rewards)\n        complete_scores.append(score)\n    env.close()\n    plt.plot(np.arange(NUM_EPISODES),\n             complete_scores)\n    plt.savefig('image1.png')\nif __name__ == '__main__':\n    main(None)",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2019-11-13T14:02:06",
        "author": "ptyshevs"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56754451/how-to-connect-the-ends-of-edges-in-order-to-close-the-holes-between-them",
    "title": "How to connect the ends of edges in order to close the holes between them?",
    "question_id": 56754451,
    "posted_date": "2019-06-25T08:47:44",
    "answers": [
      {
        "answer_id": 56763430,
        "body": "circle_mask = np.zeros(original.shape, dtype=np.uint8)\ncircles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.5, 200)\n# Convert the (x, y) coordinates and radius of the circles to integers\ncircles = np.round(circles[0, :]).astype(\"int\")\ncircle_ratio = 0.85\n# Loop over the (x, y) coordinates and radius of the circles\nfor (x, y, r) in circles:\n    # Draw the circle, create mask, and obtain soil ROI\n    cv2.circle(image, (x, y), int(r * circle_ratio), (0, 255, 0), 2)\n    cv2.circle(circle_mask, (x, y), int(r * circle_ratio), (255, 255, 255), -1)\n    soil_ROI = cv2.bitwise_and(original, circle_mask)",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2019-06-25T19:53:47",
        "author": "nathancy"
      },
      {
        "answer_id": 56763430,
        "body": "import cv2\nimport numpy as np\nimage = cv2.imread('5.png')\noriginal = image.copy()\nblur = cv2.GaussianBlur(image, (3,3), 0)\ngray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\ncircle_mask = np.zeros(original.shape, dtype=np.uint8)\ncircles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.5, 200)\n# Convert the (x, y) coordinates and radius of the circles to integers\ncircles = np.round(circles[0, :]).astype(\"int\")\ncircle_ratio = 0.85\n# Loop over the (x, y) coordinates and radius of the circles\nfor (x, y, r) in circles:\n    # Draw the circle, create mask, and obtain soil ROI\n    cv2.circle(image, (x, y), int(r * circle_ratio), (0, 255, 0), 2)\n    cv2.circle(circle_mask, (x, y), int(r * circle_ratio), (255, 255, 255), -1)\n    soil_ROI = cv2.bitwise_and(original, circle_mask)\ngray_soil_ROI = cv2.cvtColor(soil_ROI, cv2.COLOR_BGR2GRAY)\nclose = cv2.morphologyEx(gray_soil_ROI, cv2.MORPH_CLOSE, kernel)\ncnts = cv2.findContours(close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\ncrack_area = 0\nminumum_area = 25\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area > minumum_area:\n        cv2.drawContours(original,[c], 0, (36,255,12), 2)\n        crack_area += area\nprint(crack_area)\ncv2.imshow('close', close)\ncv2.imshow('circle_mask', circle_mask)\ncv2.imshow('soil_ROI', soil_ROI)\ncv2.imshow('original', original)\ncv2.waitKey(0)",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2019-06-25T19:53:47",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54328681/enable-pk-based-filtering-in-django-graphene-relay-while-retaining-global-ids",
    "title": "Enable PK based filtering in Django Graphene Relay while retaining Global IDs",
    "question_id": 54328681,
    "posted_date": "2019-01-23T08:43:05",
    "answers": [
      {
        "answer_id": 59436118,
        "body": "import django_filters\nimport graphene\nfrom graphene import relay\nfrom graphene_django import DjangoObjectType\nfrom multy_herr.objections.models import Objection\nclass ObjectionFilter(django_filters.FilterSet):\n    pk = django_filters.NumberFilter(field_name='pk')\n    class Meta:\n        model = Objection\n        fields = [\n            'pk',\n        ]\nclass ObjectionNode(DjangoObjectType):\n    pk = graphene.Field(type=graphene.Int, source='id')\n    class Meta:\n        model = Objection\n        fields = [\n            'id',\n            'pk',\n            'detail',\n            'hidden',\n            'report',\n        ]\n        filter_fields = {\n            'pk': ['exact'],\n            'detail': ['icontains', 'istartswith'],\n            'created_by__name': ['icontains', ],\n            'hidden': ['exact'],\n            'report': ['exact'],\n        }\n        interfaces = (relay.Node,)",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2019-12-21T07:18:51",
        "author": "joe"
      },
      {
        "answer_id": 59436118,
        "body": "import graphene\nfrom graphene import relay\nfrom graphene_django.filter import DjangoFilterConnectionField\nfrom multy_herr.objections.grapheql.nodes import ObjectionNode, ObjectionFilter\nfrom multy_herr.objections.models import Objection\nclass ObjectionQuery(graphene.ObjectType):\n    objection = relay.Node.Field(ObjectionNode)\n    all_objections = DjangoFilterConnectionField(ObjectionNode,\n                                                 filterset_class=ObjectionFilter)\n    def resolve_all_objections(self, info, **kwargs):\n        if info.context.user.is_authenticated is False:\n            return Objection.objects.none()\n        return Objection.objects.filter(created_by=info.context.user)",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2019-12-21T07:18:51",
        "author": "joe"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/43723214/pil-image-vs-skimage-io-when-to-use-each-and-which-if-one-is-prefered-over-t",
    "title": "PIL.Image vs skimage.io: When to use each, and which (if one) is prefered over the other in general?",
    "question_id": 43723214,
    "posted_date": "2017-05-01T13:10:20",
    "answers": [
      {
        "answer_id": 74149163,
        "body": "21/10/2022  06:20         3,363,278 imageio-2.22.2-py3-none-any.whl\n21/10/2022  06:20         2,023,640 networkx-2.8.7-py3-none-any.whl\n21/10/2022  06:20        14,643,698 numpy-1.23.4-cp310-cp310-win_amd64.whl\n21/10/2022  06:20            40,750 packaging-21.3-py3-none-any.whl\n21/10/2022  06:20         3,276,402 Pillow-9.2.0-cp310-cp310-win_amd64.whl\n21/10/2022  06:20            98,338 pyparsing-3.0.9-py3-none-any.whl\n21/10/2022  06:20         4,162,789 PyWavelets-1.4.1-cp310-cp310-win_amd64.whl\n21/10/2022  06:20        12,044,719 scikit_image-0.19.3-cp310-cp310-win_amd64.whl\n21/10/2022  06:20        40,141,232 scipy-1.9.3-cp310-cp310-win_amd64.whl\n21/10/2022  06:20           210,312 tifffile-2022.10.10-py3-none-any.whl\n              10 File(s)     80,005,158 bytes",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2022-10-21T01:34:19",
        "author": "Steve Barnes"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64096953/how-to-convert-yolo-format-bounding-box-coordinates-into-opencv-format",
    "title": "How to convert Yolo format bounding box coordinates into OpenCV format",
    "question_id": 64096953,
    "posted_date": "2020-09-28T02:25:21",
    "answers": [
      {
        "answer_id": 64097592,
        "body": "import cv2\nimport matplotlib.pyplot as plt\nimg = cv2.imread(<image_path>)\ndh, dw, _ = img.shape\nfl = open(<label_path>, 'r')\ndata = fl.readlines()\nfl.close()\nfor dt in data:\n    # Split string to float\n    _, x, y, w, h = map(float, dt.split(' '))\n    # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291\n    # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380\n    l = int((x - w / 2) * dw)\n    r = int((x + w / 2) * dw)\n    t = int((y - h / 2) * dh)\n    b = int((y + h / 2) * dh)\n\n    if l < 0:\n        l = 0\n    if r > dw - 1:\n        r = dw - 1\n    if t < 0:\n        t = 0\n    if b > dh - 1:\n        b = dh - 1\n    cv2.rectangle(img, (l, t), (r, b), (0, 0, 255), 1)\nplt.imshow(img)\nplt.show()",
        "score": 48,
        "is_accepted": true,
        "creation_date": "2020-09-28T03:20:59",
        "author": "HansHirse"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52631291/vectorizing-or-speeding-up-fuzzywuzzy-string-matching-on-pandas-column",
    "title": "Vectorizing or Speeding up Fuzzywuzzy String Matching on PANDAS Column",
    "question_id": 52631291,
    "posted_date": "2018-10-03T12:02:07",
    "answers": [
      {
        "answer_id": 61371170,
        "body": "import pandas as pd, numpy as np\nfrom rapidfuzz import process, utils\norg_list = df['org_name']\nprocessed_orgs = [utils.default_process(org) for org in org_list]\nfor (i, processed_query) in enumerate(processed_orgs):\n    # None is skipped by extractOne, so we set the current element to None an\n    # revert this change after the comparision\n    processed_orgs[i] = None\n    match = process.extractOne(processed_query, processed_orgs, processor=None, score_cutoff=93)\n    processed_orgs[i] = processed_query\n    if match:\n        df.loc[i, 'fuzzy_match'] = org_list[match[2]]\n        df.loc[i, 'fuzzy_match_score'] = match[1]",
        "score": 47,
        "is_accepted": false,
        "creation_date": "2020-04-22T13:19:04",
        "author": "maxbachmann"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/46598371/overlay-a-line-function-on-a-scatter-plot",
    "title": "Overlay a line function on a scatter plot",
    "question_id": 46598371,
    "posted_date": "2017-10-06T00:37:27",
    "answers": [
      {
        "answer_id": 69635554,
        "body": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# create a dataframe with sample x and y\nnp.random.seed(365)\nx = 5*np.random.random(200)\ndf = pd.DataFrame({'x': x, 'y': 10*x+10*np.random.random(200)})\n# add custom line to the dataframe\nbase_beta = [10, 5]\ndf['y_line'] = base_beta[0] + base_beta[1]*df.x\ndisplay(df.head())\n          x          y     y_line\n0  4.707279  50.634968  33.536394\n1  3.208014  33.890507  26.040068\n2  3.423052  37.853276  27.115262\n3  2.942810  29.899257  24.714052\n4  2.719436  36.932170  23.597180",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2021-10-19T13:50:48",
        "author": "Trenton McKinney"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63459424/how-to-add-multiple-graphs-to-dash-app-on-a-single-browser-page",
    "title": "How to add multiple graphs to Dash app on a single browser page?",
    "question_id": 63459424,
    "posted_date": "2020-08-17T18:25:29",
    "answers": [
      {
        "answer_id": 63464209,
        "body": "import dash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output\nimport pandas as pd\nimport plotly.express as px\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\napp = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n# assume you have a \"long-form\" data frame\n# see https://plotly.com/python/px-arguments/ for more options\ndf_bar = pd.DataFrame({\n    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n    \"Amount\": [4, 1, 2, 2, 4, 5],\n    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n})\nfig = px.bar(df_bar, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\napp.layout = html.Div(children=[\n    # All elements from the top of the page\n    html.Div([\n        html.H1(children='Hello Dash'),\n        html.Div(children='''\n            Dash: A web application framework for Python.\n        '''),\n        dcc.Graph(\n            id='graph1',\n            figure=fig\n        ),\n    ]),\n    # New Div for all elements in the new 'row' of the page\n    html.Div([\n        html.H1(children='Hello Dash'),\n        html.Div(children='''\n            Dash: A web application framework for Python.\n        '''),\n        dcc.Graph(\n            id='graph2',\n            figure=fig\n        ),\n    ]),\n])\nif __name__ == '__main__':\n    app.run_server(debug=True)",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2020-08-18T03:57:16",
        "author": "Kristian Haga"
      },
      {
        "answer_id": 63464209,
        "body": "import dash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output\nimport pandas as pd\nimport plotly.express as px\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\napp = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n# assume you have a \"long-form\" data frame\n# see https://plotly.com/python/px-arguments/ for more options\ndf_bar = pd.DataFrame({\n    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n    \"Amount\": [4, 1, 2, 2, 4, 5],\n    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n})\nfig = px.bar(df_bar, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\n# Data for the tip-graph\ndf_tip = px.data.tips()\napp.layout = html.Div(children=[\n    # All elements from the top of the page\n    html.Div([\n        html.H1(children='Hello Dash'),\n        html.Div(children='''\n            Dash: A web application framework for Python.\n        '''),\n        dcc.Graph(\n            id='example-graph',\n            figure=fig\n        ),\n    ]),\n    # New Div for all elements in the new 'row' of the page\n    html.Div([\n        dcc.Graph(id='tip-graph'),\n        html.Label([\n            \"colorscale\",\n            dcc.Dropdown(\n                id='colorscale-dropdown', clearable=False,\n                value='bluyl', options=[\n                    {'label': c, 'value': c}\n                    for c in px.colors.named_colorscales()\n                ])\n        ]),\n    ])\n])\n# Callback function that automatically updates the tip-graph based on chosen colorscale\n@app.callback(\n    Output('tip-graph', 'figure'),\n    [Input(\"colorscale-dropdown\", \"value\")]\n)\ndef update_tip_figure(colorscale):\n    return px.scatter(\n        df_tip, x=\"total_bill\", y=\"tip\", color=\"size\",\n        color_continuous_scale=colorscale,\n        render_mode=\"webgl\", title=\"Tips\"\n    )\nif __name__ == '__main__':\n    app.run_server(debug=True)",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2020-08-18T03:57:16",
        "author": "Kristian Haga"
      },
      {
        "answer_id": 63464209,
        "body": "import dash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output\nimport pandas as pd\nimport plotly.express as px\nfrom jupyter_dash import JupyterDash\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\napp = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n# assume you have a \"long-form\" data frame\n# see https://plotly.com/python/px-arguments/ for more options\ndf_bar = pd.DataFrame({\n    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n    \"Amount\": [4, 1, 2, 2, 4, 5],\n    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n})\nfig = px.bar(df_bar, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\napp.layout = html.Div(children=[\n    # All elements from the top of the page\n    html.Div([\n        html.Div([\n            html.H1(children='Hello Dash'),\n            html.Div(children='''\n                Dash: A web application framework for Python.\n            '''),\n            dcc.Graph(\n                id='graph1',\n                figure=fig\n            ),\n        ], className='six columns'),\n        html.Div([\n            html.H1(children='Hello Dash'),\n            html.Div(children='''\n                Dash: A web application framework for Python.\n            '''),\n            dcc.Graph(\n                id='graph2',\n                figure=fig\n            ),\n        ], className='six columns'),\n    ], className='row'),\n    # New Div for all elements in the new 'row' of the page\n    html.Div([\n        html.H1(children='Hello Dash'),\n        html.Div(children='''\n            Dash: A web application framework for Python.\n        '''),\n        dcc.Graph(\n            id='graph3',\n            figure=fig\n        ),\n    ], className='row'),\n])\nif __name__ == '__main__':\n    app.run_server(debug=True)",
        "score": 50,
        "is_accepted": true,
        "creation_date": "2020-08-18T03:57:16",
        "author": "Kristian Haga"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15827196/how-can-i-add-a-tag-to-a-key-in-boto-amazon-s3",
    "title": "How can I add a tag to a key in boto (Amazon S3)?",
    "question_id": 15827196,
    "posted_date": "2013-04-05T02:19:34",
    "answers": [
      {
        "answer_id": 61590015,
        "body": "import boto3\ns3_client = boto3.client(\n    's3',\n    region_name='region-name',\n    aws_access_key_id='aws-access-key-id',\n    aws_secret_access_key='aws-secret-access-key',\n)\nget_tags_response = s3_client.get_object_tagging(\n    Bucket='your-bucket-name',\n    Key='folder-if-any/file-name.extension',\n)\nput_tags_response = s3_client.put_object_tagging(\n    Bucket='your-bucket-name',\n    Key='folder-if-any/file-name.extension',\n    Tagging={\n        'TagSet': [\n            {\n                'Key': 'tag-key',\n                'Value': 'tag-value'\n            },\n        ]\n    }\n)",
        "score": 26,
        "is_accepted": false,
        "creation_date": "2020-05-04T06:23:51",
        "author": "valex"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48024720/python-how-to-check-if-socket-is-still-connected",
    "title": "Python - How to check if socket is still connected",
    "question_id": 48024720,
    "posted_date": "2017-12-29T10:21:26",
    "answers": [
      {
        "answer_id": 62277798,
        "body": "import logging\nimport socket\nlogger = logging.getLogger(__name__)\ndef is_socket_closed(sock: socket.socket) -> bool:\n    try:\n        # this will try to read bytes without blocking and also without removing them from buffer (peek only)\n        data = sock.recv(16, socket.MSG_DONTWAIT | socket.MSG_PEEK)\n        if len(data) == 0:\n            return True\n    except BlockingIOError:\n        return False  # socket is open and reading from it would block\n    except ConnectionResetError:\n        return True  # socket was closed for some other reason\n    except Exception as e:\n        logger.exception(\"unexpected exception when checking if a socket is closed\")\n        return False\n    return False",
        "score": 28,
        "is_accepted": false,
        "creation_date": "2020-06-09T04:03:04",
        "author": "Michael Petrov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58592291/how-to-capture-multiple-camera-streams-with-opencv",
    "title": "How to capture multiple camera streams with OpenCV?",
    "question_id": 58592291,
    "posted_date": "2019-10-28T09:59:09",
    "answers": [
      {
        "answer_id": 58599708,
        "body": "from PyQt4 import QtCore, QtGui\nimport qdarkstyle\nfrom threading import Thread\nfrom collections import deque\nfrom datetime import datetime\nimport time\nimport sys\nimport cv2\nimport imutils\nclass CameraWidget(QtGui.QWidget):\n    \"\"\"Independent camera feed\n    Uses threading to grab IP camera frames in the background\n    @param width - Width of the video frame\n    @param height - Height of the video frame\n    @param stream_link - IP/RTSP/Webcam link\n    @param aspect_ratio - Whether to maintain frame aspect ratio or force into fraame\n    \"\"\"\n    def __init__(self, width, height, stream_link=0, aspect_ratio=False, parent=None, deque_size=1):\n        super(CameraWidget, self).__init__(parent)\n\n        # Initialize deque used to store frames read from the stream\n        self.deque = deque(maxlen=deque_size)\n        # Slight offset is needed since PyQt layouts have a built in padding\n        # So add offset to counter the padding\n        self.offset = 16\n        self.screen_width = width - self.offset\n        self.screen_height = height - self.offset\n        self.maintain_aspect_ratio = aspect_ratio\n        self.camera_stream_link = stream_link\n        # Flag to check if camera is valid/working\n        self.online = False\n        self.capture = None\n        self.video_frame = QtGui.QLabel()\n        self.load_network_stream()\n\n        # Start background frame grabbing\n        self.get_frame_thread = Thread(target=self.get_frame, args=())\n        self.get_frame_thread.daemon = True\n        self.get_frame_thread.start()\n        # Periodically set video frame to display\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.set_frame)\n        self.timer.start(.5)\n        print('Started camera: {}'.format(self.camera_stream_link))\n    def load_network_stream(self):\n        \"\"\"Verifies stream link and open new stream if valid\"\"\"\n        def load_network_stream_thread():\n            if self.verify_network_stream(self.camera_stream_link):\n                self.capture = cv2.VideoCapture(self.camera_stream_link)\n                self.online = True\n        self.load_stream_thread = Thread(target=load_network_stream_thread, args=())\n        self.load_stream_thread.daemon = True\n        self.load_stream_thread.start()\n    def verify_network_stream(self, link):\n        \"\"\"Attempts to receive a frame from given link\"\"\"\n        cap = cv2.VideoCapture(link)\n        if not cap.isOpened():\n            return False\n        cap.release()\n        return True\n    def get_frame(self):\n        \"\"\"Reads frame, resizes, and converts image to pixmap\"\"\"\n        while True:\n            try:\n                if self.capture.isOpened() and self.online:\n                    # Read next frame from stream and insert into deque\n                    status, frame = self.capture.read()\n                    if status:\n                        self.deque.append(frame)\n                    else:\n                        self.capture.release()\n                        self.online = False\n                else:\n                    # Attempt to reconnect\n                    print('attempting to reconnect', self.camera_stream_link)\n                    self.load_network_stream()\n                    self.spin(2)\n                self.spin(.001)\n            except AttributeError:\n                pass\n    def spin(self, seconds):\n        \"\"\"Pause for set amount of seconds, replaces time.sleep so program doesnt stall\"\"\"\n        time_end = time.time() + seconds\n        while time.time() < time_end:\n            QtGui.QApplication.processEvents()\n    def set_frame(self):\n        \"\"\"Sets pixmap image to video frame\"\"\"\n        if not self.online:\n            self.spin(1)\n            return\n        if self.deque and self.online:\n            # Grab latest frame\n            frame = self.deque[-1]\n            # Keep frame aspect ratio\n            if self.maintain_aspect_ratio:\n                self.frame = imutils.resize(frame, width=self.screen_width)\n            # Force resize\n            else:\n                self.frame = cv2.resize(frame, (self.screen_width, self.screen_height))\n            # Add timestamp to cameras\n            cv2.rectangle(self.frame, (self.screen_width-190,0), (self.screen_width,50), color=(0,0,0), thickness=-1)\n            cv2.putText(self.frame, datetime.now().strftime('%H:%M:%S'), (self.screen_width-185,37), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), lineType=cv2.LINE_AA)\n            # Convert to pixmap and set to video frame\n            self.img = QtGui.QImage(self.frame, self.frame.shape[1], self.frame.shape[0], QtGui.QImage.Format_RGB888).rgbSwapped()\n            self.pix = QtGui.QPixmap.fromImage(self.img)\n            self.video_frame.setPixmap(self.pix)\n    def get_video_frame(self):\n        return self.video_frame\n\ndef exit_application():\n    \"\"\"Exit program event handler\"\"\"\n    sys.exit(1)\nif __name__ == '__main__':\n    # Create main application window\n    app = QtGui.QApplication([])\n    app.setStyleSheet(qdarkstyle.load_stylesheet_pyqt())\n    app.setStyle(QtGui.QStyleFactory.create(\"Cleanlooks\"))\n    mw = QtGui.QMainWindow()\n    mw.setWindowTitle('Camera GUI')\n    mw.setWindowFlags(QtCore.Qt.FramelessWindowHint)\n    cw = QtGui.QWidget()\n    ml = QtGui.QGridLayout()\n    cw.setLayout(ml)\n    mw.setCentralWidget(cw)\n    mw.showMaximized()\n\n    # Dynamically determine screen width/height\n    screen_width = QtGui.QApplication.desktop().screenGeometry().width()\n    screen_height = QtGui.QApplication.desktop().screenGeometry().height()\n\n    # Create Camera Widgets\n    username = 'Your camera username!'\n    password = 'Your camera password!'\n\n    # Stream links\n    camera0 = 'rtsp://{}:{}@192.168.1.43:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera1 = 'rtsp://{}:{}@192.168.1.45/axis-media/media.amp'.format(username, password)\n    camera2 = 'rtsp://{}:{}@192.168.1.47:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera3 = 'rtsp://{}:{}@192.168.1.40:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera4 = 'rtsp://{}:{}@192.168.1.44:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera5 = 'rtsp://{}:{}@192.168.1.42:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera6 = 'rtsp://{}:{}@192.168.1.46:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n    camera7 = 'rtsp://{}:{}@192.168.1.41:554/cam/realmonitor?channel=1&subtype=0'.format(username, password)\n\n    # Create camera widgets\n    print('Creating Camera Widgets...')\n    zero = CameraWidget(screen_width//3, screen_height//3, camera0)\n    one = CameraWidget(screen_width//3, screen_height//3, camera1)\n    two = CameraWidget(screen_width//3, screen_height//3, camera2)\n    three = CameraWidget(screen_width//3, screen_height//3, camera3)\n    four = CameraWidget(screen_width//3, screen_height//3, camera4)\n    five = CameraWidget(screen_width//3, screen_height//3, camera5)\n    six = CameraWidget(screen_width//3, screen_height//3, camera6)\n    seven = CameraWidget(screen_width//3, screen_height//3, camera7)\n\n    # Add widgets to layout\n    print('Adding widgets to layout...')\n    ml.addWidget(zero.get_video_frame(),0,0,1,1)\n    ml.addWidget(one.get_video_frame(),0,1,1,1)\n    ml.addWidget(two.get_video_frame(),0,2,1,1)\n    ml.addWidget(three.get_video_frame(),1,0,1,1)\n    ml.addWidget(four.get_video_frame(),1,1,1,1)\n    ml.addWidget(five.get_video_frame(),1,2,1,1)\n    ml.addWidget(six.get_video_frame(),2,0,1,1)\n    ml.addWidget(seven.get_video_frame(),2,1,1,1)\n    print('Verifying camera credentials...')\n    mw.show()\n    QtGui.QShortcut(QtGui.QKeySequence('Ctrl+Q'), mw, exit_application)\n    if(sys.flags.interactive != 1) or not hasattr(QtCore, 'PYQT_VERSION'):\n        QtGui.QApplication.instance().exec_()",
        "score": 45,
        "is_accepted": true,
        "creation_date": "2019-10-28T19:35:43",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67085963/generate-colors-of-noise-in-python",
    "title": "Generate colors of noise in Python",
    "question_id": 67085963,
    "posted_date": "2021-04-14T01:27:36",
    "answers": [
      {
        "answer_id": 67127726,
        "body": "def noise_psd(N, psd = lambda f: 1):\n        X_white = np.fft.rfft(np.random.randn(N));\n        S = psd(np.fft.rfftfreq(N))\n        # Normalize S\n        S = S / np.sqrt(np.mean(S**2))\n        X_shaped = X_white * S;\n        return np.fft.irfft(X_shaped);\ndef PSDGenerator(f):\n    return lambda N: noise_psd(N, f)\n@PSDGenerator\ndef white_noise(f):\n    return 1;\n@PSDGenerator\ndef blue_noise(f):\n    return np.sqrt(f);\n@PSDGenerator\ndef violet_noise(f):\n    return f;\n@PSDGenerator\ndef brownian_noise(f):\n    return 1/np.where(f == 0, float('inf'), f)\n@PSDGenerator\ndef pink_noise(f):\n    return 1/np.where(f == 0, float('inf'), np.sqrt(f))",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2021-04-16T11:06:21",
        "author": "Bob"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45828616/streaming-large-training-and-test-files-into-tensorflows-dnnclassifier",
    "title": "Streaming large training and test files into Tensorflow&#39;s DNNClassifier",
    "question_id": 45828616,
    "posted_date": "2017-08-22T20:01:29",
    "answers": [
      {
        "answer_id": 45829855,
        "body": "class MyCsvDatasetBuilder(tfds.core.GeneratorBasedBuilder):\n  VERSION = tfds.core.Version(\"0.0.1\")\n  def _info(self):\n    return tfds.core.DatasetInfo(\n        builder=self,\n        description=(\n            \"My dataset\"),\n        features=tfds.features.FeaturesDict({\n            \"features\": tfds.features.Tensor(\n              shape=(FEATURE_SIZE,), dtype=tf.float32),\n            \"label\": tfds.features.ClassLabel(\n                names=CLASS_NAMES),\n            \"index\": tfds.features.Tensor(shape=(), dtype=tf.float32)\n        }),\n        supervised_keys=(\"features\", \"label\"),\n    )\n  def _split_generators(self, dl_manager):\n    paths = dict(\n      train='/path/to/train.csv',\n      test='/path/to/test.csv',\n    )\n    # better yet, if the csv files were originally downloaded, use\n    # urls = dict(train=train_url, test=test_url)\n    # paths = dl_manager.download(urls)\n    return [\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TRAIN,\n            num_shards=10,\n            gen_kwargs=dict(path=paths['train'])),\n        tfds.core.SplitGenerator(\n            name=tfds.Split.TEST,\n            num_shards=2,\n            gen_kwargs=dict(cvs_path=paths['test']))\n    ]\n  def _generate_examples(self, csv_path):\n    with open(csv_path, 'r') as f:\n        for i, line in enumerate(f.readlines()):\n            record = line.rstrip().split(',')\n            features = [float(n) for n in record[:-1]]\n            label = int(record[-1])\n            yield dict(features=features, label=label, index=i)",
        "score": 36,
        "is_accepted": false,
        "creation_date": "2017-08-22T22:47:44",
        "author": "DomJack"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39845982/customizing-django-admin-changeform-template-adding-custom-content",
    "title": "customizing django admin ChangeForm template / adding custom content",
    "question_id": 39845982,
    "posted_date": "2016-10-04T02:56:41",
    "answers": [
      {
        "answer_id": 39848376,
        "body": "class MyObjectAdmin(admin.ModelAdmin):\n    # A template for a very customized change view:\n    change_form_template = 'admin/my_change_form.html'\n    def get_dynamic_info(self):\n        # ...\n        pass\n    def change_view(self, request, object_id, form_url='', extra_context=None):\n        extra_context = extra_context or {}\n        extra_context['osm_data'] = self.get_dynamic_info()\n        return super(MyObjectAdmin, self).change_view(\n            request, object_id, form_url, extra_context=extra_context,\n        )",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2016-10-04T05:10:35",
        "author": "Sagar Ramachandrappa"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/22306341/python-sklearn-how-to-calculate-p-values",
    "title": "Python sklearn - how to calculate p-values",
    "question_id": 22306341,
    "posted_date": "2014-03-10T12:52:21",
    "answers": [
      {
        "answer_id": 55655645,
        "body": "                           Logit Regression Results\n==============================================================================\nDep. Variable:                      y   No. Observations:               406723\nModel:                          Logit   Df Residuals:                   406710\nMethod:                           MLE   Df Model:                           12\nDate:                Fri, 12 Apr 2019   Pseudo R-squ.:                0.001661\nTime:                        16:48:45   Log-Likelihood:            -2.8145e+05\nconverged:                      False   LL-Null:                   -2.8192e+05\n                                        LLR p-value:                8.758e-193\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nx1            -0.0037      0.003     -1.078      0.281      -0.010       0.003",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2019-04-12T12:06:43",
        "author": "LinNotFound"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53587315/pandas-find-specific-value-in-entire-dataframe",
    "title": "Pandas - find specific value in entire dataframe",
    "question_id": 53587315,
    "posted_date": "2018-12-02T23:04:07",
    "answers": [
      {
        "answer_id": 64998151,
        "body": "small_df = pd.DataFrame({\"A\":list(range(500)), \"B\":list(range(500, 1000))})\nlarge_df = pd.DataFrame({\"A\":list(range(100000)), \"B\":list(range(100000, 200000))})\nlargest_df = pd.DataFrame({\"A\":list(range(1000000)), \"B\":list(range(1000000, 2000000))})\ndef filter_df_by_value_eq(df, value):\n    return df[df.eq(value).any(axis=1)]\ndef filter_df_by_value_ravel(df, value):\n    return df[(df.values.ravel() == value).reshape(df.shape).any(1)]\nIn [8]: %timeit filter_df_by_value_eq(small_df, 612)\n175 \u00b5s \u00b1 1.01 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10,000 loops each)\nIn [9]: %timeit filter_df_by_value_ravel(small_df, 612)\n78.9 \u00b5s \u00b1 215 ns per loop (mean \u00b1 std. dev. of 7 runs, 10,000 loops each)\nIn [10]: %timeit filter_df_by_value_eq(large_df, 1502964)\n307 \u00b5s \u00b1 2.21 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\nIn [11]: %timeit filter_df_by_value_ravel(large_df, 1502964)\n1.56 ms \u00b1 13.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\nIn [12]: %timeit filter_df_by_value_eq(largest_df, 10502964)\n3.04 ms \u00b1 66.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\nIn [13]: %timeit filter_df_by_value_ravel(largest_df, 10502964)\n15.2 ms \u00b1 43.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2020-11-24T22:32:39",
        "author": "Vijay Anand Pandian"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57249273/how-to-detect-paragraphs-in-a-text-document-image-for-a-non-consistent-text-stru",
    "title": "How to detect paragraphs in a text document image for a non-consistent text structure in Python OpenCV",
    "question_id": 57249273,
    "posted_date": "2019-07-29T03:46:59",
    "answers": [
      {
        "answer_id": 57262099,
        "body": "import cv2\nimport numpy as np\n# Load image, grayscale, Gaussian blur, Otsu's threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (7,7), 0)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n# Create rectangular structuring element and dilate\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\ndilate = cv2.dilate(thresh, kernel, iterations=4)\n# Find contours and draw rectangle\ncnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    x,y,w,h = cv2.boundingRect(c)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\ncv2.imshow('thresh', thresh)\ncv2.imshow('dilate', dilate)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2019-07-29T18:28:19",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55751368/python-how-to-pass-to-a-function-argument-type-of-a-class-object-typing",
    "title": "Python - how to pass to a function argument type of a class object (typing)",
    "question_id": 55751368,
    "posted_date": "2019-04-18T13:52:18",
    "answers": [
      {
        "answer_id": 60366318,
        "body": "from typing import Type, TypeVar\nclass Vehicle:\n    def __init__(self):\n        print(\"Creating a %s\" % self.__class__.__name__)\n    def move(self):\n        print(\"This %s is moving\u2026\" % self.__class__.__name__)\nTVehicle = TypeVar(\"TVehicle\", bound=Vehicle)\nclass Car(Vehicle):\n    def honk(self) -> None:\n        print(\"tuuuuut\")\nclass Bike(Vehicle):\n    def ring(self) -> None:\n        print(\"ring\")\nclass Dog:\n    def bark(self) -> None:\n        print(\"woof!\")\ndef move(v: Vehicle) -> None:\n    v.move()\ndef instantiate(class_to_instantiate: Type[TVehicle]) -> TVehicle:\n    return class_to_instantiate()  # create an instance\nmove(Bike())\nmove(Car())\ninstantiate(Bike).ring()\ninstantiate(Car).honk()\n#instantiate(Dog)",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2020-02-23T15:02:08",
        "author": "Oliver W."
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44850701/multiple-aiohttp-applications-running-in-the-same-process",
    "title": "Multiple aiohttp Application()&#39;s running in the same process?",
    "question_id": 44850701,
    "posted_date": "2017-06-30T12:03:30",
    "answers": [
      {
        "answer_id": 59018487,
        "body": "import asyncio\nfrom aiohttp import web\nrunners = []\nasync def start_site(app, address='localhost', port=8080):\n    runner = web.AppRunner(app)\n    runners.append(runner)\n    await runner.setup()\n    site = web.TCPSite(runner, address, port)\n    await site.start()\nloop = asyncio.get_event_loop()\nloop.create_task(start_site(web.Application()))\nloop.create_task(start_site(web.Application(), port=8081))\nloop.create_task(start_site(web.Application(), port=8082))\ntry:\n    loop.run_forever()\nexcept:\n    pass\nfinally:\n    for runner in runners:\n        loop.run_until_complete(runner.cleanup())",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2019-11-24T09:05:11",
        "author": "Bryan Wyatt"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71539448/using-different-pydantic-models-depending-on-the-value-of-fields",
    "title": "Using different Pydantic models depending on the value of fields",
    "question_id": 71539448,
    "posted_date": "2022-03-19T11:23:52",
    "answers": [
      {
        "answer_id": 71545639,
        "body": "#1 Successful Response   #2 Validation error                   #3 Validation error\n\n# Request body           # Request body                        # Request body\n{                        {                                     {\n  \"model_type\": \"m1\",      \"model_type\": \"m1\",                   \"model_type\": \"m2\",\n  \"A\": \"string\",           \"A\": \"string\",                        \"A\": \"string\",\n  \"B\": 0,                  \"C\": \"string\",                        \"C\": \"string\",\n  \"C\": \"string\",           \"D\": \"string\"                         \"D\": \"string\"\n  \"D\": \"string\"          }                                     }\n}\n\n# Server response    \t # Server response                     # Server response\n200                      {                                     {\n                           \"detail\": [                           \"detail\": [\n                             {                                     {\n                               \"loc\": [                              \"loc\": [\n                                 \"body\",                               \"body\",\n                                 \"Model1\",                             \"Model2\",\n                                 \"B\"                                   \"E\"\n                               ],                                    ],\n                               \"msg\": \"field required\",              \"msg\": \"field required\",\n                               \"type\": \"value_error.missing\"         \"type\": \"value_error.missing\"\n                             }                                     },\n                           ]                                       {\n                         }                                           \"loc\": [\n                                                                       \"body\",\n                                                                       \"Model2\",\n                                                                       \"F\"\n                                                                     ],\n                                                                     \"msg\": \"field required\",\n                                                                     \"type\": \"value_error.missing\"\n                                                                   }\n                                                                 ]\n                                                               }",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2022-03-20T05:43:31",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53394935/what-is-the-right-way-to-close-a-dask-localcluster",
    "title": "What is the &quot;right&quot; way to close a Dask LocalCluster?",
    "question_id": 53394935,
    "posted_date": "2018-11-20T09:13:28",
    "answers": [
      {
        "answer_id": 59015702,
        "body": "def load_and_predict(input_data_chunk):\n    model_path = '...' # On your disk, so accessible by all processes.\n    model = some_library.load_model(model_path)\n    labels, scores = model.predict(input_data_chunk, ...)\n    return np.array([labels, scores])\n# (not shown) Load `input_data`, a list of your 1M examples.\nimport dask.array as DaskArray\nda_input_data = DaskArray.from_array(input_data, chunks=(10_000,))\nprediction_results = None\nwith LocalCluster(n_workers=int(0.9 * mp.cpu_count()),\n    processes=True,\n    threads_per_worker=1,\n    memory_limit='2GB',\n    ip='tcp://localhost:9895',\n) as cluster, Client(cluster) as client:\n    prediction_results = da_input_data.map_blocks(load_and_predict).compute()\n# Combine prediction_results, which will be a list of Numpy arrays,\n# each with labels, scores for 10,000 examples.",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2019-11-24T02:59:57",
        "author": "Abhishek Divekar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71814658/python-typing-does-typeddict-allow-additional-extra-keys",
    "title": "Python typing: Does TypedDict allow additional / extra keys?",
    "question_id": 71814658,
    "posted_date": "2022-04-10T03:41:58",
    "answers": [
      {
        "answer_id": 71814659,
        "body": "> m: Movie = dict(\n>       name='Alien',\n>       year=1979,\n>       director='Ridley Scott')  # error: Unexpected key 'director'\n[emphasis by me]\nThe typecheckers `mypy`, `pyre`,  and `pyright` implement this according to the specification.\nHowever, it is possible that a value with extra keys is accepted. This is because subtyping of TypedDicts is allowed, and the subtype might implement the extra key. PEP-589 only forbids extra keys in object construction, i.e. in literal assignment. As any value that complies with a subtype is always deemed to comply with the parent type and can be upcasted from the subtype to the parent type, an extra key can be introduced through a subtype:",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2022-04-10T03:41:58",
        "author": "Jonathan Herrera"
      },
      {
        "answer_id": 71814659,
        "body": "In the example above, we see that the same value can sometimes be considered complying with `Movie` by the typing system, and sometimes not.\nAs a consequence of subtyping, typing a parameter as a certain TypedDict is not a safeguard against extra keys, because they could have been introduced through a subtype.\nIf your code is sensitive with regard to the presence of extra keys (for instance, if it makes use of `param.keys()`, `param.values()` or `len(param)` on the `TypedDict` parameter `param`), this could lead to problems when extra keys are present. A solution to this problem is to either handle the exceptional case that extra keys are actually present on the parameter or to make your code insensitive against extra keys.\nIf you want to test that your code is robust against extra keys, you cannot simply add a key in the test value:",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2022-04-10T03:41:58",
        "author": "Jonathan Herrera"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62824000/can-i-have-an-optional-parameter-in-dataclasses-that-is-omitted-when-transformed",
    "title": "Can I have an optional parameter in dataclasses that is omitted when transformed to dict?",
    "question_id": 62824000,
    "posted_date": "2020-07-09T17:29:35",
    "answers": [
      {
        "answer_id": 62827701,
        "body": "from dataclasses import asdict, dataclass\nfrom typing import List, Optional\nfrom validated_dc import ValidatedDC\n@dataclass\nclass SubOrder(ValidatedDC):\n    name: str\n@dataclass\nclass Order(ValidatedDC):\n    name: str\n    sub_orders: Optional[List[SubOrder]] = None\n    def as_dict(self):\n        data = asdict(self)\n        return {key: value for key, value in data.items() if value is not None}\ndata = {'name': 'pizza'}\norder = Order(**data)\nassert order.get_errors() is None\nassert asdict(order) == {'name': 'pizza', 'sub_orders': None}\nassert order.as_dict() == {'name': 'pizza'}\ndata = {'name': 'pizza', 'sub_orders': [{'name': 'pasta'}]}\norder = Order(**data)\nassert order.get_errors() is None\nassert asdict(order) == {'name': 'pizza', 'sub_orders': [{'name': 'pasta'}]}\nassert isinstance(order.sub_orders[0], SubOrder)",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2020-07-10T01:11:22",
        "author": "Evgeniy_Burdin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71371909/how-to-calculate-when-ones-10000-day-after-his-or-her-birthday-will-be",
    "title": "How to calculate when one&#39;s 10000 day after his or her birthday will be",
    "question_id": 71371909,
    "posted_date": "2022-03-06T11:00:53",
    "answers": [
      {
        "answer_id": 71372125,
        "body": "def is_it_a_leap_year(year) -> bool:\n    \"\"\"\n    Determine if a year is a leap year\n    Args:\n        year: int\n    Extended Summary:\n        According to:\n            https://airandspace.si.edu/stories/editorial/science-leap-year\n        The rule is that if the year is divisible by 100 and not divisible by\n        400, leap year is skipped. The year 2000 was a leap year, for example,\n        but the years 1700, 1800, and 1900 were not.  The next time a leap year\n        will be skipped is the year 2100.\n    \"\"\"\n    if year % 4 != 0:\n        return False\n    if year % 100 == 0 and year % 400 != 0:\n        return False\n    return True",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2022-03-06T11:28:48",
        "author": "Blithering"
      },
      {
        "answer_id": 71372125,
        "body": "def age_after_n_days(start_year: int,\n                     start_month: int,\n                     start_day: int,\n                     n_days: int) -> tuple:\n    \"\"\"\n    Calculate an approximate age of a person after a given number of days,\n    attempting to take into account leap years appropriately.\n    Return the number of days left until their next birthday\n    Args:\n        start_year (int): year of the start date\n        start_month (int): month of the start date\n        start_day (int): day of the start date\n        n_days (int): number of days to elapse\n    \"\"\"\n    # Check if the start date happens on a leap year and occurs before the\n    # 29 February (additional leap year day)\n    start_pre_leap = (is_it_a_leap_year(start_year) and start_month < 3)\n    # Account for the edge case where you start exactly on the 29 February\n    if start_month == 2 and start_day == 29:\n        start_pre_leap = False\n    # Keep a running counter of age\n    age = 0\n    # Store the \"current year\" whilst iterating through the days\n    current_year = start_year\n    # Count the number of days left\n    days_left = n_days\n    # While there is at least one year left to elapse...\n    while days_left > 364:\n        # Is it a leap year?\n        if is_it_a_leap_year(current_year):\n            # If not the first year\n            if age > 0:\n                days_left -= 366\n            # If the first year is a leap year but starting after the 29 Feb...\n            elif age == 0 and not start_pre_leap:\n                days_left -= 365\n            else:\n                days_left -= 366\n        # If not a leap year...\n        else:\n            days_left -= 365\n        # If the number of days left hasn't dropped below zero\n        if days_left >= 0:\n            # Increment age\n            age += 1\n            # Increment year\n            current_year += 1\n    return age, days_left",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2022-03-06T11:28:48",
        "author": "Blithering"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63679315/how-to-use-cython-with-poetry",
    "title": "How to use Cython with Poetry?",
    "question_id": 63679315,
    "posted_date": "2020-08-31T19:09:14",
    "answers": [
      {
        "answer_id": 63679316,
        "body": "import os\n# See if Cython is installed\ntry:\n    from Cython.Build import cythonize\n# Do nothing if Cython is not available\nexcept ImportError:\n    # Got to provide this function. Otherwise, poetry will fail\n    def build(setup_kwargs):\n        pass\n# Cython is installed. Compile\nelse:\n    from setuptools import Extension\n    from setuptools.dist import Distribution\n    from distutils.command.build_ext import build_ext\n    # This function will be executed in setup.py:\n    def build(setup_kwargs):\n        # The file you want to compile\n        extensions = [\n            \"mylibrary/myfile.py\"\n        ]\n        # gcc arguments hack: enable optimizations\n        os.environ['CFLAGS'] = '-O3'\n        # Build\n        setup_kwargs.update({\n            'ext_modules': cythonize(\n                extensions,\n                language_level=3,\n                compiler_directives={'linetrace': True},\n            ),\n            'cmdclass': {'build_ext': build_ext}\n        })",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2020-08-31T19:09:14",
        "author": "kolypto"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62066474/python-flask-automatically-generated-swagger-openapi-3-0",
    "title": "Python Flask automatically generated Swagger/OpenAPI 3.0",
    "question_id": 62066474,
    "posted_date": "2020-05-28T09:55:16",
    "answers": [
      {
        "answer_id": 62166840,
        "body": "from apispec import APISpec\nfrom apispec.ext.marshmallow import MarshmallowPlugin\nfrom apispec_webframeworks.flask import FlaskPlugin\nfrom marshmallow import Schema, fields\nfrom flask import Flask, abort, request, make_response, jsonify\nfrom pprint import pprint\nimport json\nclass DemoParameter(Schema):\n    gist_id = fields.Int()\nclass DemoSchema(Schema):\n    id = fields.Int()\n    content = fields.Str()\nspec = APISpec(\n    title=\"Demo API\",\n    version=\"1.0.0\",\n    openapi_version=\"3.0.2\",\n    info=dict(\n        description=\"Demo API\",\n        version=\"1.0.0-oas3\",\n        contact=dict(\n            email=\"admin@donofden.com\"\n            ),\n        license=dict(\n            name=\"Apache 2.0\",\n            url='http://www.apache.org/licenses/LICENSE-2.0.html'\n            )\n        ),\n    servers=[\n        dict(\n            description=\"Test server\",\n            url=\"https://resources.donofden.com\"\n            )\n        ],\n    tags=[\n        dict(\n            name=\"Demo\",\n            description=\"Endpoints related to Demo\"\n            )\n        ],\n    plugins=[FlaskPlugin(), MarshmallowPlugin()],\n)\nspec.components.schema(\"Demo\", schema=DemoSchema)\n# spec.components.schema(\n#     \"Gist\",\n#     {\n#         \"properties\": {\n#             \"id\": {\"type\": \"integer\", \"format\": \"int64\"},\n#             \"name\": {\"type\": \"string\"},\n#         }\n#     },\n# )\n#\n# spec.path(\n#     path=\"/gist/{gist_id}\",\n#     operations=dict(\n#         get=dict(\n#             responses={\"200\": {\"content\": {\"application/json\": {\"schema\": \"Gist\"}}}}\n#         )\n#     ),\n# )\n# Extensions initialization\n# =========================\napp = Flask(__name__)\n@app.route(\"/demo/<gist_id>\", methods=[\"GET\"])\ndef my_route(gist_id):\n    \"\"\"Gist detail view.\n    ---\n    get:\n      parameters:\n      - in: path\n        schema: DemoParameter\n      responses:\n        200:\n          content:\n            application/json:\n              schema: DemoSchema\n        201:\n          content:\n            application/json:\n              schema: DemoSchema\n    \"\"\"\n    # (...)\n    return jsonify('foo')\n# Since path inspects the view and its route,\n# we need to be in a Flask request context\nwith app.test_request_context():\n    spec.path(view=my_route)\n# We're good to go! Save this to a file for now.\nwith open('swagger.json', 'w') as f:\n    json.dump(spec.to_dict(), f)\npprint(spec.to_dict())\nprint(spec.to_yaml())",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2020-06-03T02:49:14",
        "author": "DonOfDen"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48524196/how-to-get-python-to-run-python-3-in-wsl-bash",
    "title": "How to get `python` to run Python 3 in WSL bash?",
    "question_id": 48524196,
    "posted_date": "2018-01-30T09:48:17",
    "answers": [
      {
        "answer_id": 68476984,
        "body": "cameron@Nook:/mnt/c/Users/camer$ sudo apt install python-is-python3\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following NEW packages will be installed:\n  python-is-python3\n0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2364 B of archives.\nAfter this operation, 10.2 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 python-is-python3 all 3.8.2-4 [2364 B]\nFetched 2364 B in 0s (7208 B/s)\nSelecting previously unselected package python-is-python3.\n(Reading database ... 33571 files and directories currently installed.)\nPreparing to unpack .../python-is-python3_3.8.2-4_all.deb ...\nUnpacking python-is-python3 (3.8.2-4) ...\nSetting up python-is-python3 (3.8.2-4) ...\ncameron@Nook:/mnt/c/Users/camer$ python --version\nPython 3.8.10",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2021-07-21T18:05:14",
        "author": "Cameron Tacklind"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73563804/what-is-the-recommended-way-to-instantiate-and-pass-around-a-redis-client-with-f",
    "title": "What is the recommended way to instantiate and pass around a redis client with FastAPI",
    "question_id": 73563804,
    "posted_date": "2022-08-31T22:45:56",
    "answers": [
      {
        "answer_id": 73585930,
        "body": "from fastapi import Depends, FastAPI\nimport redis\nfrom config.db import pool\napp = FastAPI()\ndef get_redis():\n  # Here, we re-use our connection pool\n  # not creating a new one\n  return redis.Redis(connection_pool=pool)\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, cache = Depends(get_redis)):\n  status = cache.get(item_id)\n  return {\"item_name\": status}\n@app.put(\"/items/{item_id}\")\ndef update_item(item_id: int, cache = Depends(get_redis)):\n  cache.set(item_id, \"available\")\n  return {\"status\": \"available\", \"item_id\": item_id}",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2022-09-02T13:06:31",
        "author": "Tegar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64118680/reload-flag-with-uvicorn-can-we-exclude-certain-code",
    "title": "reload flag with uvicorn: can we exclude certain code?",
    "question_id": 64118680,
    "posted_date": "2020-09-29T07:28:34",
    "answers": [
      {
        "answer_id": 64118929,
        "body": "--reload-include TEXT           Set glob patterns to include while watching\n                                  for files. Includes '*.py' by default, which\n                                  can be overridden in reload-excludes.\n  --reload-exclude TEXT           Set glob patterns to exclude while watching\n                                  for files. Includes '.*, .py[cod], .sw.*,\n                                  ~*' by default, which can be overridden in\n                                  reload-excludes.",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2020-09-29T07:44:32",
        "author": "euri10"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/35785962/python-how-do-i-find-which-pip-package-a-library-belongs-to",
    "title": "Python: How do I find which pip package a library belongs to?",
    "question_id": 35785962,
    "posted_date": "2016-03-03T19:42:53",
    "answers": [
      {
        "answer_id": 75144378,
        "body": ">>> from importlib.metadata import packages_distributions\n>>> packages_distributions()\n 'asttokens': ['asttokens'],\n 'backcall': ['backcall'],\n 'bitarray': ['bitarray'],\n 'colorama': ['colorama'],\n 'decorator': ['decorator'],\n 'executing': ['executing'],\n 'importlib_metadata': ['importlib-metadata'],\n 'impala': ['impyla'],\n 'IPython': ['ipython'],\n 'jedi': ['jedi'],\n 'matplotlib_inline': ['matplotlib-inline'],\n 'parso': ['parso'],\n 'pickleshare': ['pickleshare'],\n 'pip': ['pip'],\n 'prompt_toolkit': ['prompt-toolkit'],\n 'pure_eval': ['pure-eval'],\n 'puresasl': ['pure-sasl'],\n 'pygments': ['Pygments'],\n '_distutils_hack': ['setuptools'],\n 'pkg_resources': ['setuptools'],\n 'setuptools': ['setuptools'],\n 'six': ['six'],\n 'stack_data': ['stack-data'],\n 'thrift': ['thrift'],\n 'thrift_sasl': ['thrift-sasl'],\n 'traitlets': ['traitlets'],\n 'wcwidth': ['wcwidth'],\n 'zipp': ['zipp']}",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-01-17T04:33:40",
        "author": "Niko Fohr"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76459034/how-to-load-a-fine-tuned-peft-lora-model-based-on-llama-with-huggingface-transfo",
    "title": "How to load a fine-tuned peft/lora model based on llama with Huggingface transformers?",
    "question_id": 76459034,
    "posted_date": "2023-06-12T13:34:46",
    "answers": [
      {
        "answer_id": 76469875,
        "body": "import torch\nfrom peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\nmodel_name = \"decapoda-research/llama-7b-hf\"\nadapters_name = \"lucas0/empath-llama-7b\"\nprint(f\"Starting to load the model {model_name} into memory\")\nm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    #load_in_4bit=True,\n    torch_dtype=torch.bfloat16,\n    device_map={\"\": 0}\n)\nm = PeftModel.from_pretrained(m, adapters_name)\nm = m.merge_and_unload()\ntok = LlamaTokenizer.from_pretrained(model_name)\ntok.bos_token_id = 1\nstop_token_ids = [0]\nprint(f\"Successfully loaded the model {model_name} into memory\")",
        "score": 16,
        "is_accepted": true,
        "creation_date": "2023-06-13T23:01:37",
        "author": "alvas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59725560/finding-all-the-combinations-of-free-polyominoes-within-a-specific-area-with-a-s",
    "title": "Finding all the combinations of free polyominoes within a specific area with a SAT-solver (Python)",
    "question_id": 59725560,
    "posted_date": "2020-01-13T18:17:32",
    "answers": [
      {
        "answer_id": 59726235,
        "body": "from ortools.sat.python import cp_model\n(W, H) = (3, 3) # Width and height of our grid.\n(X, Y) = (0, 1) # Convenience constants.\ndef main():\n  model = cp_model.CpModel()\n  # Create an Int var for each block of each shape constrained to be within width and height of grid.\n  shapes = [\n    [\n      [ model.NewIntVar(0, W, 's1b1_x'), model.NewIntVar(0, H, 's1b1_y') ],\n      [ model.NewIntVar(0, W, 's1b2_x'), model.NewIntVar(0, H, 's1b2_y') ],\n      [ model.NewIntVar(0, W, 's1b3_x'), model.NewIntVar(0, H, 's1b3_y') ],\n    ],\n    [\n      [ model.NewIntVar(0, W, 's2b1_x'), model.NewIntVar(0, H, 's2b1_y') ],\n      [ model.NewIntVar(0, W, 's2b2_x'), model.NewIntVar(0, H, 's2b2_y') ],\n    ]\n  ]\n  # Define the shapes by constraining the blocks relative to each other.\n  # 3x1 rectangle:\n  s0 = shapes[0]\n  model.Add(s0[0][Y] == s0[1][Y])\n  model.Add(s0[0][Y] == s0[2][Y])\n  model.Add(s0[0][X] == s0[1][X] - 1)\n  model.Add(s0[0][X] == s0[2][X] - 2)\n  # 1x2 rectangle:\n  s1 = shapes[1]\n  model.Add(s1[0][X] == s1[1][X])\n  model.Add(s1[0][Y] == s1[1][Y] - 1)\n  # No blocks can overlap:\n  block_addresses = []\n  for i, block in enumerate(blocks(shapes)):\n    block_address = model.NewIntVar(0, (W+1)*(H+1), 'b%d' % (i,))\n    model.Add(block[X] + (H+1)*block[Y] == block_address)\n    block_addresses.append(block_address)\n  model.AddAllDifferent(block_addresses)\n  # Solve and print solutions as we find them\n  solver = cp_model.CpSolver()\n  solution_printer = SolutionPrinter(shapes)\n  status = solver.SearchForAllSolutions(model, solution_printer)\n  print('Status = %s' % solver.StatusName(status))\n  print('Number of solutions found: %i' % solution_printer.count)\ndef blocks(shapes):\n  ''' Helper to enumerate all blocks. '''\n  for shape in shapes:\n    for block in shape:\n      yield block\nclass SolutionPrinter(cp_model.CpSolverSolutionCallback):\n    ''' Print a solution. '''\n    def __init__(self, variables):\n        cp_model.CpSolverSolutionCallback.__init__(self)\n        self.variables = variables\n        self.count = 0\n    def on_solution_callback(self):\n      self.count += 1\n      solution = [(self.Value(block[X]), self.Value(block[Y])) for shape in self.variables for block in shape]\n      print((W+3)*'-')\n      for y in range(0, H+1):\n        print('|' + ''.join(['#' if (x,y) in solution else ' ' for x in range(0, W+1)]) + '|')\n      print((W+3)*'-')\nif __name__ == '__main__':\n  main()",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2020-01-13T19:59:37",
        "author": "spinkus"
      },
      {
        "answer_id": 59726235,
        "body": "import numpy as np\nfrom copy import copy\nfrom tabulate import tabulate\nD = 4 # Dimension of square grid.\nKCC = [5,4,2,2] # List of the sizes of the required k connected components (KCCs).\nassert(sum(KCC) <= D*D)\nVALID_CELLS = range(2,D*D)\ndef search():\n  solutions = set() # Stash of unique solutions.\n  for start in VALID_CELLS: # Try starting search from each possible starting point and expand out.\n    marked = np.zeros(D*D).tolist()\n    _search(start, marked, set(), solutions, 0, 0)\n  for solution in solutions:  # Print results.\n    print(tabulate(np.array(solution).reshape(D, D)))\n  print('Number of solutions found:', len(solutions))\ndef _search(i, marked, fringe, solutions, curr_count, curr_part):\n  ''' Recursively find each possible KCC in the remaining available cells the find the next, until none left '''\n  marked[i] = curr_part+1\n  curr_count += 1\n  if curr_count == KCC[curr_part]: # If marked K cells for the current CC move onto the next one.\n    curr_part += 1\n    if curr_part == len(KCC): # If marked K cells and there's no more CCs left we have a solution - not necessarily unique.\n      solutions.add(tuple(marked))\n    else:\n      for start in VALID_CELLS:\n        if marked[start] == 0:\n          _search(start, copy(marked), set(), solutions, 0, curr_part)\n  else:\n    fringe.update(neighbours(i, D))\n    while(len(fringe)):\n      j = fringe.pop()\n      if marked[j] == 0:\n        _search(j, copy(marked), copy(fringe), solutions, curr_count, curr_part)\ndef neighbours(i, D):\n  ''' Find the address of all cells neighbouring the i-th cell in a DxD grid. '''\n  row = int(i/D)\n  n = []\n  n += [i-1] if int((i-1)/D) == row and (i-1) >= 0 else []\n  n += [i+1] if int((i+1)/D) == row and (i+1) < D**2 else []\n  n += [i-D] if (i-D) >=0 else []\n  n += [i+D] if (i+D) < D**2 else []\n  return filter(lambda x: x in VALID_CELLS, n)\nif __name__ == '__main__':\n  search()",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2020-01-13T19:59:37",
        "author": "spinkus"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70383316/pydantic-constr-vs-field-args",
    "title": "Pydantic constr vs Field args",
    "question_id": 70383316,
    "posted_date": "2021-12-16T12:34:59",
    "answers": [
      {
        "answer_id": 70391508,
        "body": "    strip_whitespace: bool = False: removes leading and trailing whitespace\n    to_lower: bool = False: turns all characters to lowercase\n    to_upper: bool = False: turns all characters to uppercase\n    strict: bool = False: controls type coercion\n    min_length: int = None: minimum length of the string\n    max_length: int = None: maximum length of the string\n    curtail_length: int = None: shrinks the string length to the set value when it is longer than the set value\n    regex: str = None: regex to validate the string against",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2021-12-17T05:10:51",
        "author": "Bastien B"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67750367/fastapi-python-code-execution-speed-impacted-by-deployment-with-uvicorn-vs-gunic",
    "title": "Fastapi python code execution speed impacted by deployment with uvicorn vs gunicorn",
    "question_id": 67750367,
    "posted_date": "2021-05-29T06:37:31",
    "answers": [
      {
        "answer_id": 67880089,
        "body": "import asyncio, time\nfrom fastapi import FastAPI, Path\nfrom datetime import datetime\nimport statistics\napp = FastAPI()\n@app.get(\"/delay/{delay1}/{delay2}\")\nasync def get_delay(\n    delay1: float = Path(..., title=\"Nonblocking time taken to respond\"),\n    delay2: float = Path(..., title=\"Blocking time taken to respond\"),\n):\n    total_start_time = datetime.now()\n    times = []\n    for i in range(100):\n        start_time = datetime.now()\n        await asyncio.sleep(delay1)\n        time.sleep(delay2)\n        time_delta= (datetime.now()-start_time).microseconds\n        times.append(time_delta)\n    times_average = statistics.mean(times)\n    return {\"delays\":[delay1,delay2],\"total_time_taken\":(datetime.now()-total_start_time).microseconds,\"times_avarage\":times_average,\"times\":times}",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-06-07T20:37:44",
        "author": "Karol Zlot"
      },
      {
        "answer_id": 67880089,
        "body": "# `uvicorn performance_test:app --port 8083`\n{\"delays\":[0.0,0.0],\"total_time_taken\":553,\"times_avarage\":4.4,\"times\":[15,7,5,4,4,4,4,5,5,4,4,5,4,4,5,4,4,5,4,4,5,4,4,5,4,4,4,5,4,4,5,4,4,5,4,4,4,4,4,5,4,5,5,4,4,4,4,4,4,5,4,4,4,5,4,4,4,4,4,4,5,4,4,5,4,4,4,4,5,4,4,5,4,4,4,4,4,5,4,4,5,4,4,5,4,4,5,4,4,4,4,4,4,4,5,4,4,4,5,4]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":575,\"times_avarage\":4.61,\"times\":[15,6,5,5,5,5,5,5,5,5,5,4,5,5,5,5,4,4,4,4,4,5,5,5,4,5,4,4,4,5,5,5,4,5,5,4,4,4,4,5,5,5,5,4,4,4,4,5,5,4,4,4,4,4,4,4,4,5,5,4,4,4,4,5,5,5,5,5,5,5,4,4,4,4,5,5,4,5,5,4,4,4,4,4,4,5,5,5,4,4,4,4,5,5,5,5,4,4,4,4]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":548,\"times_avarage\":4.31,\"times\":[14,6,5,4,4,4,4,4,4,4,5,4,4,4,4,4,4,5,4,4,5,4,4,4,4,4,4,4,5,4,4,4,5,4,4,4,4,4,4,4,4,5,4,4,4,4,4,4,5,4,4,4,4,4,5,5,4,4,4,4,4,4,4,5,4,4,4,4,4,5,4,4,5,4,4,5,4,4,5,4,4,4,4,4,4,4,5,4,4,5,4,4,5,4,4,5,4,4,4,4]}\n# `gunicorn performance_test:app -b localhost:8084 -k uvicorn.workers.UvicornWorker --workers 1`\n{\"delays\":[0.0,0.0],\"total_time_taken\":551,\"times_avarage\":4.34,\"times\":[13,6,5,5,5,5,5,4,4,4,5,4,4,4,4,4,5,4,4,5,4,4,5,4,4,4,4,4,5,4,4,4,4,4,5,4,4,4,4,4,4,4,5,4,4,5,4,4,4,4,4,4,4,4,5,4,4,4,4,4,4,4,5,4,4,4,4,4,4,4,4,4,5,4,4,5,4,5,4,4,5,4,4,4,4,5,4,4,5,4,4,4,4,4,4,4,5,4,4,5]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":558,\"times_avarage\":4.48,\"times\":[14,7,5,5,5,5,5,5,4,4,4,4,4,4,5,5,4,4,4,4,5,4,4,4,5,5,4,4,4,5,5,4,4,4,5,4,4,4,5,5,4,4,4,4,5,5,4,4,5,5,4,4,5,5,4,4,4,5,4,4,5,4,4,5,5,4,4,4,5,4,4,4,5,4,4,4,5,4,5,4,4,4,5,4,4,4,5,4,4,4,5,4,4,4,5,4,4,4,5,4]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":550,\"times_avarage\":4.34,\"times\":[15,6,5,4,4,4,4,4,4,5,4,4,4,4,4,5,4,4,5,4,4,5,4,4,4,4,4,5,4,4,4,4,5,5,4,4,4,4,5,4,4,4,4,4,5,4,4,5,4,4,5,4,4,5,4,4,5,4,4,5,4,4,4,4,4,4,5,4,4,5,4,4,4,4,4,4,4,4,4,5,4,4,5,4,4,4,4,4,4,4,4,5,4,4,5,4,4,4,4,4]}",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-06-07T20:37:44",
        "author": "Karol Zlot"
      },
      {
        "answer_id": 67880089,
        "body": "# `uvicorn performance_test:app --port 8083`\n{\"delays\":[0.0,0.0],\"total_time_taken\":159,\"times_avarage\":0.6,\"times\":[3,1,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":162,\"times_avarage\":0.49,\"times\":[3,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,1,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":156,\"times_avarage\":0.61,\"times\":[3,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1]}\n# `gunicorn performance_test:app -b localhost:8084 -k uvicorn.workers.UvicornWorker --workers 1`\n{\"delays\":[0.0,0.0],\"total_time_taken\":159,\"times_avarage\":0.59,\"times\":[2,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":165,\"times_avarage\":0.62,\"times\":[3,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,1,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1]}\n{\"delays\":[0.0,0.0],\"total_time_taken\":164,\"times_avarage\":0.54,\"times\":[2,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1]}",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-06-07T20:37:44",
        "author": "Karol Zlot"
      },
      {
        "answer_id": 67880089,
        "body": "import statistics\nimport requests\nfrom time import sleep\nnumber_of_tests=1000\nsites_to_test=[\n    {\n        'name':'only uvicorn    ',\n        'url':'http://127.0.0.1:8083/delay/0.0/0.0'\n    },\n    {\n        'name':'gunicorn+uvicorn',\n        'url':'http://127.0.0.1:8084/delay/0.0/0.0'\n    }]\nfor test in sites_to_test:\n    total_time_taken_list=[]\n    times_avarage_list=[]\n    requests.get(test['url']) # first request may be slower, so better to not measure it\n    for a in range(number_of_tests):\n        r = requests.get(test['url'])\n        json= r.json()\n        total_time_taken_list.append(json['total_time_taken'])\n        times_avarage_list.append(json['times_avarage'])\n        # sleep(1) # results are slightly different with sleep between requests\n    total_time_taken_avarage=statistics.mean(total_time_taken_list)\n    times_avarage_avarage=statistics.mean(times_avarage_list)\n    print({'name':test['name'], 'number_of_tests':number_of_tests, 'total_time_taken_avarage':total_time_taken_avarage, 'times_avarage_avarage':times_avarage_avarage})",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-06-07T20:37:44",
        "author": "Karol Zlot"
      },
      {
        "answer_id": 67880089,
        "body": "import statistics\nimport requests\nfrom time import sleep\nnumber_of_tests=1000\nsites_to_test=[\n    {\n        'name':'only uvicorn    ',\n        'url':'http://127.0.0.1:8083/delay/0.0/0.0',\n        'total_time_taken_list':[],\n        'times_avarage_list':[]\n    },\n    {\n        'name':'gunicorn+uvicorn',\n        'url':'http://127.0.0.1:8084/delay/0.0/0.0',\n        'total_time_taken_list':[],\n        'times_avarage_list':[]\n    }]\nfor test in sites_to_test:\n    requests.get(test['url']) # first request may be slower, so better to not measure it\nfor a in range(number_of_tests):\n    for test in sites_to_test:\n        r = requests.get(test['url'])\n        json= r.json()\n        test['total_time_taken_list'].append(json['total_time_taken'])\n        test['times_avarage_list'].append(json['times_avarage'])\n        # sleep(1) # results are slightly different with sleep between requests\nfor test in sites_to_test:\n    total_time_taken_avarage=statistics.mean(test['total_time_taken_list'])\n    times_avarage_avarage=statistics.mean(test['times_avarage_list'])\n    print({'name':test['name'], 'number_of_tests':number_of_tests, 'total_time_taken_avarage':total_time_taken_avarage, 'times_avarage_avarage':times_avarage_avarage})",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-06-07T20:37:44",
        "author": "Karol Zlot"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71253495/how-to-annotate-the-type-of-arguments-forwarded-to-another-function",
    "title": "How to annotate the type of arguments forwarded to another function?",
    "question_id": 71253495,
    "posted_date": "2022-02-24T09:27:21",
    "answers": [
      {
        "answer_id": 71262408,
        "body": "from typing import TypeVar, ParamSpec, Callable, Optional\nT = TypeVar('T')\nP = ParamSpec('P')\ndef take_annotation_from(this: Callable[P, Optional[T]]) -> Callable[[Callable], Callable[P, Optional[T]]]:\n    def decorator(real_function: Callable) -> Callable[P, Optional[T]]:\n        def new_function(*args: P.args, **kwargs: P.kwargs) -> Optional[T]:\n            return real_function(*args, **kwargs)\n        return new_function\n    return decorator\n@take_annotation_from(open)\ndef open_for_writing(*args, **kwargs):\n    kwargs['mode'] = 'w'\n    return open(*args, **kwargs)\nopen_for_writing(some_fake_arg=123)\nopen_for_writing(file='')",
        "score": 11,
        "is_accepted": true,
        "creation_date": "2022-02-25T02:25:26",
        "author": "Simon Hawe"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74968585/using-environment-variables-in-pyproject-toml-for-versioning",
    "title": "Using environment variables in `pyproject.toml` for versioning",
    "question_id": 74968585,
    "posted_date": "2022-12-31T04:16:16",
    "answers": [
      {
        "answer_id": 77001804,
        "body": "# pyproject.toml\n[project]\nname = \"hello-world\"\nreadme = \"README.md\"\nauthors = [...]\ndependencies = [...]\ndynamic = [\"version\"]\n[build-system]\nrequires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta:__legacy__\"\n# The difference between `__legacy__` and the regular `build_meta`\n# is that `__legacy__` does the equivalent of\n# `sys.path.insert(0, os.path.dirname(__file__))`.\n# This allows you to `import` your modules from the `CWD`.\n# If you don't like using `__legacy__` you can\n# manually add `CWD` to `sys.path` inside your `setup.py`.",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2023-08-29T11:57:28",
        "author": "Anderson Bravalheri"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54060274/dynamic-communication-between-main-and-subprocess-in-python",
    "title": "Dynamic communication between main and subprocess in Python",
    "question_id": 54060274,
    "posted_date": "2019-01-06T04:35:36",
    "answers": [
      {
        "answer_id": 54066021,
        "body": "import os\ndef child():\n    \"\"\"This function is executed in a child process.\"\"\"\n    infile = os.fdopen(r1)\n    outfile = os.fdopen(w2, 'w', buffering=1)\n    for line in infile:\n        if line.rstrip() == 'quit':\n            break\n        print(line.upper(), end='', file=outfile)\ndef parent():\n    \"\"\"This function is executed in a parent process.\"\"\"\n    outfile = os.fdopen(w1, 'w', buffering=1)\n    infile = os.fdopen(r2)\n    print('Foo', file=outfile)\n    print(infile.readline(), end='')\n    print('bar', file=outfile)\n    print(infile.readline(), end='')\n    print('quit', file=outfile)\n(r1, w1) = os.pipe()  # for parent -> child writes\n(r2, w2) = os.pipe()  # for child -> parent writes\npid = os.fork()\nif pid == 0:\n    child()  # child code runs here\nelif pid > 0:\n    parent()  # parent code runs here\n    os.waitpid(pid, 0)  # wait for child\nelse:\n    raise RuntimeError(\"This should not have happened.\")",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2019-01-06T16:15:24",
        "author": "Ondrej K."
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49350821/runtimewarning-coroutine-was-never-awaited-in-tests",
    "title": "RuntimeWarning: coroutine was never awaited in tests",
    "question_id": 49350821,
    "posted_date": "2018-03-18T13:24:48",
    "answers": [
      {
        "answer_id": 59281658,
        "body": "========================================================================================================================================================================= test session starts ==========================================================================================================================================================================\nplatform darwin -- Python 3.7.5, pytest-5.3.1, py-1.8.0, pluggy-0.13.1\nrootdir: /Users/ldu020/workspace/github.com/mrdulin/python-codelab\nplugins: asyncio-0.10.0\ncollected 1 item\nsrc/stackoverflow/49350821/test_post_helpers.py F                                                                                                                                                                                                                                                                                                                [100%]\n=============================================================================================================================================================================== FAILURES ===============================================================================================================================================================================\n_________________________________________________________________________________________________________________________________________________________________________ test_get_post_exists _________________________________________________________________________________________________________________________________________________________________________\n    @pytest.mark.asyncio\n    async def test_get_post_exists():\n        returned_post = await posts.get_post('0')\n        assert returned_post.id == 0\n        assert returned_post.text == 'Text for the post body.'\n>       assert True == False\nE       assert True == False\nsrc/stackoverflow/49350821/test_post_helpers.py:11: AssertionError\n========================================================================================================================================================================== 1 failed in 0.15s ===========================================================================================================================================================================",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2019-12-11T03:34:58",
        "author": "Lin Du"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/78574898/how-to-find-base-line-of-curved-text",
    "title": "How to find Base-line of Curved Text?",
    "question_id": 78574898,
    "posted_date": "2024-06-04T06:46:09",
    "answers": [
      {
        "answer_id": 78601209,
        "body": "import cv2\nimport math\nimport uuid\nimport numpy as np\nfrom scipy import stats\ndef resizeImageByPercentage(img,scalePercent = 60):\n    width = int(img.shape[1] * scalePercent / 100)\n    height = int(img.shape[0] * scalePercent / 100)\n    dim = (width, height)\n    # resize image\n    return cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\ndef calcMedianContourWithAndHeigh(contourList):\n    hs = list()\n    ws = list()\n    for cnt in contourList:\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        ws.append(w)\n        hs.append(h)\n    return np.median(ws),np.median(hs)\ndef calcCentroid(contour):\n    houghMoments = cv2.moments(contour)\n    # calculate x,y coordinate of centroid\n    if houghMoments[\"m00\"] != 0: #case no contour could be calculated\n        cX = int(houghMoments[\"m10\"] / houghMoments[\"m00\"])\n        cY = int(houghMoments[\"m01\"] / houghMoments[\"m00\"])\n    else:\n    # set values as what you need in the situation\n        cX, cY = -1, -1\n    return cX,cY\ndef applyDilateImgFilter(img,kernelSize= 3,iterations=1):\n    img_bin = 255 - img #invert\n    kernel = np.ones((kernelSize,kernelSize),np.uint8)\n    img_dilated = cv2.dilate(img_bin, kernel, iterations = iterations)\n    return (255- img_dilated) #invert back\ndef randomColor():\n    return tuple(np.random.randint(0, 255, 3).tolist())\ndef drawGaussianValuesInsideRange(start, end, center, stdDev, amountValues):\n    values = []\n    if center < 0:\n        return values\n    if start > end:\n        return values\n    while len(values) < amountValues:\n        valueListPotencial = np.random.normal(center, stdDev, amountValues)\n        valueListFiltered = [value for value in valueListPotencial if start <= value <= end]\n        values.extend(valueListFiltered)\n    return values[:amountValues]\ndef drawRandomPointsInPolygon(amountPoints, cntFactObj):\n    pointList = list()\n    if not isinstance(cntFactObj, ContourFacts):\n        return pointList\n    #we calc basic parameter from random point selection\n    horizontalStart = cntFactObj.x\n    horizontalEnd = cntFactObj.x + cntFactObj.w\n    verticalStart = cntFactObj.y\n    verticalEnd = cntFactObj.y + cntFactObj.h\n    #calc std deviation connected to length and ratio\n    horitonalStdDeviation = 1 / cntFactObj.ratioHeightoWidth * (horizontalEnd-horizontalStart)\n    verticalStdDeviation = 1 / cntFactObj.ratioHeightoWidth * (verticalEnd-verticalStart)\n    while len(pointList)<amountPoints:\n        if cntFactObj.centoird[0] < 0 or cntFactObj.centoird[1] < 0:\n            return pointList\n        drawXValues = drawGaussianValuesInsideRange(horizontalStart, horizontalEnd, cntFactObj.centoird[0],\n                                          horitonalStdDeviation, amountPoints)\n        drawYValues = drawGaussianValuesInsideRange(verticalStart, verticalEnd, cntFactObj.centoird[1],\n                                         verticalStdDeviation, amountPoints)\n        #we create the points and check if they are inside the polygon\n        for i in range(0,len(drawXValues)):\n            #create points\n            point = (drawXValues[i],drawYValues[i])\n            # check if the point is inside the polygon\n            if cv2.pointPolygonTest(cntFactObj.contour, point, False) > 0:\n                pointList.append(point)\n    return pointList[:amountPoints]\ndef drawCountourOn(img,contours,color=None):\n    imgContour = img.copy()\n    for i in range(len(contours)):\n        if color is None:\n            color = randomColor()\n        cv2.drawContours(imgContour, contours, i, color, 2)\n    return imgContour\nDEBUGMODE = True\nfileIn = \"bZzzEeCU.jpg\"#\"269aSnEM.jpg\"\nimg = cv2.imread(fileIn)\n## A) apply filters to merge letters to words\n# prepare img load\nimgGrey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#gaussian filter\nimgGaussianBlur = cv2.GaussianBlur(imgGrey,(3,3),1)\n#make binary img, black and white via filter\n_, imgBinThres = cv2.threshold(imgGaussianBlur, 140, 230, cv2.THRESH_BINARY)\nif DEBUGMODE:\n    cv2.imwrite(\"img01bw.jpg\",resizeImageByPercentage(imgBinThres,30))\n## 3 steps merged by helper class ContourFacts\n## B) select contours of words (filter by: ratio heights vs widths , area size)\n## C) get random points from wordcontours with gaussian distribution and center point centroid of contour\n## D) use linear regression to find middle line of wordcontours\n#apply dilate filter to merge letter to words\nimgDilated = applyDilateImgFilter(imgBinThres,5,3)\nif DEBUGMODE:\n    cv2.imwrite(\"img02dilated.jpg\",resizeImageByPercentage(imgDilated,30))\n# detect contours\ncontourList, _ = cv2.findContours(imgDilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nif DEBUGMODE:\n    imgContour = drawCountourOn(img,contourList)\n    cv2.imwrite(\"img03contourAll.jpg\",resizeImageByPercentage(imgContour,30))\n\n#do a selection of contours by rule\n#A) ratio h vs w\n#B) area size\nmediaWordWidth, medianWordHigh = calcMedianContourWithAndHeigh(contourList)\nprint(\"median word width: \", mediaWordWidth)\nprint(\"median word high: \", medianWordHigh)\ncontourSelectedByRatio=list()\n#we calc for every contour ratio h vs w\nratioThresholdHeightToWidth = 1.1 #thresold ratio should be a least be 1 to 1\n# e.g word to -->  10 pixel / 13 pixel\n#helper class for contour atrributess\nclass ContourFacts:\n    def __init__(self,contour):\n        if contour is None:\n            return\n        self.uid = uuid.uuid4()\n        (self.x, self.y, self.w, self.h) = cv2.boundingRect(contour)\n        self.minRect = cv2.minAreaRect(contour)\n        self.angle = self.minRect[-1]\n        _, (rectWidth, rectHeight), _ = self.minRect\n        self.minRectArea = rectWidth * rectHeight\n        self.ratioHeightoWidth = self.h / self.w\n        self.contour = contour\n        self.centoird = calcCentroid(contour)\n        self.randomPoinsInCnt = self.DrawRandomPoints()\n        if len(self.randomPoinsInCnt) > 0:\n            (self.bottomSlope, self.bottomIntercept) = self.EstimateCenterLineViaLinearReg()\n            self.bottomMinX = min([x for x,y in self.randomPoinsInCnt])\n            self.bottomMaxX = max([x for x,y in self.randomPoinsInCnt])\n    def EstimateCenterLineViaLinearReg(self):\n        if self.contour is None:\n            return (0,0)\n        slope = 0\n        intercept = 0\n        #model = slope (x) + intercept\n        xValues = [x for x,y in self.randomPoinsInCnt]\n        yValues = [y for x,y in self.randomPoinsInCnt]\n        if len(xValues) < 2:\n            return (0,0)\n        elif len(xValues) ==2:\n            #we calc a line with 2 points\n            # y = m*x + b\n            deltaX = xValues[1]-xValues[0]\n            if deltaX == 0:\n                return (0,0)\n            slope = (yValues[1]-yValues[0])/(deltaX)\n            intercept = yValues[0] - (slope*xValues[0])\n        else:\n            #normal linear regression above 2 points\n            slope, intercept, r, p, std_err = stats.linregress(xValues, yValues)\n        #TODO check std_err\n        return slope, intercept\n\n    def DrawRandomPoints(self,pointFactor=2):\n        pointList = list()\n        #calc area to amount point relation  -> bigger area more points\n        amountPointsNeeded = int(self.minRectArea/pointFactor)\n        pointList = drawRandomPointsInPolygon(amountPointsNeeded,self)\n        return pointList\n\n    def GetCenterLineLeftCorner(self):\n        if self.contour is None or len(self.randomPoinsInCnt) == 0:\n            return (0,0)\n        # calc via  y = m*x + b with min\n        return (int(self.bottomMinX), int(self.bottomSlope*self.bottomMinX + self.bottomIntercept))\n    def GetCenterLineRightCorner(self):\n        if self.contour is None or len(self.randomPoinsInCnt) == 0:\n            return (0,0)\n        # calc via via y = m*x + b with max\n        return (int(self.bottomMaxX), int(self.bottomSlope*self.bottomMaxX + self.bottomIntercept))\n    def __eq__(self, other):\n        if isinstance(other, ContourFacts):\n            return self.uid == other.uid\n        return False\n    def __hash__(self):\n        return hash(self.uid)\n#calc mean area size from area size\nvectorOfAreaSize = np.array([cv2.contourArea(cnt) for cnt in contourList])\nmeanAreaSize = np.mean(vectorOfAreaSize)\nprint(\"mean area size: \", meanAreaSize)\nstdDevAreaSize = np.std(vectorOfAreaSize)\nprint(\"std dev area size: \", stdDevAreaSize)\nthresoldDiffAreaSize = stdDevAreaSize/4\n#we iterate all contours and select by ratio and size\nfor cnt in contourList:\n    #construct helper class instance\n    contourFactObj = ContourFacts(cnt)\n    #calc abs diff to mean area size\n    diffArea = abs(cv2.contourArea(cnt) - meanAreaSize)\n    if contourFactObj.ratioHeightoWidth < ratioThresholdHeightToWidth and diffArea < (thresoldDiffAreaSize):\n        contourSelectedByRatio.append(contourFactObj)\n#debug print\nif DEBUGMODE:\n    #we print words\n    imgContourSelection = img.copy()\n    for cnt in contourSelectedByRatio:\n        contourColor = randomColor()\n        imgContourSelection = drawCountourOn(imgContourSelection,[cnt.contour],contourColor)\n        #we print centroid\n        cv2.circle(imgContourSelection, cnt.centoird, 5, (0, 0, 255), -1)\n        p1 = cnt.GetCenterLineLeftCorner()\n        p2 = cnt.GetCenterLineRightCorner()\n        if p1 != (0,0) or p2 != (0,0):\n            cv2.circle(imgContourSelection, p1, 5, (0, 0, 255), -1)\n            cv2.circle(imgContourSelection, p2, 5, (0, 0, 255), -1)\n            cv2.line(imgContourSelection, p1, p2, (0, 255, 0), 2)\n    cv2.imwrite(\"img04contourSelection.jpg\",resizeImageByPercentage(imgContourSelection,30))\n## E) merge all wordcontours which are neighbours to linecontours (outer middle line points are close together)\n#define distance function, differences in height is negativ weighted\ndef euclidianDistanceWithNegativHeightWeight(cnt1,cnt2,negativeHeightWeight=2.0):\n    if cnt1 is None or cnt2 is None:\n        return 1000000\n    if not isinstance(cnt1, ContourFacts) or not isinstance(cnt2, ContourFacts):\n        return 1000000\n    p1 = cnt1.GetCenterLineRightCorner()\n    p2 = cnt2.GetCenterLineLeftCorner()\n    return math.sqrt((p2[0] - p1[0])**2 + (negativeHeightWeight*(p2[1] - p1[1]))**2)\n# helper class to group contours\nclass ContourGroup:\n    def __init__(self):\n        self.uuid = uuid.uuid4()\n        self.contourList = list()\n    def GetLastElement(self):\n        if len(self.contourList) == 0:\n            return None\n        return self.contourList[-1]\n    def Add(self,cnt):\n        self.contourList.append(cnt)\n    def __eq__(self, other):\n        if isinstance(other, ContourGroup):\n            return self.uuid == other.uuid\n        return False\n\ngroupMap = dict()\nlineGroupList = list()\n## we grouping the contours to lines\nmaxDistanceThresholNextWord= medianWordHigh *0.9 #TODO get better estimate\n#recursive function to get nearest neighbors\ndef getNearestNeighbors(cnt1,depthCounter,contourSelectedByRatio,maxDistanceThresholNextWord):\n    maxDepth = 10 #var for max recursion depth\n    nearestCnt = None\n    nearestDist = maxDistanceThresholNextWord\n    for j in range(0,len(contourSelectedByRatio)):\n        cnt2 = contourSelectedByRatio[j]\n        if cnt1 == cnt2:#skip same\n            continue\n        dist = euclidianDistanceWithNegativHeightWeight(cnt1,cnt2)\n        if dist < nearestDist:\n            nearestDist = dist\n            nearestCnt = cnt2\n    if nearestCnt is not None:#call recursive\n        nearaestListWeHave = [nearestCnt] #new list\n        depthCounter += 1\n        if depthCounter < maxDepth:# all to call\n            nearListWeGet =getNearestNeighbors(nearestCnt,depthCounter,contourSelectedByRatio,maxDistanceThresholNextWord)\n            if nearListWeGet is None:\n                return nearaestListWeHave\n            else:\n                nearListWeGet.extend(nearaestListWeHave)\n                return nearListWeGet\n        else:#limit reached of recursion skip\n            return nearaestListWeHave\n    else:\n        return None\n## E) merge all wordcontours which are neighbours to linecontours (outer middle line points are close together)\n#we group all contours\nfor i in range(0,len(contourSelectedByRatio)):\n    cnt1 = contourSelectedByRatio[i]\n    if cnt1 in groupMap:\n        continue\n    lineGroup = ContourGroup()\n    lineGroup.Add(cnt1)\n    groupMap[cnt1] = lineGroup\n    depthCounter = 0\n    nearaestList = getNearestNeighbors(cnt1,depthCounter,\n                                       contourSelectedByRatio,maxDistanceThresholNextWord)\n    if nearaestList is None:\n        lineGroupList.append(lineGroup) #no neighbor found\n        continue\n    for cnt in nearaestList:\n        groupMap[cnt] = lineGroup\n        lineGroup.Add(cnt)\n    lineGroupList.append(lineGroup)\nif DEBUGMODE:\n    imgContourGroup = img.copy()\n    for group in lineGroupList:\n        #print(f\"group({group.uuid} size: {len(group.contourList)}\")\n        #we print all corner points\n        for cnt in group.contourList:\n            leftCorner = cnt.GetCenterLineLeftCorner()\n            rigthCorner = cnt.GetCenterLineRightCorner()\n            cv2.circle(imgContourGroup, leftCorner, 5, (0, 0, 255), -1)\n            cv2.circle(imgContourGroup, rigthCorner, 5, (140, 0, 0), -1)\n        #we print estimated underlines\n        for cnt in group.contourList:\n            leftCorner = cnt.GetCenterLineLeftCorner()\n            rigthCorner = cnt.GetCenterLineRightCorner()\n            cv2.line(imgContourGroup, leftCorner, rigthCorner, (0, 255, 0), 2)\n        # we print all contours\n        groupColor = randomColor()\n        cntList = [cnt.contour for cnt in group.contourList]\n        imgContourGroup = drawCountourOn(imgContourGroup,cntList,groupColor)\n    cv2.imwrite(\"img05contourGroup.jpg\",resizeImageByPercentage(imgContourGroup,30))\n## F) do polynomial regression 2nd order to estimate middle line of linecontours\n# calc line from stable group points\nminAmountRegressionElements = 12\nmovingWindowSize = 3\nletterCenterOffset = medianWordHigh * 0.5\nlineListCollection = list()\nfor group in lineGroupList:\n    stablePoints = list()\n    for cnt in group.contourList:\n        stablePoints.extend(cnt.randomPoinsInCnt)\n    if len(stablePoints) >= minAmountRegressionElements :\n        xValues = [x for x,y in stablePoints]\n        yValues = [y for x,y in stablePoints]\n        # perform polynomial regression of degree 2\n        coefffientValues = np.polyfit(np.array(xValues), np.array(yValues), 2)\n        # create a polynomial function with the coefficients\n        polynomial = np.poly1d(coefffientValues)\n        #we filter to build something like a line\n        xValuesNewLineFilter = list()\n        xMin =int( min(xValues))\n        xMax = int(max(xValues))\n        for xNew in range(xMin,xMax,movingWindowSize):\n                xValuesNewLineFilter.append(xNew)\n        #we predict new points with all old x values\n        yValuesNew = polynomial(xValuesNewLineFilter)\n        yValuesNewHighCorrect =np.array(yValuesNew) + letterCenterOffset\n        lineList = list()\n        #we create a list of points\n        for i in range(0,len(xValuesNewLineFilter)):\n            pointInt = (int(xValuesNewLineFilter[i]),int(yValuesNewHighCorrect[i]))\n            lineList.append(pointInt)\n        lineListCollection.append(lineList)\n## G) write the lines\nimgLines = img.copy()\nfor lineList in lineListCollection:\n    p1 = lineList[0]\n    for j in range(1,len(lineList)):\n        p2 = lineList[j]\n        #cv2.circle(imgLines, p2Int, 5, (0, 0, 255), -1)\n        cv2.line(imgLines, p1, p2, (0, 255, 0), 2)\n        p1 = p2\ncv2.imwrite(\"img06Lines.jpg\",resizeImageByPercentage(imgLines,30))\nif DEBUGMODE:\n    cv2.waitKey(0)",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2024-06-10T04:23:47",
        "author": "t2solve"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48171611/difference-between-pandas-read-sql-query-and-read-sql-table",
    "title": "difference between pandas read sql query and read sql table",
    "question_id": 48171611,
    "posted_date": "2018-01-09T10:33:24",
    "answers": [
      {
        "answer_id": 67685588,
        "body": "import time\nimport pandas as pd\nfrom sqlalchemy import create_engine\nsqlite_engine = create_engine('sqlite:///coffee.db', echo=False)\nmariadb_engine = create_engine('mariadb+mariadbconnector://root:admin@127.0.0.1:3306/coffee')\npostgres_engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/coffee')\nfor engine in [sqlite_engine, mariadb_engine, postgres_engine]:\n    print(engine)\n    print('\\tpd.read_sql_query:')\n    startTime = time.time()\n    for i in range(100):\n        pd.read_sql_query('SELECT * FROM arabica;', engine)\n    print(f\"\\t[-- TIME --] {time.time()-startTime:.2f} sec\\n\")\n    print('\\tpd.read_sql_table:')\n    startTime = time.time()\n    for i in range(100):\n        pd.read_sql_table('arabica', engine)\n    print(f\"\\t[-- TIME --] {time.time()-startTime:.2f} sec\\n\")",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2021-05-25T05:49:49",
        "author": "Ricardo"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54426123/how-to-inform-class-weights-when-using-tensorflow-python-keras-estimator-model",
    "title": "How to inform class weights when using `tensorflow.python.keras.estimator.model_to_estimator` to convert Keras Models to Estimator API?",
    "question_id": 54426123,
    "posted_date": "2019-01-29T12:02:46",
    "answers": [
      {
        "answer_id": 54429884,
        "body": "import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\ndef weighted_loss_fn(class_weights):\n\n    def _loss_fn(y_true, y_pred):\n        class_weights_tensor = K.variable(class_weights)\n        y_true_labels = K.argmax(y_true,axis=1)\n        weights = K.gather(class_weights_tensor,y_true_labels)\n        return tf.losses.softmax_cross_entropy(onehot_labels=y_true, logits=y_pred, weights=weights)\n    return _loss_fn\ndef keras_estimator_model(n_classes=None, model_dir='./tmp-model/', config=None, class_weights=None):\n    with tf.device('/gpu:0'):\n        # Inputs\n        inp_raw = Input(shape=(max_len,), name='word_raw')\n        # raw text LSTM network\n        word_raw_emb = Embedding(\n            input_dim=nunique_chars_raw,\n            output_dim=EMBED_SIZE,\n            input_length=MAX_WORD_LENGTH,\n            trainable=True,\n            name='word_raw_emb')(inp_raw)\n        word_raw_emb = Dropout(rate=dropout_rate)(word_raw_emb)\n        word_raw_emb_lstm = Bidirectional(\n            LSTM(48, return_sequences=True))(word_raw_emb)\n        word_raw_emb_gru = Bidirectional(\n            GRU(48, return_sequences=False))(word_raw_emb_lstm)\n        word_raw_net = Dense(16, activation='relu')(word_raw_emb_gru)\n        output_raw_net = Dense(n_classes, activation='softmax')(word_raw_net)\n        model = Model(inputs=inp_raw, outputs=output_raw_net)\n        optz = keras.optimizers.RMSprop(\n            lr=0.002, rho=0.9, epsilon=None, decay=0.0)\n        loss_fn = weighted_loss_fn(class_weights)\n        model.compile(loss=loss_fn,\n                      optimizer=optz, metrics=['categorical_accuracy'])\n        model_estimator = model_to_estimator(keras_model=model, model_dir=model_dir, config=config)\n        return model_estimator\nestimator_model = keras_estimator_model(5)\ntrain_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,max_steps=10)\neval_spec = tf.estimator.EvalSpec(\n        input_fn=eval_input_fn,\n        steps=None,\n        start_delay_secs=10,\n        throttle_secs=10)\ntf.estimator.train_and_evaluate(estimator_model, train_spec, eval_spec)",
        "score": 3,
        "is_accepted": true,
        "creation_date": "2019-01-29T16:29:54",
        "author": "Rodrigo Pereira"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52576365/resampling-time-series-or-dataframes-with-javascript-node-js",
    "title": "Resampling time series or dataframes with Javascript / Node.js",
    "question_id": 52576365,
    "posted_date": "2018-09-30T04:59:26",
    "answers": [
      {
        "answer_id": 73451293,
        "body": "var a = [{\n    \"time\": \"28-09-2018 21:29:04\",\n    \"value1\": 1280,\n    \"value2\": 800\n},\n{\n    \"time\": \"28-09-2018 21:38:56\",\n    \"value1\": 600,\n    \"value2\": 700\n},\n{\n    \"time\": \"29-09-2018 10:40:00\",\n    \"value1\": 1100,\n    \"value2\": 300\n},\n{\n    \"time\": \"29-09-2018 23:50:48\",\n    \"value1\": 140\n}];\nvar b = Object.values(a.reduce((container, current) => {\n  var date = current['time'].substring(0, 10);\n  if (!container[date])\n    container[date] = {time: date + ' 00:00:00', value1: current['value1'] || 0, value2: current['value2'] || 0};\n  else {\n    container[date]['value1'] += current['value1'] || 0;\n    container[date]['value2'] += current['value2'] || 0;\n  }\n  return container;\n}, {}));",
        "score": 2,
        "is_accepted": false,
        "creation_date": "2022-08-22T17:44:44",
        "author": "Ripper346"
      },
      {
        "answer_id": 73451293,
        "body": "var resample = 12;\nvar b = Object.values(a.reduce((container, current) => {\n  var date = new Date(current['time'].replace(/(\\d+)-(\\d+)-(\\d+) (\\d+):(\\d+):(\\d+)/, '$3-$2-$1T$4:$5:$6'));\n  date.setHours(Math.floor(date.getHours() / resample) * resample);\n  date.setMinutes(0);\n  date.setSeconds(0);\n  if (!container[date.toString()])\n    container[date.toString()] = {time: date, value1: current['value1'] || 0, value2: current['value2'] || 0};\n  else {\n    container[date.toString()]['value1'] += current['value1'] || 0;\n    container[date.toString()]['value2'] += current['value2'] || 0;\n  }\n  return container;\n}, {}));",
        "score": 2,
        "is_accepted": false,
        "creation_date": "2022-08-22T17:44:44",
        "author": "Ripper346"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/46689334/how-to-customize-docstring-color-for-python-in-vscodes-default-theme",
    "title": "How to customize docstring color for Python in VSCode&#39;s default theme?",
    "question_id": 46689334,
    "posted_date": "2017-10-11T09:21:04",
    "answers": [
      {
        "answer_id": 64721961,
        "body": "    \"editor.tokenColorCustomizations\": {\n        \"textMateRules\": [\n            {\n                \"scope\": [\n                    \"string.quoted.docstring.multi.python\",\n                    \"string.quoted.docstring.multi.python punctuation.definition.string.begin.python\",\n                    \"string.quoted.docstring.multi.python punctuation.definition.string.end.python\",\n                    \"string.quoted.docstring.multi.python constant.character.escape.python\"\n                ],\n                \"settings\": {\n                    \"foreground\": \"#aab5da\" //change to your preference\n                }\n            }\n        ]\n    },",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2020-11-06T16:40:46",
        "author": "Yashash Gaurav"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/42076424/how-to-batch-get-item-many-items-at-once-given-a-list-of-primary-partition-key-v",
    "title": "How to batch_get_item many items at once given a list of primary partition key values",
    "question_id": 42076424,
    "posted_date": "2017-02-06T15:11:14",
    "answers": [
      {
        "answer_id": 62905794,
        "body": "import logging\nimport boto3\ndynamodb = boto3.resource('dynamodb')\nlogger = logging.getLogger(__name__)\nmovie_table = dynamodb.Table('Movies')\nactor_table = dyanmodb.Table('Actors')\nbatch_keys = {\n    movie_table.name: {\n        'Keys': [{'year': movie[0], 'title': movie[1]} for movie in movie_list]\n    },\n    actor_table.name: {\n        'Keys': [{'name': actor} for actor in actor_list]\n    }\n}\nresponse = dynamodb.batch_get_item(RequestItems=batch_keys)\nfor response_table, response_items in response.items():\n    logger.info(\"Got %s items from %s.\", len(response_items), response_table)",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2020-07-14T20:21:02",
        "author": "Laren Crawford"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73150560/get-the-name-of-all-fields-in-a-dataclass",
    "title": "Get the name of all fields in a dataclass",
    "question_id": 73150560,
    "posted_date": "2022-07-28T05:39:13",
    "answers": [
      {
        "answer_id": 73150769,
        "body": "import dataclasses\nimport inspect\n@dataclasses.dataclass\nclass Test:\n    a: str = \"a value\"\n    b: str = \"b value\"\ndef print_data_class(dataclass_instance):\n    # option 1: fields\n    fields = dataclasses.fields(dataclass_instance)\n    # option 2: inspect\n    members = inspect.getmembers(type(dataclass_instance))\n    fields = list(dict(members)['__dataclass_fields__'].values())\n    for v in fields:\n        print(f'{v.name}: ({v.type.__name__}) = {getattr(dataclass_instance, v.name)}')\nprint_data_class(Test())\n# a: (str) = a value\n# b: (str) = b value\nprint_data_class(Test(a=\"1\", b=\"2\"))\n# a: (str) = 1\n# b: (str) = 2",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2022-07-28T05:53:15",
        "author": "K.Mat"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58895486/how-to-send-server-side-events-from-python-fastapi-upon-calls-to-a-function-th",
    "title": "How to send server-side events from python (fastapi) upon calls to a function that updates the backend state",
    "question_id": 58895486,
    "posted_date": "2019-11-16T16:44:04",
    "answers": [
      {
        "answer_id": 62817008,
        "body": "import asyncio\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom sse_starlette.sse import EventSourceResponse\nMESSAGE_STREAM_DELAY = 1  # second\nMESSAGE_STREAM_RETRY_TIMEOUT = 15000  # milisecond\napp = FastAPI()\n@app.get('/stream')\nasync def message_stream(request: Request):\n    def new_messages(): ...\n    async def event_generator():\n        while True:\n            # If client was closed the connection\n            if await request.is_disconnected():\n                break\n            # Checks for new messages and return them to client if any\n            if new_messages():\n                yield {\n                        \"event\": \"new_message\",\n                        \"id\": \"message_id\",\n                        \"retry\": MESSAGE_STREAM_RETRY_TIMEOUT,\n                        \"data\": \"message_content\"\n                }\n            await asyncio.sleep(MESSAGE_STREAM_DELAY)\n    return EventSourceResponse(event_generator())\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)",
        "score": 34,
        "is_accepted": false,
        "creation_date": "2020-07-09T10:19:48",
        "author": "Saber Hayati"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/16065694/is-it-possible-to-create-encoded-base64-url-from-image-object",
    "title": "Is it possible to create encoded base64 URL from Image object?",
    "question_id": 16065694,
    "posted_date": "2013-04-17T12:46:59",
    "answers": [
      {
        "answer_id": 16066722,
        "body": "data:image/jpg;base64,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",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2013-04-17T13:47:27",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15229896/combining-scatter-plot-with-surface-plot",
    "title": "Combining scatter plot with surface plot",
    "question_id": 15229896,
    "posted_date": "2013-03-05T12:09:00",
    "answers": [
      {
        "answer_id": 15231187,
        "body": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom random import random, seed\nfrom matplotlib import cm\nimport matplotlib as mpl\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(projection='3d')              # to work in 3d\nx_surf=np.arange(0, 1, 0.01)                # generate a mesh\ny_surf=np.arange(0, 1, 0.01)\nx_surf, y_surf = np.meshgrid(x_surf, y_surf)\nz_surf = np.sqrt(x_surf+y_surf)             # ex. function, which depends on x and y\nax.plot_surface(x_surf, y_surf, z_surf, cmap=cm.hot, ec='k')  # plot a 3d surface plot\nn = 100\nseed(0)                                     # seed let us to have a reproducible set of random numbers\nx=[random() for i in range(n)]              # generate n random points\ny=[random() for i in range(n)]\nz=[random() for i in range(n)]\nax.scatter(x, y, z);                        # plot a 3d scatter plot\nax.set_xlabel('x label')\nax.set_ylabel('y label')\nax.set_zlabel('z label')\nplt.show()",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2013-03-05T13:19:46",
        "author": "sissi_luaty"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/68705698/how-to-write-tests-for-pydantic-models-in-fastapi",
    "title": "How to write tests for Pydantic models in FastAPI?",
    "question_id": 68705698,
    "posted_date": "2021-08-08T20:27:36",
    "answers": [
      {
        "answer_id": 68726632,
        "body": "from fastapi.testclient import TestClient\nclient = TestClient(app)\ndef test_add_phonenumber_ok():\n    \"\"\"Valid PhoneNumber, should be 200/OK\"\"\"\n    # This would be what the JSON body of the request would look like\n    body = {\n        \"id\": 1,\n        \"country\": \"Japan\",\n        \"country_code\": \"JA\",\n        \"number\": \"123\",\n        \"extension\": \"81\",\n    }\n    response = client.post(\"/phonenumber\", json=body)\n    assert response.status_code == 200\ndef test_add_phonenumber_error():\n    \"\"\"Invalid PhoneNumber, should be a validation error\"\"\"\n    # This would be what the JSON body of the request would look like\n    body = {\n        \"id\": 1,\n        \"country\": \"Japan\",\n                             # `country_code` is missing\n        \"number\": 99999,     # `number` is int, not str\n        \"extension\": \"81\",\n    }\n    response = client.post(\"/phonenumber\", json=body)\n    assert response.status_code == 422\n    assert response.json() == {\n        'detail': [{\n            'loc': ['body', 'country_code'],\n            'msg': 'field required',\n            'type': 'value_error.missing'\n        }]\n    }",
        "score": 37,
        "is_accepted": true,
        "creation_date": "2021-08-10T08:13:20",
        "author": "Gino Mempin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57024802/numpy-in-place-operation-performance",
    "title": "Numpy in-place operation performance",
    "question_id": 57024802,
    "posted_date": "2019-07-14T01:17:00",
    "answers": [
      {
        "answer_id": 57025687,
        "body": "from simple_benchmark import BenchmarkBuilder, MultiArgument\nimport numpy as np\nb = BenchmarkBuilder()\n@b.add_function()\ndef func1(a1, a2):\n    a1 = a1 + a2\n@b.add_function()\ndef func2(a1, a2):\n    a1 += a2\n\n@b.add_arguments('array size')\ndef argument_provider():\n    for exp in range(3, 28):\n        dim_size = int(1.4**exp)\n        a1 = np.random.random([dim_size, dim_size])\n        a2 = np.random.random([dim_size, dim_size])\n        yield dim_size ** 2, MultiArgument([a1, a2])\n\nr = b.run()\nr.plot()",
        "score": 22,
        "is_accepted": false,
        "creation_date": "2019-07-14T04:18:10",
        "author": "MSeifert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51206500/how-to-convert-a-string-datetime-with-unknown-timezone-to-timestamp-in-python",
    "title": "how to convert a string datetime with unknown timezone to timestamp in python",
    "question_id": 51206500,
    "posted_date": "2018-07-06T04:52:13",
    "answers": [
      {
        "answer_id": 54629675,
        "body": "#!/usr/bin/env python\n# encoding:utf-8\nfrom dateutil import parser\nwhois_timezone_info = {\n        \"A\": 1 * 3600,\n        \"ACDT\": 10.5 * 3600,\n        \"ACST\": 9.5 * 3600,\n        \"ACT\": -5 * 3600,\n        \"ACWST\": 8.75 * 3600,\n        \"ADT\": 4 * 3600,\n        \"AEDT\": 11 * 3600,\n        \"AEST\": 10 * 3600,\n        \"AET\": 10 * 3600,\n        \"AFT\": 4.5 * 3600,\n        \"AKDT\": -8 * 3600,\n        \"AKST\": -9 * 3600,\n        \"ALMT\": 6 * 3600,\n        \"AMST\": -3 * 3600,\n        \"AMT\": -4 * 3600,\n        \"ANAST\": 12 * 3600,\n        \"ANAT\": 12 * 3600,\n        \"AQTT\": 5 * 3600,\n        \"ART\": -3 * 3600,\n        \"AST\": 3 * 3600,\n        \"AT\": -4 * 3600,\n        \"AWDT\": 9 * 3600,\n        \"AWST\": 8 * 3600,\n        \"AZOST\": 0 * 3600,\n        \"AZOT\": -1 * 3600,\n        \"AZST\": 5 * 3600,\n        \"AZT\": 4 * 3600,\n        \"AoE\": -12 * 3600,\n        \"B\": 2 * 3600,\n        \"BNT\": 8 * 3600,\n        \"BOT\": -4 * 3600,\n        \"BRST\": -2 * 3600,\n        \"BRT\": -3 * 3600,\n        \"BST\": 6 * 3600,\n        \"BTT\": 6 * 3600,\n        \"C\": 3 * 3600,\n        \"CAST\": 8 * 3600,\n        \"CAT\": 2 * 3600,\n        \"CCT\": 6.5 * 3600,\n        \"CDT\": -5 * 3600,\n        \"CEST\": 2 * 3600,\n        \"CET\": 1 * 3600,\n        \"CHADT\": 13.75 * 3600,\n        \"CHAST\": 12.75 * 3600,\n        \"CHOST\": 9 * 3600,\n        \"CHOT\": 8 * 3600,\n        \"CHUT\": 10 * 3600,\n        \"CIDST\": -4 * 3600,\n        \"CIST\": -5 * 3600,\n        \"CKT\": -10 * 3600,\n        \"CLST\": -3 * 3600,\n        \"CLT\": -4 * 3600,\n        \"COT\": -5 * 3600,\n        \"CST\": -6 * 3600,\n        \"CT\": -6 * 3600,\n        \"CVT\": -1 * 3600,\n        \"CXT\": 7 * 3600,\n        \"ChST\": 10 * 3600,\n        \"D\": 4 * 3600,\n        \"DAVT\": 7 * 3600,\n        \"DDUT\": 10 * 3600,\n        \"E\": 5 * 3600,\n        \"EASST\": -5 * 3600,\n        \"EAST\": -6 * 3600,\n        \"EAT\": 3 * 3600,\n        \"ECT\": -5 * 3600,\n        \"EDT\": -4 * 3600,\n        \"EEST\": 3 * 3600,\n        \"EET\": 2 * 3600,\n        \"EGST\": 0 * 3600,\n        \"EGT\": -1 * 3600,\n        \"EST\": -5 * 3600,\n        \"ET\": -5 * 3600,\n        \"F\": 6 * 3600,\n        \"FET\": 3 * 3600,\n        \"FJST\": 13 * 3600,\n        \"FJT\": 12 * 3600,\n        \"FKST\": -3 * 3600,\n        \"FKT\": -4 * 3600,\n        \"FNT\": -2 * 3600,\n        \"G\": 7 * 3600,\n        \"GALT\": -6 * 3600,\n        \"GAMT\": -9 * 3600,\n        \"GET\": 4 * 3600,\n        \"GFT\": -3 * 3600,\n        \"GILT\": 12 * 3600,\n        \"GMT\": 0 * 3600,\n        \"GST\": 4 * 3600,\n        \"GYT\": -4 * 3600,\n        \"H\": 8 * 3600,\n        \"HDT\": -9 * 3600,\n        \"HKT\": 8 * 3600,\n        \"HOVST\": 8 * 3600,\n        \"HOVT\": 7 * 3600,\n        \"HST\": -10 * 3600,\n        \"I\": 9 * 3600,\n        \"ICT\": 7 * 3600,\n        \"IDT\": 3 * 3600,\n        \"IOT\": 6 * 3600,\n        \"IRDT\": 4.5 * 3600,\n        \"IRKST\": 9 * 3600,\n        \"IRKT\": 8 * 3600,\n        \"IRST\": 3.5 * 3600,\n        \"IST\": 5.5 * 3600,\n        \"JST\": 9 * 3600,\n        \"K\": 10 * 3600,\n        \"KGT\": 6 * 3600,\n        \"KOST\": 11 * 3600,\n        \"KRAST\": 8 * 3600,\n        \"KRAT\": 7 * 3600,\n        \"KST\": 9 * 3600,\n        \"KUYT\": 4 * 3600,\n        \"L\": 11 * 3600,\n        \"LHDT\": 11 * 3600,\n        \"LHST\": 10.5 * 3600,\n        \"LINT\": 14 * 3600,\n        \"M\": 12 * 3600,\n        \"MAGST\": 12 * 3600,\n        \"MAGT\": 11 * 3600,\n        \"MART\": 9.5 * 3600,\n        \"MAWT\": 5 * 3600,\n        \"MDT\": -6 * 3600,\n        \"MHT\": 12 * 3600,\n        \"MMT\": 6.5 * 3600,\n        \"MSD\": 4 * 3600,\n        \"MSK\": 3 * 3600,\n        \"MST\": -7 * 3600,\n        \"MT\": -7 * 3600,\n        \"MUT\": 4 * 3600,\n        \"MVT\": 5 * 3600,\n        \"MYT\": 8 * 3600,\n        \"N\": -1 * 3600,\n        \"NCT\": 11 * 3600,\n        \"NDT\": 2.5 * 3600,\n        \"NFT\": 11 * 3600,\n        \"NOVST\": 7 * 3600,\n        \"NOVT\": 7 * 3600,\n        \"NPT\": 5.5 * 3600,\n        \"NRT\": 12 * 3600,\n        \"NST\": 3.5 * 3600,\n        \"NUT\": -11 * 3600,\n        \"NZDT\": 13 * 3600,\n        \"NZST\": 12 * 3600,\n        \"O\": -2 * 3600,\n        \"OMSST\": 7 * 3600,\n        \"OMST\": 6 * 3600,\n        \"ORAT\": 5 * 3600,\n        \"P\": -3 * 3600,\n        \"PDT\": -7 * 3600,\n        \"PET\": -5 * 3600,\n        \"PETST\": 12 * 3600,\n        \"PETT\": 12 * 3600,\n        \"PGT\": 10 * 3600,\n        \"PHOT\": 13 * 3600,\n        \"PHT\": 8 * 3600,\n        \"PKT\": 5 * 3600,\n        \"PMDT\": -2 * 3600,\n        \"PMST\": -3 * 3600,\n        \"PONT\": 11 * 3600,\n        \"PST\": -8 * 3600,\n        \"PT\": -8 * 3600,\n        \"PWT\": 9 * 3600,\n        \"PYST\": -3 * 3600,\n        \"PYT\": -4 * 3600,\n        \"Q\": -4 * 3600,\n        \"QYZT\": 6 * 3600,\n        \"R\": -5 * 3600,\n        \"RET\": 4 * 3600,\n        \"ROTT\": -3 * 3600,\n        \"S\": -6 * 3600,\n        \"SAKT\": 11 * 3600,\n        \"SAMT\": 4 * 3600,\n        \"SAST\": 2 * 3600,\n        \"SBT\": 11 * 3600,\n        \"SCT\": 4 * 3600,\n        \"SGT\": 8 * 3600,\n        \"SRET\": 11 * 3600,\n        \"SRT\": -3 * 3600,\n        \"SST\": -11 * 3600,\n        \"SYOT\": 3 * 3600,\n        \"T\": -7 * 3600,\n        \"TAHT\": -10 * 3600,\n        \"TFT\": 5 * 3600,\n        \"TJT\": 5 * 3600,\n        \"TKT\": 13 * 3600,\n        \"TLT\": 9 * 3600,\n        \"TMT\": 5 * 3600,\n        \"TOST\": 14 * 3600,\n        \"TOT\": 13 * 3600,\n        \"TRT\": 3 * 3600,\n        \"TVT\": 12 * 3600,\n        \"U\": -8 * 3600,\n        \"ULAST\": 9 * 3600,\n        \"ULAT\": 8 * 3600,\n        \"UTC\": 0 * 3600,\n        \"UYST\": -2 * 3600,\n        \"UYT\": -3 * 3600,\n        \"UZT\": 5 * 3600,\n        \"V\": -9 * 3600,\n        \"VET\": -4 * 3600,\n        \"VLAST\": 11 * 3600,\n        \"VLAT\": 10 * 3600,\n        \"VOST\": 6 * 3600,\n        \"VUT\": 11 * 3600,\n        \"W\": -10 * 3600,\n        \"WAKT\": 12 * 3600,\n        \"WARST\": -3 * 3600,\n        \"WAST\": 2 * 3600,\n        \"WAT\": 1 * 3600,\n        \"WEST\": 1 * 3600,\n        \"WET\": 0 * 3600,\n        \"WFT\": 12 * 3600,\n        \"WGST\": -2 * 3600,\n        \"WGT\": -3 * 3600,\n        \"WIB\": 7 * 3600,\n        \"WIT\": 9 * 3600,\n        \"WITA\": 8 * 3600,\n        \"WST\": 14 * 3600,\n        \"WT\": 0 * 3600,\n        \"X\": -11 * 3600,\n        \"Y\": -12 * 3600,\n        \"YAKST\": 10 * 3600,\n        \"YAKT\": 9 * 3600,\n        \"YAPT\": 10 * 3600,\n        \"YEKST\": 6 * 3600,\n        \"YEKT\": 5 * 3600,\n        \"Z\": 0 * 3600,\n}\ntimestamp = parser.parse(\"Thu Jun 02 11:56:53 CDT 2011\", tzinfos={\"CDT\": -5*3600})",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-02-11T06:33:31",
        "author": "h-j-13"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74965764/how-can-i-properly-hash-dictionaries-with-a-common-set-of-keys-for-deduplicatio",
    "title": "How can I properly hash dictionaries with a common set of keys, for deduplication purposes?",
    "question_id": 74965764,
    "posted_date": "2022-12-30T16:00:14",
    "answers": [
      {
        "answer_id": 74965910,
        "body": ">>> def show_hash(d):\n...     return bin(hash(frozenset(d.values())))\n...\n>>> show_hash({'id': '1', 'error': None, 'value': 'apple'})\n'0b101010010100001000111001000001000111101111110100010000010101110'\n>>> # Changing a value changes the hash...\n>>> show_hash({'id': '1', 'error': None, 'value': 'orange'})\n'0b11111111001000011101011001001011100010100100010010110000100100'\n>>> # but rearranging them does not:\n>>> show_hash({'id': '1', 'error': 'orange', 'value': None})\n'0b11111111001000011101011001001011100010100100010010110000100100'",
        "score": 22,
        "is_accepted": true,
        "creation_date": "2022-12-30T16:25:42",
        "author": "Karl Knechtel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61041707/plotly-log-scale-in-subplot-python",
    "title": "Plotly Log Scale in Subplot Python",
    "question_id": 61041707,
    "posted_date": "2020-04-05T07:17:48",
    "answers": [
      {
        "answer_id": 61042885,
        "body": "import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Default Scale\", \"Logarithmic Scale\"))\n# subplot in default scale\nfig.add_trace(go.Scatter(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=[1.105, 1.221, 1.35, 1.492, 1.649]), row=1, col=1)\nfig.update_xaxes(title_text=\"x-axis in default scale\", row=1, col=1)\nfig.update_yaxes(title_text=\"y-axis in default scale\", row=1, col=1)\n# subplot in logarithmic scale\nfig.add_trace(go.Scatter(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=[1.105, 1.221, 1.35, 1.492, 1.649]), row=1, col=2)\nfig.update_xaxes(title_text=\"x-axis in logarithmic scale\", type=\"log\", row=1, col=2)\nfig.update_yaxes(title_text=\"y-axis in logarithmic scale\", type=\"log\", row=1, col=2)\nfig.update_layout(showlegend=False)\nfig.show()",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2020-04-05T08:51:57",
        "author": "user11989081"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/50689359/django-natural-sort-queryset",
    "title": "Django: Natural Sort QuerySet",
    "question_id": 50689359,
    "posted_date": "2018-06-04T18:01:03",
    "answers": [
      {
        "answer_id": 59220344,
        "body": "from django.contrib.admin import ModelAdmin, register, SimpleListFilter\nfrom django.db.models.functions import Length, StrIndex, Substr, NullIf, Coalesce\nfrom django.db.models import Value as V\nfrom .models import Item\nclass AlphanumericSignatureFilter(SimpleListFilter):\n    title = 'Signature (alphanumeric)'\n    parameter_name = 'signature_alphanumeric'\n    def lookups(self, request, model_admin):\n        return (\n            ('signature', 'Signature (alphanumeric)'),\n        )\n    def queryset(self, request, queryset):\n        if self.value() == 'signature':\n            return queryset.order_by(\n                Coalesce(Substr('signature', V(0), NullIf(StrIndex('signature', V(' ')), V(0))), 'signature'),\n                Length('signature'),\n                'signature'\n            )\n@register(Item)\nclass Item(ModelAdmin):\n    list_filter = [AlphanumericSignatureFilter]",
        "score": 16,
        "is_accepted": true,
        "creation_date": "2019-12-06T16:07:40",
        "author": "Alexandr Shurigin"
      },
      {
        "answer_id": 59220344,
        "body": "from django.contrib.admin import ModelAdmin, register, SimpleListFilter\nfrom django.db.models.functions import StrIndex, Concat\nfrom django.db.models import Value as V\nfrom natsort import natsorted\nfrom .models import Item\nclass AlphanumericTruePythonSignatureFilter(SimpleListFilter):\n    title = 'Signature (alphanumeric true python)'\n    parameter_name = 'signature_alphanumeric_python'\n    def lookups(self, request, model_admin):\n        return (\n            ('signature', 'Signature (alphanumeric)'),\n        )\n    def queryset(self, request, queryset):\n        if self.value() == 'signature':\n            all_ids = list(queryset.values_list('signature', flat=True))\n            # let's use \"!:!\" as a separator for signature values\n            all_ids_sorted = \"!:!\" + \"!:!\".join(natsorted(all_ids))\n            return queryset.order_by(\n                StrIndex(V(all_ids_sorted), Concat(V('!:!'), 'signature')),\n            )\n@register(Item)\nclass Item(ModelAdmin):\n    list_filter = [AlphanumericTruePythonSignatureFilter]",
        "score": 16,
        "is_accepted": true,
        "creation_date": "2019-12-06T16:07:40",
        "author": "Alexandr Shurigin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67549023/why-is-the-gnu-scientific-library-matrix-multiplication-slower-than-numpy-matmul",
    "title": "Why is the GNU scientific library matrix multiplication slower than numpy.matmul?",
    "question_id": 67549023,
    "posted_date": "2021-05-15T12:37:10",
    "answers": [
      {
        "answer_id": 67550027,
        "body": "110:   lea          0x80(%rsp),%rsi\n       add          $0x60,%rsi\n       mov          %r12,%rax\n       sar          $0x3,%rax\n       cmp          $0x2,%rax\n     \u2193 jl           d26\n       prefetcht0   0x200(%rdi)          # Data prefetching\n       vmovups      -0x60(%rsi),%ymm1\n       prefetcht0   0xa0(%rsi)\n       vbroadcastsd -0x80(%rdi),%ymm0    # Fast SIMD instruction (AVX)\n       prefetcht0   0xe0(%rsi)\n       vmovups      -0x40(%rsi),%ymm2\n       prefetcht0   0x120(%rsi)\n       vmovups      -0x20(%rsi),%ymm3\n       vmulpd       %ymm0,%ymm1,%ymm4\n       prefetcht0   0x160(%rsi)\n       vmulpd       %ymm0,%ymm2,%ymm8\n       vmulpd       %ymm0,%ymm3,%ymm12\n       prefetcht0   0x1a0(%rsi)\n       vbroadcastsd -0x78(%rdi),%ymm0\n       vmulpd       %ymm0,%ymm1,%ymm5\n       vmulpd       %ymm0,%ymm2,%ymm9\n       [...]",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2021-05-15T14:26:17",
        "author": "J&#233;r&#244;me Richard"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56284121/why-is-heap-slower-than-sort-for-k-closest-points-to-origin",
    "title": "Why is heap slower than sort for K Closest Points to Origin?",
    "question_id": 56284121,
    "posted_date": "2019-05-23T19:33:47",
    "answers": [
      {
        "answer_id": 56329957,
        "body": "import timeit\nimport matplotlib.pyplot as plt\ns = \"\"\"\nimport heapq\ndef k_heap(points, K):\n    return heapq.nsmallest(K, points, key = lambda P: P[0]**2 + P[1]**2)\ndef k_sort(points, K):\n    points.sort(key = lambda P: P[0]**2 + P[1]**2)\n    return points[:K]\n\"\"\"\nrandom.seed(1)\npoints = [(random.random(), random.random()) for _ in range(1000000)]\nr = list(range(11, 500000, 50000))\nheap_times = []\nsort_times = []\nfor i in r:\n    heap_times.append(timeit.timeit('k_heap({}, 10)'.format(points[:i]), setup=s, number=1))\n    sort_times.append(timeit.timeit('k_sort({}, 10)'.format(points[:i]), setup=s, number=1))\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n#plt.plot(left, 0, marker='.')\nplt.plot(r, heap_times, marker='o')\nplt.plot(r, sort_times, marker='D')\nplt.show()",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2019-05-27T13:00:29",
        "author": "vurmux"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/78056934/pandas-or-polars-find-index-of-previous-element-larger-than-current-one",
    "title": "pandas or Polars: find index of previous element larger than current one",
    "question_id": 78056934,
    "posted_date": "2024-02-25T12:22:09",
    "answers": [
      {
        "answer_id": 78058031,
        "body": "from numba import njit, prange\n@njit(parallel=True)\ndef get_values(values):\n    out = np.zeros_like(values, dtype=np.float64)\n    for i in prange(len(values)):\n        idx = np.int64(i)\n        v = values[idx]\n        while idx > -1 and values[idx] <= v:\n            idx -= 1\n        if idx > -1:\n            out[i] = i - idx\n    out[0] = np.nan\n    return out\ndata = {\n    \"value\": [1, 9, 6, 7, 3, 2, 4, 5, 1, 9],\n    \"out\": [None, 0, 1, 2, 1, 1, 3, 4, 1, 0],\n}\ndf = pd.DataFrame(data)\ndf[\"out2\"] = get_values(df[\"value\"].values)\nprint(df)",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2024-02-25T18:14:52",
        "author": "Andrej Kesely"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55345608/instantiate-a-type-that-is-a-typevar",
    "title": "Instantiate a type that is a TypeVar",
    "question_id": 55345608,
    "posted_date": "2019-03-25T16:04:42",
    "answers": [
      {
        "answer_id": 55345696,
        "body": "from typing import TypeVar, Generic, List, NewType, Type\nimport random\nclass PopMember:\n    def __init__(self):\n        self.x = random.randint(0, 100)\n    def __repr__(self):\n        return \"Pop({})\".format(self.x)\nTPopMember = TypeVar(\"TPopMember\")\nPopulation = NewType('Population', List[TPopMember])\nclass EvolutionaryAlgorithm(Generic[TPopMember]):\n    def __init__(self, member_class: Type[TPopMember], populationSize: int) -> None:\n        self.__population = Population([member_class() for _ in range(populationSize)])\n    def __repr__(self):\n        return \"EA({})\".format(self.__population)\nx = EvolutionaryAlgorithm(PopMember, 5)\nprint(x)",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2019-03-25T16:11:30",
        "author": "adrtam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61741997/how-to-format-requirements-txt-when-package-source-is-from-specific-websites",
    "title": "How to format requirements.txt when package source is from specific websites?",
    "question_id": 61741997,
    "posted_date": "2020-05-11T20:59:46",
    "answers": [
      {
        "answer_id": 61742742,
        "body": "$ pip install -r requirements.txt\nLooking in links: https://download.pytorch.org/whl/torch_stable.html, https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\nCollecting torch==1.5.0+cu101 (from -r requirements.txt (line 3))\n  Using cached https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp38-cp38-linux_x86_64.whl\nCollecting torchvision==0.6.0+cu101 (from -r requirements.txt (line 4))\n  Using cached https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp38-cp38-linux_x86_64.whl\nCollecting detectron2 (from -r requirements.txt (line 8))\n  Using cached https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/detectron2-0.1.2%2Bcu101-cp38-cp38-linux_x86_64.whl\n...",
        "score": 33,
        "is_accepted": true,
        "creation_date": "2020-05-11T22:28:03",
        "author": "Gino Mempin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55609339/how-to-perform-feature-selection-with-gridsearchcv-in-sklearn-in-python",
    "title": "How to perform feature selection with gridsearchcv in sklearn in python",
    "question_id": 55609339,
    "posted_date": "2019-04-10T05:36:31",
    "answers": [
      {
        "answer_id": 55629709,
        "body": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.33,\n                                                    random_state=42)\nfrom sklearn.pipeline import Pipeline\n#this is the classifier used for feature selection\nclf_featr_sele = RandomForestClassifier(n_estimators=30,\n                                        random_state=42,\n                                        class_weight=\"balanced\")\nrfecv = RFECV(estimator=clf_featr_sele,\n              step=1,\n              cv=5,\n              scoring = 'roc_auc')\n#you can have different classifier for your final classifier\nclf = RandomForestClassifier(n_estimators=10,\n                             random_state=42,\n                             class_weight=\"balanced\")\nCV_rfc = GridSearchCV(clf,\n                      param_grid={'max_depth':[2,3]},\n                      cv= 5, scoring = 'roc_auc')\npipeline  = Pipeline([('feature_sele',rfecv),\n                      ('clf_cv',CV_rfc)])\npipeline.fit(X_train, y_train)\npipeline.predict(X_test)",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2019-04-11T05:57:05",
        "author": "Venkatachalam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/5408675/ascii-visualisation-of-a-graph-of-nodes-in-python",
    "title": "ASCII Visualisation of a graph of nodes in python",
    "question_id": 5408675,
    "posted_date": "2011-03-23T12:40:28",
    "answers": [
      {
        "answer_id": 62073648,
        "body": "+-------------------+           +--------------------+\n| test_data.csv.dvc |           | train_data.csv.dvc |\n+-------------------+           +--------------------+\n                  **              **\n                    ***        ***\n                       **    **\n                +-------------------+\n                | featurization.dvc |\n                +-------------------+\n                  ***            ***\n                **                  ***\n              **                       **\n    +--------------+                     **\n    | training.dvc |                   **\n    +--------------+                ***\n                  ***            ***\n                     **        **\n                       **    **\n                     +---------+\n                     | Dvcfile |\n                     +---------+",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2020-05-28T16:08:40",
        "author": "Ruslan Kuprieiev"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62684468/pythons-requests-triggers-cloudflares-security-while-urllib-does-not",
    "title": "Python&#39;s requests triggers Cloudflare&#39;s security while urllib does not",
    "question_id": 62684468,
    "posted_date": "2020-07-01T15:58:21",
    "answers": [
      {
        "answer_id": 62687390,
        "body": "import requests\nfrom collections import OrderedDict\nfrom requests import Session\nimport socket\n# grab the address using socket.getaddrinfo\nanswers = socket.getaddrinfo('grimaldis.myguestaccount.com', 443)\n(family, type, proto, canonname, (address, port)) = answers[0]\ns = Session()\nheaders = OrderedDict({\n    'Accept-Encoding': 'gzip, deflate, br',\n    'Host': \"grimaldis.myguestaccount.com\",\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0'\n})\ns.headers = headers\nresponse = s.get(f\"https://{address}/guest/accountlogin\", headers=headers, verify=False).text\nprint(response)",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2020-07-01T20:56:42",
        "author": "TuanGeek"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/49084322/how-to-limit-field-access-on-a-model-based-on-user-type-on-graphene-django",
    "title": "How to limit field access on a model based on user type on Graphene/Django?",
    "question_id": 49084322,
    "posted_date": "2018-03-03T07:53:48",
    "answers": [
      {
        "answer_id": 49283138,
        "body": "class SetEmployee(graphene.Mutation):\n\n    class Arguments:\n        id = graphene.ID()\n        first_name = graphene.String()\n        last_name = graphene.String()\n        salary = graphene.String()\n\n    employee = graphene.Field(lambda: EmployeeType)\n\n\n    @classmethod\n    def mutate(cls, root, info, **args):\n        employee_id = args.get('employee_id')\n\n        # Fetch the employee object by id\n        employee = Employee.objects.get(id=employee_id)\n        first_name = args.get('first_name')\n        last_name = args.get('last_name')\n        salary = args.get('salary')\n\n        # Update the employee fields from the mutation inputs\n        if first_name:\n            employee.first_name = first_name\n        if last_name:\n            employee.last_name = last_name\n        if salary and info.context.user.has_perm('myapp.can_edit_salary'):\n            employee.salary = salary\n        employee.save()\n        return SetEmployee(employee=employee)",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2018-03-14T12:33:24",
        "author": "Mark Chackerian"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62249443/linking-pyenv-python-to-homebrew-in-order-to-avoid-homebrew-python3-8-installat",
    "title": "Linking pyenv python to homebrew in order to avoid homebrew python@3.8 installation",
    "question_id": 62249443,
    "posted_date": "2020-06-07T13:53:44",
    "answers": [
      {
        "answer_id": 68169157,
        "body": "$  brew pyenv-sync --help\nUsage: brew pyenv-sync\nCreate symlinks for Homebrew's installed Python versions in ~/.pyenv/versions.\nNote that older patch version symlinks will be created and linked to the minor\nversion so e.g. Python 3.11.0 will also be symlinked to 3.11.3.\n  -d, --debug                      Display any debugging information.\n  -q, --quiet                      Make some output more quiet.\n  -v, --verbose                    Make some output more verbose.\n  -h, --help                       Show this message.",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2021-06-28T15:38:38",
        "author": "cesarcoatl"
      },
      {
        "answer_id": 68169157,
        "body": "$ ls -al $(brew --prefix black)/libexec/bin\ntotal 104\ndrwxr-xr-x  16 thecesrom  staff   512 Jun 11 08:32 .\ndrwxr-xr-x   6 thecesrom  staff   192 Jun 11 08:32 ..\n-rw-r--r--   1 thecesrom  staff  8834 Jun 10 15:27 Activate.ps1\n-rw-r--r--   1 thecesrom  staff  1916 Jun 11 08:32 activate\n-rw-r--r--   1 thecesrom  staff   865 Jun 11 08:32 activate.csh\n-rw-r--r--   1 thecesrom  staff  2005 Jun 11 08:32 activate.fish\n-rwxr-xr-x   1 thecesrom  staff   256 Jun 11 08:32 black\n-rwxr-xr-x   1 thecesrom  staff   251 Jun 11 08:32 black-primer\n-rwxr-xr-x   1 thecesrom  staff   257 Jun 11 08:32 blackd\n-rwxr-xr-x   1 thecesrom  staff  1000 Jun 11 08:32 chardetect\n-rwxr-xr-x   1 thecesrom  staff   257 Jun 11 08:32 pip\n-rwxr-xr-x   1 thecesrom  staff   257 Jun 11 08:32 pip3\n-rwxr-xr-x   1 thecesrom  staff   257 Jun 11 08:32 pip3.9\nlrwxr-xr-x   1 thecesrom  staff    84 Jun 10 15:27 python -> ../../../../../opt/python@3.9/Frameworks/Python.framework/Versions/3.9/bin/python3.9\nlrwxr-xr-x   1 thecesrom  staff    84 Jun 10 15:27 python3 -> ../../../../../opt/python@3.9/Frameworks/Python.framework/Versions/3.9/bin/python3.9\nlrwxr-xr-x   1 thecesrom  staff    84 Jun 10 15:27 python3.9 -> ../../../../../opt/python@3.9/Frameworks/Python.framework/Versions/3.9/bin/python3.9",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2021-06-28T15:38:38",
        "author": "cesarcoatl"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70051773/polars-is-there-a-json-normalize-like-feature-in-polars",
    "title": "Polars : Is there a json_normalize like feature in Polars?",
    "question_id": 70051773,
    "posted_date": "2021-11-20T23:10:05",
    "answers": [
      {
        "answer_id": 75591960,
        "body": "grades = {\n  \"name\": \"Ravi\",\n  \"Subjects\": {\n    \"Maths\": 92,\n    \"English\": 94,\n    \"Hindi\": 98\n  }}\ngrades_with_list = {key:[value] for key, value in grades.items()}\npl.DataFrame(grades_with_list)\n# Output\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name \u2506 Subjects   \u2502\n\u2502 ---  \u2506 ---        \u2502\n\u2502 str  \u2506 struct[3]  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Ravi \u2506 {92,94,98} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# You can also un-nest the Subjets column, to get a separate column for each subject.\npl.DataFrame(grades_with_list).unnest('Subjects')\n# Output\nshape: (1, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name \u2506 Maths \u2506 English \u2506 Hindi \u2502\n\u2502 ---  \u2506 ---   \u2506 ---     \u2506 ---   \u2502\n\u2502 str  \u2506 i64   \u2506 i64     \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Ravi \u2506 92    \u2506 94      \u2506 98    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2023-02-28T07:17:05",
        "author": "Luca"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57030125/automatically-adjusting-brightness-of-image-with-opencv",
    "title": "Automatically adjusting brightness of image with OpenCV",
    "question_id": 57030125,
    "posted_date": "2019-07-14T14:35:21",
    "answers": [
      {
        "answer_id": 57046925,
        "body": "import cv2\nimport numpy as np\n# from matplotlib import pyplot as plt\n# Automatic brightness and contrast optimization with optional histogram clipping\ndef automatic_brightness_and_contrast(image, clip_hist_percent=25):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Calculate grayscale histogram\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n    hist_size = len(hist)\n\n    # Calculate cumulative distribution from the histogram\n    accumulator = []\n    accumulator.append(float(hist[0]))\n    for index in range(1, hist_size):\n        accumulator.append(accumulator[index -1] + float(hist[index]))\n\n    # Locate points to clip\n    maximum = accumulator[-1]\n    clip_hist_percent *= (maximum/100.0)\n    clip_hist_percent /= 2.0\n\n    # Locate left cut\n    minimum_gray = 0\n    while accumulator[minimum_gray] < clip_hist_percent:\n        minimum_gray += 1\n\n    # Locate right cut\n    maximum_gray = hist_size -1\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n        maximum_gray -= 1\n\n    # Calculate alpha and beta values\n    alpha = 255 / (maximum_gray - minimum_gray)\n    beta = -minimum_gray * alpha\n\n    '''\n    # Calculate new histogram with desired range and show histogram\n    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n    plt.plot(hist)\n    plt.plot(new_hist)\n    plt.xlim([0,256])\n    plt.show()\n    '''\n    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n    return (auto_result, alpha, beta)\nimage = cv2.imread('1.png')\nauto_result, alpha, beta = automatic_brightness_and_contrast(image)\nprint('alpha', alpha)\nprint('beta', beta)\ncv2.imshow('auto_result', auto_result)\ncv2.imwrite('auto_result.png', auto_result)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2019-07-15T16:41:32",
        "author": "nathancy"
      },
      {
        "answer_id": 57046925,
        "body": "import cv2\nimport numpy as np\n# from matplotlib import pyplot as plt\ndef convertScale(img, alpha, beta):\n    \"\"\"Add bias and gain to an image with saturation arithmetics. Unlike\n    cv2.convertScaleAbs, it does not take an absolute value, which would lead to\n    nonsensical results (e.g., a pixel at 44 with alpha = 3 and beta = -210\n    becomes 78 with OpenCV, when in fact it should become 0).\n    \"\"\"\n    new_img = img * alpha + beta\n    new_img[new_img < 0] = 0\n    new_img[new_img > 255] = 255\n    return new_img.astype(np.uint8)\n# Automatic brightness and contrast optimization with optional histogram clipping\ndef automatic_brightness_and_contrast(image, clip_hist_percent=25):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # Calculate grayscale histogram\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n    hist_size = len(hist)\n    # Calculate cumulative distribution from the histogram\n    accumulator = []\n    accumulator.append(float(hist[0]))\n    for index in range(1, hist_size):\n        accumulator.append(accumulator[index -1] + float(hist[index]))\n    # Locate points to clip\n    maximum = accumulator[-1]\n    clip_hist_percent *= (maximum/100.0)\n    clip_hist_percent /= 2.0\n    # Locate left cut\n    minimum_gray = 0\n    while accumulator[minimum_gray] < clip_hist_percent:\n        minimum_gray += 1\n    # Locate right cut\n    maximum_gray = hist_size -1\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n        maximum_gray -= 1\n    # Calculate alpha and beta values\n    alpha = 255 / (maximum_gray - minimum_gray)\n    beta = -minimum_gray * alpha\n    '''\n    # Calculate new histogram with desired range and show histogram\n    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n    plt.plot(hist)\n    plt.plot(new_hist)\n    plt.xlim([0,256])\n    plt.show()\n    '''\n    auto_result = convertScale(image, alpha=alpha, beta=beta)\n    return (auto_result, alpha, beta)\nimage = cv2.imread('1.jpg')\nauto_result, alpha, beta = automatic_brightness_and_contrast(image)\nprint('alpha', alpha)\nprint('beta', beta)\ncv2.imshow('auto_result', auto_result)\ncv2.imwrite('auto_result.png', auto_result)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2019-07-15T16:41:32",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51241367/matplotlib-surface-plot-hides-scatter-points-which-should-be-in-front",
    "title": "matplotlib surface plot hides scatter points which should be in front",
    "question_id": 51241367,
    "posted_date": "2018-07-09T04:45:01",
    "answers": [
      {
        "answer_id": 71429859,
        "body": "import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\ndf = pd.DataFrame({10: {10: 1,15: 1,20: 1,25: 1,30: 1,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   15: {10: 4,15: 1,20: 1,25: 1,30: 1,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   20: {10: 6,15: 3,20: 1,25: 1,30: 1,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   25: {10: 7,15: 5,20: 3,25: 1,30: 1,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   30: {10: 9,15: 6,20: 4,25: 3,30: 1,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   35: {10: 10,15: 7,20: 5,25: 4,30: 2,35: 1,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   40: {10: 11,15: 8,20: 6,25: 4,30: 3,35: 2,40: 1,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   45: {10: 12,15: 9,20: 7,25: 5,30: 4,35: 3,40: 2,45: 1,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   50: {10: 13,15: 9,20: 7,25: 6,30: 5,35: 4,40: 3,45: 2,50: 1,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   55: {10: 14,15: 10,20: 8,25: 7,30: 5,35: 4,40: 3,45: 3,50: 2,55: 1,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   60: {10: 15,15: 11,20: 9,25: 7,30: 6,35: 5,40: 4,45: 3,50: 3,55: 2,60: 1,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   65: {10: 16,15: 12,20: 9,25: 8,30: 6,35: 5,40: 5,45: 4,50: 3,55: 2,60: 2,65: 1,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   70: {10: 17,15: 12,20: 10,25: 8,30: 7,35: 6,40: 5,45: 4,50: 4,55: 3,60: 2,65: 2,70: 1,75: 1,80: 1,85: 1,90: 1},\n                   75: {10: 18,15: 13,20: 10,25: 9,30: 7,35: 6,40: 5,45: 5,50: 4,55: 3,60: 3,65: 2,70: 2,75: 1,80: 1,85: 1,90: 1},\n                   80: {10: 19,15: 14,20: 11,25: 9,30: 8,35: 7,40: 6,45: 5,50: 4,55: 4,60: 3,65: 3,70: 2,75: 2,80: 1,85: 1,90: 1},\n                   85: {10: 21,15: 14,20: 11,25: 10,30: 8,35: 7,40: 6,45: 6,50: 5,55: 4,60: 4,65: 3,70: 3,75: 2,80: 2,85: 1,90: 1},\n                   90: {10: 23,15: 15,20: 12,25: 10,30: 9,35: 8,40: 7,45: 6,50: 5,55: 5,60: 4,65: 3,70: 3,75: 3,80: 2,85: 2,90: 1}})\nxv, yv = np.meshgrid(df.index, df.columns)\nma = np.nanmax(df.values)\nnorm = matplotlib.colors.Normalize(vmin = 0, vmax = ma, clip = True)\nfig = plt.figure(1)\nax = Axes3D(fig, computed_zorder=False)\nax.scatter(10,70,4, c='k', depthshade=False, alpha = 1, s=100)\nsurf = ax.plot_surface(yv,xv,df, cmap='viridis_r', linewidth=0.3,\n                       alpha = 0.8, edgecolor = 'k', norm=norm)\nax.scatter(25,35,4, c='k', depthshade=False, alpha = 1, s=100)\nplt.show()",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2022-03-10T14:38:50",
        "author": "TomDLT"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48941648/how-to-remove-a-word-completely-from-a-word2vec-model-in-gensim",
    "title": "How to remove a word completely from a Word2Vec model in gensim?",
    "question_id": 48941648,
    "posted_date": "2018-02-23T00:26:07",
    "answers": [
      {
        "answer_id": 54258997,
        "body": "def restrict_w2v(w2v, restricted_word_set):\n    new_vectors = []\n    new_vocab = {}\n    new_index2entity = []\n    new_vectors_norm = []\n    for i in range(len(w2v.vocab)):\n        word = w2v.index2entity[i]\n        vec = w2v.vectors[i]\n        vocab = w2v.vocab[word]\n        vec_norm = w2v.vectors_norm[i]\n        if word in restricted_word_set:\n            vocab.index = len(new_index2entity)\n            new_index2entity.append(word)\n            new_vocab[word] = vocab\n            new_vectors.append(vec)\n            new_vectors_norm.append(vec_norm)\n    w2v.vocab = new_vocab\n    w2v.vectors = new_vectors\n    w2v.index2entity = new_index2entity\n    w2v.index2word = new_index2entity\n    w2v.vectors_norm = new_vectors_norm",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2019-01-18T12:42:17",
        "author": "zsozso"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57417520/selecting-and-renaming-columns-at-the-same-time",
    "title": "Selecting and renaming columns at the same time",
    "question_id": 57417520,
    "posted_date": "2019-08-08T13:02:00",
    "answers": [
      {
        "answer_id": 61487953,
        "body": "data = {\n    'Commander': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'Date': ['2012, 02, 08', '2012, 02, 08', '2012, 02, 08',\n             '2012, 02, 08', '2012, 02, 08'],\n    'Score': [4, 24, 31, 2, 3],\n    'Team': ['Green', 'Yellow', 'Green', 'Yellow', 'Yellow'],\n}\ndf = pd.DataFrame(data, index=['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\ndf\n           Commander          Date  Score    Team\nCochice        Jason  2012, 02, 08      4   Green\nPima           Molly  2012, 02, 08     24  Yellow\nSanta Cruz      Tina  2012, 02, 08     31   Green\nMaricopa        Jake  2012, 02, 08      2  Yellow\nYuma             Amy  2012, 02, 08      3  Yellow\nselector_d = {'Team': 'Team', 'Commander': 'Com', 'Score': 'Sco'}\ndf.rename(columns=selector_d)[[*selector_d.values()]]\n              Team    Com  Sco\nCochice      Green  Jason    4\nPima        Yellow  Molly   24\nSanta Cruz   Green   Tina   31\nMaricopa    Yellow   Jake    2\nYuma        Yellow    Amy    3",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2020-04-28T15:03:01",
        "author": "pjdrew"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61292464/get-confidence-interval-from-sklearn-linear-regression-in-python",
    "title": "Get confidence interval from sklearn linear regression in python",
    "question_id": 61292464,
    "posted_date": "2020-04-18T12:22:30",
    "answers": [
      {
        "answer_id": 74673133,
        "body": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\nalpha = 0.05 # for 95% confidence interval; use 0.01 for 99%-CI.\n# fit a sklearn LinearRegression model\nlin_model = LinearRegression().fit(X_train, Y_train)\n# the coefficients of the regression model\ncoefs = np.r_[[lin_model.intercept_], lin_model.coef_]\n# build an auxiliary dataframe with the constant term in it\nX_aux = X_train.copy()\nX_aux.insert(0, 'const', 1)\n# degrees of freedom\ndof = -np.diff(X_aux.shape)[0]\n# Student's t-distribution table lookup\nt_val = stats.t.isf(alpha/2, dof)\n# MSE of the residuals\nmse = np.sum((Y_train - lin_model.predict(X_train)) ** 2) / dof\n# inverse of the variance of the parameters\nvar_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n# distance between lower and upper bound of CI\ngap = t_val * np.sqrt(mse * var_params)\nconf_int = pd.DataFrame({'lower': coefs - gap, 'upper': coefs + gap}, index=X_aux.columns)",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2022-12-04T00:36:01",
        "author": "cottontail"
      },
      {
        "answer_id": 74673133,
        "body": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\ndef get_conf_int(alpha, lr, X=X_train, y=Y_train):\n\n    \"\"\"\n    Returns (1-alpha) 2-sided confidence intervals\n    for sklearn.LinearRegression coefficients\n    as a pandas DataFrame\n    \"\"\"\n\n    coefs = np.r_[[lr.intercept_], lr.coef_]\n    X_aux = X.copy()\n    X_aux.insert(0, 'const', 1)\n    dof = -np.diff(X_aux.shape)[0]\n    mse = np.sum((y - lr.predict(X)) ** 2) / dof\n    var_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n    t_val = stats.t.isf(alpha/2, dof)\n    gap = t_val * np.sqrt(mse * var_params)\n    return pd.DataFrame({\n        'lower': coefs - gap, 'upper': coefs + gap\n    }, index=X_aux.columns)\n# for 95% confidence interval; use 0.01 for 99%-CI.\nalpha = 0.05\n# fit a sklearn LinearRegression model\nlin_model = LinearRegression().fit(X_train, Y_train)\nget_conf_int(alpha, lin_model, X_train, Y_train)",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2022-12-04T00:36:01",
        "author": "cottontail"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/32397347/is-there-a-fast-way-to-return-sin-and-cos-of-the-same-value-in-python",
    "title": "Is there a fast Way to return Sin and Cos of the same value in Python?",
    "question_id": 32397347,
    "posted_date": "2015-09-04T07:48:53",
    "answers": [
      {
        "answer_id": 62160938,
        "body": "import perfplot\nimport numpy as np\ndef sin_cos(x):\n    return np.sin(x), np.cos(x)\ndef exp_ix(x):\n    eix = np.exp(1j * x)\n    return eix.imag, eix.real\ndef cos_from_sin(x):\n    sin = np.sin(x)\n    abs_cos = np.sqrt(1 - sin**2)\n    sgn_cos = np.sign(((x - np.pi / 2) % (2 * np.pi)) - np.pi)\n    cos = abs_cos * sgn_cos\n    return sin, cos\nb = perfplot.bench(\n    setup=lambda n: np.linspace(0.0, 2 * np.pi, n),\n    kernels=[sin_cos, exp_ix, cos_from_sin],\n    n_range=[2**k for k in range(20)],\n    xlabel=\"n\",\n)\nb.save(\"out.png\")\nb.show()",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2020-06-02T16:32:51",
        "author": "Nico Schl&#246;mer"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59341761/what-are-the-differences-between-a-classmethod-and-a-metaclass-method",
    "title": "What are the differences between a `classmethod` and a metaclass method?",
    "question_id": 59341761,
    "posted_date": "2019-12-15T01:46:28",
    "answers": [
      {
        "answer_id": 59412323,
        "body": "class M1(type):\n    def clsmethod1(cls):\n        pass\nclass CLS1(metaclass=M1):\n    pass\ndef runtime_wrap(cls, method_name, wrapper):\n    mcls = type(cls)\n    setattr(mcls, method_name,  wrapper(getatttr(mcls, method_name)))\ndef wrapper(classmethod):\n    def new_method(cls):\n        print(\"wrapper called\")\n        return classmethod(cls)\n    return new_method\nruntime_wrap(cls1, \"clsmethod1\", wrapper)\nclass CLS2:\n    @classmethod\n    def classmethod2(cls):\n        pass\n def runtime_wrap2(cls, method_name, wrapper):\n    setattr(cls, method_name,  classmethod(\n                wrapper(getatttr(cls, method_name).__func__)\n        )\n    )\nruntime_wrap2(cls1, \"clsmethod1\", wrapper)",
        "score": 9,
        "is_accepted": true,
        "creation_date": "2019-12-19T10:04:37",
        "author": "jsbueno"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55426342/how-to-implement-indentation-based-code-folding-in-qscintilla",
    "title": "How to implement indentation based code folding in QScintilla?",
    "question_id": 55426342,
    "posted_date": "2019-03-29T18:44:10",
    "answers": [
      {
        "answer_id": 55554175,
        "body": "from PyQt5.Qsci import QsciScintilla\nfrom PyQt5.Qt import *\ndef set_fold(prev, line, fold, full):\n    if (prev[0] >= 0):\n        fmax = max(fold, prev[1])\n        for iter in range(prev[0], line + 1):\n            view.SendScintilla(view.SCI_SETFOLDLEVEL, iter,\n                fmax | (0, view.SC_FOLDLEVELHEADERFLAG)[iter + 1 < full])\ndef line_empty(line):\n    return view.SendScintilla(view.SCI_GETLINEENDPOSITION, line) \\\n        <= view.SendScintilla(view.SCI_GETLINEINDENTPOSITION, line)\ndef modify(position, modificationType, text, length, linesAdded,\n           line, foldLevelNow, foldLevelPrev, token, annotationLinesAdded):\n    full = view.SC_MOD_INSERTTEXT | view.SC_MOD_DELETETEXT\n    if (~modificationType & full == full):\n        return\n    prev = [-1, 0]\n    full = view.SendScintilla(view.SCI_GETLINECOUNT)\n    lbgn = view.SendScintilla(view.SCI_LINEFROMPOSITION, position)\n    lend = view.SendScintilla(view.SCI_LINEFROMPOSITION, position + length)\n    for iter in range(max(lbgn - 1, 0), -1, -1):\n        if ((iter == 0) or not line_empty(iter)):\n            lbgn = iter\n            break\n    for iter in range(min(lend + 1, full), full + 1):\n        if ((iter == full) or not line_empty(iter)):\n            lend = min(iter + 1, full)\n            break\n    for iter in range(lbgn, lend):\n        if (line_empty(iter)):\n            if (prev[0] == -1):\n                prev[0] = iter\n        else:\n            fold = view.SendScintilla(view.SCI_GETLINEINDENTATION, iter)\n            fold //= view.SendScintilla(view.SCI_GETTABWIDTH)\n            set_fold(prev, iter - 1, fold, full)\n            set_fold([iter, fold], iter, fold, full)\n            prev = [-1, fold]\n    set_fold(prev, lend - 1, 0, full)\nif __name__ == '__main__':\n    import sys\n    import textwrap\n    app = QApplication(sys.argv)\n    view = QsciScintilla()\n    view.SendScintilla(view.SCI_SETMULTIPLESELECTION, True)\n    view.SendScintilla(view.SCI_SETMULTIPASTE, 1)\n    view.SendScintilla(view.SCI_SETADDITIONALSELECTIONTYPING, True)\n    view.SendScintilla(view.SCI_SETINDENTATIONGUIDES, view.SC_IV_REAL);\n    view.SendScintilla(view.SCI_SETTABWIDTH, 4)\n    view.setFolding(view.BoxedFoldStyle)\n    view.SCN_MODIFIED.connect(modify)\n    NUM_CHUNKS = 20000\n    chunk = textwrap.dedent(\"\"\"\\\n        x = 1\n            x = 2\n            x = 3\n    \"\"\")\n    view.setText(\"\\n\".join([chunk for i in range(NUM_CHUNKS)]))\n    view.show()\n    app.exec_()",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2019-04-06T18:58:12",
        "author": "hidefromkgb"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55672724/airflow-creating-dynamic-tasks-from-xcom",
    "title": "Airflow - creating dynamic Tasks from XCOM",
    "question_id": 55672724,
    "posted_date": "2019-04-14T02:55:11",
    "answers": [
      {
        "answer_id": 56556790,
        "body": "from airflow.models import TaskInstance\nfrom airflow.utils.db import provide_session\ndag = DAG(...)\n@provide_session\ndef get_files_list(session):\n    execution_date = dag.previous_schedule(datetime.now())\n    // Find previous task instance:\n    ti = session.query(TaskInstance).filter(\n        TaskInstance.dag_id == dag.dag_id,\n        TaskInstance.execution_date == execution_date,\n        TaskInstance.task_id == upstream_task_id).first()\n    if ti:\n        files_list = ti.xcom_pull()\n        if files_list:\n            return files_list\n    // Return default state:\n    return {...}\nfiles_list = get_files_list()\n// Generate tasks based on upstream task state:\ntask = PythonOperator(\n    ...\n    xcom_push=True,\n    dag=dag)",
        "score": 12,
        "is_accepted": true,
        "creation_date": "2019-06-12T03:29:48",
        "author": "Michael Spector"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55455010/how-to-stop-pandas-dataframe-from-converting-int-to-float-for-no-reason",
    "title": "How to stop Pandas DataFrame from converting int to float for no reason?",
    "question_id": 55455010,
    "posted_date": "2019-04-01T08:21:11",
    "answers": [
      {
        "answer_id": 55464801,
        "body": "import pandas as pd\nimport numpy as np\nimport sys\nprint(sys.version)\nprint(pd.__version__)\nprint(\"int dtypes preserved\")\n# append on populated DataFrame\ndf = pd.DataFrame([[0, 0], [1,1]], index=['a', 'b'], columns=[\"col1\", \"col2\"])\ndf.loc[\"c\"] = np.int64(0)\n# slice existing rows\ndf.loc[\"a\":\"c\"] = np.int64(1)\ndf.loc[\"a\":\"c\", \"col1\":\"col2\":1] = np.int64(2)\nprint(df.dtypes)\n# no selection AND no data, remains np.int64 if defined as such\ndf = pd.DataFrame(columns=[\"col1\", \"col2\"], dtype=np.int64)\ndf.loc[:, \"col1\":\"col2\":1] = np.int64(0)\ndf.loc[:,:] = np.int64(0)\nprint(df.dtypes)\n# and works if no index but data\ndf = pd.DataFrame([[0, 0], [1,1]], columns=[\"col1\", \"col2\"])\ndf.loc[:,\"col1\":\"col2\":1] = np.int64(0)\nprint(df.dtypes)\n# the surprise... label based insertion for the entire row does not convert to float\ndf = pd.DataFrame(columns=[\"col1\", \"col2\"], dtype=np.int64)\ndf.loc[\"a\"] = np.int64(0)\nprint(df.dtypes)\n# a surprise because referring to all columns, as above, does convert to float\nprint(\"unexpectedly converted to float dtypes\")\ndf = pd.DataFrame(columns=[\"col1\", \"col2\"], dtype=np.int64)\ndf.loc[\"a\", \"col1\":\"col2\"] = np.int64(0)\nprint(df.dtypes)",
        "score": 6,
        "is_accepted": true,
        "creation_date": "2019-04-01T19:10:20",
        "author": "Rich Andrews"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65012892/how-to-specify-node-label-position-for-sankey-diagram-in-plotly",
    "title": "How to Specify Node Label Position for Sankey Diagram in Plotly",
    "question_id": 65012892,
    "posted_date": "2020-11-25T16:24:40",
    "answers": [
      {
        "answer_id": 75662652,
        "body": "const TEXTPAD = 3; // constant used in Plotly.js\nfunction sankeyNodeLabelsAlign(position, forcePos) {\n  const textAnchor = {left: 'end', right: 'start', center: 'middle'}[position];\n  const nodes = gd.getElementsByClassName('sankey-node');\n  for (const node of nodes) {\n    const d = node.__data__;\n    const label = node.getElementsByClassName('node-label').item(0);\n    // Ensure to reset any previous modifications\n    label.setAttribute('x', 0);\n    if (!d.horizontal)\n      continue;\n    // This is how Plotly's default text positioning is computed (coordinates\n    // are relative to that of the cooresponding node).\n    const padX = d.nodeLineWidth / 2 + TEXTPAD;\n    const posX = padX + d.visibleWidth;\n    let x;\n    switch (position) {\n      case 'left':\n        if (d.left || d.node.originalLayer === 0 && !forcePos)\n          continue;\n        x = -posX - padX;\n        break;\n      case 'right':\n        if (!d.left || !forcePos)\n          continue;\n        x = posX + padX;\n        break;\n      case 'center':\n        if (!forcePos && (d.left || d.node.originalLayer === 0))\n          continue;\n        x = (d.nodeLineWidth + d.visibleWidth)/2 + (d.left ? padX : -posX);\n        break;\n    }\n    label.setAttribute('x', x);\n    label.setAttribute('text-anchor', textAnchor);\n  }\n}",
        "score": 5,
        "is_accepted": false,
        "creation_date": "2023-03-07T08:33:40",
        "author": "EricLavault"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/29745635/creating-wxslider-with-range-on-linux",
    "title": "Creating wxSlider with range on Linux",
    "question_id": 29745635,
    "posted_date": "2015-04-20T06:42:12",
    "answers": [
      {
        "answer_id": 59494283,
        "body": "import wx\ndef fraction_to_value(fraction, min_value, max_value):\n    return (max_value - min_value) * fraction + min_value\ndef value_to_fraction(value, min_value, max_value):\n    return float(value - min_value) / (max_value - min_value)\nclass SliderThumb:\n    def __init__(self, parent, value):\n        self.parent = parent\n        self.dragged = False\n        self.mouse_over = False\n        self.thumb_poly = ((0, 0), (0, 13), (5, 18), (10, 13), (10, 0))\n        self.thumb_shadow_poly = ((0, 14), (4, 18), (6, 18), (10, 14))\n        min_coords = [float('Inf'), float('Inf')]\n        max_coords = [-float('Inf'), -float('Inf')]\n        for pt in list(self.thumb_poly) + list(self.thumb_shadow_poly):\n            for i_coord, coord in enumerate(pt):\n                if coord > max_coords[i_coord]:\n                    max_coords[i_coord] = coord\n                if coord < min_coords[i_coord]:\n                    min_coords[i_coord] = coord\n        self.size = (max_coords[0] - min_coords[0],\n                     max_coords[1] - min_coords[1])\n        self.value = value\n        self.normal_color = wx.Colour((0, 120, 215))\n        self.normal_shadow_color = wx.Colour((120, 180, 228))\n        self.dragged_color = wx.Colour((204, 204, 204))\n        self.dragged_shadow_color = wx.Colour((222, 222, 222))\n        self.mouse_over_color = wx.Colour((23, 23, 23))\n        self.mouse_over_shadow_color = wx.Colour((132, 132, 132))\n    def GetPosition(self):\n        min_x = self.GetMin()\n        max_x = self.GetMax()\n        parent_size = self.parent.GetSize()\n        min_value = self.parent.GetMin()\n        max_value = self.parent.GetMax()\n        fraction = value_to_fraction(self.value, min_value, max_value)\n        pos = (fraction_to_value(fraction, min_x, max_x), parent_size[1] / 2 + 1)\n        return pos\n    def SetPosition(self, pos):\n        pos_x = pos[0]\n        # Limit movement by the position of the other thumb\n        who_other, other_thumb = self.GetOtherThumb()\n        other_pos = other_thumb.GetPosition()\n        if who_other == 'low':\n            pos_x = max(other_pos[0] + other_thumb.size[0]/2 + self.size[0]/2, pos_x)\n        else:\n            pos_x = min(other_pos[0] - other_thumb.size[0]/2 - self.size[0]/2, pos_x)\n        # Limit movement by slider boundaries\n        min_x = self.GetMin()\n        max_x = self.GetMax()\n        pos_x = min(max(pos_x, min_x), max_x)\n        fraction = value_to_fraction(pos_x, min_x, max_x)\n        self.value = fraction_to_value(fraction, self.parent.GetMin(), self.parent.GetMax())\n        # Post event notifying that position changed\n        self.PostEvent()\n    def GetValue(self):\n        return self.value\n    def SetValue(self, value):\n        self.value = value\n        # Post event notifying that value changed\n        self.PostEvent()\n    def PostEvent(self):\n        event = wx.PyCommandEvent(wx.EVT_SLIDER.typeId, self.parent.GetId())\n        event.SetEventObject(self.parent)\n        wx.PostEvent(self.parent.GetEventHandler(), event)\n    def GetMin(self):\n        min_x = self.parent.border_width + self.size[0] / 2\n        return min_x\n    def GetMax(self):\n        parent_size = self.parent.GetSize()\n        max_x = parent_size[0] - self.parent.border_width - self.size[0] / 2\n        return max_x\n    def IsMouseOver(self, mouse_pos):\n        in_hitbox = True\n        my_pos = self.GetPosition()\n        for i_coord, mouse_coord in enumerate(mouse_pos):\n            boundary_low = my_pos[i_coord] - self.size[i_coord] / 2\n            boundary_high = my_pos[i_coord] + self.size[i_coord] / 2\n            in_hitbox = in_hitbox and (boundary_low <= mouse_coord <= boundary_high)\n        return in_hitbox\n    def GetOtherThumb(self):\n        if self.parent.thumbs['low'] != self:\n            return 'low', self.parent.thumbs['low']\n        else:\n            return 'high', self.parent.thumbs['high']\n    def OnPaint(self, dc):\n        if self.dragged or not self.parent.IsEnabled():\n            thumb_color = self.dragged_color\n            thumb_shadow_color = self.dragged_shadow_color\n        elif self.mouse_over:\n            thumb_color = self.mouse_over_color\n            thumb_shadow_color = self.mouse_over_shadow_color\n        else:\n            thumb_color = self.normal_color\n            thumb_shadow_color = self.normal_shadow_color\n        my_pos = self.GetPosition()\n        # Draw thumb shadow (or anti-aliasing effect)\n        dc.SetBrush(wx.Brush(thumb_shadow_color, style=wx.BRUSHSTYLE_SOLID))\n        dc.SetPen(wx.Pen(thumb_shadow_color, width=1, style=wx.PENSTYLE_SOLID))\n        dc.DrawPolygon(points=self.thumb_shadow_poly,\n                       xoffset=my_pos[0] - self.size[0]/2,\n                       yoffset=my_pos[1] - self.size[1]/2)\n        # Draw thumb itself\n        dc.SetBrush(wx.Brush(thumb_color, style=wx.BRUSHSTYLE_SOLID))\n        dc.SetPen(wx.Pen(thumb_color, width=1, style=wx.PENSTYLE_SOLID))\n        dc.DrawPolygon(points=self.thumb_poly,\n                       xoffset=my_pos[0] - self.size[0] / 2,\n                       yoffset=my_pos[1] - self.size[1] / 2)\nclass RangeSlider(wx.Panel):\n    def __init__(self, parent, id=wx.ID_ANY, lowValue=None, highValue=None, minValue=0, maxValue=100,\n                 pos=wx.DefaultPosition, size=wx.DefaultSize, style=wx.SL_HORIZONTAL, validator=wx.DefaultValidator,\n                 name='rangeSlider'):\n        if style != wx.SL_HORIZONTAL:\n            raise NotImplementedError('Styles not implemented')\n        if validator != wx.DefaultValidator:\n            raise NotImplementedError('Validator not implemented')\n        super().__init__(parent=parent, id=id, pos=pos, size=size, name=name)\n        self.SetMinSize(size=(max(50, size[0]), max(26, size[1])))\n        if minValue > maxValue:\n            minValue, maxValue = maxValue, minValue\n        self.min_value = minValue\n        self.max_value = maxValue\n        if lowValue is None:\n            lowValue = self.min_value\n        if highValue is None:\n            highValue = self.max_value\n        if lowValue > highValue:\n            lowValue, highValue = highValue, lowValue\n        lowValue = max(lowValue, self.min_value)\n        highValue = min(highValue, self.max_value)\n        self.border_width = 8\n        self.thumbs = {\n            'low': SliderThumb(parent=self, value=lowValue),\n            'high': SliderThumb(parent=self, value=highValue)\n        }\n        self.thumb_width = self.thumbs['low'].size[0]\n        # Aesthetic definitions\n        self.slider_background_color = wx.Colour((231, 234, 234))\n        self.slider_outline_color = wx.Colour((214, 214, 214))\n        self.selected_range_color = wx.Colour((0, 120, 215))\n        self.selected_range_outline_color = wx.Colour((0, 120, 215))\n        # Bind events\n        self.Bind(wx.EVT_LEFT_DOWN, self.OnMouseDown)\n        self.Bind(wx.EVT_LEFT_UP, self.OnMouseUp)\n        self.Bind(wx.EVT_MOTION, self.OnMouseMotion)\n        self.Bind(wx.EVT_MOUSE_CAPTURE_LOST, self.OnMouseLost)\n        self.Bind(wx.EVT_ENTER_WINDOW, self.OnMouseEnter)\n        self.Bind(wx.EVT_LEAVE_WINDOW, self.OnMouseLeave)\n        self.Bind(wx.EVT_PAINT, self.OnPaint)\n        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)\n        self.Bind(wx.EVT_SIZE, self.OnResize)\n    def Enable(self, enable=True):\n        super().Enable(enable)\n        self.Refresh()\n    def Disable(self):\n        super().Disable()\n        self.Refresh()\n    def SetValueFromMousePosition(self, click_pos):\n        for thumb in self.thumbs.values():\n            if thumb.dragged:\n                thumb.SetPosition(click_pos)\n    def OnMouseDown(self, evt):\n        if not self.IsEnabled():\n            return\n        click_pos = evt.GetPosition()\n        for thumb in self.thumbs.values():\n            if thumb.IsMouseOver(click_pos):\n                thumb.dragged = True\n                thumb.mouse_over = False\n                break\n        self.SetValueFromMousePosition(click_pos)\n        self.CaptureMouse()\n        self.Refresh()\n    def OnMouseUp(self, evt):\n        if not self.IsEnabled():\n            return\n        self.SetValueFromMousePosition(evt.GetPosition())\n        for thumb in self.thumbs.values():\n            thumb.dragged = False\n        if self.HasCapture():\n            self.ReleaseMouse()\n        self.Refresh()\n    def OnMouseLost(self, evt):\n        for thumb in self.thumbs.values():\n            thumb.dragged = False\n            thumb.mouse_over = False\n        self.Refresh()\n    def OnMouseMotion(self, evt):\n        if not self.IsEnabled():\n            return\n        refresh_needed = False\n        mouse_pos = evt.GetPosition()\n        if evt.Dragging() and evt.LeftIsDown():\n            self.SetValueFromMousePosition(mouse_pos)\n            refresh_needed = True\n        else:\n            for thumb in self.thumbs.values():\n                old_mouse_over = thumb.mouse_over\n                thumb.mouse_over = thumb.IsMouseOver(mouse_pos)\n                if old_mouse_over != thumb.mouse_over:\n                    refresh_needed = True\n        if refresh_needed:\n            self.Refresh()\n    def OnMouseEnter(self, evt):\n        if not self.IsEnabled():\n            return\n        mouse_pos = evt.GetPosition()\n        for thumb in self.thumbs.values():\n            if thumb.IsMouseOver(mouse_pos):\n                thumb.mouse_over = True\n                self.Refresh()\n                break\n    def OnMouseLeave(self, evt):\n        if not self.IsEnabled():\n            return\n        for thumb in self.thumbs.values():\n            thumb.mouse_over = False\n        self.Refresh()\n    def OnResize(self, evt):\n        self.Refresh()\n    def OnPaint(self, evt):\n        w, h = self.GetSize()\n        # BufferedPaintDC should reduce flickering\n        dc = wx.BufferedPaintDC(self)\n        background_brush = wx.Brush(self.GetBackgroundColour(), wx.SOLID)\n        dc.SetBackground(background_brush)\n        dc.Clear()\n        # Draw slider\n        track_height = 12\n        dc.SetPen(wx.Pen(self.slider_outline_color, width=1, style=wx.PENSTYLE_SOLID))\n        dc.SetBrush(wx.Brush(self.slider_background_color, style=wx.BRUSHSTYLE_SOLID))\n        dc.DrawRectangle(self.border_width, h/2 - track_height/2, w - 2 * self.border_width, track_height)\n        # Draw selected range\n        if self.IsEnabled():\n            dc.SetPen(wx.Pen(self.selected_range_outline_color, width=1, style=wx.PENSTYLE_SOLID))\n            dc.SetBrush(wx.Brush(self.selected_range_color, style=wx.BRUSHSTYLE_SOLID))\n        else:\n            dc.SetPen(wx.Pen(self.slider_outline_color, width=1, style=wx.PENSTYLE_SOLID))\n            dc.SetBrush(wx.Brush(self.slider_outline_color, style=wx.BRUSHSTYLE_SOLID))\n        low_pos = self.thumbs['low'].GetPosition()[0]\n        high_pos = self.thumbs['high'].GetPosition()[0]\n        dc.DrawRectangle(low_pos, h / 2 - track_height / 4, high_pos - low_pos, track_height / 2)\n        # Draw thumbs\n        for thumb in self.thumbs.values():\n            thumb.OnPaint(dc)\n        evt.Skip()\n    def OnEraseBackground(self, evt):\n        # This should reduce flickering\n        pass\n    def GetValues(self):\n        return self.thumbs['low'].value, self.thumbs['high'].value\n    def SetValues(self, lowValue, highValue):\n        if lowValue > highValue:\n            lowValue, highValue = highValue, lowValue\n        lowValue = max(lowValue, self.min_value)\n        highValue = min(highValue, self.max_value)\n        self.thumbs['low'].SetValue(lowValue)\n        self.thumbs['high'].SetValue(highValue)\n        self.Refresh()\n    def GetMax(self):\n        return self.max_value\n    def GetMin(self):\n        return self.min_value\n    def SetMax(self, maxValue):\n        if maxValue < self.min_value:\n            maxValue = self.min_value\n        _, old_high = self.GetValues()\n        if old_high > maxValue:\n            self.thumbs['high'].SetValue(maxValue)\n        self.max_value = maxValue\n        self.Refresh()\n    def SetMin(self, minValue):\n        if minValue > self.max_value:\n            minValue = self.max_value\n        old_low, _ = self.GetValues()\n        if old_low < minValue:\n            self.thumbs['low'].SetValue(minValue)\n        self.min_value = minValue\n        self.Refresh()\nclass TestFrame(wx.Frame):\n    def __init__(self):\n        wx.Frame.__init__(self, None, -1, 'Range Slider Demo', size=(300, 100))\n        panel = wx.Panel(self)\n        b = 6\n        vbox = wx.BoxSizer(orient=wx.VERTICAL)\n        vbox.Add(wx.StaticText(parent=panel, label='Custom Range Slider:'), flag=wx.ALIGN_LEFT | wx.ALL, border=b)\n        self.rangeslider = RangeSlider(parent=panel, lowValue=20, highValue=80, minValue=0, maxValue=100,\n                                       size=(300, 26))\n        self.rangeslider.Bind(wx.EVT_SLIDER, self.rangeslider_changed)\n        vbox.Add(self.rangeslider, proportion=1, flag=wx.EXPAND | wx.ALL, border=b)\n        self.rangeslider_static = wx.StaticText(panel)\n        vbox.Add(self.rangeslider_static, flag=wx.ALIGN_LEFT | wx.ALL, border=b)\n        vbox.Add(wx.StaticText(parent=panel, label='Regular Slider with wx.SL_SELRANGE style:'),\n                 flag=wx.ALIGN_LEFT | wx.ALL, border=b)\n        self.slider = wx.Slider(parent=panel, style=wx.SL_SELRANGE)\n        self.slider.SetSelection(20, 40)\n        self.slider.Bind(wx.EVT_SLIDER, self.slider_changed)\n        vbox.Add(self.slider, proportion=1, flag=wx.EXPAND | wx.ALL, border=b)\n        self.slider_static = wx.StaticText(panel)\n        vbox.Add(self.slider_static, flag=wx.ALIGN_LEFT | wx.ALL, border=b)\n        self.button_toggle = wx.Button(parent=panel, label='Disable')\n        self.button_toggle.Bind(wx.EVT_BUTTON, self.toggle_slider_enable)\n        vbox.Add(self.button_toggle, flag=wx.ALIGN_CENTER | wx.ALL, border=b)\n        panel.SetSizerAndFit(vbox)\n        box = wx.BoxSizer()\n        box.Add(panel, proportion=1, flag=wx.EXPAND)\n        self.SetSizerAndFit(box)\n    def slider_changed(self, evt):\n        obj = evt.GetEventObject()\n        val = obj.GetValue()\n        self.slider_static.SetLabel('Value: {}'.format(val))\n    def rangeslider_changed(self, evt):\n        obj = evt.GetEventObject()\n        lv, hv = obj.GetValues()\n        self.rangeslider_static.SetLabel('Low value: {:.0f}, High value: {:.0f}'.format(lv, hv))\n    def toggle_slider_enable(self, evt):\n        if self.button_toggle.GetLabel() == 'Disable':\n            self.slider.Enable(False)\n            self.rangeslider.Enable(False)\n            self.button_toggle.SetLabel('Enable')\n        else:\n            self.slider.Enable(True)\n            self.rangeslider.Enable(True)\n            self.button_toggle.SetLabel('Disable')\ndef main():\n    app = wx.App()\n    TestFrame().Show()\n    app.MainLoop()\nif __name__ == \"__main__\":\n    main()",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2019-12-26T18:01:18",
        "author": "Pasa"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/883370/python-multiprocessing-atexit-error-error-in-atexit-run-exitfuncs",
    "title": "Python Multiprocessing atexit Error &quot;Error in atexit._run_exitfuncs&quot;",
    "question_id": 883370,
    "posted_date": "2009-05-19T11:13:33",
    "answers": [
      {
        "answer_id": 68638868,
        "body": "import sys\nimport time\nfrom multiprocessing import Process\ndef main():\n    # Set up inputs..\n    # Spawn processes\n    try:\n        processes = [Proc(1), Proc(2)]\n        [p.start() for p in processes]\n        [p.join() for p in processes]\n    except KeyboardInterrupt:\n        pass\nclass Proc(Process):\n    def __init__(self, procNum):\n        self.id = procNum\n        Process.__init__(self)\n    def run(self):\n        while True:\n            try:\n                # Do work...\n                time.sleep(1)\n                sys.stdout.write('.')\n            except KeyboardInterrupt:\n                print(\"User aborted.\")\n                break\n# Main Entry\nif __name__ == \"__main__\":\n    main()",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2021-08-03T11:30:25",
        "author": "Anake"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67093166/pylint-pylint-django-does-not-work-when-django-settings-module-flag-is-speci",
    "title": "pylint (pylint_django) does not work when --django-settings-module flag is specified",
    "question_id": 67093166,
    "posted_date": "2021-04-14T09:53:55",
    "answers": [
      {
        "answer_id": 76658594,
        "body": "Traceback (most recent call last):\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint_django/checkers/foreign_key_strings.py\", line 92, in open\n    django.setup()\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/django/__init__.py\", line 19, in setup\n    configure_logging(settings.LOGGING_CONFIG, settings.LOGGING)\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/django/conf/__init__.py\", line 102, in __getattr__\n    self._setup(name)\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/django/conf/__init__.py\", line 82, in _setup\n    raise ImproperlyConfigured(\ndjango.core.exceptions.ImproperlyConfigured: Requested setting LOGGING_CONFIG, but settings are not configured. You must either define the environment variable DJANGO_SETTINGS_MODULE or call settings.configure() before accessing settings.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint_django/checkers/foreign_key_strings.py\", line 120, in open\n    settings.configure(Settings(self.config.django_settings_module))\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/django/conf/__init__.py\", line 217, in __init__\n    mod = importlib.import_module(self.SETTINGS_MODULE)\n  File \"/usr/local/python/3.10.12/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1004, in _find_and_load_unlocked\nModuleNotFoundError: No module named 'backend.settings'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/workspaces/checkout/backend/.venv/bin/pylint\", line 8, in <module>\n    sys.exit(run_pylint())\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/__init__.py\", line 36, in run_pylint\n    PylintRun(argv or sys.argv[1:])\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/lint/run.py\", line 215, in __init__\n    linter.check(args)\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/lint/pylinter.py\", line 713, in check\n    with self._astroid_module_checker() as check_astroid_module:\n  File \"/usr/local/python/3.10.12/lib/python3.10/contextlib.py\", line 135, in __enter__\n    return next(self.gen)\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/lint/pylinter.py\", line 1015, in _astroid_module_checker\n    checker.open()\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint_django/checkers/foreign_key_strings.py\", line 125, in open\n    self.add_message(\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/checkers/base_checker.py\", line 164, in add_message\n    self.linter.add_message(\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/lint/pylinter.py\", line 1341, in add_message\n    self._add_one_message(\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/lint/pylinter.py\", line 1274, in _add_one_message\n    self.stats.increase_single_module_message_count(\n  File \"/workspaces/checkout/backend/.venv/lib/python3.10/site-packages/pylint/utils/linterstats.py\", line 315, in increase_single_module_message_count\n    self.by_module[modname][type_name] += increase\nKeyError: 'Command line or configuration file'",
        "score": 2,
        "is_accepted": false,
        "creation_date": "2023-07-10T23:45:15",
        "author": "GaNiziolek"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64689342/plotly-how-to-add-volume-to-a-candlestick-chart",
    "title": "Plotly: How to add volume to a candlestick chart",
    "question_id": 64689342,
    "posted_date": "2020-11-04T18:54:28",
    "answers": [
      {
        "answer_id": 65997291,
        "body": "import pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n# data\ndf = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')\n# Create subplots and mention plot grid size\nfig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n               vertical_spacing=0.03, subplot_titles=('OHLC', 'Volume'),\n               row_width=[0.2, 0.7])\n# Plot OHLC on 1st row\nfig.add_trace(go.Candlestick(x=df[\"Date\"], open=df[\"AAPL.Open\"], high=df[\"AAPL.High\"],\n                low=df[\"AAPL.Low\"], close=df[\"AAPL.Close\"], name=\"OHLC\"),\n                row=1, col=1\n)\n# Bar trace for volumes on 2nd row without legend\nfig.add_trace(go.Bar(x=df['Date'], y=df['AAPL.Volume'], showlegend=False), row=2, col=1)\n# Do not show OHLC's rangeslider plot\nfig.update(layout_xaxis_rangeslider_visible=False)\nfig.show()",
        "score": 32,
        "is_accepted": false,
        "creation_date": "2021-02-01T12:24:43",
        "author": "Mega J"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/12526606/callback-for-celery-apply-async",
    "title": "Callback for celery apply_async",
    "question_id": 12526606,
    "posted_date": "2012-09-21T04:09:48",
    "answers": [
      {
        "answer_id": 13494345,
        "body": "from celery import Task\nclass CallbackTask(Task):\n    def on_success(self, retval, task_id, args, kwargs):\n        '''\n        retval \u2013 The return value of the task.\n        task_id \u2013 Unique id of the executed task.\n        args \u2013 Original arguments for the executed task.\n        kwargs \u2013 Original keyword arguments for the executed task.\n        '''\n        pass\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        '''\n        exc \u2013 The exception raised by the task.\n        task_id \u2013 Unique id of the failed task.\n        args \u2013 Original arguments for the task that failed.\n        kwargs \u2013 Original keyword arguments for the task that failed.\n        '''\n        pass",
        "score": 52,
        "is_accepted": true,
        "creation_date": "2012-11-21T08:27:27",
        "author": "Douwe van der Meij"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15899861/efficient-term-document-matrix-with-nltk",
    "title": "efficient Term Document Matrix with NLTK",
    "question_id": 15899861,
    "posted_date": "2013-04-09T06:46:56",
    "answers": [
      {
        "answer_id": 28727111,
        "body": "import textmining\n\n# Create some very short sample documents\ndoc1 = 'John and Bob are brothers.'\ndoc2 = 'John went to the store. The store was closed.'\ndoc3 = 'Bob went to the store too.'\n# Initialize class to create term-document matrix\ntdm = textmining.TermDocumentMatrix()\n# Add the documents\ntdm.add_doc(doc1)\ntdm.add_doc(doc2)\ntdm.add_doc(doc3)\n# Write matrix file -- cutoff=1 means words in 1+ documents are retained\ntdm.write_csv('matrix.csv', cutoff=1)\n# Instead of writing the matrix, access its rows directly\nfor row in tdm.rows(cutoff=1):\n    print row",
        "score": 37,
        "is_accepted": false,
        "creation_date": "2015-02-25T13:43:07",
        "author": "duhaime"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7755501/embed-picture-in-email",
    "title": "Embed picture in email",
    "question_id": 7755501,
    "posted_date": "2011-10-13T10:15:03",
    "answers": [
      {
        "answer_id": 7755994,
        "body": "from email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText  # Added\nfrom email.mime.image import MIMEImage\nattachment = 'bob.jpg'\nmsg = MIMEMultipart()\nmsg[\"To\"] = to_addr\nmsg[\"From\"] = from_addr\nmsg[\"Subject\"] = subject\nmsgText = MIMEText('<b>%s</b><br/><img src=\"cid:%s\"/><br/>' % (body, attachment), 'html')\nmsg.attach(msgText)   # Added, and edited the previous line\nwith open(attachment, 'rb') as fp:\n    img = MIMEImage(fp.read())\nimg.add_header('Content-ID', '<{}>'.format(attachment))\nmsg.attach(img)\nprint(msg.as_string()) # or go ahead and send it",
        "score": 48,
        "is_accepted": true,
        "creation_date": "2011-10-13T10:48:56",
        "author": "tripleee"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61366664/how-to-upsert-pandas-dataframe-to-postgresql-table",
    "title": "How to upsert pandas DataFrame to PostgreSQL table?",
    "question_id": 61366664,
    "posted_date": "2020-04-22T09:43:41",
    "answers": [
      {
        "answer_id": 62379384,
        "body": "import sqlalchemy as sa\n# \u2026\nwith engine.begin() as conn:\n    # step 0.0 - create test environment\n    conn.exec_driver_sql(\"DROP TABLE IF EXISTS main_table\")\n    conn.exec_driver_sql(\n        \"CREATE TABLE main_table (id int primary key, txt varchar(50))\"\n    )\n    conn.exec_driver_sql(\n        \"INSERT INTO main_table (id, txt) VALUES (1, 'row 1 old text')\"\n    )\n    # step 0.1 - create DataFrame to UPSERT\n    df = pd.DataFrame(\n        [(2, \"new row 2 text\"), (1, \"row 1 new text\")], columns=[\"id\", \"txt\"]\n    )\n\n    # step 1 - create temporary table and upload DataFrame\n    conn.exec_driver_sql(\n        \"CREATE TEMPORARY TABLE temp_table AS SELECT * FROM main_table WHERE false\"\n    )\n    df.to_sql(\"temp_table\", conn, index=False, if_exists=\"append\")\n    # step 2 - merge temp_table into main_table\n    conn.exec_driver_sql(\n        \"\"\"\\\n        INSERT INTO main_table (id, txt)\n        SELECT id, txt FROM temp_table\n        ON CONFLICT (id) DO\n            UPDATE SET txt = EXCLUDED.txt\n        \"\"\"\n    )\n    # step 3 - confirm results\n    result = conn.exec_driver_sql(\"SELECT * FROM main_table ORDER BY id\").all()\n    print(result)  # [(1, 'row 1 new text'), (2, 'new row 2 text')]",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-06-14T19:36:21",
        "author": "Gord Thompson"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44385652/add-senders-name-in-the-from-field-of-the-email-in-python",
    "title": "add sender&#39;s name in the from field of the email in python",
    "question_id": 44385652,
    "posted_date": "2017-06-06T04:59:07",
    "answers": [
      {
        "answer_id": 47823846,
        "body": "import smtplib\nfrom email.mime.text import MIMEText\ndef send_email(to=['example@example.com'],\n               f_host='example.example.com',\n               f_port=587,\n               f_user='example@example.com',\n               f_passwd='example-pass',\n               subject='default subject',\n               message='content message'):\n    smtpserver = smtplib.SMTP(f_host, f_port)\n    smtpserver.ehlo()\n    smtpserver.starttls()\n    smtpserver.ehlo\n    smtpserver.login(f_user, f_passwd)  # from email credential\n    msg = MIMEText(message, 'html')\n    msg['Subject'] = 'My custom Subject'\n    msg['From'] = \"Your name <Your email>\"\n    msg['To'] = ','.join(to)\n    for t in to:\n        smtpserver.sendmail(f_user, t, msg.as_string())  # you just need to add\n                                                         # this in for loop in\n                                                         # your code.\n    smtpserver.close()\n    print('Mail is sent successfully!!')\n    cont = \"\"\"\n    <html>\n    <head></head>\n    <body>\n    <p>Hi!<br>\n      How are you?<br>\n      Here is the <a href=\"http://www.google.com\">link</a> you wanted.\n    </p>\n    </body>\n    </html>\n    \"\"\"\n    try:\n        send_email(message=cont)\n    except:\n        print('Mail could not be sent')",
        "score": 43,
        "is_accepted": false,
        "creation_date": "2017-12-14T18:48:14",
        "author": "Matheus Candido"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55749899/training-a-simple-model-in-tensorflow-gpu-slower-than-cpu",
    "title": "Training a simple model in Tensorflow GPU slower than CPU",
    "question_id": 55749899,
    "posted_date": "2019-04-18T12:05:25",
    "answers": [
      {
        "answer_id": 55750666,
        "body": "import tensorflow as tf\nimport time\ncpu_times = []\nsizes = [1, 10, 100, 500, 1000, 2000, 3000, 4000, 5000, 8000, 10000]\nfor size in sizes:\n    tf.reset_default_graph()\n    start = time.time()\n    with tf.device('cpu:0'):\n        v1 = tf.Variable(tf.random_normal((size, size)))\n        v2 = tf.Variable(tf.random_normal((size, size)))\n        op = tf.matmul(v1, v2)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(op)\n    cpu_times.append(time.time() - start)\n    print('cpu time took: {0:.4f}'.format(time.time() - start))\nimport tensorflow as tf\nimport time\ngpu_times = []\nfor size in sizes:\n    tf.reset_default_graph()\n    start = time.time()\n    with tf.device('gpu:0'):\n        v1 = tf.Variable(tf.random_normal((size, size)))\n        v2 = tf.Variable(tf.random_normal((size, size)))\n        op = tf.matmul(v1, v2)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(op)\n    gpu_times.append(time.time() - start)\n    print('gpu time took: {0:.4f}'.format(time.time() - start))\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(sizes, gpu_times, label='GPU')\nax.plot(sizes, cpu_times, label='CPU')\nplt.xlabel('MATRIX SIZE')\nplt.ylabel('TIME (sec)')\nplt.legend()\nplt.show()",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2019-04-18T12:59:43",
        "author": "Vlad"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/12435765/can-a-decorated-function-access-variables-of-the-decorator",
    "title": "Can a decorated function access variables of the decorator",
    "question_id": 12435765,
    "posted_date": "2012-09-15T04:21:23",
    "answers": [
      {
        "answer_id": 12436503,
        "body": "def funcDec(func):\n    localVariable = \"I'm a local string\"\n    # Local variable(s) to inject into wrapped func.\n    context = {'localVariable': localVariable}\n    def wrapped(*args):\n        func_globals = func.__globals__\n        # Save copy of any global values that will be replaced.\n        saved_values = {key: func_globals[key] for key in context if key in func_globals}\n        func_globals.update(context)\n        print(f'Calling localVariable from funcDec: {localVariable!r}')\n        try:\n            func(*args)\n        finally:\n            func_globals.update(saved_values)  # Restore any replaced globals.\n        print(f'done with calling {func.__name__}()')\n    return wrapped\n@funcDec\ndef f1(x, y):\n    print(x + y)\n    print(f'Calling funcDec localVariable from f1: {localVariable!r}')\nf1(2, 3)",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2012-09-15T06:16:37",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62722416/plot-confusion-matrix-for-multilabel-classifcation-python",
    "title": "Plot Confusion Matrix for multilabel Classifcation Python",
    "question_id": 62722416,
    "posted_date": "2020-07-03T16:39:47",
    "answers": [
      {
        "answer_id": 62750227,
        "body": "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.tree import DecisionTreeClassifier\nX, y = make_multilabel_classification(n_samples=1000,\n                                      n_classes=15, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state=42)\ntree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nf, axes = plt.subplots(3, 5, figsize=(25, 15))\naxes = axes.ravel()\nfor i in range(15):\n    disp = ConfusionMatrixDisplay(confusion_matrix(y_test[:, i],\n                                                   y_pred[:, i]),\n                                  display_labels=[0, i])\n    disp.plot(ax=axes[i], values_format='.4g')\n    disp.ax_.set_title(f'class {i}')\n    if i<10:\n        disp.ax_.set_xlabel('')\n    if i%5!=0:\n        disp.ax_.set_ylabel('')\n    disp.im_.colorbar.remove()\nplt.subplots_adjust(wspace=0.10, hspace=0.1)\nf.colorbar(disp.im_, ax=axes)\nplt.show()",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2020-07-06T02:14:14",
        "author": "Venkatachalam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55578387/email-verification-in-django",
    "title": "Email verification in Django",
    "question_id": 55578387,
    "posted_date": "2019-04-08T13:05:08",
    "answers": [
      {
        "answer_id": 56116529,
        "body": "from django.contrib.auth import get_user_model\nfrom django.utils.http import urlsafe_base64_encode, urlsafe_base64_decode\nfrom django.contrib.sites.shortcuts import get_current_site\nfrom .tokens import account_activation_token\nfrom django.core.mail import send_mail\nfrom django.utils.encoding import force_bytes\nfrom django.template.loader import render_to_string\ndef signup(request):\n    User = get_user_model()\n    if request.method == 'POST':\n        form = SignupForm(request.POST)\n        if form.is_valid():\n            email = form.cleaned_data.get('email')\n            if Yourmodel.objects.filter(email__iexact=email).count() == 1:\n                user = form.save(commit=False)\n                user.is_active = False\n                user.save()\n                current_site = get_current_site(request)\n                mail_subject = 'Activate your account.'\n                message = render_to_string('email_template.html', {\n                            'user': user,\n                            'domain': current_site.domain,\n                            'uid': urlsafe_base64_encode(force_bytes(user.pk)),\n                            'token': account_activation_token.make_token(user),\n                        })\n                to_email = form.cleaned_data.get('email')\n                send_mail(mail_subject, message, 'youremail', [to_email])\n                return HttpResponse('Please confirm your email address to complete the registration')\n     else:\n        form = SignupForm()\n    return render(request, 'regform.html', {'form': form})\ndef activate(request, uidb64, token):\n    User = get_user_model()\n    try:\n        uid = force_text(urlsafe_base64_decode(uidb64))\n        user = User.objects.get(pk=uid)\n    except(TypeError, ValueError, OverflowError, User.DoesNotExist):\n        user = None\n    if user is not None and account_activation_token.check_token(user, token):\n        user.is_active = True\n        user.save()\n        return HttpResponse('Thank you for your email confirmation. Now you can login your account.')\n    else:\n        return HttpResponse('Activation link is invalid!')",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2019-05-13T12:36:53",
        "author": "Joel Deleep"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56086764/section-divider-in-spyder",
    "title": "Section divider in Spyder",
    "question_id": 56086764,
    "posted_date": "2019-05-10T22:47:45",
    "answers": [
      {
        "answer_id": 64939055,
        "body": "#%% Notes\n#### Defining Code Cells\n# A \u201ccode cell\u201d in Spyder is a block of lines, typically in a script, that can be\n# easily executed all at once.\n# You can separate cells by lines starting with either:\n# 1) #%% (standard cell separator)\n# 2) # %% (standard cell separator, when file has been edited with Eclipse)\n# 3) # <codecell> (IPython notebook cell separator)\n#### Cell heirarchy\n# To nest navigable sections within a cell, use \"#### ~some heading~\"\n# To nest subcells within a cell, use \"#%% >> #%%% >> #%%%% .... \"",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2020-11-20T20:47:56",
        "author": "rahul-ahuja"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41569206/flask-sqlalchemy-foreign-key-relationships",
    "title": "Flask SQLAlchemy Foreign Key Relationships",
    "question_id": 41569206,
    "posted_date": "2017-01-10T07:46:43",
    "answers": [
      {
        "answer_id": 41569395,
        "body": "class Request(db.Model):\n    __tablename__ = 'request'\n    id = db.Column(db.Integer, primary_key=True)\n    applicationdate = db.Column(db.DateTime)\nclass Agent(db.Model):\n    __tablename__ = 'agent'\n    id = db.Column(db.Integer, primary_key=True)\n    request_id = db.Column(db.Integer, db.ForeignKey('request.id'))\n    request = db.relationship(\"Request\", backref=backref(\"request\", uselist=False))\n    name = db.Column(db.String(80))\n    company = db.Column(db.String(80))\n    address = db.Column(db.String(180))",
        "score": 36,
        "is_accepted": true,
        "creation_date": "2017-01-10T07:57:44",
        "author": "MrLeeh"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/26108436/how-can-i-get-the-matplotlib-rgb-color-given-the-colormap-name-boundrynorm-an",
    "title": "How can I get the matplotlib rgb color, given the colormap name, BoundryNorm, and &#39;c=&#39;?",
    "question_id": 26108436,
    "posted_date": "2014-09-29T16:37:58",
    "answers": [
      {
        "answer_id": 26109298,
        "body": "import numpy as np\n# setup the plot\nfig, ax = plt.subplots(1,1, figsize=(6,6))\n# define the data between 0 and 20\nNUM_VALS = 20\nx = np.random.uniform(0, NUM_VALS, size=NUM_VALS)\ny = np.random.uniform(0, NUM_VALS, size=NUM_VALS)\n# define the color chart between 2 and 10 using the 'autumn_r' colormap, so\n#   y <= 2  is yellow\n#   y >= 10 is red\n#   2 < y < 10 is between from yellow to red, according to its value\nCOL = MplColorHelper('autumn_r', 2, 10)\nscat = ax.scatter(x,y,s=300, c=COL.get_rgb(y))\nax.set_title('Well defined discrete colors')\nplt.show()",
        "score": 23,
        "is_accepted": false,
        "creation_date": "2014-09-29T17:34:17",
        "author": "TrailDreaming"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/21356439/how-to-load-and-play-a-video-in-pygame",
    "title": "How to load and play a video in pygame",
    "question_id": 21356439,
    "posted_date": "2014-01-25T16:25:12",
    "answers": [
      {
        "answer_id": 69054207,
        "body": "import pygame\nimport cv2\nvideo = cv2.VideoCapture(\"video.mp4\")\nsuccess, video_image = video.read()\nfps = video.get(cv2.CAP_PROP_FPS)\nwindow = pygame.display.set_mode(video_image.shape[1::-1])\nclock = pygame.time.Clock()\nrun = success\nwhile run:\n    clock.tick(fps)\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    success, video_image = video.read()\n    if success:\n        video_surf = pygame.image.frombuffer(\n            video_image.tobytes(), video_image.shape[1::-1], \"BGR\")\n    else:\n        run = False\n    window.blit(video_surf, (0, 0))\n    pygame.display.flip()\npygame.quit()\nexit()",
        "score": 17,
        "is_accepted": false,
        "creation_date": "2021-09-04T05:51:04",
        "author": "Rabbid76"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69527239/what-is-context-variable-in-airflow-operators",
    "title": "What is context variable in Airflow operators",
    "question_id": 69527239,
    "posted_date": "2021-10-11T09:43:20",
    "answers": [
      {
        "answer_id": 73022488,
        "body": "        return {\n            'conf': conf,\n            'dag': task.dag,\n            'dag_run': dag_run,\n            'ds': ds,\n            'ds_nodash': ds_nodash,\n            'execution_date': pendulum.instance(self.execution_date),\n            'inlets': task.inlets,\n            'macros': macros,\n            'next_ds': next_ds,\n            'next_ds_nodash': next_ds_nodash,\n            'next_execution_date': next_execution_date,\n            'outlets': task.outlets,\n            'params': params,\n            'prev_ds': prev_ds,\n            'prev_ds_nodash': prev_ds_nodash,\n            'prev_execution_date': prev_execution_date,\n            'prev_execution_date_success': lazy_object_proxy.Proxy(\n                lambda: self.get_previous_execution_date(state=State.SUCCESS)\n            ),\n            'prev_start_date_success': lazy_object_proxy.Proxy(\n                lambda: self.get_previous_start_date(state=State.SUCCESS)\n            ),\n            'run_id': run_id,\n            'task': task,\n            'task_instance': self,\n            'task_instance_key_str': ti_key_str,\n            'test_mode': self.test_mode,\n            'ti': self,\n            'tomorrow_ds': tomorrow_ds,\n            'tomorrow_ds_nodash': tomorrow_ds_nodash,\n            'ts': ts,\n            'ts_nodash': ts_nodash,\n            'ts_nodash_with_tz': ts_nodash_with_tz,\n            'var': {\n                'json': VariableJsonAccessor(),\n                'value': VariableAccessor(),\n            },\n            'yesterday_ds': yesterday_ds,\n            'yesterday_ds_nodash': yesterday_ds_nodash,\n        }",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2022-07-18T08:43:49",
        "author": "LondonRob"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67476156/pass-commandline-arguments-to-a-python-script-installed-with-poetry",
    "title": "Pass commandline arguments to a Python script installed with Poetry",
    "question_id": 67476156,
    "posted_date": "2021-05-10T14:55:04",
    "answers": [
      {
        "answer_id": 67476157,
        "body": "import argparse\ndef some_function(target, end=\"!\"):\n    \"\"\"Some example funcion\"\"\"\n    msg = \"hi \" + target + end\n    print(msg)\ndef start():\n    # All the logic of argparse goes in this function\n    parser = argparse.ArgumentParser(description='Say hi.')\n    parser.add_argument('target', type=str, help='the name of the target')\n    parser.add_argument('--end', dest='end', default=\"!\",\n                    help='sum the integers (default: find the max)')\n    args = parser.parse_args()\n    some_function(args.target, end=args.end)",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2021-05-10T14:55:04",
        "author": "Lucas"
      },
      {
        "answer_id": 67476157,
        "body": "# run with poetry\n$ poetry run my-script\n# install the proyect (this will create a virtualenv if you didn't have it created)\n$ poetry install\n# activate the virtualenv\n$ poetry shell\n# run the script\n$ my-script --help\nusage: my-script [-h] [--end END] target\nSay hi.\npositional arguments:\n  target      the name of the target\noptional arguments:\n  -h, --help  show this help message and exit\n  --end END   sum the integers (default: find the max)\n$ my-script \"spanish inquisition\" --end \"?\"\nhi spanish inquisition?",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2021-05-10T14:55:04",
        "author": "Lucas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45473501/getting-pil-pillow-4-2-1-to-upload-properly-to-aws-lambda-py3-6",
    "title": "Getting PIL/Pillow 4.2.1 to upload properly to AWS Lambda Py3.6",
    "question_id": 45473501,
    "posted_date": "2017-08-02T21:46:31",
    "answers": [
      {
        "answer_id": 47423994,
        "body": "#!/bin/sh\nset -ex\ncd /code/\nif [ ! -d \"PIL\" ]; then\n\t# Create virtual env, activate it and install PIL\n\tvirtualenv env && source env/bin/activate && pip install pillow requests\n\t# Copy necessary files to the root folder\n\trm -f build-output.zip\n\t#mkdir PIL\n\tcp -f -r env/lib/python3.6/site-packages/PIL .\n\tcp -f -r env/lib/python3.6/site-packages/requests .\n\n\t# below are the dependencies for the requests pkg\n\tcp -f -r env/lib/python3.6/site-packages/urllib3 .\n\tcp -f -r env/lib/python3.6/site-packages/certifi .\n\tcp -f -r env/lib/python3.6/site-packages/chardet .\n\tcp -f -r env/lib/python3.6/site-packages/idna .\n\n\t# Remove temp files\n\trm -r env\nfi\n# ZIP it\nzip -9 build-output *.py\nzip -9 -r build-output PIL\nzip -9 -r build-output requests\nzip -9 -r build-output urllib3\nzip -9 -r build-output certifi\nzip -9 -r build-output chardet\nzip -9 -r build-output idna",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2017-11-21T17:43:01",
        "author": "Diego Jancic"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/36194865/configure-a-first-cell-by-default-in-jupyter-notebooks",
    "title": "Configure a first cell by default in Jupyter notebooks",
    "question_id": 36194865,
    "posted_date": "2016-03-24T03:09:10",
    "answers": [
      {
        "answer_id": 43156449,
        "body": "    define([\n        'base/js/namespace'\n    ], function(\n        Jupyter\n    ) {\n        function load_ipython_extension() {\n          if (Jupyter.notebook.get_cells().length===1){\n       //do your thing\n            Jupyter.notebook.insert_cell_above('code', 0).set_text(\"# Scientific libraries\\nimport numpy as np\\nimport scipy\\n\\n# import Pandas\\n\\nimport pandas as pd\\n\\n# Graphic libraries\\n\\nimport matplotlib as plt\\n%matplotlib inline\\nimport seaborn as sns\\nfrom plotly.offline import init_notebook_mode, iplot, download_plotlyjs\\ninit_notebook_mode()\\nimport plotly.graph_objs as go\\n\\n# Extra options \\n\\npd.options.display.max_rows = 10\\npd.set_option('max_columns', 50)\\nsns.set(style='ticks', context='talk')\\n\\n# Creating alias for magic commands\\n%alias_magic t time\");\n          }\n        }\n        return {\n            load_ipython_extension: load_ipython_extension\n        };\n    });",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2017-04-01T07:45:48",
        "author": "MCMZL"
      },
      {
        "answer_id": 43156449,
        "body": "    default_cells\n    =========\n\n    Add default cells to each new notebook. You have to modify this line in the main.js file to change your default cell. For example\n\n    `Jupyter.notebook.insert_cell_above('code', 0).set_text(\"import numpy as np/nimportpandas as pd\")`\n\n\n    You can also add another default cell by creating a new line just below :\n\n    `Jupyter.notebook.insert_cell_above('code', 1).set_text(\"from sklearn.meatrics import mean_squared_error\")`\n\n    **Don't forget to increment 1 if you want more than one extra cell. **",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2017-04-01T07:45:48",
        "author": "MCMZL"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57287400/find-all-the-numbers-in-one-file-that-are-not-in-another-file-in-python",
    "title": "Find all the numbers in one file that are not in another file in python",
    "question_id": 57287400,
    "posted_date": "2019-07-31T05:21:18",
    "answers": [
      {
        "answer_id": 57287702,
        "body": "i1 = iter(open(\"3k.txt\"))\ni2 = iter(open(\"2k.txt\"))\na = int(next(i1))\nb = int(next(i2))\naNotB = []\n# bNotA = []\nwhile True:\n    try:\n        if a < b:\n            aNotB += [a]\n            a = int(next(i1, None))\n        elif a > b:\n            # bNotA += [a]\n            b = int(next(i2, None))\n        elif a == b:\n            a = int(next(i1, None))\n            b = int(next(i2, None))\n    except TypeError:\n        if not b:\n            aNotB += list(i1)\n            break\n        else:\n            # bNotA += list(i1)\n            break\nprint(aNotB)",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2019-07-31T05:37:41",
        "author": "yukashima huksay"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54264073/what-is-the-use-and-when-to-use-classmethod-in-python",
    "title": "what is the use and when to use @classmethod in python?",
    "question_id": 54264073,
    "posted_date": "2019-01-18T23:31:51",
    "answers": [
      {
        "answer_id": 54264481,
        "body": "class Person():\n    species='homo_sapiens' # This is class variable\n    def __init__(self, name, age):\n        self.name = name # This is instance variable\n        self.age = age\n    def show(self):\n        print('Name: {}, age: {}.'.format(self.name, date.today().year - self.age))\n\n    @classmethod\n    def create_with_birth_year(cls, name, birth_year):\n        return cls(name, date.today().year - birth_year)\n\t@classmethod\n\tdef print_species(cls):\n\t    print('species: {}'.format(cls.species))\n\n    @staticmethod\n    def get_birth_year(age):\n        return date.today().year - age\nclass Teacher(Person):\n    pass",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2019-01-19T00:58:36",
        "author": "Navy Cheng"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/41796290/unhashable-type-error-in-pandas-dataframe",
    "title": "Unhashable type error in pandas dataframe",
    "question_id": 41796290,
    "posted_date": "2017-01-22T16:20:37",
    "answers": [
      {
        "answer_id": 73124652,
        "body": "PS C:\\Users\\rascoussier\\python\\stackoverflow\\type_error_with_df_loc> C:\\Users\\rascoussier\\Anaconda3\\envs\\elastic-1\\python.exe .\\main.py\n   A  B  C  D  E  F\n0  1  4  7  1  5  7\n1  2  5  8  3  3  4\n2  3  6  9  5  6  3\nTraceback (most recent call last):\n  File \"C:\\Users\\rascoussier\\python\\stackoverflow\\type_error_with_df_loc\\main.py\", line 12, in <module>\n    print(df.loc(\n  File \"C:\\Users\\rascoussier\\Anaconda3\\envs\\elastic-1\\lib\\site-packages\\pandas\\core\\indexing.py\", line 634, in __call__\n    axis = self.obj._get_axis_number(axis)\n  File \"C:\\Users\\rascoussier\\Anaconda3\\envs\\elastic-1\\lib\\site-packages\\pandas\\core\\generic.py\", line 550, in _get_axis_number\n    return cls._AXIS_TO_AXIS_NUMBER[axis]\nTypeError: unhashable type: 'Series'",
        "score": 12,
        "is_accepted": false,
        "creation_date": "2022-07-26T09:52:11",
        "author": "Onyr"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25764201/how-to-work-with-the-scrapy-contracts",
    "title": "How to work with the scrapy contracts?",
    "question_id": 25764201,
    "posted_date": "2014-09-10T07:26:31",
    "answers": [
      {
        "answer_id": 58758047,
        "body": "F..\n======================================================================\nFAIL: [example] parse (@returns post-hook)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/adnauseum/.virtualenvs/scrapy_testing-CfFR3tdG/lib/python3.7/site-packages/scrapy/contracts/__init__.py\", line 151, in wrapper\n    self.post_process(output)\n  File \"/Users/adnauseum/.virtualenvs/scrapy_testing-CfFR3tdG/lib/python3.7/site-packages/scrapy/contracts/default.py\", line 90, in post_process\n    (occurrences, self.obj_name, expected))\nscrapy.exceptions.ContractFail: Returned 10 items, expected 0\n----------------------------------------------------------------------",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2019-11-07T17:56:39",
        "author": "adnauseam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/77697302/how-to-run-ollama-in-google-colab",
    "title": "How to run ollama in google colab?",
    "question_id": 77697302,
    "posted_date": "2023-12-21T05:28:07",
    "answers": [
      {
        "answer_id": 77828874,
        "body": "import threading\nimport time\nimport os\nimport asyncio\nfrom pyngrok import ngrok\nimport threading\nimport queue\nimport time\nfrom threading import Thread\n# Get your ngrok token from your ngrok account:\n# https://dashboard.ngrok.com/get-started/your-authtoken\ntoken=\"your token goes here - don't forget to replace this with it!\"\nngrok.set_auth_token(token)\n# set up a stoppable thread (not mandatory, but cleaner if you want to stop this later\nclass StoppableThread(threading.Thread):\n    def __init__(self, *args, **kwargs):\n        super(StoppableThread, self).__init__(*args, **kwargs)\n        self._stop_event = threading.Event()\n    def stop(self):\n        self._stop_event.set()\n    def is_stopped(self):\n        return self._stop_event.is_set()\ndef start_ngrok(q, stop_event):\n    try:\n        # Start an HTTP tunnel on the specified port\n        public_url = ngrok.connect(11434)\n        # Put the public URL in the queue\n        q.put(public_url)\n        # Keep the thread alive until stop event is set\n        while not stop_event.is_set():\n            time.sleep(1)  # Adjust sleep time as needed\n    except Exception as e:\n        print(f\"Error in start_ngrok: {e}\")",
        "score": 13,
        "is_accepted": true,
        "creation_date": "2024-01-16T16:48:02",
        "author": "Gruff"
      },
      {
        "answer_id": 77828874,
        "body": "import os\nimport asyncio\n# NB: You may need to set these depending and get cuda working depending which backend you are running.\n# Set environment variable for NVIDIA library\n# Set environment variables for CUDA\nos.environ['PATH'] += ':/usr/local/cuda/bin'\n# Set LD_LIBRARY_PATH to include both /usr/lib64-nvidia and CUDA lib directories\nos.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/cuda/lib64'\nasync def run_process(cmd):\n    print('>>> starting', *cmd)\n    process = await asyncio.create_subprocess_exec(\n        *cmd,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE\n    )\n    # define an async pipe function\n    async def pipe(lines):\n        async for line in lines:\n            print(line.decode().strip())\n        await asyncio.gather(\n            pipe(process.stdout),\n            pipe(process.stderr),\n        )\n    # call it\n    await asyncio.gather(pipe(process.stdout), pipe(process.stderr))",
        "score": 13,
        "is_accepted": true,
        "creation_date": "2024-01-16T16:48:02",
        "author": "Gruff"
      },
      {
        "answer_id": 77828874,
        "body": "import asyncio\nimport threading\nasync def start_ollama_serve():\n    await run_process(['ollama', 'serve'])\ndef run_async_in_thread(loop, coro):\n    asyncio.set_event_loop(loop)\n    loop.run_until_complete(coro)\n    loop.close()\n# Create a new event loop that will run in a new thread\nnew_loop = asyncio.new_event_loop()\n# Start ollama serve in a separate thread so the cell won't block execution\nthread = threading.Thread(target=run_async_in_thread, args=(new_loop, start_ollama_serve()))\nthread.start()",
        "score": 13,
        "is_accepted": true,
        "creation_date": "2024-01-16T16:48:02",
        "author": "Gruff"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65041691/is-python-dictionary-async-safe",
    "title": "Is python dictionary async safe?",
    "question_id": 65041691,
    "posted_date": "2020-11-27T12:48:24",
    "answers": [
      {
        "answer_id": 65042939,
        "body": "# correct (1), using double check\nif key not in d:\n    value = await read_value()\n    # Check again whether the key is vacant. Since there are no awaits\n    # between this check and the update, the operation is atomic.\n    if key not in d:\n        d[key] = value\n# correct (2), using a shared asyncio.Lock:\nasync with d_lock:\n    # Single check is sufficient because the lock ensures that\n    # no one can modify the dict while we're reading the value.\n    if key not in d:\n        d[key] = await read_value()",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2020-11-27T14:32:57",
        "author": "user4815162342"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63264888/pydantic-using-property-getter-decorator-for-a-field-with-an-alias",
    "title": "pydantic: Using property.getter decorator for a field with an alias",
    "question_id": 63264888,
    "posted_date": "2020-08-05T08:09:29",
    "answers": [
      {
        "answer_id": 63283599,
        "body": "class PropertyBaseModel(BaseModel):\n    \"\"\"\n    Workaround for serializing properties with pydantic until\n    https://github.com/samuelcolvin/pydantic/issues/935\n    is solved\n    \"\"\"\n    @classmethod\n    def get_properties(cls):\n        return [prop for prop in dir(cls) if isinstance(getattr(cls, prop), property) and prop not in (\"__values__\", \"fields\")]\n    def dict(\n        self,\n        *,\n        include: Union['AbstractSetIntStr', 'MappingIntStrAny'] = None,\n        exclude: Union['AbstractSetIntStr', 'MappingIntStrAny'] = None,\n        by_alias: bool = False,\n        skip_defaults: bool = None,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n    ) -> 'DictStrAny':\n        attribs = super().dict(\n            include=include,\n            exclude=exclude,\n            by_alias=by_alias,\n            skip_defaults=skip_defaults,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none\n        )\n        props = self.get_properties()\n        # Include and exclude properties\n        if include:\n            props = [prop for prop in props if prop in include]\n        if exclude:\n            props = [prop for prop in props if prop not in exclude]\n        # Update the attribute dict with the properties\n        if props:\n            attribs.update({prop: getattr(self, prop) for prop in props})\n        return attribs",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2020-08-06T08:25:54",
        "author": "Gabriel Cappelli"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58089300/python-how-to-override-type-hint-on-an-instance-attribute-in-a-subclass",
    "title": "Python: how to override type hint on an instance attribute in a subclass?",
    "question_id": 58089300,
    "posted_date": "2019-09-24T19:31:16",
    "answers": [
      {
        "answer_id": 58159769,
        "body": "from abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\nSomethingT = TypeVar('SomethingT', bound='Something')\n...\nclass Foo(ABC, Generic[SomethingT]):\n    my_class: SomethingT\n    def __init__(self):\n        self.my_class = self.get_something()\n    @abstractmethod\n    def get_something(self) -> SomethingT:\n        pass\nclass SubclassOfFoo(Foo[SubclassOfSomething]):\n    def __init__(self):\n        super().__init__()\n    def get_something(self) -> SubclassOfSomething:\n        return SubclassOfSomething()\n    def do_something_special(self):\n        # inferred type of `self.my_class` will be `SubclassOfSomething`\n        self.my_class.something_special()",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2019-09-29T18:40:30",
        "author": "user2235698"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69046990/how-to-pass-dependency-files-to-sagemaker-sklearnprocessor-and-use-it-in-pipelin",
    "title": "How to pass dependency files to sagemaker SKLearnProcessor and use it in Pipeline?",
    "question_id": 69046990,
    "posted_date": "2021-09-03T10:59:45",
    "answers": [
      {
        "answer_id": 70102015,
        "body": "from sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.20.0\",\n    role=role,\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n)\nsklearn_processor.run(\n    code=\"preprocessing.py\",  # <- this gets uploaded as /opt/ml/processing/input/code/preprocessing.py\n    inputs=[\n        ProcessingInput(source=input_data, destination='/opt/ml/processing/input'),\n        # Send my_package as /opt/ml/processing/input/code/my_package/\n        ProcessingInput(source='my_package/', destination=\"/opt/ml/processing/input/code/my_package/\")\n    ],\n    outputs=[\n        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n    ],\n    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n)",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2021-11-24T14:39:22",
        "author": "Tulio Casagrande"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/40118037/how-can-i-detect-gaps-and-consecutive-periods-in-a-time-series-in-pandas",
    "title": "How Can I Detect Gaps and Consecutive Periods In A Time Series In Pandas",
    "question_id": 40118037,
    "posted_date": "2016-10-18T17:04:14",
    "answers": [
      {
        "answer_id": 60255374,
        "body": "from datetime import datetime, timedelta\nimport pandas as pd\n# Construct dummy dataframe\ndates = pd.to_datetime([\n    '2016-08-03',\n    '2016-08-04',\n    '2016-08-05',\n    '2016-08-17',\n    '2016-09-05',\n    '2016-09-06',\n    '2016-09-07',\n    '2016-09-19'])\ndf = pd.DataFrame(dates, columns=['date'])\n# Take the diff of the first column (drop 1st row since it's undefined)\ndeltas = df['date'].diff()[1:]\n# Filter diffs (here days > 1, but could be seconds, hours, etc)\ngaps = deltas[deltas > timedelta(days=1)]\n# Print results\nprint(f'{len(gaps)} gaps with average gap duration: {gaps.mean()}')\nfor i, g in gaps.iteritems():\n    gap_start = df['date'][i - 1]\n    print(f'Start: {datetime.strftime(gap_start, \"%Y-%m-%d\")} | '\n          f'Duration: {str(g.to_pytimedelta())}')",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2020-02-16T21:57:37",
        "author": "Addison Klinke"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71658991/how-to-apply-a-custom-function-in-polars-that-does-the-processing-row-by-row",
    "title": "How to apply a custom function in Polars that does the processing row by row?",
    "question_id": 71658991,
    "posted_date": "2022-03-29T04:42:15",
    "answers": [
      {
        "answer_id": 71679606,
        "body": "def my_complicated_function(row: dict) -> int:\n    \"\"\"\n    A function that cannot utilize polars expressions.\n    This should be avoided.\n    \"\"\"\n    # a dict with column names as keys\n    print(f\"[DEBUG]: {row=}\")\n\n    # do some work\n    return row[\"foo\"] + row[\"bar\"] + row[\"baz\"]\ndf = pl.DataFrame({\n    \"foo\": [1, 2, 3],\n    \"bar\": [4, 5, 6],\n    \"baz\": [7, 8, 9]\n})\ndf = df.with_columns(\n    pl.struct(pl.all())\n      .map_elements(my_complicated_function, return_dtype=pl.Int64)\n      .alias(\"foo + bar + baz\")\n)",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2022-03-30T10:56:49",
        "author": "ritchie46"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/67205522/set-order-on-sns-histplot",
    "title": "Set order on sns histplot",
    "question_id": 67205522,
    "posted_date": "2021-04-21T21:27:39",
    "answers": [
      {
        "answer_id": 67205743,
        "body": "import pandas as pd\nimport seaborn as sns\ndf = pd.DataFrame({\n    'Label' : ['A','B','C','B','B','C','C','B','B','A','C','A','B','A','C','A'],\n    'Item' : ['Up','Left','Up','Left','Down','Right','Up','Down','Right','Down','Right','Up','Up','Right','Down','Left'],\n   })\ndf['Item'] = pd.Categorical(df['Item'], ['Up','Down','Left','Right'])\ng = sns.histplot(data = df,\n            x = 'Item',\n            hue = 'Label',\n            #order = ['Up','Down','Left','Right'],\n            multiple = 'fill',\n            shrink = 0.8,\n            discrete = True,\n            legend = True,\n            )",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2021-04-21T22:02:00",
        "author": "dataista"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63483246/how-to-call-an-api-from-another-api-in-fastapi",
    "title": "How to call an api from another api in fastapi?",
    "question_id": 63483246,
    "posted_date": "2020-08-19T04:44:26",
    "answers": [
      {
        "answer_id": 63500734,
        "body": "import requests\ndef test_function(request: Request, path_parameter: path_param):\n    request_example = {\"test\" : \"in\"}\n    host = request.client.host\n    data_source_id = path_parameter.id\n    get_test_url= f\"http://{host}/test/{id}/\"\n    get_inp_url = f\"http://{host}/test/{id}/inp\"\n    test_get_response = requests.get(get_test_url)\n    inp_post_response = requests.post(get_inp_url , json=request_example)\n    if inp_post_response .status_code == 200:\n        print(json.loads(test_get_response.content.decode('utf-8')))",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2020-08-20T03:59:33",
        "author": "Sudip Kandel"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52133482/how-to-omit-remove-virtual-environment-venv-from-python-coverage-unit-testin",
    "title": "How to omit (remove) virtual environment (venv) from python coverage unit testing?",
    "question_id": 52133482,
    "posted_date": "2018-09-01T22:17:32",
    "answers": [
      {
        "answer_id": 58767040,
        "body": "$ coverage run --omit 'venv/*' -m unittest tests/*.py && coverage report -m\n........\n----------------------------------------------------------------------\nRan 8 tests in 0.023s\nOK\nName                      Stmts   Miss  Cover   Missing\n-------------------------------------------------------\nruterstop.py                 84      8    90%   177, 188, 191-197, 207\ntests/test_ruterstop.py     108      0   100%\n-------------------------------------------------------\nTOTAL                       192      8    96%",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-11-08T07:55:46",
        "author": "sshow"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63000388/how-to-include-simpleimputer-before-countvectorizer-in-a-scikit-learn-pipeline",
    "title": "How to include SimpleImputer before CountVectorizer in a scikit-learn Pipeline?",
    "question_id": 63000388,
    "posted_date": "2020-07-20T13:00:46",
    "answers": [
      {
        "answer_id": 63000389,
        "body": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'text':['abc def', 'abc ghi', np.nan]})\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(strategy='constant')\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer()\n# CREATE TRANSFORMER\nfrom sklearn.preprocessing import FunctionTransformer\none_dim = FunctionTransformer(np.reshape, kw_args={'newshape':-1})\n# INCLUDE TRANSFORMER IN PIPELINE\nfrom sklearn.pipeline import make_pipeline\npipe = make_pipeline(imp, one_dim, vect)\npipe.fit_transform(df[['text']]).toarray()",
        "score": 15,
        "is_accepted": true,
        "creation_date": "2020-07-20T13:00:46",
        "author": "Kevin Markham"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48091874/downloading-multiple-s3-objects-in-parallel-in-python",
    "title": "Downloading multiple S3 objects in parallel in Python",
    "question_id": 48091874,
    "posted_date": "2018-01-04T04:06:30",
    "answers": [
      {
        "answer_id": 57445139,
        "body": "#!/usr/bin/env python3\nimport multiprocessing\nimport boto3\nimport sys\n# make a per process s3_client\ns3_client = None\ndef initialize():\n  global s3_client\n  s3_client = boto3.client('s3')\n# the work function of each process which will fetch something from s3\ndef download(job):\n  bucket, key, filename = job\n  s3_client.download_file(bucket, key, filename)\nif __name__ == '__main__':\n  # make the jobs, arguments to program are: bucket s3_key_0 s3_key_1 ... s3_key_n\n  bucket = sys.argv[1]\n  jobs = [(bucket, key, key.replace('/', '_')) for key in sys.argv[2:] ]\n  # make a process pool to do the work\n  pool = multiprocessing.Pool(multiprocessing.cpu_count(), initialize)\n  pool.map(download, jobs)\n  pool.close()\n  pool.join()",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2019-08-10T15:34:08",
        "author": "Kevin Kreiser"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18832763/drawing-directions-fields",
    "title": "Drawing directions fields",
    "question_id": 18832763,
    "posted_date": "2013-09-16T12:17:09",
    "answers": [
      {
        "answer_id": 18833385,
        "body": "import matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\nimport numpy as np\nfig = plt.figure()\ndef vf(x, t):\n    dx = np.zeros(2)\n    dx[0] = 1.0\n    dx[1] = x[0] ** 2 - x[0] - 2.0\n    return dx\n# Solution curves\nt0 = 0.0\ntEnd = 10.0\n# Vector field\nX, Y = np.meshgrid(np.linspace(-5, 5, 20), np.linspace(-10, 10, 20))\nU = 1.0\nV = X ** 2 - X - 2\n# Normalize arrows\nN = np.sqrt(U ** 2 + V ** 2)\nU = U / N\nV = V / N\nplt.quiver(X, Y, U, V, angles=\"xy\")\nt = np.linspace(t0, tEnd, 100)\nfor y0 in np.linspace(-5.0, 0.0, 10):\n    y_initial = [y0, -10.0]\n    y = odeint(vf, y_initial, t)\n    plt.plot(y[:, 0], y[:, 1], \"-\")\nplt.xlim([-5, 5])\nplt.ylim([-10, 10])\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$y$\")",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2013-09-16T12:56:07",
        "author": "PepeToro"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51817148/dynamically-add-new-wtforms-fieldlist-entries-from-user-interface",
    "title": "Dynamically add new WTForms FieldList entries from user interface",
    "question_id": 51817148,
    "posted_date": "2018-08-13T03:24:20",
    "answers": [
      {
        "answer_id": 55900291,
        "body": "<form method=\"POST\" action=\"\">\n            {{ form.hidden_tag() }}\n            <fieldset class=\"form-group\">\n                <legend class=\"border-bottom mb-4\">XYZ</legend>\n                <div>\n                    {{ form.standard.label(class=\"form-control-label\") }}\n                    {{ form.standard(class=\"form-control form-control-lg\") }}\n                </div>\n                <div>\n                    {{ form.wps.label(class=\"form-control-label\") }}\n                    {{ form.wps(class=\"form-control form-control-lg\") }}\n                </div>\n            ...\n            </fieldset>\n            <div class=\"form-group\">\n                {{ form.submit(class='btn btn-outline-success') }}\n            </div>\n        </form>",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2019-04-29T05:18:22",
        "author": "jojostev97"
      },
      {
        "answer_id": 55900291,
        "body": "<script>\n $(document).ready(function(){\n            $(\"#standard\").change(function(){\n                var std = $(this).find('option:selected').val(); //capture value from form.\n                $.getJSON(\"{{url_for('modifywps')}}\",{'std':std}, function(result){ //use captured value to sent to view via a dictionary {'key':val}, via url_for('view_name')\n\n                    $.each(result, function(i, field){ //value you want will be back here and gone through..\n                        $.each(field, function(j,k){\n                            $(\"#wps\").append('<option value=\"'+j+'\">'+k+'</option>'); // use jQuery to insert it back into the form, via the form name you gave in jinja templating\n                        });\n                    });\n                });\n            });\n            $(\"#wps\").change(function(){\n\n                    var std = $('#wps').find('option:selected').val(); // capture value from form.\n                    $.getJSON(\"{{url_for('modifyprocess')}}\",{'std':std}, function(result)\n\n                        $.each(result, function(i, field){\n                            $.each(field, function(j,k){\n                                $(\"#processes\").append('<option value=\"'+j+'\">'+k+'</option>');\n                            });\n                        });\n                    });\n            });\n</script>",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2019-04-29T05:18:22",
        "author": "jojostev97"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62274412/cv2-approxpolydp-cv2-arclength-how-these-works",
    "title": "cv2.approxPolyDP() , cv2.arcLength() How these works",
    "question_id": 62274412,
    "posted_date": "2020-06-08T23:13:49",
    "answers": [
      {
        "answer_id": 62274558,
        "body": "import cv2\nimport imutils\n# edged is the edge detected image\ncnts = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\ncnts = imutils.grab_contours(cnts)\ncnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n# loop over the contours\nfor c in cnts:\n\t# approximate the contour\n\tperi = cv2.arcLength(c, True)\n\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n\t# if our approximated contour has four points, then we\n\t# can assume that we have found our screen\n\tif len(approx) == 4:\n\t\tscreenCnt = approx\n\t\tbreak",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2020-06-08T23:32:05",
        "author": "amras"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60248319/how-to-set-column-width-to-bestfit-in-openpyxl",
    "title": "How to set column width to bestFit in openpyxl",
    "question_id": 60248319,
    "posted_date": "2020-02-16T07:11:48",
    "answers": [
      {
        "answer_id": 69698578,
        "body": "# Imorting the necessary modules\ntry:\n        from openpyxl.cell import get_column_letter\nexcept ImportError:\n        from openpyxl.utils import get_column_letter\n        from openpyxl.utils import column_index_from_string\nfrom openpyxl import load_workbook\nimport openpyxl\nfrom openpyxl import Workbook\nfor column_cells in sheet.columns:\n    new_column_length = max(len(str(cell.value)) for cell in column_cells)\n    new_column_letter = (get_column_letter(column_cells[0].column))\n    if new_column_length > 0:\n        sheet.column_dimensions[new_column_letter].width = new_column_length*1.23",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2021-10-24T12:10:56",
        "author": "Mounesh"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76686267/what-is-the-new-way-to-declare-mongo-objectid-with-pydantic-v2-0",
    "title": "What is the new way to declare Mongo ObjectId with PyDantic v2.0^?",
    "question_id": 76686267,
    "posted_date": "2023-07-14T05:07:30",
    "answers": [
      {
        "answer_id": 76719893,
        "body": "from typing import Annotated, Any\nfrom bson import ObjectId\nfrom pydantic_core import core_schema\nfrom pydantic import BaseModel\nfrom pydantic.json_schema import JsonSchemaValue\nclass ObjectIdPydanticAnnotation:\n    @classmethod\n    def validate_object_id(cls, v: Any, handler) -> ObjectId:\n        if isinstance(v, ObjectId):\n            return v\n        s = handler(v)\n        if ObjectId.is_valid(s):\n            return ObjectId(s)\n        else:\n            raise ValueError(\"Invalid ObjectId\")\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source_type, _handler) -> core_schema.CoreSchema:\n        assert source_type is ObjectId\n        return core_schema.no_info_wrap_validator_function(\n            cls.validate_object_id,\n            core_schema.str_schema(),\n            serialization=core_schema.to_string_ser_schema(),\n        )\n    @classmethod\n    def __get_pydantic_json_schema__(cls, _core_schema, handler) -> JsonSchemaValue:\n        return handler(core_schema.str_schema())\nclass Model(BaseModel):\n    id: Annotated[ObjectId, ObjectIdPydanticAnnotation]\nprint(Model(id='64b7abdecf2160b649ab6085'))\nprint(Model(id='64b7abdecf2160b649ab6085').model_dump_json())\nprint(Model(id=ObjectId()))\nprint(Model.model_json_schema())\nprint(Model(id='foobar'))  # will error",
        "score": 13,
        "is_accepted": true,
        "creation_date": "2023-07-19T05:37:53",
        "author": "Samuel Colvin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52627739/how-to-merge-numerical-and-embedding-sequential-models-to-treat-categories-in-rn",
    "title": "How to Merge Numerical and Embedding Sequential Models to treat categories in RNN",
    "question_id": 52627739,
    "posted_date": "2018-10-03T09:07:04",
    "answers": [
      {
        "answer_id": 52629902,
        "body": "__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to\n==================================================================================================\n cat1_input (InputLayer)     [(None, 100)]                0         []\n\n cat2_input (InputLayer)     [(None, 100)]                0         []\n\n cat3_input (InputLayer)     [(None, 100)]                0         []\n\n embedding_14 (Embedding)    (None, 100, 50)              50000     ['cat1_input[0][0]']\n\n embedding_15 (Embedding)    (None, 100, 10)              5000      ['cat2_input[0][0]']\n\n embedding_16 (Embedding)    (None, 100, 100)             10000     ['cat3_input[0][0]']\n\n numeric_input (InputLayer)  [(None, 100, 10)]            0         []\n\n concatenate_26 (Concatenat  (None, 100, 160)             0         ['embedding_14[0][0]',\n e)                                                                  'embedding_15[0][0]',\n                                                                     'embedding_16[0][0]']\n\n concatenate_27 (Concatenat  (None, 100, 170)             0         ['numeric_input[0][0]',\n e)                                                                  'concatenate_26[0][0]']\n\n lstm_5 (LSTM)               (None, 64)                   60160     ['concatenate_27[0][0]']\n\n==================================================================================================\nTotal params: 125160 (488.91 KB)\nTrainable params: 125160 (488.91 KB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________",
        "score": 17,
        "is_accepted": true,
        "creation_date": "2018-10-03T10:54:30",
        "author": "today"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56852581/how-to-drop-duplicates-but-keep-the-rows-if-a-particular-other-column-is-not-nul",
    "title": "How to drop duplicates but keep the rows if a particular other column is not null (Pandas)",
    "question_id": 56852581,
    "posted_date": "2019-07-02T08:32:23",
    "answers": [
      {
        "answer_id": 56852739,
        "body": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'firstname': ['foo Bar', 'Bar Bar', 'Foo Bar'],\n                   'lastname': ['Foo Bar', 'Bar', 'Foo Bar'],\n                   'email': ['Foo bar', 'Bar', 'Foo Bar'],\n                   'bank': [np.nan, 'abc', 'xyz']})\nuniq_indx = (df.sort_values(by=\"bank\", na_position='last').dropna(subset=['firstname', 'lastname', 'email'])\n             .applymap(lambda s: s.lower() if type(s) == str else s)\n             .applymap(lambda x: x.replace(\" \", \"\") if type(x) == str else x)\n             .drop_duplicates(subset=['firstname', 'lastname', 'email'], keep='first')).index\n# save unique records\ndfiban_uniq = df.loc[uniq_indx]\nprint(dfiban_uniq)",
        "score": 12,
        "is_accepted": true,
        "creation_date": "2019-07-02T08:40:39",
        "author": "Adam.Er8"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/31514136/how-to-add-punctuation-to-text-using-python",
    "title": "How to add punctuation to text using python?",
    "question_id": 31514136,
    "posted_date": "2015-07-20T06:26:12",
    "answers": [
      {
        "answer_id": 73572089,
        "body": "from rpunct import RestorePuncts\n# The default language is 'english'\nrpunct = RestorePuncts(use_cuda=False)\nrpunct.punctuate(\"\"\"in 2018 cornell researchers built a high-powered detector that in combination with an algorithm-driven process called ptychography set a world record\nby tripling the resolution of a state-of-the-art electron microscope as successful as it was that approach had a weakness it only worked with ultrathin samples that were\na few atoms thick anything thicker would cause the electrons to scatter in ways that could not be disentangled now a team again led by david muller the samuel b eckert\nprofessor of engineering has bested its own record by a factor of two with an electron microscope pixel array detector empad that incorporates even more sophisticated\n3d reconstruction algorithms the resolution is so fine-tuned the only blurring that remains is the thermal jiggling of the atoms themselves\"\"\")",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2022-09-01T11:38:20",
        "author": "Marc Maxmeister"
      },
      {
        "answer_id": 73572089,
        "body": ">>> from deepmultilingualpunctuation import PunctuationModel\n>>> model = PunctuationModel()\nDownloading config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 892/892 [00:00<00:00, 335kB/s]\nDownloading pytorch_model.bin: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.08G/2.08G [04:54<00:00, 7.60MB/s]\nDownloading tokenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 406/406 [00:00<00:00, 216kB/s]\nDownloading sentencepiece.bpe.model: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.83M/4.83M [00:00<00:00, 8.08MB/s]\nDownloading special_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 239/239 [00:00<00:00, 158kB/s]\n/opt/anaconda3/envs/punct/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n  warnings.warn(\n>>> text = \"My name is Clara and I live in Berkeley California Ist das eine Frage Frau M\u00fcller\"\n>>> result = model.restore_punctuation(text)\n>>> print(result)\nMy name is Clara and I live in Berkeley, California. Ist das eine Frage, Frau M\u00fcller?",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2022-09-01T11:38:20",
        "author": "Marc Maxmeister"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55677165/python-flask-as-windows-service",
    "title": "Python Flask as Windows Service",
    "question_id": 55677165,
    "posted_date": "2019-04-14T11:48:37",
    "answers": [
      {
        "answer_id": 55721496,
        "body": "# -*- mode: python -*-\nblock_cipher = None\na = Analysis(['win32_service.py'],\n             pathex=['C:\\\\Users\\\\Win7\\\\Desktop\\\\FaaS'],\n             binaries=[],\n             datas=[],\n             hiddenimports=['win32timezone',\n                            'altgraph',\n                            'Click'\n                            'Flask',\n                            'future',\n                            'itsdangerous',\n                            'Jinja2',\n                            'macholib',\n                            'MarkupSafe',\n                            'pefile',\n                            'PyInstaller',\n                            'pyodbc',\n                            'pywin32',\n                            'pywin32-ctypes',\n                            'Werkzeug',],\n             hookspath=[],\n             runtime_hooks=[],\n             excludes=[],\n             win_no_prefer_redirects=False,\n             win_private_assemblies=False,\n             cipher=block_cipher,\n             noarchive=False)\npyz = PYZ(a.pure, a.zipped_data,\n             cipher=block_cipher)\nexe = EXE(pyz,\n          a.scripts,\n          a.binaries,\n          a.zipfiles,\n          a.datas,\n          [],\n          name='win32_service',\n          debug=False,\n          bootloader_ignore_signals=False,\n          strip=False,\n          upx=True,\n          runtime_tmpdir=None,\n          console=True )",
        "score": 7,
        "is_accepted": false,
        "creation_date": "2019-04-17T02:47:56",
        "author": "DarkSuniuM"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39817641/how-to-send-a-json-object-using-tcp-socket-in-python",
    "title": "How to send a json object using tcp socket in python",
    "question_id": 39817641,
    "posted_date": "2016-10-02T09:46:14",
    "answers": [
      {
        "answer_id": 61350221,
        "body": "import socket\nimport sys\nimport json\nHOST, PORT = \"localhost\", 9999\n#m ='{\"id\": 2, \"name\": \"abc\"}'\nm = {\"id\": 2, \"name\": \"abc\"} # a real dict.\ndata = json.dumps(m)\n# Create a socket (SOCK_STREAM means a TCP socket)\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ntry:\n    # Connect to server and send data\n    sock.connect((HOST, PORT))\n    sock.sendall(bytes(data,encoding=\"utf-8\"))\n    # Receive data from the server and shut down\n    received = sock.recv(1024)\n    received = received.decode(\"utf-8\")\n\nfinally:\n    sock.close()\nprint \"Sent:     {}\".format(data)\nprint \"Received: {}\".format(received)",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2020-04-21T14:10:31",
        "author": "harry"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/39309046/what-is-the-proper-way-of-testing-throttling-in-drf",
    "title": "What is the proper way of testing throttling in DRF?",
    "question_id": 39309046,
    "posted_date": "2016-09-03T12:29:37",
    "answers": [
      {
        "answer_id": 55025328,
        "body": "from unittest.mock import patch\nfrom django.core.cache import cache\nfrom rest_framework import status\nclass Tests(SimpleTestCase):\n    def setUp(self):\n        cache.clear()\n    @patch('path.to.AuthRateThrottle.get_rate')\n    def test_throttling(self, mock):\n        mock.return_value = '1/day'\n        response = self.client.post(self.url, {})\n        self.assertEqual(\n            response.status_code,\n            status.HTTP_400_BAD_REQUEST,  # some fields are required\n        )\n        response = self.client.post(self.url, {})\n        self.assertEqual(\n            response.status_code,\n            status.HTTP_429_TOO_MANY_REQUESTS,\n        )",
        "score": 8,
        "is_accepted": false,
        "creation_date": "2019-03-06T09:22:50",
        "author": "yofee"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69115825/remove-white-borders-from-segmented-images",
    "title": "Remove white borders from segmented images",
    "question_id": 69115825,
    "posted_date": "2021-09-09T05:42:25",
    "answers": [
      {
        "answer_id": 69202279,
        "body": "import cv2\nimport numpy as np\nimage = cv2.imread('1.png')\nhighlight = image.copy()\noriginal = image.copy()\n# Convert image to grayscale, Otsu's threshold, and find contours\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\ncontours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncontours = contours[0] if len(contours) == 2 else contours[1]\n# Create black mask to extract desired objects\nmask = np.zeros(image.shape, dtype=np.uint8)\n# Search for objects by filtering using contour area and aspect ratio\nfor c in contours:\n    # Contour area\n    area = cv2.contourArea(c)\n    # Contour perimeter\n    peri = cv2.arcLength(c, True)\n    # Contour approximation\n    approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n    (x, y, w, h) = cv2.boundingRect(approx)\n    aspect_ratio = w / float(h)\n    # Draw filled contour onto mask if passes filter\n    # These are arbitary values, may need to change depending on input image\n    if aspect_ratio <= 1.2 or area < 5000:\n        cv2.drawContours(highlight, [c], 0, (0,255,0), -1)\n        cv2.drawContours(mask, [c], 0, (255,255,255), -1)\n# Convert 3-channel mask to grayscale then bitwise-and with original image for result\nmask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\nresult = cv2.bitwise_and(original, original, mask=mask)\n# Uncomment if you want background to be white instead of black\n# result[mask==0] = (255,255,255)\n# Display\ncv2.imshow('gray', gray)\ncv2.imshow('thresh', thresh)\ncv2.imshow('highlight', highlight)\ncv2.imshow('mask', mask)\ncv2.imshow('result', result)\n# Save images\n# cv2.imwrite('gray.png', gray)\n# cv2.imwrite('thresh.png', thresh)\n# cv2.imwrite('highlight.png', highlight)\n# cv2.imwrite('mask.png', mask)\n# cv2.imwrite('result.png', result)\ncv2.waitKey(0)",
        "score": 11,
        "is_accepted": true,
        "creation_date": "2021-09-16T00:17:21",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54413434/type-hinting-with-descriptors",
    "title": "Type hinting with descriptors",
    "question_id": 54413434,
    "posted_date": "2019-01-28T22:28:28",
    "answers": [
      {
        "answer_id": 75852866,
        "body": "from typing import Callable, Generic, Type, TypeVar, overload, Union\nInstance = TypeVar('Instance')\nValue = TypeVar('Value')\nAttribute = TypeVar('Attribute')\nclass Descriptor(Generic[Instance, Attribute, Value]):\n    def __init__(self, method: Callable[[Instance, Attribute], Value]):\n        \"\"\" Called on initialisation of descriptor \"\"\"\n    @overload\n    def __get__(self, instance: None, owner: Type[Instance]) -> 'Descriptor':\n        \"\"\" Called when an attribute is accessed via class not an instance \"\"\"\n    @overload\n    def __get__(self, instance: Instance, owner: Type[Instance]) -> Value:\n        \"\"\" Called when an attribute is accessed on an instance variable \"\"\"\n    def __get__(self, instance: Union[Instance, None], owner: Type[Instance]) -> Union[Value, 'Descriptor']:\n        \"\"\" Full implementation is declared here \"\"\"\n        ...\n    def __set__(self, instance: Instance, value: Value):\n        \"\"\" Called when setting a value.\"\"\"",
        "score": 8,
        "is_accepted": true,
        "creation_date": "2023-03-27T02:55:02",
        "author": "serhiy1"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48079364/wrapping-text-not-working-in-matplotlib",
    "title": "Wrapping text not working in matplotlib",
    "question_id": 48079364,
    "posted_date": "2018-01-03T09:29:45",
    "answers": [
      {
        "answer_id": 56552098,
        "body": "import matplotlib.pyplot as plt\nimport matplotlib.text as mtext\nclass WrapText(mtext.Text):\n    def __init__(self,\n                 x=0, y=0, text='',\n                 width=0,\n                 **kwargs):\n        mtext.Text.__init__(self,\n                 x=x, y=y, text=text,\n                 wrap=True,\n                 **kwargs)\n        self.width = width  # in screen pixels. You could do scaling first\n    def _get_wrap_line_width(self):\n        return self.width\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(111)\ntext = ('Lorem ipsum dolor sit amet, consectetur adipiscing elit, '\n        'sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. ')\n# Create artist object. Note clip_on is True by default\n# The axes doesn't have this method, so the object is created separately\n# and added afterwards.\nwtxt = WrapText(.8, .4, text, width=500, va='top', clip_on=False,\n                bbox=dict(boxstyle='square', fc='w', ec='b'))\n# Add artist to the axes\nax.add_artist(wtxt)\nplt.show()",
        "score": 12,
        "is_accepted": true,
        "creation_date": "2019-06-11T17:47:46",
        "author": "Dan Neuman"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/18515275/can-cython-code-be-compiled-to-a-dll-so-c-application-can-call-it",
    "title": "Can Cython code be compiled to a dll so C++ application can call it?",
    "question_id": 18515275,
    "posted_date": "2013-08-29T11:36:55",
    "answers": [
      {
        "answer_id": 62417945,
        "body": "//cyfun_dll.c\n#define BUILDING_DLL\n#include \"cyfun_dll.h\"\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n#include \"cyfun.h\"\nDLL_PUBLIC int cyfun_init(){\n  int status=PyImport_AppendInittab(\"cyfun\", PyInit_cyfun);\n  if(status==-1){\n    return -1;//error\n  }\n  Py_Initialize();\n  PyObject *module = PyImport_ImportModule(\"cyfun\");\n  if(module==NULL){\n     Py_Finalize();\n     return -1;//error\n  }\n  return 0;\n}\nDLL_PUBLIC void cyfun_finalize(){\n   Py_Finalize();\n}\nDLL_PUBLIC int cyfun_double_me(int me){\n    return double_me(me);\n}\nDLL_PUBLIC void cyfun_print_me(int me){\n    print_me(me);\n}",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2020-06-16T17:33:48",
        "author": "ead"
      },
      {
        "answer_id": 62417945,
        "body": "BOOL WINAPI DllMain(\n    HINSTANCE hinstDLL,  // handle to DLL module\n    DWORD fdwReason,     // reason for calling function\n    LPVOID lpReserved )  // reserved\n{\n    // Perform actions based on the reason for calling.\n    switch( fdwReason )\n    {\n        case DLL_PROCESS_ATTACH:\n            return cyfun_init()==0;\n        case DLL_PROCESS_DETACH:\n            cyfun_finalize();\n            break;\n        case DLL_THREAD_ATTACH:\n         // Do thread-specific initialization.\n            break;\n        case DLL_THREAD_DETACH:\n         // Do thread-specific cleanup.\n            break;\n    }\n    return TRUE;\n}",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2020-06-16T17:33:48",
        "author": "ead"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/75363733/sqlalchemy-2-0-orm-model-datetime-insertion",
    "title": "SQLAlchemy 2.0 ORM Model DateTime Insertion",
    "question_id": 75363733,
    "posted_date": "2023-02-06T11:01:44",
    "answers": [
      {
        "answer_id": 75364468,
        "body": "import datetime\nfrom sqlalchemy import Integer, String, DateTime\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.sql import func\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\nfrom sqlalchemy.orm import Session\nclass Base(DeclarativeBase):\n    pass\nclass MyTable(Base):\n    __tablename__ = \"my_table\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String)\n    created_date: Mapped[datetime.datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now()\n    )\ndef initialize_engine(filename):\n    return create_engine(f\"sqlite+pysqlite:///{filename}\", echo=True)\ndef initialize_tables(engine):\n    Base.metadata.create_all(engine)\ndef add_row(engine, name):\n    this_row = MyTable(name=name)\n    print(this_row)\n    with Session(engine) as session:\n        session.add(this_row)\n        session.commit()\nmy_file = \"test.db\"\nmy_engine = initialize_engine(my_file)\ninitialize_tables(my_engine)\nadd_row(my_engine, \"Dave\")",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2023-02-06T12:11:09",
        "author": "Remi"
      },
      {
        "answer_id": 75364468,
        "body": "python datetest.py\n2023-02-06 11:02:41,157 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n2023-02-06 11:02:41,158 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"my_table\")\n2023-02-06 11:02:41,158 INFO sqlalchemy.engine.Engine [raw sql] ()\n2023-02-06 11:02:41,158 INFO sqlalchemy.engine.Engine COMMIT\n<__main__.MyTable object at 0x000002CC767ECD50>\n2023-02-06 11:02:41,159 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n2023-02-06 11:02:41,160 INFO sqlalchemy.engine.Engine INSERT INTO my_table (name) VALUES (?) RETURNING id, created_date\n2023-02-06 11:02:41,160 INFO sqlalchemy.engine.Engine [generated in 0.00020s] ('Dave',)\n2023-02-06 11:02:41,171 INFO sqlalchemy.engine.Engine COMMIT",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2023-02-06T12:11:09",
        "author": "Remi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58966874/adding-attention-on-top-of-simple-lstm-layer-in-tensorflow-2-0",
    "title": "Adding Attention on top of simple LSTM layer in Tensorflow 2.0",
    "question_id": 58966874,
    "posted_date": "2019-11-20T22:32:21",
    "answers": [
      {
        "answer_id": 64916600,
        "body": "model = keras.models.Sequential()\n        model.add(keras.layers.LSTM(cfg.LSTM, input_shape=(cfg.TIMESTEPS,\n                  cfg.FEATURES),\n                  return_sequences=True))\n        model.add(SeqSelfAttention(attention_width=cfg.ATTNWIDTH,\n                attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n                attention_activation='softmax',\n                name='Attention'))\n        model.add(keras.layers.Dense(cfg.DENSE))\n        model.add(keras.layers.Dense(cfg.OUTPUT, activation='sigmoid'))",
        "score": 8,
        "is_accepted": true,
        "creation_date": "2020-11-19T12:10:24",
        "author": "greco.roamin"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/45275141/tensorflow-is-there-a-way-to-convert-a-frozen-graph-into-a-checkpoint-model",
    "title": "TensorFlow: Is there a way to convert a frozen graph into a checkpoint model?",
    "question_id": 45275141,
    "posted_date": "2017-07-24T04:00:15",
    "answers": [
      {
        "answer_id": 57596363,
        "body": "import numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.graph_editor as ge\nconst_var_name_pairs = []\nwith tf_graph.as_default() as g:\n    for name in to_convert:\n        tensor = g.get_tensor_by_name('{}:0'.format(name))\n        with tf.Session() as sess:\n            tensor_as_numpy_array = sess.run(tensor)\n        var_shape = tensor.get_shape()\n        # Give each variable a name that doesn't already exist in the graph\n        var_name = '{}_turned_var'.format(name)\n        # Create TensorFlow variable initialized by values of original const.\n        var = tf.get_variable(name=var_name, dtype='float32', shape=var_shape, \\\n                      initializer=tf.constant_initializer(tensor_as_numpy_array))\n        # We want to keep track of our variables names for later.\n        const_var_name_pairs.append((name, var_name))\n    # At this point, we added a bunch of tf.Variables to the graph, but they're\n    # not connected to anything.\n    # The magic: we use TF Graph Editor to swap the Constant nodes' outputs with\n    # the outputs of our newly created Variables.\n    for const_name, var_name in const_var_name_pairs:\n        const_op = g.get_operation_by_name(const_name)\n        var_reader_op = g.get_operation_by_name(var_name + '/read')\n        ge.swap_outputs(ge.sgv(const_op), ge.sgv(var_reader_op))",
        "score": 5,
        "is_accepted": false,
        "creation_date": "2019-08-21T13:13:17",
        "author": "Max Wu"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/6850798/why-doesnt-filter-attached-to-the-root-logger-propagate-to-descendant-loggers",
    "title": "Why doesn&#39;t filter attached to the root logger propagate to descendant loggers?",
    "question_id": 6850798,
    "posted_date": "2011-07-27T16:26:43",
    "answers": [
      {
        "answer_id": 60823209,
        "body": "import logging\nclass MyFilter(logging.Filter):\n    def filter(self, record):\n        record.msg = 'MY FILTER: ' + record.msg\n        return 1\nmyfilter = MyFilter()\nmyformatter = logging.Formatter(\"MY HANDLER: %(name)s - %(message)s\")\nmyhandler = logging.StreamHandler()\nmyhandler.setFormatter(myformatter)\nmyhandler.addFilter(myfilter)\nfoo_logger = logging.getLogger('foo')\nfoo_logger.addHandler(myhandler)\nfoo_bar_logger = logging.getLogger('foo.bar')\nfoo_logger.error('asdfasdf')\nfoo_bar_logger.error('zxcvzxcv')",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2020-03-23T20:00:26",
        "author": "Elijas Dap\u0161auskas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63918342/refresh-token-using-fastapi-and-swagger",
    "title": "Refresh token using FastAPI and Swagger",
    "question_id": 63918342,
    "posted_date": "2020-09-16T06:44:02",
    "answers": [
      {
        "answer_id": 67839696,
        "body": "# source: /fastapi/security/oauth2.py\n#\nclass OAuth2AuthorizationCodeBearer(OAuth2):\n    def __init__(\n        self,\n        authorizationUrl: str,\n        tokenUrl: str,\n        refreshUrl: Optional[str] = None,\n        scheme_name: Optional[str] = None,\n        scopes: Optional[Dict[str, str]] = None,\n        auto_error: bool = True,\n    ):\n        if not scopes:\n            scopes = {}\n        flows = OAuthFlowsModel(\n            authorizationCode={\n                \"authorizationUrl\": authorizationUrl,\n                \"tokenUrl\": tokenUrl,\n                \"refreshUrl\": refreshUrl,\n                \"scopes\": scopes,\n            }\n        )\n        super().__init__(flows=flows, scheme_name=scheme_name, auto_error=auto_error)\n    async def __call__(self, request: Request) -> Optional[str]:\n        authorization: str = request.headers.get(\"Authorization\")\n        scheme, param = get_authorization_scheme_param(authorization)\n        if not authorization or scheme.lower() != \"bearer\":\n            if self.auto_error:\n                raise HTTPException(\n                    status_code=HTTP_401_UNAUTHORIZED,\n                    detail=\"Not authenticated\",\n                    headers={\"WWW-Authenticate\": \"Bearer\"},\n                )\n            else:\n                return None  # pragma: nocover\n        return param",
        "score": 5,
        "is_accepted": false,
        "creation_date": "2021-06-04T11:11:52",
        "author": "Life is complex"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54511769/running-lstm-with-multiple-gpus-gets-input-and-hidden-tensors-are-not-at-the-sa",
    "title": "Running LSTM with multiple GPUs gets &quot;Input and hidden tensors are not at the same device&quot;",
    "question_id": 54511769,
    "posted_date": "2019-02-04T02:31:43",
    "answers": [
      {
        "answer_id": 57816143,
        "body": "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nclass MyModule(nn.Module):\n    # ... __init__, other methods, etc.\n    # padded_input is of shape [B x T x *] (batch_first mode) and contains\n    # the sequences sorted by lengths\n    #   B is the batch size\n    #   T is max sequence length\n    def forward(self, padded_input, input_lengths):\n        total_length = padded_input.size(1)  # get the max sequence length\n        packed_input = pack_padded_sequence(padded_input, input_lengths,\n                                            batch_first=True)\n        packed_output, _ = self.my_lstm(packed_input)\n        output, _ = pad_packed_sequence(packed_output, batch_first=True,\n                                        total_length=total_length)\n        return output\nm = MyModule().cuda()\ndp_m = nn.DataParallel(m)",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2019-09-06T01:21:14",
        "author": "sayan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/26937213/how-to-store-python-objects-in-cython-c-containers",
    "title": "How to store python objects in Cython C++ containers?",
    "question_id": 26937213,
    "posted_date": "2014-11-14T14:12:21",
    "answers": [
      {
        "answer_id": 66836764,
        "body": "cdef class PortValue:\n    cdef cadevs.PortValue[PythonObject, PythonObject]* _c_portvalue\n    # Add fields to keep stored Python objects alive.\n    cdef object port_ref_holder\n    cdef object value_ref_holder\n    def __cinit__(self, object port, object value):\n        self._c_portvalue = new cadevs.PortValue[PythonObject, PythonObject](\n            <PyObject *>port, <PyObject *>value\n        )\n        # Assign objects here to keep them alive.\n        port_ref_holder = port\n        value_ref_holder = value",
        "score": 2,
        "is_accepted": false,
        "creation_date": "2021-03-27T18:37:04",
        "author": "Golden Rockefeller"
      },
      {
        "answer_id": 66836764,
        "body": "from cpython.ref cimport PyObject, Py_INCREF, Py_DECREF\ncdef extern from *:\n    \"\"\"\n    class PyRef {\n        PyObject* obj;\n    public:\n\n        PyObject* get() {return obj;}\n        PyRef() {obj = NULL;}\n        PyRef(PyObject* set_obj) {\n            Py_XINCREF(set_obj);\n            obj = set_obj;}\n\n        ~PyRef() {\n            Py_XDECREF(obj);obj = NULL;\n        }\n        PyRef(const PyRef& other)  {\n            Py_XINCREF(other.obj);\n            obj = other.obj;\n        }\n        PyRef(PyRef&& other) {obj = other.obj; other.obj = NULL;}\n        PyRef& operator=(const PyRef& other) {\n            Py_XDECREF(obj);\n            Py_XINCREF(other.obj);\n            obj = other.obj;\n            return *this;\n        }\n        PyRef& operator=(PyRef&& other) {\n            Py_XDECREF(obj);\n            obj = other.obj;\n            other.obj = NULL;\n            return *this;\n        }\n    };\n    \"\"\"\n    cdef cppclass PyRef:\n        PyRef() except +\n        PyRef(PyObject* set_obj) except +\n        PyObject* get() except +",
        "score": 2,
        "is_accepted": false,
        "creation_date": "2021-03-27T18:37:04",
        "author": "Golden Rockefeller"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73442335/how-to-upload-a-large-file-%e2%89%a53gb-to-fastapi-backend",
    "title": "How to Upload a large File (\u22653GB) to FastAPI backend?",
    "question_id": 73442335,
    "posted_date": "2022-08-22T04:42:32",
    "answers": [
      {
        "answer_id": 73443824,
        "body": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\nfrom urllib.parse import unquote\nimport aiofiles\nimport os\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\n@app.post('/upload')\nasync def upload(request: Request):\n    try:\n        filename = request.headers['filename']\n        filename = unquote(filename)\n        filepath = os.path.join('./', os.path.basename(filename))\n        async with aiofiles.open(filepath, 'wb') as f:\n            async for chunk in request.stream():\n                await f.write(chunk)\n    except Exception:\n        raise HTTPException(status_code=500, detail='Something went wrong')\n\n    return {\"message\": f\"Successfuly uploaded: {filename}\"}\n\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(request=request, name=\"index.html\")",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "<!DOCTYPE html>\n<html>\n   <body>\n      <label for=\"fileInput\">Choose file(s) to upload</label>\n      <input type=\"file\" id=\"fileInput\" name=\"fileInput\" onchange=\"reset()\" multiple><br>\n      <input type=\"button\" value=\"Submit\" onclick=\"go()\">\n      <p id=\"response\"></p>\n      <script>\n         var resp = document.getElementById(\"response\");\n\n         function reset() {\n            resp.innerHTML = \"\";\n         }\n\n         function go() {\n            var fileInput = document.getElementById('fileInput');\n            if (fileInput.files[0]) {\n               for (const file of fileInput.files) {\n                  let reader = new FileReader();\n                  reader.onload = function () {\n                     uploadFile(reader.result, file.name);\n                  }\n                  reader.readAsArrayBuffer(file);\n               }\n            }\n         }\n\n         function uploadFile(contents, filename) {\n            var headers = new Headers();\n\t\t\tfilename = encodeURI(filename);\n            headers.append(\"filename\", filename);\n            fetch('/upload', {\n                  method: 'POST',\n                  headers: headers,\n                  body: contents,\n               })\n               .then(response => response.json()) // or, response.text(), etc.\n               .then(data => {\n                  resp.innerHTML += JSON.stringify(data); // data is a JSON object\n               })\n               .catch(error => {\n                  console.error(error);\n               });\n         }\n      </script>\n   </body>\n</html>",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "from fastapi import FastAPI, Request, HTTPException, status\nfrom streaming_form_data import StreamingFormDataParser\nfrom streaming_form_data.targets import FileTarget, ValueTarget\nfrom streaming_form_data.validators import MaxSizeValidator\nimport streaming_form_data\nfrom starlette.requests import ClientDisconnect\nfrom urllib.parse import unquote\nimport os\nMAX_FILE_SIZE = 1024 * 1024 * 1024 * 4  # = 4GB\nMAX_REQUEST_BODY_SIZE = MAX_FILE_SIZE + 1024\napp = FastAPI()\nclass MaxBodySizeException(Exception):\n    def __init__(self, body_len: str):\n        self.body_len = body_len\nclass MaxBodySizeValidator:\n    def __init__(self, max_size: int):\n        self.body_len = 0\n        self.max_size = max_size\n    def __call__(self, chunk: bytes):\n        self.body_len += len(chunk)\n        if self.body_len > self.max_size:\n            raise MaxBodySizeException(body_len=self.body_len)\n\n@app.post('/upload')\nasync def upload(request: Request):\n    body_validator = MaxBodySizeValidator(MAX_REQUEST_BODY_SIZE)\n    filename = request.headers.get('filename')\n\n    if not filename:\n        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail='Filename header is missing')\n    try:\n        filename = unquote(filename)\n        filepath = os.path.join('./', os.path.basename(filename))\n        file_ = FileTarget(filepath, validator=MaxSizeValidator(MAX_FILE_SIZE))\n        data = ValueTarget()\n        parser = StreamingFormDataParser(headers=request.headers)\n        parser.register('file', file_)\n        parser.register('data', data)\n\n        async for chunk in request.stream():\n            body_validator(chunk)\n            parser.data_received(chunk)\n    except ClientDisconnect:\n        print(\"Client Disconnected\")\n    except MaxBodySizeException as e:\n        raise HTTPException(status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,\n           detail=f'Maximum request body size limit ({MAX_REQUEST_BODY_SIZE} bytes) exceeded ({e.body_len} bytes read)')\n    except streaming_form_data.validators.ValidationError:\n        raise HTTPException(status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,\n            detail=f'Maximum file size limit ({MAX_FILE_SIZE} bytes) exceeded')\n    except Exception:\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail='There was an error uploading the file')\n\n    if not file_.multipart_filename:\n        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail='File is missing')\n    print(data.value.decode())\n    print(file_.multipart_filename)\n\n    return {\"message\": f\"Successfuly uploaded {filename}\"}",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "from fastapi import FastAPI, Request, HTTPException, status\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\nfrom starlette.requests import ClientDisconnect\nfrom urllib.parse import unquote\nimport streaming_form_data\nfrom streaming_form_data import StreamingFormDataParser\nfrom streaming_form_data.targets import FileTarget, ValueTarget\nimport os\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\n@app.get(\"/\", response_class=HTMLResponse)\nasync def main(request: Request):\n    return templates.TemplateResponse(request=request, name=\"index.html\")\n@app.post('/upload')\nasync def upload(request: Request):\n    try:\n        parser = StreamingFormDataParser(headers=request.headers)\n        data = ValueTarget()\n        parser.register('data', data)\n        headers = dict(request.headers)\n        filenames = []\n        i = 0\n        while True:\n            filename =  headers.get(f'filename{i}', None)\n            if filename is None:\n                break\n            filename = unquote(filename)\n            filenames.append(filename)\n            filepath = os.path.join('./', os.path.basename(filename))\n            file_ = FileTarget(filepath)\n            parser.register(f'file{i}', file_)\n            i += 1\n        async for chunk in request.stream():\n            parser.data_received(chunk)\n    except ClientDisconnect:\n        print(\"Client Disconnected\")\n    except Exception:\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail='There was an error uploading the file')\n    print(data.value.decode())\n    return {\"message\": f\"Successfuly uploaded {filenames}\"}",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "<!DOCTYPE html>\n<html>\n   <body>\n      <input type=\"file\" id=\"fileInput\" name=\"files\" onchange=\"reset()\" multiple><br>\n      <input type=\"button\" value=\"Submit\" onclick=\"submitUsingFetch()\">\n      <p id=\"response\"></p>\n      <script>\n         var resp = document.getElementById(\"response\");\n\n         function reset() {\n            resp.innerHTML = \"\";\n         }\n\n         function submitUsingFetch() {\n            var fileInput = document.getElementById('fileInput');\n            if (fileInput.files[0]) {\n               var formData = new FormData();\n               var headers = new Headers();\n               formData.append(\"data\", \"Hello World!\");\n\n               var i = 0;\n               for (const file of fileInput.files) {\n                  filename = encodeURI(file.name);\n                  headers.append(`filename${i}`, filename);\n                  formData.append(`file${i}`, file, filename);\n                  i++;\n               }\n\n               fetch('/upload', {\n                     method: 'POST',\n                     headers: headers,\n                     body: formData,\n                  })\n                  .then(response => response.json())  // or, response.text(), etc.\n                  .then(data => {\n                     resp.innerHTML = JSON.stringify(data);  // data is a JSON object\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n            }\n         }\n      </script>\n   </body>\n</html>",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "import httpx\nimport time\nfrom urllib.parse import quote\nurl ='http://127.0.0.1:8000/upload'\nfilename0 = 'bigFile.zip'\nfilename1 = 'otherBigFile.zip'\nheaders = {'filename0': quote(filename0), 'filename1': quote(filename1)}\nfiles = [('file0', open(filename0, 'rb')), ('file1', open(filename1, 'rb'))]\ndata = {'data': 'Hello World!'}\nwith httpx.Client() as client:\n    start = time.time()\n    r = client.post(url, data=data, files=files, headers=headers)\n    end = time.time()\n    print(f'Time elapsed: {end - start}s')\n    print(r.status_code, r.json(), sep=' ')",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "#...\nfrom fastapi import Form\nfrom pydantic import BaseModel, ValidationError\nfrom typing import Optional\nfrom fastapi.encoders import jsonable_encoder\n#...\nclass Base(BaseModel):\n    name: str\n    point: Optional[float] = None\n    is_accepted: Optional[bool] = False\n\ndef checker(data: str = Form(...)):\n    try:\n        return Base.model_validate_json(data)\n    except ValidationError as e:\n        raise HTTPException(detail=jsonable_encoder(e.errors()), status_code=status.HTTP_422_UNPROCESSABLE_ENTITY)\n\n@app.post('/upload')\nasync def upload(request: Request):\n\t#...\n\n    # place the below after the try-except block in the example given earlier\n\tmodel = checker(data.value.decode())\n\tprint(dict(model))",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      },
      {
        "answer_id": 73443824,
        "body": "from fastapi import FastAPI, File, UploadFile, Form, HTTPException, status\nimport aiofiles\nimport os\nCHUNK_SIZE = 1024 * 1024  # adjust the chunk size as desired\napp = FastAPI()\n@app.post(\"/upload\")\nasync def upload(file: UploadFile = File(...), data: str = Form(...)):\n    try:\n        filepath = os.path.join('./', os.path.basename(file.filename))\n        async with aiofiles.open(filepath, 'wb') as f:\n            while chunk := await file.read(CHUNK_SIZE):\n                await f.write(chunk)\n    except Exception:\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail='There was an error uploading the file')\n    finally:\n        await file.close()\n    return {\"message\": f\"Successfuly uploaded {file.filename}\"}",
        "score": 49,
        "is_accepted": true,
        "creation_date": "2022-08-22T06:42:35",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56781635/how-to-find-extreme-outer-points-in-an-image-with-python-opencv",
    "title": "How to find extreme outer points in an image with Python OpenCV",
    "question_id": 56781635,
    "posted_date": "2019-06-26T18:20:37",
    "answers": [
      {
        "answer_id": 56781750,
        "body": "import cv2\nimport numpy as np\n# Load image, grayscale, Gaussian blur, threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 220, 255, cv2.THRESH_BINARY_INV)[1]\n# Find contours\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nc = max(cnts, key=cv2.contourArea)\n# Obtain outer coordinates\nleft = tuple(c[c[:, :, 0].argmin()][0])\nright = tuple(c[c[:, :, 0].argmax()][0])\ntop = tuple(c[c[:, :, 1].argmin()][0])\nbottom = tuple(c[c[:, :, 1].argmax()][0])\n# Draw dots onto image\ncv2.drawContours(image, [c], -1, (36, 255, 12), 2)\ncv2.circle(image, left, 8, (0, 50, 255), -1)\ncv2.circle(image, right, 8, (0, 255, 255), -1)\ncv2.circle(image, top, 8, (255, 50, 0), -1)\ncv2.circle(image, bottom, 8, (255, 255, 0), -1)\nprint('left: {}'.format(left))\nprint('right: {}'.format(right))\nprint('top: {}'.format(top))\nprint('bottom: {}'.format(bottom))\ncv2.imshow('thresh', thresh)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2019-06-26T18:36:45",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71862398/install-python-3-6-on-mac-m1",
    "title": "Install python 3.6.* on Mac M1",
    "question_id": 71862398,
    "posted_date": "2022-04-13T14:37:45",
    "answers": [
      {
        "answer_id": 71957981,
        "body": "#Install Rosetta\n/usr/sbin/softwareupdate --install-rosetta --agree-to-license\n# Install x86_64 brew\narch -x86_64 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n# Set up x86_64 homebrew and pyenv and temporarily set aliases\nalias brew86=\"arch -x86_64 /usr/local/bin/brew\"\nalias pyenv86=\"arch -x86_64 pyenv\"\n# Install required packages and flags for building this particular python version through emulation\nbrew86 install pyenv gcc libffi gettext\nexport CPPFLAGS=\"-I$(brew86 --prefix libffi)/include -I$(brew86 --prefix openssl)/include -I$(brew86 --prefix readline)/lib\"\nexport CFLAGS=\"-I$(brew86 --prefix openssl)/include -I$(brew86 --prefix bzip2)/include -I$(brew86 --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include -Wno-implicit-function-declaration\"\nexport LDFLAGS=\"-L$(brew86 --prefix openssl)/lib -L$(brew86 --prefix readline)/lib -L$(brew86 --prefix zlib)/lib -L$(brew86 --prefix bzip2)/lib -L$(brew86 --prefix gettext)/lib -L$(brew86 --prefix libffi)/lib\"\n# Providing an incorrect openssl version forces a proper openssl version to be downloaded and linked during the build\nexport PYTHON_BUILD_HOMEBREW_OPENSSL_FORMULA=openssl@1.0\n# Install Python 3.6\npyenv86 install --patch 3.6.15 <<(curl -sSL https://raw.githubusercontent.com/pyenv/pyenv/master/plugins/python-build/share/python-build/patches/3.6.15/Python-3.6.15/0008-bpo-45405-Prevent-internal-configure-error-when-runn.patch\\?full_index\\=1)",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2022-04-21T12:39:15",
        "author": "dontirun"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69660200/how-to-render-svg-image-to-png-file-in-python",
    "title": "How to render SVG image to PNG file in Python?",
    "question_id": 69660200,
    "posted_date": "2021-10-21T06:23:57",
    "answers": [
      {
        "answer_id": 69791039,
        "body": "import cairosvg\n# read svg file -> write png file\ncairosvg.svg2png(url=input_svg_path, write_to=output_png_path, output_width=width, output_height=height)\n# read svg file -> png data\npng_data = cairosvg.svg2png(url=input_svg_path, output_width=width, output_height=height)\n# svg string -> write png file\ncairosvg.svg2png(bytestring=svg_str.encode(), write_to=output_png_path, output_width=width, output_height=height)\n# svg string -> png data\npng_data = cairosvg.svg2png(bytestring=svg_str.encode(), output_width=width, output_height=height)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-31T18:23:14",
        "author": "amgg"
      },
      {
        "answer_id": 69791039,
        "body": "import subprocess\ninkscape = ... # path to inkscape executable\n# read svg file -> write png file\nsubprocess.run([inkscape, '--export-type=png', f'--export-filename={output_png_path}', f'--export-width={width}', f'--export-height={height}', input_svg_path])\n# read svg file -> png data\nresult = subprocess.run([inkscape, '--export-type=png', '--export-filename=-', f'--export-width={width}', f'--export-height={height}', input_svg_path], capture_output=True)\n#   (result.stdout will have the png data)\n# svg string -> write png file\nsubprocess.run([inkscape, '--export-type=png', f'--export-filename={output_png_path}', f'--export-width={width}', f'--export-height={height}', '--pipe'], input=svg_str.encode())\n# svg string -> png data\nresult = subprocess.run([inkscape, '--export-type=png', '--export-filename=-', f'--export-width={width}', f'--export-height={height}', '--pipe'], input=svg_str.encode(), capture_output=True)\n#   (result.stdout will have the png data)",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-31T18:23:14",
        "author": "amgg"
      },
      {
        "answer_id": 69791039,
        "body": "from wand.image import Image\nfrom wand.Color import Color\nwith Color('#00000000') as bgcolor,\\\n  # to read input from a file:\n  Image(filename=input_svg_path, width=width, height=height, background=bgcolor) as img:\n  # or, to use input from a string:\n  Image(blob=svg_str.encode(), format='svg', width=width, height=height, background=bgcolor) as img:\n    # to save output to a file:\n    with img.convert('png') as output_img:\n        output_img.save(filename=output_png_path)\n    # or, to get the output data in a variable:\n    png_data = img.make_blob(format='png')",
        "score": 35,
        "is_accepted": true,
        "creation_date": "2021-10-31T18:23:14",
        "author": "amgg"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/4126348/how-can-this-function-be-rewritten-to-implement-ordereddict",
    "title": "How can this function be rewritten to implement OrderedDict?",
    "question_id": 4126348,
    "posted_date": "2010-11-08T12:32:23",
    "answers": [
      {
        "answer_id": 4127426,
        "body": "import collections\nclass OrderedDefaultdict(collections.OrderedDict):\n    \"\"\" A defaultdict with OrderedDict as its base class. \"\"\"\n    def __init__(self, default_factory=None, *args, **kwargs):\n        if not (default_factory is None or callable(default_factory)):\n            raise TypeError('first argument must be callable or None')\n        super(OrderedDefaultdict, self).__init__(*args, **kwargs)\n        self.default_factory = default_factory  # called by __missing__()\n    def __missing__(self, key):\n        if self.default_factory is None:\n            raise KeyError(key,)\n        self[key] = value = self.default_factory()\n        return value\n    def __reduce__(self):  # Optional, for pickle support.\n        args = (self.default_factory,) if self.default_factory else tuple()\n        return self.__class__, args, None, None, iter(self.items())\n    def __repr__(self):  # Optional.\n        return '%s(%r, %r)' % (self.__class__.__name__, self.default_factory, self.items())\ndef simplexml_load_file(file):\n    from lxml import etree\n    tree = etree.parse(file)\n    root = tree.getroot()\n    def xml_to_item(el):\n        item = el.text or None\n        child_dicts = OrderedDefaultdict(list)\n        for child in el.getchildren():\n            child_dicts[child.tag].append(xml_to_item(child))\n        return collections.OrderedDict(child_dicts) or item\n    def xml_to_dict(el):\n        return {el.tag: xml_to_item(el)}\n    return xml_to_dict(root)\nx = simplexml_load_file('routines/test.xml')\nprint(x)\nfor y in x['root']:\n    print(y)",
        "score": 38,
        "is_accepted": true,
        "creation_date": "2010-11-08T14:49:13",
        "author": "martineau"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11921188/how-to-send-email-with-pdf-attachment-in-python",
    "title": "How to send email with pdf attachment in Python?",
    "question_id": 11921188,
    "posted_date": "2012-08-12T05:34:10",
    "answers": [
      {
        "answer_id": 11921241,
        "body": "def send_email_pdf_figs(path_to_pdf, subject, message, destination, password_path=None):\n    ## credits: http://linuxcursor.com/python-programming/06-how-to-send-pdf-ppt-attachment-with-html-body-in-python-script\n    from socket import gethostname\n    #import email\n    from email.mime.application import MIMEApplication\n    from email.mime.multipart import MIMEMultipart\n    from email.mime.text import MIMEText\n    import smtplib\n    import json\n    server = smtplib.SMTP('smtp.gmail.com', 587)\n    server.starttls()\n    with open(password_path) as f:\n        config = json.load(f)\n        server.login('me@gmail.com', config['password'])\n        # Craft message (obj)\n        msg = MIMEMultipart()\n        message = f'{message}\\nSend from Hostname: {gethostname()}'\n        msg['Subject'] = subject\n        msg['From'] = 'me@gmail.com'\n        msg['To'] = destination\n        # Insert the text to the msg going by e-mail\n        msg.attach(MIMEText(message, \"plain\"))\n        # Attach the pdf to the msg going by e-mail\n        with open(path_to_pdf, \"rb\") as f:\n            #attach = email.mime.application.MIMEApplication(f.read(),_subtype=\"pdf\")\n            attach = MIMEApplication(f.read(),_subtype=\"pdf\")\n        attach.add_header('Content-Disposition','attachment',filename=str(path_to_pdf))\n        msg.attach(attach)\n        # send msg\n        server.send_message(msg)",
        "score": 32,
        "is_accepted": true,
        "creation_date": "2012-08-12T05:44:47",
        "author": "verisimilitude"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/65331736/how-can-i-publish-python-packages-to-codeartifact-using-poetry",
    "title": "How can I publish Python packages to CodeArtifact using Poetry?",
    "question_id": 65331736,
    "posted_date": "2020-12-16T16:59:06",
    "answers": [
      {
        "answer_id": 65935044,
        "body": "# This will give the repo url without the /simple/ part\n# Example: https://<my-domain>-<domain-owner-id>.d.codeartifact.<region>.amazonaws.com/pypi/<my-repo>/\n# Note the lack of the \"aws:auth-token@\" part\nexport CODEARTIFACT_REPOSITORY_URL=`aws codeartifact get-repository-endpoint --domain my-domain --domain-owner domain-owner-id --repository my-repo --format pypi --query repositoryEndpoint --output text`\n# This will give the token to access the repo\nexport CODEARTIFACT_AUTH_TOKEN=`aws codeartifact get-authorization-token --domain my-domain --domain-owner domain-owner-id --query authorizationToken --output text`\n# This specifies the user who accesses the repo\nexport CODEARTIFACT_USER=aws\n# Now use all of these when configuring the repo in poetry\npoetry config repositories.<my-repo-name-for-poetry> $CODEARTIFACT_REPOSITORY_URL\npoetry config http-basic.<my-repo-name-for-poetry> $CODEARTIFACT_USER $CODEARTIFACT_AUTH_TOKEN",
        "score": 27,
        "is_accepted": true,
        "creation_date": "2021-01-28T05:15:31",
        "author": "Jels Boulangier"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72482384/how-to-read-emails-from-gmail",
    "title": "How to read emails from gmail?",
    "question_id": 72482384,
    "posted_date": "2022-06-02T17:09:51",
    "answers": [
      {
        "answer_id": 73215051,
        "body": "import os.path\nimport base64\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nSCOPES = ['https://www.googleapis.com/auth/gmail.readonly','https://www.googleapis.com/auth/gmail.modify']\ndef readEmails():\n    \"\"\"Shows basic usage of the Gmail API.\n    Lists the user's Gmail labels.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                # your creds file here. Please create json file as here https://cloud.google.com/docs/authentication/getting-started\n                'my_cred_file.json', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n    try:\n        # Call the Gmail API\n        service = build('gmail', 'v1', credentials=creds)\n        results = service.users().messages().list(userId='me', labelIds=['INBOX'], q=\"is:unread\").execute()\n        messages = results.get('messages',[]);\n        if not messages:\n            print('No new messages.')\n        else:\n            message_count = 0\n            for message in messages:\n                msg = service.users().messages().get(userId='me', id=message['id']).execute()\n                email_data = msg['payload']['headers']\n                for values in email_data:\n                    name = values['name']\n                    if name == 'From':\n                        from_name= values['value']\n                        for part in msg['payload']['parts']:\n                            try:\n                                data = part['body'][\"data\"]\n                                byte_code = base64.urlsafe_b64decode(data)\n                                text = byte_code.decode(\"utf-8\")\n                                print (\"This is the message: \"+ str(text))\n                                # mark the message as read (optional)\n                                msg  = service.users().messages().modify(userId='me', id=message['id'], body={'removeLabelIds': ['UNREAD']}).execute()\n                            except BaseException as error:\n                                pass\n    except Exception as error:\n        print(f'An error occurred: {error}')",
        "score": 25,
        "is_accepted": false,
        "creation_date": "2022-08-02T20:18:24",
        "author": "Mark P"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61819120/how-to-get-the-endpoint-of-a-linestring-in-shapely",
    "title": "How to get the endpoint of a LineString in Shapely",
    "question_id": 61819120,
    "posted_date": "2020-05-15T08:22:43",
    "answers": [
      {
        "answer_id": 61852287,
        "body": "from shapely.wkt import loads\nfirst_line = loads(\"LINESTRING (51.2176008 4.4177154, 51.21758 4.4178548, 51.2175729 4.4179023, 51.21745162000732 4.41871738126533)\")\nsecond_line = loads(\"LINESTRING (51.21745162000732 4.41871738126533, 51.2174025 4.4190475, 51.217338 4.4194807, 51.2172511 4.4200562, 51.2172411 4.4201077, 51.2172246 4.4201654, 51.2172067 4.420205, 51.2171806 4.4202355, 51.2171074 4.4202929, 51.2170063 4.4203409, 51.2169564 4.4203641, 51.2168076 4.4204243, 51.2166588 4.4204833, 51.2159018 4.420431, 51.2154117 4.4203843)\")\nfirst_line = LineString(first_line.coords[:-1])\nsecond_line = LineString(second_line.coords[1:])\nprint(first_line.boundary[1], second_line.boundary[0])\n# POINT (51.2175729 4.4179023) POINT (51.2174025 4.4190475)",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2020-05-17T09:07:41",
        "author": "Georgy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56858924/multivariate-input-lstm-in-pytorch",
    "title": "Multivariate input LSTM in pytorch",
    "question_id": 56858924,
    "posted_date": "2019-07-02T15:27:34",
    "answers": [
      {
        "answer_id": 56893248,
        "body": "import random\nimport numpy as np\nimport torch\n# multivariate data preparation\nfrom numpy import array\nfrom numpy import hstack\n\n# split a multivariate sequence into samples\ndef split_sequences(sequences, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequences)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the dataset\n        if end_ix > len(sequences):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nin_seq1 = array([x for x in range(0,100,10)])\nin_seq2 = array([x for x in range(5,105,10)])\nout_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n# convert to [rows, columns] structure\nin_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nout_seq = out_seq.reshape((len(out_seq), 1))\n# horizontally stack columns\ndataset = hstack((in_seq1, in_seq2, out_seq))",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2019-07-04T15:09:00",
        "author": "Tomas Trdla"
      },
      {
        "answer_id": 56893248,
        "body": "class MV_LSTM(torch.nn.Module):\n    def __init__(self,n_features,seq_length):\n        super(MV_LSTM, self).__init__()\n        self.n_features = n_features\n        self.seq_len = seq_length\n        self.n_hidden = 20 # number of hidden states\n        self.n_layers = 1 # number of LSTM layers (stacked)\n\n        self.l_lstm = torch.nn.LSTM(input_size = n_features,\n                                 hidden_size = self.n_hidden,\n                                 num_layers = self.n_layers,\n                                 batch_first = True)\n        # according to pytorch docs LSTM output is\n        # (batch_size,seq_len, num_directions * hidden_size)\n        # when considering batch_first = True\n        self.l_linear = torch.nn.Linear(self.n_hidden*self.seq_len, 1)\n\n\n    def init_hidden(self, batch_size):\n        # even with batch_first = True this remains same as docs\n        hidden_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n        cell_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n        self.hidden = (hidden_state, cell_state)\n\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.size()\n\n        lstm_out, self.hidden = self.l_lstm(x,self.hidden)\n        # lstm_out(with batch_first = True) is\n        # (batch_size,seq_len,num_directions * hidden_size)\n        # for following linear layer we want to keep batch_size dimension and merge rest\n        # .contiguous() -> solves tensor compatibility error\n        x = lstm_out.contiguous().view(batch_size,-1)\n        return self.l_linear(x)",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2019-07-04T15:09:00",
        "author": "Tomas Trdla"
      },
      {
        "answer_id": 56893248,
        "body": "mv_net.train()\nfor t in range(train_episodes):\n    for b in range(0,len(X),batch_size):\n        inpt = X[b:b+batch_size,:,:]\n        target = y[b:b+batch_size]\n\n        x_batch = torch.tensor(inpt,dtype=torch.float32)\n        y_batch = torch.tensor(target,dtype=torch.float32)\n\n        mv_net.init_hidden(x_batch.size(0))\n    #    lstm_out, _ = mv_net.l_lstm(x_batch,nnet.hidden)\n    #    lstm_out.contiguous().view(x_batch.size(0),-1)\n        output = mv_net(x_batch)\n        loss = criterion(output.view(-1), y_batch)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    print('step : ' , t , 'loss : ' , loss.item())",
        "score": 34,
        "is_accepted": true,
        "creation_date": "2019-07-04T15:09:00",
        "author": "Tomas Trdla"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55576314/conv1d-with-kernel-size-1-vs-linear-layer",
    "title": "Conv1D with kernel_size=1 vs Linear layer",
    "question_id": 55576314,
    "posted_date": "2019-04-08T10:58:55",
    "answers": [
      {
        "answer_id": 56685503,
        "body": "def count_parameters(model):\n    \"\"\"Count the number of parameters in a model.\"\"\"\n    return sum([p.numel() for p in model.parameters()])\nconv = torch.nn.Conv1d(8,32,1)\nprint(count_parameters(conv))\n# 288\nlinear = torch.nn.Linear(8,32)\nprint(count_parameters(linear))\n# 288\nprint(conv.weight.shape)\n# torch.Size([32, 8, 1])\nprint(linear.weight.shape)\n# torch.Size([32, 8])\n# use same initialization\nlinear.weight = torch.nn.Parameter(conv.weight.squeeze(2))\nlinear.bias = torch.nn.Parameter(conv.bias)\ntensor = torch.randn(128,256,8)\npermuted_tensor = tensor.permute(0,2,1).clone().contiguous()\nout_linear = linear(tensor)\nprint(out_linear.mean())\n# tensor(0.0067, grad_fn=<MeanBackward0>)\nout_conv = conv(permuted_tensor)\nprint(out_conv.mean())\n# tensor(0.0067, grad_fn=<MeanBackward0>)",
        "score": 29,
        "is_accepted": true,
        "creation_date": "2019-06-20T07:58:56",
        "author": "Yann Dubois"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61427583/how-do-i-plot-a-keras-tensorflow-subclassing-api-model",
    "title": "How do I plot a Keras/Tensorflow subclassing API model?",
    "question_id": 61427583,
    "posted_date": "2020-04-25T10:54:51",
    "answers": [
      {
        "answer_id": 63898244,
        "body": "class my_model(keras.Model):\n    def __init__(self, dim):\n        super(my_model, self).__init__()\n        self.Base  = keras.keras.applications.VGG16(\n            input_shape=(dim),\n            include_top = False,\n            weights = 'imagenet'\n        )\n        self.GAP   = L.GlobalAveragePooling2D()\n        self.BAT   = L.BatchNormalization()\n        self.DROP  = L.Dropout(rate=0.1)\n        self.DENS  = L.Dense(256, activation='relu', name = 'dense_A')\n        self.OUT   = L.Dense(1, activation='sigmoid')\n\n    def call(self, inputs):\n        x  = self.Base(inputs)\n        g  = self.GAP(x)\n        b  = self.BAT(g)\n        d  = self.DROP(b)\n        d  = self.DENS(d)\n        return self.OUT(d)\n\n    # AFAIK: The most convenient method to print model.summary()\n    # similar to the sequential or functional API like.\n    def build_graph(self):\n        x = Input(shape=(dim))\n        return Model(inputs=[x], outputs=self.call(x))\ndim = (124,124,3)\nmodel = my_model((dim))\nmodel.build((None, *dim))\nmodel.build_graph().summary()",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2020-09-15T04:45:40",
        "author": "Innat"
      },
      {
        "answer_id": 63898244,
        "body": "Layer (type)                 Output Shape              Param #\n=================================================================\ninput_67 (InputLayer)        [(None, 124, 124, 3)]     0\n_________________________________________________________________\nvgg16 (Functional)           (None, 3, 3, 512)         14714688\n_________________________________________________________________\nglobal_average_pooling2d_32  (None, 512)               0\n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 512)               2048\n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0\n_________________________________________________________________\ndense_A (Dense)              (None, 256)               402192\n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 785\n=================================================================\nTotal params: 14,848,321\nTrainable params: 14,847,297\nNon-trainable params: 1,024",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2020-09-15T04:45:40",
        "author": "Innat"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59979467/accessing-microsoft-sharepoint-files-and-data-using-python",
    "title": "Accessing Microsoft Sharepoint files and data using Python",
    "question_id": 59979467,
    "posted_date": "2020-01-30T00:11:06",
    "answers": [
      {
        "answer_id": 59981556,
        "body": "from office365.runtime.auth.authentication_context import AuthenticationContext\nfrom office365.sharepoint.client_context import ClientContext\nfrom office365.sharepoint.files.file import File\n####inputs########\n# This will be the URL that points to your sharepoint site.\n# Make sure you change only the parts of the link that start with \"Your\"\nurl_shrpt = 'https://YourOrganisation.sharepoint.com/sites/YourSharepointSiteName'\nusername_shrpt = 'YourUsername'\npassword_shrpt = 'YourPassword'\nfolder_url_shrpt = '/sites/YourSharepointSiteName/Shared%20Documents/YourSharepointFolderName/'\n#######################\n###Authentication###For authenticating into your sharepoint site###\nctx_auth = AuthenticationContext(url_shrpt)\nif ctx_auth.acquire_token_for_user(username_shrpt, password_shrpt):\n  ctx = ClientContext(url_shrpt, ctx_auth)\n  web = ctx.web\n  ctx.load(web)\n  ctx.execute_query()\n  print('Authenticated into sharepoint as: ',web.properties['Title'])\nelse:\n  print(ctx_auth.get_last_error())\n############################\n\n\n\n\n####Function for extracting the file names of a folder in sharepoint###\n###If you want to extract the folder names instead of file names, you have to change \"sub_folders = folder.files\" to \"sub_folders = folder.folders\" in the below function\nglobal print_folder_contents\ndef print_folder_contents(ctx, folder_url):\n    try:\n\n        folder = ctx.web.get_folder_by_server_relative_url(folder_url)\n        fold_names = []\n        sub_folders = folder.files #Replace files with folders for getting list of folders\n        ctx.load(sub_folders)\n        ctx.execute_query()\n\n        for s_folder in sub_folders:\n\n            fold_names.append(s_folder.properties[\"Name\"])\n        return fold_names\n    except Exception as e:\n        print('Problem printing out library contents: ', e)\n######################################################\n\n\n# Call the function by giving your folder URL as input\nfilelist_shrpt=print_folder_contents(ctx,folder_url_shrpt)\n#Print the list of files present in the folder\nprint(filelist_shrpt)",
        "score": 22,
        "is_accepted": true,
        "creation_date": "2020-01-30T03:14:06",
        "author": "Karthick Mohanraj"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/11161901/how-to-install-python-modules-in-blender",
    "title": "How to install python modules in blender",
    "question_id": 11161901,
    "posted_date": "2012-06-22T14:14:30",
    "answers": [
      {
        "answer_id": 68964354,
        "body": "# 1. launch next 2 lines of code in blender python interpreter\nimport pip\npip.main(['install', 'tqdm', '--user'])\nimport sys\n# 2. watch blender's python path in console output at this moment\n# 3. insert the path to packages_path below and uncomment\n# packages_path = \"C:\\\\Users\\\\<Username>\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts\" + \"\\\\..\\\\site-packages\" # the path you see in console\n# 4. uncomment the next code and launch script in blender interpreter again\n# sys.path.insert(0, packages_path )\n# import tqdm\n# use installed packages here",
        "score": 14,
        "is_accepted": false,
        "creation_date": "2021-08-28T08:28:05",
        "author": "Ornstein89"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57734298/how-can-i-provide-shared-state-to-my-flask-app-with-multiple-workers-without-dep",
    "title": "How can I provide shared state to my Flask app with multiple workers without depending on additional software?",
    "question_id": 57734298,
    "posted_date": "2019-08-30T20:11:30",
    "answers": [
      {
        "answer_id": 57810915,
        "body": "from multiprocessing import Lock\nfrom multiprocessing.managers import AcquirerProxy, BaseManager, DictProxy\ndef get_shared_state(host, port, key):\n    shared_dict = {}\n    shared_lock = Lock()\n    manager = BaseManager((host, port), key)\n    manager.register(\"get_dict\", lambda: shared_dict, DictProxy)\n    manager.register(\"get_lock\", lambda: shared_lock, AcquirerProxy)\n    try:\n        manager.get_server()\n        manager.start()\n    except OSError:  # Address already in use\n        manager.connect()\n    return manager.get_dict(), manager.get_lock()",
        "score": 27,
        "is_accepted": false,
        "creation_date": "2019-09-05T14:07:08",
        "author": "finefoot"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/25972482/how-to-move-files-in-google-cloud-storage-from-one-bucket-to-another-bucket-by-p",
    "title": "How to move files in Google Cloud Storage from one bucket to another bucket by Python",
    "question_id": 25972482,
    "posted_date": "2014-09-22T06:59:20",
    "answers": [
      {
        "answer_id": 58241516,
        "body": "from google.cloud import storage\nimport os\n\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"path_to_your_creds.json\"\ndef mv_blob(bucket_name, blob_name, new_bucket_name, new_blob_name):\n    \"\"\"\n    Function for moving files between directories or buckets. it will use GCP's copy\n    function then delete the blob from the old location.\n\n    inputs\n    -----\n    bucket_name: name of bucket\n    blob_name: str, name of file\n        ex. 'data/some_location/file_name'\n    new_bucket_name: name of bucket (can be same as original if we're just moving around directories)\n    new_blob_name: str, name of file in new directory in target bucket\n        ex. 'data/destination/file_name'\n    \"\"\"\n    storage_client = storage.Client()\n    source_bucket = storage_client.get_bucket(bucket_name)\n    source_blob = source_bucket.blob(blob_name)\n    destination_bucket = storage_client.get_bucket(new_bucket_name)\n    # copy to new destination\n    new_blob = source_bucket.copy_blob(\n        source_blob, destination_bucket, new_blob_name)\n    # delete in old destination\n    source_blob.delete()\n\n    print(f'File moved from {source_blob} to {new_blob_name}')",
        "score": 26,
        "is_accepted": false,
        "creation_date": "2019-10-04T14:27:23",
        "author": "dmlee8"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73547776/how-to-redirect-from-one-domain-to-another-and-set-cookies-or-headers-for-the-ot",
    "title": "How to redirect from one domain to another and set cookies or headers for the other domain?",
    "question_id": 73547776,
    "posted_date": "2022-08-30T15:50:49",
    "answers": [
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI\nfrom fastapi.responses import RedirectResponse, HTMLResponse\nimport uvicorn\napp = FastAPI()\n\n@app.get('/', response_class=HTMLResponse)\nasync def home():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <body>\n          <h2>Click the \"Submit\" button to be redirected to domain B</h2>\n          <form method=\"POST\" action=\"/submit\">\n             <input type=\"submit\" value=\"Submit\">\n          </form>\n       </body>\n    </html>\n    \"\"\"\n\n@app.post(\"/submit\")\nasync def submit():\n    token = 'MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3'\n    redirect_url = f'http://example.test:8001/submit?token={token}'\n    response = RedirectResponse(redirect_url)\n    response.set_cookie(key='access-token', value=token, httponly=True)  # set cookie for domain A too\n    return response\n\nif __name__ == '__main__':\n    uvicorn.run(app, host='0.0.0.0', port=8000)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, status\nfrom fastapi.responses import RedirectResponse\nimport uvicorn\napp = FastAPI()\n@app.get('/')\nasync def home(request: Request):\n    token = request.cookies.get('access-token')\n    return 'You have successfully been redirected to domain B!' \\\n           f' Your access token is: {token}'\n\n@app.post('/submit')\nasync def submit(request: Request, token: str):\n    redirect_url = request.url_for('home')\n    response = RedirectResponse(redirect_url, status_code=status.HTTP_303_SEE_OTHER)\n    response.set_cookie(key='access-token', value=token, httponly=True)\n    return response\n\nif __name__ == '__main__':\n    uvicorn.run(app, host='0.0.0.0', port=8001)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\n@app.get('/', response_class=HTMLResponse)\nasync def home():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <body>\n          <h2>Click the \"Submit\" button to be redirected to domain B</h2>\n          <input type=\"button\" value=\"Submit\" onclick=\"submit()\"><br>\n          <iframe id=\"cross_domain_page\" src=\"http://example.test:8001/iframe\"  frameborder=\"0\" scrolling=\"no\" style=\"background:transparent;margin:auto;display:block\"></iframe>\n          <script>\n             function submit() {\n                fetch('/submit', {\n                     method: 'POST',\n                  })\n                  .then(res => {\n                     authHeader = res.headers.get('Authorization');\n                     if (authHeader.startsWith(\"Bearer \"))\n                        token = authHeader.substring(7, authHeader.length);\n                     return res.text();\n                  })\n                  .then(data => {\n                     document.getElementById('cross_domain_page').contentWindow.postMessage(token, \"http://example.test:8001\");\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n             }\n\n             window.addEventListener(\"message\", (event) => {\n                if (event.origin !== \"http://example.test:8001\")\n                  return;\n\n                if (event.data == \"cookie is set\")\n                  window.location.href = 'http://example.test:8001/';\n             }, false);\n          </script>\n       </body>\n    </html>\n    \"\"\"\n@app.post('/submit')\nasync def submit():\n    token = 'MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3'\n    headers = {'Authorization': f'Bearer {token}'}\n    response = Response('success', headers=headers)\n    response.set_cookie(key='access-token', value=token, httponly=True)  # set cookie for domain A too\n    return response\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8000)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\n@app.get('/iframe', response_class=HTMLResponse)\nasync def iframe():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <head>\n          <script>\n             window.addEventListener(\"message\", (event) => {\n                if (event.origin !== \"http://127.0.0.1:8000\" && event.origin !== \"http://localhost:8000\")\n                   return;\n\n                fetch('/submit', {\n                      method: 'POST',\n                      headers: {\n                         'Authorization': `Bearer ${event.data}`\n                      }\n                   })\n                   .then(res => res.text())\n                   .then(data => {\n                      event.source.postMessage(\"cookie is set\", event.origin);\n                   })\n                   .catch(error => {\n                      console.error(error);\n                   })\n             }, false);\n          </script>\n       </head>\n    </html>\n    \"\"\"\n\n@app.get('/')\nasync def home(request: Request):\n    token = request.cookies.get('access-token')\n    return 'You have been successfully redirected to domain B!' \\\n           f' Your access token is: {token}'\n@app.post('/submit')\nasync def submit(request: Request, response: Response):\n    authHeader = request.headers.get('Authorization')\n    if authHeader.startswith(\"Bearer \"):\n        token = authHeader[7:]\n    response.set_cookie(key='access-token', value=token, samesite='none', secure=True, httponly=True)\n    return 'success'\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8001)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\n\n@app.get('/', response_class=HTMLResponse)\nasync def home():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <body>\n          <h2>Click the \"Submit\" button to be redirected to domain B</h2>\n          <input type=\"button\" value=\"Submit\" onclick=\"submit()\"><br>\n          <iframe id=\"cross_domain_page\" src=\"http://example.test:8001/iframe\"  frameborder=\"0\" scrolling=\"no\" style=\"background:transparent;margin:auto;display:block\"></iframe>\n          <script>\n             function submit() {\n                fetch('/submit', {\n                     method: 'POST',\n                  })\n                  .then(res => {\n                     authHeader = res.headers.get('Authorization');\n                     if (authHeader.startsWith(\"Bearer \"))\n                        token = authHeader.substring(7, authHeader.length);\n                     return res.text();\n                  })\n                  .then(data => {\n                     document.getElementById('cross_domain_page').contentWindow.postMessage(token, \"http://example.test:8001\");\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n             }\n\n             window.addEventListener(\"message\", (event) => {\n                if (event.origin !== \"http://example.test:8001\")\n                  return;\n\n                if (event.data == \"token stored\")\n                  window.location.href = 'http://example.test:8001/redirect';\n             }, false);\n\n          </script>\n       </body>\n    </html>\n    \"\"\"\n@app.post('/submit')\nasync def submit():\n    token = 'MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3'\n    headers = {'Authorization': f'Bearer {token}'}\n    response = Response('success', headers=headers)\n    response.set_cookie(key='access-token', value=token, httponly=True)  # set cookie for domain A too\n    return response\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8000)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\n@app.get('/iframe', response_class=HTMLResponse)\nasync def iframe():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <head>\n          <script>\n             window.addEventListener(\"message\", (event) => {\n                if (event.origin !== \"http://127.0.0.1:8000\" && event.origin !== \"http://localhost:8000\")\n                   return;\n\n                localStorage.setItem('token', event.data);\n                event.source.postMessage(\"token stored\", event.origin);\n             }, false);\n          </script>\n       </head>\n    </html>\n    \"\"\"\n\n@app.get('/redirect', response_class=HTMLResponse)\nasync def redirect():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <head>\n          <script>\n            const token = localStorage.getItem('token');\n            localStorage.removeItem(\"token\");\n            fetch('/submit', {\n                  method: 'POST',\n                  headers: {\n                     'Authorization': `Bearer ${token}`\n                  }\n               })\n               .then(res => res.text())\n               .then(data => {\n                  window.location.href = 'http://example.test:8001/';\n               })\n               .catch(error => {\n                  console.error(error);\n               })\n          </script>\n       </head>\n    </html>\n    \"\"\"\n\n\n@app.get('/')\nasync def home(request: Request):\n    token = request.cookies.get('access-token')\n    return 'You have been successfully redirected to domain B!' \\\n           f' Your access token is: {token}'\n@app.post('/submit')\nasync def submit(request: Request, response: Response):\n    authHeader = request.headers.get('Authorization')\n    if authHeader.startswith(\"Bearer \"):\n        token = authHeader[7:]\n    response.set_cookie(key='access-token', value=token, httponly=True)\n    return 'success'\n\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8001)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Response\nfrom fastapi.responses import HTMLResponse\napp = FastAPI()\n@app.get('/', response_class=HTMLResponse)\nasync def home():\n    return \"\"\"\n    <!DOCTYPE html>\n    <html>\n       <body>\n          <h2>Click the \"Submit\" button to be redirected to domain B</h2>\n          <input type=\"button\" value=\"Submit\" onclick=\"submit()\"><br>\n          <script>\n            function submit() {\n               fetch('/submit', {\n                     method: 'POST',\n                  })\n                  .then(res => {\n                     authHeader = res.headers.get('Authorization');\n                     if (authHeader.startsWith(\"Bearer \"))\n                        token = authHeader.substring(7, authHeader.length);\n                     return res.text();\n                  })\n                  .then(data => {\n                     var url = 'http://example.test:8001/submit?token=' + encodeURIComponent(token);\n                     var img = document.createElement('img');\n                     img.style = 'display:none';\n                     img.crossOrigin = 'use-credentials'; // needed for CORS\n                     img.onerror = function(){\n\t\t\t\t\t\twindow.location.href = 'http://example.test:8001/';\n                     }\n                     img.src = url;\n                  })\n                  .catch(error => {\n                     console.error(error);\n                  });\n            }\n          </script>\n       </body>\n    </html>\n    \"\"\"\n\n@app.post('/submit')\nasync def submit():\n    token = 'MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3'\n    headers = {'Authorization': f'Bearer {token}'}\n    response = Response('success', headers=headers)\n    response.set_cookie(key='access-token', value=token, httponly=True)  # set cookie for domain A too\n    return response\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8000)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      },
      {
        "answer_id": 73599289,
        "body": "from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import RedirectResponse\nfrom fastapi.middleware.cors import CORSMiddleware\napp = FastAPI()\norigins = ['http://localhost:8000', 'http://127.0.0.1:8000',\n           'https://localhost:8000', 'https://127.0.0.1:8000']\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n@app.get('/')\nasync def home(request: Request):\n    token = request.cookies.get('access-token')\n    return 'You have been successfully redirected to domain B!' \\\n           f' Your access token is: {token}'\n\n@app.get('/submit')\nasync def submit(request: Request, response: Response, token: str):\n    response.set_cookie(key='access-token', value=token, samesite='none', secure=True, httponly=True)\n    return 'success'\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host='0.0.0.0', port=8001)",
        "score": 30,
        "is_accepted": false,
        "creation_date": "2022-09-04T08:11:48",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/63721614/unhashable-type-in-fastapi-request",
    "title": "Unhashable type in FastAPI request",
    "question_id": 63721614,
    "posted_date": "2020-09-03T06:20:30",
    "answers": [
      {
        "answer_id": 63774573,
        "body": "from pydantic import BaseModel\nfrom typing import Set\nclass MyBaseModel(BaseModel):\n    def __hash__(self):  # make hashable BaseModel subclass\n        return hash((type(self),) + tuple(self.__dict__.values()))\nclass Customer(MyBaseModel):  # Use hashable sublclass for your model\n    UID: str\n    CustName: str\nclass PackageIn(BaseModel):\n    lead_id: str\n    parties: Set[Customer]\n    # threshold: Optional[int] = 85\ndata = {\n    \"lead_id\": 'LD123',\n    \"parties\": [\n       {\n           \"UID\": 123123,\n           \"CustName\": \"JOhn Doe\",\n       }]}\nPackageIn.parse_obj(data) # This part fastapi will make on post request, just for test\n> <PackageIn lead_id='LD123' parties={<Customer UID='123123' CustName='JOhn Doe'>}>",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2020-09-07T05:09:38",
        "author": "Alexey Sherchenkov"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55819330/catching-exceptions-raised-in-qapplication",
    "title": "Catching exceptions raised in QApplication",
    "question_id": 55819330,
    "posted_date": "2019-04-23T16:57:23",
    "answers": [
      {
        "answer_id": 55819545,
        "body": "import sys\nimport traceback\nfrom PyQt5 import QtWidgets, QtGui, QtCore\nclass ErrorApp:\n    # ...\n    def raise_error(self):\n        assert False\ndef excepthook(exc_type, exc_value, exc_tb):\n    tb = \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n    print(\"error caught!:\")\n    print(\"error message:\\n\", tb)\n    QtWidgets.QApplication.quit()\n    # or QtWidgets.QApplication.exit(0)\nsys.excepthook = excepthook\ne = ErrorApp()\nret = e.app.exec_()\nprint(\"event loop exited\")\nsys.exit(ret)",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2019-04-23T17:17:47",
        "author": "eyllanesc"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/64294962/how-to-implement-learning-to-rank-using-lightgbm",
    "title": "How to implement learning to rank using lightgbm?",
    "question_id": 64294962,
    "posted_date": "2020-10-10T11:12:22",
    "answers": [
      {
        "answer_id": 67627169,
        "body": "query_id      var1      var2      var3  relevance\n0           0  0.624776  0.191463  0.598358          0\n1           0  0.258280  0.658307  0.148386          0\n2           0  0.893683  0.059482  0.340426          0\n3           0  0.879514  0.526022  0.712648          1\n4           0  0.188580  0.279471  0.062942          0\n..        ...       ...       ...       ...        ...\n995        99  0.509672  0.552873  0.166913          0\n996        99  0.244307  0.356738  0.925570          0\n997        99  0.827925  0.827747  0.695029          1\n998        99  0.476761  0.390823  0.670150          0\n999        99  0.241392  0.944994  0.671594          0\n[1000 rows x 5 columns]",
        "score": 28,
        "is_accepted": false,
        "creation_date": "2021-05-20T15:58:23",
        "author": "charelf"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/71581197/what-is-the-loss-function-used-in-trainer-from-the-transformers-library-of-huggi",
    "title": "What is the loss function used in Trainer from the Transformers library of Hugging Face?",
    "question_id": 71581197,
    "posted_date": "2022-03-22T22:35:51",
    "answers": [
      {
        "answer_id": 71585375,
        "body": "if labels is not None:\n    if self.config.problem_type is None:\n        if self.num_labels == 1:\n            self.config.problem_type = \"regression\"\n        elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n            self.config.problem_type = \"single_label_classification\"\n        else:\n            self.config.problem_type = \"multi_label_classification\"\n    if self.config.problem_type == \"regression\":\n        loss_fct = MSELoss()\n        if self.num_labels == 1:\n            loss = loss_fct(logits.squeeze(), labels.squeeze())\n        else:\n            loss = loss_fct(logits, labels)\n    elif self.config.problem_type == \"single_label_classification\":\n        loss_fct = CrossEntropyLoss()\n        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n    elif self.config.problem_type == \"multi_label_classification\":\n        loss_fct = BCEWithLogitsLoss()\n        loss = loss_fct(logits, labels)",
        "score": 26,
        "is_accepted": true,
        "creation_date": "2022-03-23T06:12:24",
        "author": "dennlinger"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60637120/detect-circles-in-opencv",
    "title": "Detect circles in openCV",
    "question_id": 60637120,
    "posted_date": "2020-03-11T09:24:14",
    "answers": [
      {
        "answer_id": 60644656,
        "body": "import cv2\nimport numpy as np\n# Load image, grayscale, median blur, Otsus threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.medianBlur(gray, 11)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n# Morph open\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\nopening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=3)\n# Find contours and filter using contour area and aspect ratio\ncnts = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    peri = cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n    area = cv2.contourArea(c)\n    if len(approx) > 5 and area > 1000 and area < 500000:\n        ((x, y), r) = cv2.minEnclosingCircle(c)\n        cv2.circle(image, (int(x), int(y)), int(r), (36, 255, 12), 2)\ncv2.imshow('thresh', thresh)\ncv2.imshow('opening', opening)\ncv2.imshow('image', image)\ncv2.waitKey()",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2020-03-11T17:26:01",
        "author": "nathancy"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/34593609/modifying-rules-for-a-given-ec2-security-group-with-boto3",
    "title": "Modifying rules for a given EC2 security group with Boto3",
    "question_id": 34593609,
    "posted_date": "2016-01-04T09:41:53",
    "answers": [
      {
        "answer_id": 69128078,
        "body": "import boto3\nclient = boto3.client('ec2')\nsg_rules_list = [{'SecurityGroupRuleId': 'sgr-07de36a0521f39c8b',\n                  'SecurityGroupRule': {\n                      'IpProtocol': 'tcp',\n                      'FromPort': 22,\n                      'ToPort': 22,\n                      'CidrIpv4': '3.3.3.3/32',\n                      'Description': 'added ssh port'\n                  }\n                  }\n                 ]\nresponse = client.modify_security_group_rules(GroupId='sg-00f3b9232325b20fb',\n                                              SecurityGroupRules=sg_rules_list)",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2021-09-10T02:25:06",
        "author": "Randhir"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/62988494/adjust-width-of-dropdown-menu-option-in-dash-plotly",
    "title": "Adjust width of dropdown menu option in Dash-Plotly",
    "question_id": 62988494,
    "posted_date": "2020-07-20T00:04:50",
    "answers": [
      {
        "answer_id": 62988751,
        "body": "app.layout = html.Div(\n    children=[\n        html.H1(children=\"Welcome to Portfolio Construction Engine!\"),\n        html.Div(\n            children=\"What would you like to do?\",\n            style={\"font-style\": \"italic\", \"font-weight\": \"bold\"},\n        ),\n        html.Div(\n            [\n                dcc.Dropdown(\n                    id=\"demo-dropdown\",\n                    options=[\n                        {\"label\": \"Upload Scores\", \"value\": \"upload_scores\"},\n                        {\"label\": \"Analyze Portfolios\", \"value\": \"analyze_portfoliio\"},\n                        {\n                            \"label\": \"Generate Data for IC Engine\",\n                            \"value\": \"gen_data_ic_engine\",\n                        },\n                    ],\n                    placeholder=\"Select a task...\",\n                    # style={\"width\": \"50%\"},  NOT HERE\n                ),\n                html.Div(id=\"dd-output-container\"),\n            ],\n            style={\"width\": \"50%\"},\n        ),\n    ]\n)",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-07-20T00:37:18",
        "author": "lahsuk"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61112684/how-to-subclass-a-dictionary-so-it-supports-generic-type-hints",
    "title": "How to subclass a dictionary so it supports generic type hints?",
    "question_id": 61112684,
    "posted_date": "2020-04-08T21:44:57",
    "answers": [
      {
        "answer_id": 64323140,
        "body": "from collections import abc  # Used for isinstance check in `update()`.\nfrom typing import Dict, Iterator, MutableMapping, TypeVar\nKT = TypeVar('KT')\nVT = TypeVar('VT')\nclass MyDict(MutableMapping[KT, VT]):\n    def __init__(self, dictionary=None, /, **kwargs) -> None:\n        self.data: Dict[KT, VT] = {}\n        if dictionary is not None:\n            self.update(dictionary)\n        if kwargs:\n            self.update(kwargs)\n\n    def __contains__(self, key: KT) -> bool:\n        return key in self.data\n    def __delitem__(self, key: KT) -> None:\n        del self.data[key]\n    def __getitem__(self, key: KT) -> VT:\n        if key in self.data:\n            return self.data[key]\n        raise KeyError(key)\n    def __len__(self) -> int:\n        return len(self.data)\n    def __iter__(self) -> Iterator[KT]:\n        return iter(self.data)\n    def __setitem__(self, key: KT, value: VT) -> None:\n        self.data[key] = value\n\n    @classmethod\n    def fromkeys(cls, iterable: Iterable[KT], value: VT) -> \"MyDict\":\n        \"\"\"Create a new dictionary with keys from `iterable` and values set\n        to `value`.\n        Args:\n            iterable: A collection of keys.\n            value: The default value. All of the values refer to just a single\n                instance, so it generally does not make sense for `value` to be a\n                mutable object such as an empty list. To get distinct values, use\n                a dict comprehension instead.\n        Returns:\n            A new instance of MyDict.\n        \"\"\"\n        d = cls()\n        for key in iterable:\n            d[key] = value\n        return d\n    def update(self, other=(), /, **kwds) -> None:\n        \"\"\"Updates the dictionary from an iterable or mapping object.\"\"\"\n        if isinstance(other, abc.Mapping):\n            for key in other:\n                self.data[key] = other[key]\n        elif hasattr(other, \"keys\"):\n            for key in other.keys():\n                self.data[key] = other[key]\n        else:\n            for key, value in other:\n                self.data[key] = value\n        for key, value in kwds.items():\n            self.data[key] = value",
        "score": 15,
        "is_accepted": false,
        "creation_date": "2020-10-12T14:07:55",
        "author": "Christopher Peisert"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/44760221/pyodbc-connect-works-but-not-sqlalchemy-create-engine-connect",
    "title": "pyodbc.connect() works, but not sqlalchemy.create_engine().connect()",
    "question_id": 44760221,
    "posted_date": "2017-06-26T08:52:50",
    "answers": [
      {
        "answer_id": 44764826,
        "body": "import pandas as pd\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine import URL\nconnection_string = (\n    r\"Driver=ODBC Driver 17 for SQL Server;\"\n    r\"Server=(local)\\SQLEXPRESS;\"\n    r\"Database=myDb;\"\n    r\"Trusted_Connection=yes;\"\n)\nconnection_url = URL.create(\n    \"mssql+pyodbc\",\n    query={\"odbc_connect\": connection_string}\n)\nengine = create_engine(connection_url)\ndf = pd.DataFrame([(1, \"foo\")], columns=[\"id\", \"txt\"])\npd.to_sql(\"test_table\", engine, if_exists=\"replace\", index=False)",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2017-06-26T12:59:10",
        "author": "Gord Thompson"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70866415/how-to-install-python-specific-version-on-docker",
    "title": "How to install python specific version on docker?",
    "question_id": 70866415,
    "posted_date": "2022-01-26T10:59:34",
    "answers": [
      {
        "answer_id": 70866416,
        "body": "# compile python from source - avoid unsupported library problems\nRUN apt update -y && sudo apt upgrade -y && \\\n    apt-get install -y wget build-essential checkinstall  libreadline-gplv2-dev  libncursesw5-dev  libssl-dev  libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev libffi-dev zlib1g-dev && \\\n    cd /usr/src && \\\n    sudo wget https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tgz && \\\n    sudo tar xzf Python-3.8.10.tgz && \\\n    cd Python-3.8.10 && \\\n    sudo ./configure --enable-optimizations && \\\n    sudo make altinstall",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2022-01-26T10:59:34",
        "author": "Gulzar"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57909401/what-are-the-command-line-arguments-passed-to-grpc-tools-protoc",
    "title": "What are the command line arguments passed to grpc_tools.protoc",
    "question_id": 57909401,
    "posted_date": "2019-09-12T10:53:53",
    "answers": [
      {
        "answer_id": 58020359,
        "body": "$ python -m grpc.tools.protoc -h\nUsage: /usr/local/google/home/lidiz/.local/lib/python2.7/site-packages/grpc_tools/protoc.py [OPTION] PROTO_FILES\nParse PROTO_FILES and generate output based on the options given:\n  -IPATH, --proto_path=PATH   Specify the directory in which to search for\n                              imports.  May be specified multiple times;\n                              directories will be searched in order.  If not\n                              given, the current working directory is used.\n  --version                   Show version info and exit.\n  -h, --help                  Show this text and exit.\n  --encode=MESSAGE_TYPE       Read a text-format message of the given type\n                              from standard input and write it in binary\n                              to standard output.  The message type must\n                              be defined in PROTO_FILES or their imports.\n  --decode=MESSAGE_TYPE       Read a binary message of the given type from\n                              standard input and write it in text format\n                              to standard output.  The message type must\n                              be defined in PROTO_FILES or their imports.\n  --decode_raw                Read an arbitrary protocol message from\n                              standard input and write the raw tag/value\n                              pairs in text format to standard output.  No\n                              PROTO_FILES should be given when using this\n                              flag.\n  --descriptor_set_in=FILES   Specifies a delimited list of FILES\n                              each containing a FileDescriptorSet (a\n                              protocol buffer defined in descriptor.proto).\n                              The FileDescriptor for each of the PROTO_FILES\n                              provided will be loaded from these\n                              FileDescriptorSets. If a FileDescriptor\n                              appears multiple times, the first occurrence\n                              will be used.\n  -oFILE,                     Writes a FileDescriptorSet (a protocol buffer,\n    --descriptor_set_out=FILE defined in descriptor.proto) containing all of\n                              the input files to FILE.\n  --include_imports           When using --descriptor_set_out, also include\n                              all dependencies of the input files in the\n                              set, so that the set is self-contained.\n  --include_source_info       When using --descriptor_set_out, do not strip\n                              SourceCodeInfo from the FileDescriptorProto.\n                              This results in vastly larger descriptors that\n                              include information about the original\n                              location of each decl in the source file as\n                              well as surrounding comments.\n  --dependency_out=FILE       Write a dependency output file in the format\n                              expected by make. This writes the transitive\n                              set of input file paths to FILE\n  --error_format=FORMAT       Set the format in which to print errors.\n                              FORMAT may be 'gcc' (the default) or 'msvs'\n                              (Microsoft Visual Studio format).\n  --print_free_field_numbers  Print the free field numbers of the messages\n                              defined in the given proto files. Groups share\n                              the same field number space with the parent\n                              message. Extension ranges are counted as\n                              occupied fields numbers.\n  --plugin=EXECUTABLE         Specifies a plugin executable to use.\n                              Normally, protoc searches the PATH for\n                              plugins, but you may specify additional\n                              executables not in the path using this flag.\n                              Additionally, EXECUTABLE may be of the form\n                              NAME=PATH, in which case the given plugin name\n                              is mapped to the given executable even if\n                              the executable's own name differs.\n  --grpc_python_out=OUT_DIR   Generate Python source file.\n  --python_out=OUT_DIR        Generate Python source file.\n  @<filename>                 Read options and filenames from file. If a\n                              relative file path is specified, the file\n                              will be searched in the working directory.\n                              The --proto_path option will not affect how\n                              this argument file is searched. Content of\n                              the file will be expanded in the position of\n                              @<filename> as in the argument list. Note\n                              that shell expansion is not applied to the\n                              content of the file (i.e., you cannot use\n                              quotes, wildcards, escapes, commands, etc.).\n                              Each line corresponds to a single argument,\n                              even if it contains spaces.",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2019-09-19T20:38:33",
        "author": "Lidi Zheng"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48925086/choosing-subset-of-farthest-points-in-given-set-of-points",
    "title": "Choosing subset of farthest points in given set of points",
    "question_id": 48925086,
    "posted_date": "2018-02-22T05:29:28",
    "answers": [
      {
        "answer_id": 60955896,
        "body": "import numpy as np\nfrom scipy.spatial import ConvexHull\nfrom scipy.spatial.distance import cdist\np = 300\nN = 16000000\n# Find a convex hull in O(N log N)\npoints = np.random.rand(N, 3)   # N random points in 3-D\n# Returned 420 points in testing\nhull = ConvexHull(points)\n# Extract the points forming the hull\nhullpoints = points[hull.vertices,:]\n# Naive way of finding the best pair in O(H^2) time if H is number of points on\n# hull\nhdist = cdist(hullpoints, hullpoints, metric='euclidean')\n# Get the farthest apart points\nbestpair = np.unravel_index(hdist.argmax(), hdist.shape)\nP = np.array([hullpoints[bestpair[0]],hullpoints[bestpair[1]]])\n# Now we have a problem\nprint(\"Finding optimal set...\")\nwhile len(P)<p:\n  print(\"P size = {0}\".format(len(P)))\n  distance_to_P        = cdist(points, P)\n  minimum_to_each_of_P = np.min(distance_to_P, axis=1)\n  best_new_point_idx   = np.argmax(minimum_to_each_of_P)\n  best_new_point = np.expand_dims(points[best_new_point_idx,:],0)\n  P = np.append(P,best_new_point,axis=0)\nprint(P)",
        "score": 18,
        "is_accepted": true,
        "creation_date": "2020-03-31T12:57:18",
        "author": "Richard"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/36937461/how-can-i-send-an-email-using-python-loggings-smtphandler-and-ssl",
    "title": "How can I send an email using python logging&#39;s SMTPHandler and SSL",
    "question_id": 36937461,
    "posted_date": "2016-04-29T07:41:33",
    "answers": [
      {
        "answer_id": 36937462,
        "body": "from email.message import EmailMessage\nimport email.utils\nclass SSLSMTPHandler(SMTPHandler):\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n        \"\"\"\n        try:\n            port = self.mailport\n            if not port:\n                port = smtplib.SMTP_PORT\n            smtp = smtplib.SMTP_SSL(self.mailhost, port)\n            msg = EmailMessage()\n            msg['From'] = self.fromaddr\n            msg['To'] = ','.join(self.toaddrs)\n            msg['Subject'] = self.getSubject(record)\n            msg['Date'] = email.utils.localtime()\n            msg.set_content(self.format(record))\n            if self.username:\n                smtp.login(self.username, self.password)\n            smtp.send_message(msg, self.fromaddr, self.toaddrs)\n            smtp.quit()\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)",
        "score": 23,
        "is_accepted": true,
        "creation_date": "2016-04-29T07:41:33",
        "author": "thclark"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/72610552/most-replayed-data-of-youtube-video-via-api",
    "title": "&quot;Most Replayed&quot; Data of YouTube Video via API",
    "question_id": 72610552,
    "posted_date": "2022-06-13T21:17:17",
    "answers": [
      {
        "answer_id": 72624653,
        "body": "{\n    \"kind\": \"youtube#videoListResponse\",\n    \"etag\": \"NotImplemented\",\n    \"items\": [\n        {\n            \"kind\": \"youtube#video\",\n            \"etag\": \"NotImplemented\",\n            \"id\": \"XiCrniLQGYc\",\n            \"mostReplayed\": {\n                \"markers\": [\n                    {\n                        \"startMillis\": 0,\n                        \"intensityScoreNormalized\": 1\n                    },\n                    {\n                        \"startMillis\": 2580,\n                        \"intensityScoreNormalized\": 0.7083409245967562\n                    },\n                    {\n                        \"startMillis\": 5160,\n                        \"intensityScoreNormalized\": 0.6381007317793738\n                    },\n                    ...\n                    {\n                        \"startMillis\": 255420,\n                        \"intensityScoreNormalized\": 0.012864077773078256\n                    }\n                ],\n                \"timedMarkerDecorations\": [\n                    {\n                        \"visibleTimeRangeStartMillis\": 0,\n                        \"visibleTimeRangeEndMillis\": 10320\n                    }\n                ]\n            }\n        }\n    ]\n}",
        "score": 21,
        "is_accepted": true,
        "creation_date": "2022-06-14T20:13:44",
        "author": "Benjamin Loison"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/59996493/does-await-always-give-other-tasks-a-chance-to-execute",
    "title": "Does await always give other tasks a chance to execute?",
    "question_id": 59996493,
    "posted_date": "2020-01-30T19:33:26",
    "answers": [
      {
        "answer_id": 59998823,
        "body": "import asyncio\nimport time\nasync def caller1():\n    for i in range(5):\n        await callee1()\nasync def callee1():\n    await asyncio.sleep(1)\n    print(f\"called at {time.strftime('%X')}\")\nasync def caller2():\n    for i in range(5):\n        await callee2()\nasync def callee2():\n    time.sleep(1)\n    print(f\"sync called at {time.strftime('%X')}\")\nasync def main():\n    task1 = asyncio.create_task(caller1())\n    task2 = asyncio.create_task(caller2())\n    await task1\n    await task2\nasyncio.run(main())",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2020-01-31T01:19:06",
        "author": "Hurried-Helpful"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60873454/how-can-i-list-all-the-virtual-environments-created-with-venv",
    "title": "How can I list all the virtual environments created with venv?",
    "question_id": 60873454,
    "posted_date": "2020-03-26T14:02:25",
    "answers": [
      {
        "answer_id": 60876151,
        "body": "`\njvenvfindall(){  # search for Python virtual envs.  -v for verbose details\n    unset verbose\n\n    OPTIND=1\n    while getopts 'v' OPTION; do\n      case \"$OPTION\" in\n\n        v)\n          verbose=1\n          ;;\n\n        ?)\n          ;;\n      esac\n    done\n    shift \"$(($OPTIND -1))\"\n\n\n    local bup=$PWD\n    for dn in $(mdfind -name activate | egrep /bin/activate$|  xargs -o egrep -l nondestructive 2>/dev/null | xargs -L 1 dirname | xargs -L 1 dirname)\n    do\n        if [[ -z \"$verbose\" ]]; then\n            printf \"$dn\\n\"\n        else\n            printf \"\\n\\nvenv info for $dn:\\n\"\n            cd $dn\n            echo space usage, $(du -d 0 -h)\n            #requires the jq and jc utilities... to extract create and modification times\n            echo create, mod dttm: $(stat . | jc --stat | jq '.[]|{birth_time, change_time}')\n            tree -d -L 1 lib\n        fi\n    done\n    cd $bup\n}",
        "score": 14,
        "is_accepted": true,
        "creation_date": "2020-03-26T17:07:56",
        "author": "JL Peyret"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/51525237/how-to-set-up-httphandler-for-python-logging",
    "title": "How to set up HTTPHandler for python logging",
    "question_id": 51525237,
    "posted_date": "2018-07-25T14:10:04",
    "answers": [
      {
        "answer_id": 64360700,
        "body": "import json\nimport logging\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry\nclass CustomHttpHandler(logging.Handler):\n    def __init__(self, url: str, token: str, silent: bool = True):\n        '''\n        Initializes the custom http handler\n        Parameters:\n            url (str): The URL that the logs will be sent to\n            token (str): The Authorization token being used\n            silent (bool): If False the http response and logs will be sent\n                           to STDOUT for debug\n        '''\n        self.url = url\n        self.token = token\n        self.silent = silent\n        # sets up a session with the server\n        self.MAX_POOLSIZE = 100\n        self.session = session = requests.Session()\n        session.headers.update({\n            'Content-Type': 'application/json',\n            'Authorization': 'Bearer %s' % (self.token)\n        })\n        self.session.mount('https://', HTTPAdapter(\n            max_retries=Retry(\n                total=5,\n                backoff_factor=0.5,\n                status_forcelist=[403, 500]\n            ),\n            pool_connections=self.MAX_POOLSIZE,\n            pool_maxsize=self.MAX_POOLSIZE\n        ))\n        super().__init__()\n    def emit(self, record):\n        '''\n        This function gets called when a log event gets emitted. It recieves a\n        record, formats it and sends it to the url\n        Parameters:\n            record: a log record\n        '''\n        logEntry = self.format(record)\n        response = self.session.post(self.url, data=logEntry)\n        if not self.silent:\n            print(logEntry)\n            print(response.content)\n# create logger\nlog = logging.getLogger('')\nlog.setLevel(logging.INFO)\n# create formatter - this formats the log messages accordingly\nformatter = logging.Formatter(json.dumps({\n    'time': '%(asctime)s',\n    'pathname': '%(pathname)s',\n    'line': '%(lineno)d',\n    'logLevel': '%(levelname)s',\n    'message': '%(message)s'\n}))\n# create a custom http logger handler\nhttpHandler = CustomHttpHandler(\n    url='<YOUR_URL>',\n    token='<YOUR_TOKEN>',\n    silent=False\n)\nhttpHandler.setLevel(logging.INFO)\n# add formatter to custom http handler\nhttpHandler.setFormatter(formatter)\n# add handler to logger\nlog.addHandler(httpHandler)\nlog.info('Hello world!')",
        "score": 10,
        "is_accepted": false,
        "creation_date": "2020-10-14T16:01:07",
        "author": "Istvan"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15667578/how-do-i-install-mezzanine-as-a-django-app",
    "title": "How do I install Mezzanine as a Django app?",
    "question_id": 15667578,
    "posted_date": "2013-03-27T15:19:41",
    "answers": [
      {
        "answer_id": 27972009,
        "body": "`\n    ...\n    \"mezzanine.core.request.CurrentRequestMiddleware\",\n\t\"mezzanine.core.middleware.RedirectFallbackMiddleware\",\n\t\"mezzanine.core.middleware.TemplateForDeviceMiddleware\",\n\t\"mezzanine.core.middleware.TemplateForHostMiddleware\",\n\t\"mezzanine.core.middleware.AdminLoginInterfaceSelectorMiddleware\",\n\t\"mezzanine.core.middleware.SitePermissionMiddleware\",\n\t# Uncomment the following if using any of the SSL settings:\n\t# \"mezzanine.core.middleware.SSLRedirectMiddleware\",\n\t\"mezzanine.pages.middleware.PageMiddleware\",\n    ....",
        "score": 13,
        "is_accepted": false,
        "creation_date": "2015-01-15T15:02:41",
        "author": "Bobby"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/73458524/importerror-dll-load-failed-while-importing-ctypes-the-specified-module-coul",
    "title": "ImportError: DLL load failed while importing _ctypes : The specified module could not be found",
    "question_id": 73458524,
    "posted_date": "2022-08-23T08:12:16",
    "answers": [
      {
        "answer_id": 76791146,
        "body": ">    [cfati@CFATI-5510-0:E:\\Work\\Dev\\StackExchange\\StackOverflow\\q073458524]> sopr.bat\n    >    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n    >\n    >    [prompt]>\n    >    [prompt]> $_CTss = Get-ChildItem 'c:\\Install\\pc064\\Python\\Python' -Filter '_ctypes.pyd' -Recurse\n    >    [prompt]> foreach ($_CTs in $_CTss) {\n    >    >>     echo $_CTs.FullName\n    >    >>     Start-Process -Wait -FilePath 'c:\\Install\\pc064\\Depends\\DependencyWalkerPolitistTexan\\Version\\depends.exe' -ArgumentList '-c', '-ot:out.txt', $_CTs.FullName\n    >    >>     Get-Content 'out.txt' | Select-String 'FFI.*\\.DLL$'\n    >    >> }\n    >    C:\\Install\\pc064\\Python\\Python\\02.07.18\\DLLs\\_ctypes.pyd\n    >    C:\\Install\\pc064\\Python\\Python\\03.04.04\\DLLs\\_ctypes.pyd\n    >    C:\\Install\\pc064\\Python\\Python\\03.05.04\\DLLs\\_ctypes.pyd\n    >    C:\\Install\\pc064\\Python\\Python\\03.06.08\\DLLs\\_ctypes.pyd\n    >    C:\\Install\\pc064\\Python\\Python\\03.07.09\\DLLs\\_ctypes.pyd\n    >    C:\\Install\\pc064\\Python\\Python\\03.08\\DLLs\\_ctypes.pyd\n    >\n    >         [  6] c:\\install\\pc064\\python\\python\\03.08\\dlls\\LIBFFI-7.DLL\n    >    C:\\Install\\pc064\\Python\\Python\\03.09\\DLLs\\_ctypes.pyd\n    >         [  6] c:\\install\\pc064\\python\\python\\03.09\\dlls\\LIBFFI-7.DLL\n    >    C:\\Install\\pc064\\Python\\Python\\03.10\\DLLs\\_ctypes.pyd\n    >         [  6] c:\\install\\pc064\\python\\python\\03.10\\dlls\\LIBFFI-7.DLL\n    >    C:\\Install\\pc064\\Python\\Python\\03.11\\DLLs\\_ctypes.pyd\n    >         [  6] c:\\install\\pc064\\python\\python\\03.11\\dlls\\LIBFFI-8.DLL\n    >",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    [cristian.fati@cfati-16i2019-0:~/Work/Dev/StackExchange/StackOverflow/q073458524]> ~/sopr.sh\n    >    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n    >\n    >    Running OSX\n    >    [064bit prompt]>\n    >    [064bit prompt]> uname -a\n    >    Darwin cfati-16i2019-0 22.5.0 Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:22 PDT 2023; root:xnu-8796.121.3~7/RELEASE_X86_64 x86_64\n    >    [064bit prompt]>\n    >    [064bit prompt]> for g in 7 8 9 10 11; do _CTS=$(python3.${g} -c \"import ctypes;print(_ctypes.__file__)\"); echo ${_CTS}; otool -L ${_CTS} | grep ffi; done\n    >    /usr/local/cellar/python@3.7/3.7.16/frameworks/python.framework/versions/3.7/lib/python3.7/lib-dynload/_ctypes.cpython-37m-darwin.so\n    >    /usr/local/cellar/python@3.8/3.8.17_1/frameworks/python.framework/versions/3.8/lib/python3.8/lib-dynload/_ctypes.cpython-38-darwin.so\n    >    \t/usr/lib/libffi.dylib (compatibility version 1.0.0, current version 30.0.0)\n    >    /usr/local/cellar/python@3.9/3.9.17_1/frameworks/python.framework/versions/3.9/lib/python3.9/lib-dynload/_ctypes.cpython-39-darwin.so\n    >    \t/usr/lib/libffi.dylib (compatibility version 1.0.0, current version 30.0.0)\n    >    /usr/local/cellar/python@3.10/3.10.12_1/frameworks/python.framework/versions/3.10/lib/python3.10/lib-dynload/_ctypes.cpython-310-darwin.so\n    >    \t/usr/lib/libffi.dylib (compatibility version 1.0.0, current version 30.0.0)\n    >    /usr/local/cellar/python@3.11/3.11.4_1/frameworks/python.framework/versions/3.11/lib/python3.11/lib-dynload/_ctypes.cpython-311-darwin.so\n    >    \t/usr/lib/libffi.dylib (compatibility version 1.0.0, current version 30.0.0)\n    >",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    (qaic-env) [cfati@cfati-5510-0:/mnt/e/Work/Dev/StackExchange/StackOverflow/q073458524]> ~/sopr.sh\n    >    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n    >\n    >    [064bit prompt]>\n    >    [064bit prompt]> uname -a\n    >    Linux cfati-5510-0 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n    >    [064bit prompt]>\n    >    [064bit prompt]> for g in 5 6 7 8 9 10 11 12; do _CTS=$(python3.${g} -c \"import _ctypes;print(_ctypes.__file__)\"); echo ${_CTS}; ldd ${_CTS} | grep ffi; done\n    >    /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\n    >        libffi.so.7 => /lib/x86_64-linux-gnu/libffi.so.7 (0x00007ff1fb7d1000)\n    >    /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so\n    >        libffi.so.7 => /lib/x86_64-linux-gnu/libffi.so.7 (0x00007f0bf4ec5000)\n    >    /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007fc2a3ae6000)\n    >    /usr/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007f32b6176000)\n    >    /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007f40e590a000)\n    >    /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007f20bcbc7000)\n    >    /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007f01a5555000)\n    >    /usr/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so\n    >        libffi.so.8 => /lib/x86_64-linux-gnu/libffi.so.8 (0x00007f4a95e2d000)\n    >",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    [root@cfati-5510-0:/work/q073458524]> ~/sopr.sh\n    >    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n    >\n    >    [064bit prompt]>\n    >    [064bit prompt]> cat /etc/os-release | grep PRODUCT\n    >    REDHAT_SUPPORT_PRODUCT=\"centos\"\n    >    REDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\n    >    [064bit prompt]>\n    >    [064bit prompt]> for g in 2.7 3.6; do _CTS=$(python${g} -c \"import _ctypes;print(_ctypes.__file__)\"); echo ${_CTS}; ldd ${_CTS} | grep ffi; done\n    >    /usr/lib64/python2.7/lib-dynload/_ctypes.so\n    >        libffi.so.6 => /lib64/libffi.so.6 (0x00007f6529d71000)\n    >    /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so\n    >        libffi.so.6 => /lib64/libffi.so.6 (0x00007f1085acc000)\n    >",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    (base) [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackExchange\\StackOverflow\\q073458524]> :: ------- Anaconda Prompt -------\n>    (base) [cfati@CFATI-5510-0:e:\\Work\\Dev\\StackExchange\\StackOverflow\\q073458524]> cd /d f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\n>\n>    (base) [cfati@CFATI-5510-0:f:\\Install\\pc064\\Anaconda\\Anaconda\\Version]> sopr.bat\n>    ### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n>\n>    [prompt]> :: Reactivate base to have active environment in prompt\n>    [prompt]> conda deactivate & conda activate base\n>\n>    (base) [prompt]> :: ------- Anaconda Prompt (still) -------\n>    (base) [prompt]> :: ------- ${ANACONDA_INSTALL_PATH} is a placeholder for f:\\Install\\pc064\\Anaconda\\Anaconda\\Version -------\n>    (base) [prompt]> conda env list\n>    # conda environments:\n>    #\n>                             F:\\Install\\pc032\\Intel\\OneAPI\\Version\\intelpython\\python3.7\n>                             F:\\Install\\pc032\\Intel\\OneAPI\\Version\\intelpython\\python3.7\\envs\\2021.1.1\n>    base                  *  ${ANACONDA_INSTALL_PATH}\n>    py_pc032_030602_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc032_030602_00\n>    py_pc064_030610_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030610_00\n>    py_pc064_030704_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030704_00\n>    py_pc064_030716_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030716_00\n>    py_pc064_030800_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030800_00\n>    py_pc064_030808_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030808_00\n>    py_pc064_030817_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\n>    py_pc064_030900_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030900_00\n>    py_pc064_030917_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_00\n>    py_pc064_030917_01       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_01\n>    py_pc064_031000_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031000_00\n>    py_pc064_031006_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031006_00\n>    py_pc064_031012_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_00\n>    py_pc064_031012_01       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_01\n>    py_pc064_031104_00       ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031104_00\n>\n>\n>    (base) [prompt]>\n>    (base) [prompt]> :: Search environments for _ctypes.pyd\n>    (base) [prompt]> dir /B /S \"envs\\*_ctypes.pyd\"\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc032_030602_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030610_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030610_00\\DLLs\\instrumented\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030704_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030704_00\\DLLs\\instrumented\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030716_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030800_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030800_00\\DLLs\\instrumented\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030808_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030900_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_01\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031000_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031006_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_00\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_01\\DLLs\\_ctypes.pyd\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031104_00\\DLLs\\_ctypes.pyd\n>\n>    (base) [prompt]>\n>    (base) [prompt]> :: Search environments for the FFI dll\n>    (base) [prompt]> dir /B /S \"envs\\*ffi*.dll\"\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030800_00\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030808_00\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030817_00\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030900_00\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_00\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_030917_01\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031000_00\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031000_00\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031000_00\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031006_00\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031006_00\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031006_00\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_00\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_00\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_00\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_01\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_01\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031012_01\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031104_00\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031104_00\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\envs\\py_pc064_031104_00\\Library\\bin\\ffi.dll\n>",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    (base) [prompt]> :: ------- Anaconda Prompt (still) -------\n>    (base) [prompt]> :: ------- ${ANACONDA_INSTALL_PATH} is a placeholder for f:\\Install\\pc064\\Anaconda\\Anaconda\\Version -------\n>    (base) [prompt]> dir /B /S \"pkgs\\*ffi*.dll\"\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_4\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_4\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_4\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_6\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_6\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.2-hd77b12b_6\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.4-hd77b12b_0\\Library\\bin\\ffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.4-hd77b12b_0\\Library\\bin\\ffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\libffi-3.4.4-hd77b12b_0\\Library\\bin\\ffi.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.0-hff0d562_2\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.12-h6244533_0\\DLLs\\libffi-8.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.13-h6244533_0\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.17-h1aa4202_0\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.5-h5fd99cc_1\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.8.8-hdbf39b2_5\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.9.0-h6244533_2\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.9.12-h6244533_0\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.9.16-h6244533_2\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.9.17-h1aa4202_0\\DLLs\\libffi-7.dll\n>    ${ANACONDA_INSTALL_PATH}\\pkgs\\python-3.9.17-h6244533_0\\DLLs\\libffi-7.dll\n>",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    (base) [prompt]> :: ------- Anaconda Prompt (still) -------\n    >    (base) [prompt]> :: --- PATH in active (base) environment ---\n    >    (base) [prompt]> echo off & (for %g in (\"%PATH:;=\" \"%\") do (echo %~g)) & echo on\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\Library\\mingw-w64\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\Library\\usr\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\Library\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\Scripts\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\condabin\n    >    C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\n    >    C:\\WINDOWS\\System32\n    >    C:\\WINDOWS\n    >    C:\\WINDOWS\\System32\\Wbem\n    >    C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin\n    >    C:\\Program Files\\dotnet\n    >    e:\\Work\\Dev\\Utils\\current\\Win\n    >    e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\n    >    C:\\Users\\cfati\\.dotnet\\tools\n    >    .\n    >\n    >    (base) [prompt]>\n    >    (base) [prompt]> :: --- Activate Python 3.10.12 environment ---\n    >    (base) [prompt]> conda activate py_pc064_031012_00\n    >\n    >    (py_pc064_031012_00) [prompt]> :: --- PATH in active (py_pc064_031012_00) environment ---\n    >    (py_pc064_031012_00) [prompt]> echo off & (for %g in (\"%PATH:;=\" \"%\") do (echo %~g)) & echo on\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\\Library\\mingw-w64\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\\Library\\usr\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\\Library\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\\Scripts\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\envs\\py_pc064_031012_00\\bin\n    >    f:\\Install\\pc064\\Anaconda\\Anaconda\\Version\\condabin\n    >    C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\n    >    C:\\WINDOWS\\System32\n    >    C:\\WINDOWS\n    >    C:\\WINDOWS\\System32\\Wbem\n    >    C:\\Install\\pc064\\Docker\\Docker\\Version\\Docker\\resources\\bin\n    >    C:\\Program Files\\dotnet\n    >    e:\\Work\\Dev\\Utils\\current\\Win\n    >    e:\\Work\\Dev\\VEnvs\\py_pc064_03.10_test0\\Scripts\n    >    C:\\Users\\cfati\\.dotnet\\tools\n    >    .\n    >",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      },
      {
        "answer_id": 76791146,
        "body": ">    (py_pc064_031012_00) [prompt]> :: ------- Anaconda Prompt (still) -------\n>    (py_pc064_031012_00) [prompt]> \"f:\\Install\\pc064\\LucasG\\DependencyWalkerPolitistTexan\\Version\\DependenciesGui.exe\" \"envs\\%CONDA_DEFAULT_ENV%\\DLLs\\_ctypes.pyd\"\n>\n>    (py_pc064_031012_00) [prompt]> conda deactivate & conda activate py_pc064_030817_00\n>\n>    (py_pc064_030817_00) [prompt]> \"f:\\Install\\pc064\\LucasG\\DependencyWalkerPolitistTexan\\Version\\DependenciesGui.exe\" \"envs\\%CONDA_DEFAULT_ENV%\\DLLs\\_ctypes.pyd\"\n>",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2023-07-28T17:37:02",
        "author": "CristiFati"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/40447290/python-unittest-and-multithreading",
    "title": "Python unittest and multithreading",
    "question_id": 40447290,
    "posted_date": "2016-11-06T03:17:54",
    "answers": [
      {
        "answer_id": 60625943,
        "body": "import unittest\nimport threading\nfrom concurrent import futures\nclass catch_threading_exception:\n    \"\"\"\n    https://docs.python.org/3/library/test.html#test.support.catch_threading_exception\n    Context manager catching threading.Thread exception using\n    threading.excepthook.\n    Attributes set when an exception is catched:\n    * exc_type\n    * exc_value\n    * exc_traceback\n    * thread\n    See threading.excepthook() documentation for these attributes.\n    These attributes are deleted at the context manager exit.\n    Usage:\n        with support.catch_threading_exception() as cm:\n            # code spawning a thread which raises an exception\n            ...\n            # check the thread exception, use cm attributes:\n            # exc_type, exc_value, exc_traceback, thread\n            ...\n        # exc_type, exc_value, exc_traceback, thread attributes of cm no longer\n        # exists at this point\n        # (to avoid reference cycles)\n    \"\"\"\n    def __init__(self):\n        self.exc_type = None\n        self.exc_value = None\n        self.exc_traceback = None\n        self.thread = None\n        self._old_hook = None\n    def _hook(self, args):\n        self.exc_type = args.exc_type\n        self.exc_value = args.exc_value\n        self.exc_traceback = args.exc_traceback\n        self.thread = args.thread\n    def __enter__(self):\n        self._old_hook = threading.excepthook\n        threading.excepthook = self._hook\n        return self\n    def __exit__(self, *exc_info):\n        threading.excepthook = self._old_hook\n        del self.exc_type\n        del self.exc_value\n        del self.exc_traceback\n        del self.thread\nclass MyTests(unittest.TestCase):\n    def test_tpe(self):\n        with futures.ThreadPoolExecutor() as pool:\n            pool.submit(self.fail).result()\n    def test_t_excepthook(self):\n        with catch_threading_exception() as cm:\n            t = threading.Thread(target=self.fail)\n            t.start()\n            t.join()\n            if cm.exc_value is not None:\n                raise cm.exc_value\nif __name__ == '__main__':\n    unittest.main()",
        "score": 7,
        "is_accepted": false,
        "creation_date": "2020-03-10T17:07:40",
        "author": "Thomas Grainger"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/35851782/why-does-handling-multiple-exceptions-require-a-tuple-but-not-a-list",
    "title": "Why does handling multiple exceptions require a tuple, but not a list?",
    "question_id": 35851782,
    "posted_date": "2016-03-07T14:00:25",
    "answers": [
      {
        "answer_id": 35852234,
        "body": "case PyCmp_EXC_MATCH:\n    if (PyTuple_Check(w)) {\n        Py_ssize_t i, length;\n        length = PyTuple_Size(w);\n        for (i = 0; i < length; i += 1) {\n            PyObject *exc = PyTuple_GET_ITEM(w, i);\n            if (!PyExceptionClass_Check(exc)) {\n                _PyErr_SetString(tstate, PyExc_TypeError,\n                                 CANNOT_CATCH_MSG);\n                return NULL;\n            }\n        }\n    }\n    else {\n        if (!PyExceptionClass_Check(w)) {\n            _PyErr_SetString(tstate, PyExc_TypeError,\n                             CANNOT_CATCH_MSG);\n            return NULL;\n        }\n    }\n    res = PyErr_GivenExceptionMatches(v, w);\n    break;",
        "score": 11,
        "is_accepted": false,
        "creation_date": "2016-03-07T14:25:36",
        "author": "Aaron Hall"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/74817656/construct-string-from-its-permutation-with-least-jumps-back",
    "title": "Construct string from its permutation with least jumps back",
    "question_id": 74817656,
    "posted_date": "2022-12-15T16:16:46",
    "answers": [
      {
        "answer_id": 74818404,
        "body": "import itertools\nimport random\nimport numpy as np\nimport timeit\nimport matplotlib.pyplot as plt\nW=10 # Size of a word\n# Generate a random word\ndef randomWord():\n    return ''.join(np.random.choice(list(\"abcdef\"),W))\n# And a random shuffling of it\ndef shuffle(s):\n    return ''.join(random.sample(s,len(s)))\n# Quick'n'dirty implementation of the function you are using\n# It would have been better, btw, if you had provided them, as\n# needed to create a minimal reproducible example\ndef findOccurrences(s, c):\n    return [pos for pos, char in enumerate(s) if char == c]\ndef stringPop(s, i):\n    return s[:i]+s[i+1:]\n# Your function\ndef solvenaive(s1, s2, curr_ind):\n    if len(s1) == 0:\n        return 0\n    first_s1 = s1[0]\n\n    vorkommen = findOccurrences(s2, first_s1)\n    results = []\n    for i in vorkommen:\n        new_s1 = s1[1:]\n        new_s2 = stringPop(s2, i)\n        res = solvenaive(new_s1, new_s2, i)\n\n        if curr_ind > i:\n            results.append(res+1)\n        else:\n            results.append(res)\n\n    return min(results)\n# Mine. Almost the same.\n# But I add 2 parameters\n# bestScore which is what we have seen best\n# and sofar, a partial score\ndef solvecut(s1, s2, curr_ind, bestScore, sofar=0):\n    if len(s1)==0: # If we reach a \"leaf\" of recursion, then\n                   # return the score. (sofar is a real score in that case, not a partial)\n        return sofar\n    # Otherwise, we will recurse... unless it is a lost cause\n    if sofar>=bestScore: # No need to try better, we are already over our best\n        return 1e9\n    first_s1 = s1[0]\n\n    vorkommen = findOccurrences(s2, first_s1)\n    for i in vorkommen:\n        new_s1 = s1[1:] # I let that one here in the loop because I don't want to optimize anything other that my \"cuts\"\n                        # so that improvement are clearly imputable to those cuts\n                        # but, obviously that could have been done outside the loop\n        new_s2 = stringPop(s2, i)\n        if curr_ind>i:\n            res=solvecut(new_s1, new_s2, i, bestScore, sofar+1)\n        else:\n            res=solvecut(new_s1, new_s2, i, bestScore, sofar)\n        if res<bestScore:\n            bestScore=res\n    return bestScore # Sometimes we'll return that just because we did nothing best, but it doesn't matter\n# Test if result are the same on some examples\nfor i in range(20):\n    w=randomWord()\n    s=shuffle(w)\n    sc1=solvenaive(w,s,0)\n    sc2=solvecut(w, s, 0, 1e9)\n    print(w, s, sc1, sc2)\n# Timeit\n# Note that timing depends a lot of the word (letter repetition, etc.). So it is important to do them with the same words\n# Especially since this is not very fast, so we need to timit with number=1\nW=17\nw1=randomWord()\ns1=shuffle(w1)\nprint(timeit.timeit(lambda: solvenaive(w1, s1, 0), number=1))\nprint(timeit.timeit(lambda: solvecut(w1, s1, 0, 1e9), number=1))",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2022-12-15T17:49:19",
        "author": "chrslg"
      },
      {
        "answer_id": 74818404,
        "body": "cbaaecffae aaebcffcae 2 2\needeafdffb ffdbeefaed 3 3\naedefdceba adeefcabde 4 4\naaafccaafb aafacaafcb 2 2\neaffdfafef efdffefaaf 2 2\ndedbfffbce bcdffbedfe 3 3\nfedfcbaeed bedcfaefde 4 4\nffeebfcfab feaebcffbf 3 3\nfcdaddbfbf ffddacbfbd 3 3\ndeffcdeaea eeafdadfce 4 4\ncafeeebcdb beaedfbecc 4 4\nbeefdaeabd edaefbbdea 3 3\nddccbdbdae cdbdbcdead 3 3\nbcbababdef decafbbbba 4 4\ndfaeceefea edfcefaaee 2 2\nabcdcbbdbf fbbadccbdb 4 4\nacbedbaefc cbeacaebdf 3 3\naaffacfbde cfaaeafbfd 3 3\nedceddebdc dedcecbded 2 2\necafabdfea fafaeaedbc 3 3\n4.060046362923458\n0.05187216284684837",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2022-12-15T17:49:19",
        "author": "chrslg"
      },
      {
        "answer_id": 74818404,
        "body": "1 cut=6.040092557668686e-06\n2 cut=8.61193984746933e-06\n3 cut=1.5990110114216805e-05\n4 cut=1.5911879017949104e-05\n5 cut=2.897903323173523e-05\n6 cut=3.5561854019761086e-05\n7 cut=5.8827921748161316e-05\n8 cut=0.00018196692690253258\n9 cut=0.0001191610936075449\n10 cut=0.0002572301309555769\n11 cut=0.0008078841492533684\n12 cut=0.0009584939107298851\n13 cut=0.008062224835157394\n14 cut=0.004587493138387799\n15 cut=0.08773919194936752\n16 cut=0.02209200686775148\n17 cut=0.045466484036296606\n18 cut=0.11209587100893259\n19 cut=0.40787983988411725\n20 cut=2.2789966259151697\n21 cut=1.8927371250465512\n22 cut=1.097903796005994",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2022-12-15T17:49:19",
        "author": "chrslg"
      },
      {
        "answer_id": 74818404,
        "body": "def lessNaive(s1, s2, curr_ind, bestScore, sofar):\n    if len(s1)==0:\n        return sofar\n    if sofar>=bestScore or (curr_ind>0 and sofar+1>=bestScore): # No need to try better, we are already over our best\n        return 1e9\n    first_s1 = s1[0]\n    new_s1 = s1[1:]\n    for i in range(len(s2)):\n        if s2[i]!=first_s1: continue\n        new_s2 = stringPop(s2, i)\n        if curr_ind>i:\n            res=lessNaive(new_s1, new_s2, i, bestScore, sofar+1)\n        else:\n            res=lessNaive(new_s1, new_s2, i, bestScore, sofar)\n        if res<bestScore:\n            bestScore=res\n    return bestScore # Sometimes we'll return that just because we did nothing best, but it doesn't matter",
        "score": 6,
        "is_accepted": false,
        "creation_date": "2022-12-15T17:49:19",
        "author": "chrslg"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60517190/are-poetry-lock-files-os-independent",
    "title": "Are poetry.lock files OS independent?",
    "question_id": 60517190,
    "posted_date": "2020-03-03T18:50:05",
    "answers": [
      {
        "answer_id": 71691471,
        "body": "!toml\nwatchdog = [\n    {file = \"watchdog-2.1.6-cp310-cp310-macosx_10_9_universal2.whl\", hash = \"sha256:9693f35162dc6208d10b10ddf0458cc09ad70c30ba689d9206e02cd836ce28a3\"},\n    {file = \"watchdog-2.1.6-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:aba5c812f8ee8a3ff3be51887ca2d55fb8e268439ed44110d3846e4229eb0e8b\"},\n    {file = \"watchdog-2.1.6-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:4ae38bf8ba6f39d5b83f78661273216e7db5b00f08be7592062cb1fc8b8ba542\"},\n    {file = \"watchdog-2.1.6-cp36-cp36m-macosx_10_9_x86_64.whl\", hash = \"sha256:ad6f1796e37db2223d2a3f302f586f74c72c630b48a9872c1e7ae8e92e0ab669\"},\n    {file = \"watchdog-2.1.6-cp37-cp37m-macosx_10_9_x86_64.whl\", hash = \"sha256:922a69fa533cb0c793b483becaaa0845f655151e7256ec73630a1b2e9ebcb660\"},\n    {file = \"watchdog-2.1.6-cp38-cp38-macosx_10_9_universal2.whl\", hash = \"sha256:b2fcf9402fde2672545b139694284dc3b665fd1be660d73eca6805197ef776a3\"},\n    {file = \"watchdog-2.1.6-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:3386b367e950a11b0568062b70cc026c6f645428a698d33d39e013aaeda4cc04\"},\n    {file = \"watchdog-2.1.6-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:8f1c00aa35f504197561060ca4c21d3cc079ba29cf6dd2fe61024c70160c990b\"},\n    {file = \"watchdog-2.1.6-cp39-cp39-macosx_10_9_universal2.whl\", hash = \"sha256:b52b88021b9541a60531142b0a451baca08d28b74a723d0c99b13c8c8d48d604\"},\n    {file = \"watchdog-2.1.6-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:8047da932432aa32c515ec1447ea79ce578d0559362ca3605f8e9568f844e3c6\"},\n    {file = \"watchdog-2.1.6-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:e92c2d33858c8f560671b448205a268096e17870dcf60a9bb3ac7bfbafb7f5f9\"},\n    {file = \"watchdog-2.1.6-pp37-pypy37_pp73-macosx_10_9_x86_64.whl\", hash = \"sha256:b7d336912853d7b77f9b2c24eeed6a5065d0a0cc0d3b6a5a45ad6d1d05fb8cd8\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_aarch64.whl\", hash = \"sha256:cca7741c0fcc765568350cb139e92b7f9f3c9a08c4f32591d18ab0a6ac9e71b6\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_armv7l.whl\", hash = \"sha256:25fb5240b195d17de949588628fdf93032ebf163524ef08933db0ea1f99bd685\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_i686.whl\", hash = \"sha256:be9be735f827820a06340dff2ddea1fb7234561fa5e6300a62fe7f54d40546a0\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_ppc64.whl\", hash = \"sha256:d0d19fb2441947b58fbf91336638c2b9f4cc98e05e1045404d7a4cb7cddc7a65\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_ppc64le.whl\", hash = \"sha256:3becdb380d8916c873ad512f1701f8a92ce79ec6978ffde92919fd18d41da7fb\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_s390x.whl\", hash = \"sha256:ae67501c95606072aafa865b6ed47343ac6484472a2f95490ba151f6347acfc2\"},\n    {file = \"watchdog-2.1.6-py3-none-manylinux2014_x86_64.whl\", hash = \"sha256:e0f30db709c939cabf64a6dc5babb276e6d823fd84464ab916f9b9ba5623ca15\"},\n    {file = \"watchdog-2.1.6-py3-none-win32.whl\", hash = \"sha256:e02794ac791662a5eafc6ffeaf9bcc149035a0e48eb0a9d40a8feb4622605a3d\"},\n    {file = \"watchdog-2.1.6-py3-none-win_amd64.whl\", hash = \"sha256:bd9ba4f332cf57b2c1f698be0728c020399ef3040577cde2939f2e045b39c1e5\"},\n    {file = \"watchdog-2.1.6-py3-none-win_ia64.whl\", hash = \"sha256:a0f1c7edf116a12f7245be06120b1852275f9506a7d90227648b250755a03923\"},\n    {file = \"watchdog-2.1.6.tar.gz\", hash = \"sha256:a36e75df6c767cbf46f61a91c70b3ba71811dfa0aca4a324d9407a06a8b7a2e7\"},\n]\nweasyprint = [\n    {file = \"weasyprint-54.1-py3-none-any.whl\", hash = \"sha256:27c078ded67a43c9a05c349eda01ea327805d48e5c3ca3b704f57eb82bd78592\"},\n    {file = \"weasyprint-54.1.tar.gz\", hash = \"sha256:fa57db862e06bd01c5e7d82dad399b3b9952a39827023c17bee9b1c061ff1bbd\"},\n]",
        "score": 11,
        "is_accepted": true,
        "creation_date": "2022-03-31T07:10:25",
        "author": "N1ngu"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/53237266/how-can-i-minimize-maximize-windows-in-macos-with-the-cocoa-api-from-a-python-sc",
    "title": "How can I minimize/maximize windows in macOS with the Cocoa API from a Python script?",
    "question_id": 53237266,
    "posted_date": "2018-11-10T03:27:07",
    "answers": [
      {
        "answer_id": 57507448,
        "body": "from AppKit import NSApplication, NSApp, NSWorkspace\nfrom Quartz import kCGWindowListOptionOnScreenOnly, kCGNullWindowID, CGWindowListCopyWindowInfo\nworkspace = NSWorkspace.sharedWorkspace()\nactiveApps = workspace.runningApplications()\nfor app in activeApps:\n    if app.isActive():\n        options = kCGWindowListOptionOnScreenOnly\n        windowList = CGWindowListCopyWindowInfo(options,\n                                                kCGNullWindowID)\n        for window in windowList:\n            if window['kCGWindowOwnerName'] == app.localizedName():\n                print(window.getKeys_)\n                break\n        break",
        "score": 10,
        "is_accepted": true,
        "creation_date": "2019-08-15T05:16:16",
        "author": "Tarun Lalwani"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/54855780/how-to-create-ner-pipeline-with-multiple-models-in-spacy",
    "title": "How to create NER pipeline with multiple models in Spacy",
    "question_id": 54855780,
    "posted_date": "2019-02-24T14:41:54",
    "answers": [
      {
        "answer_id": 59528727,
        "body": "import spacy # tested with v2.2.3\nfrom spacy.pipeline import EntityRecognizer\ntext = \"Jane lives in Boston. Jan lives in Bremen.\"\n# load the English and German models\nnlp_en = spacy.load('en_core_web_sm')  # NER tags PERSON, GPE, ...\nnlp_de = spacy.load('de_core_news_sm') # NER tags PER, LOC, ...\n# the Vocab objects are not the same\nassert nlp_en.vocab != nlp_de.vocab\n# but the vectors are identical (because neither model has vectors)\nassert nlp_en.vocab.vectors.to_bytes() == nlp_de.vocab.vectors.to_bytes()\n# original English output\ndoc1 = nlp_en(text)\nprint([(ent.text, ent.label_) for ent in doc1.ents])\n# [('Jane', 'PERSON'), ('Boston', 'GPE'), ('Bremen', 'GPE')]\n# original German output (the German model makes weird predictions for English text)\ndoc2 = nlp_de(text)\nprint([(ent.text, ent.label_) for ent in doc2.ents])\n# [('Jane lives', 'PER'), ('Boston', 'LOC'), ('Jan lives', 'PER'), ('Bremen', 'LOC')]\n# initialize a new NER component with the vocab from the English pipeline\nner_de = EntityRecognizer(nlp_en.vocab)\n# reload the NER component from the German model by serializing\n# without the vocab and deserializing using the new NER component\nner_de.from_bytes(nlp_de.get_pipe(\"ner\").to_bytes(exclude=[\"vocab\"]))\n# add the German NER component to the end of the English pipeline\nnlp_en.add_pipe(ner_de, name=\"ner_de\")\n# check that they have the same vocab\nassert nlp_en.vocab == ner_de.vocab\n# combined output (English NER runs first, German second)\ndoc3 = nlp_en(text)\nprint([(ent.text, ent.label_) for ent in doc3.ents])\n# [('Jane', 'PERSON'), ('Boston', 'GPE'), ('Jan lives', 'PER'), ('Bremen', 'GPE')]",
        "score": 9,
        "is_accepted": false,
        "creation_date": "2019-12-30T04:46:42",
        "author": "aab"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/47125723/keras-lstm-for-text-generation-keeps-repeating-a-line-or-a-sequence",
    "title": "Keras LSTM for Text Generation keeps repeating a line or a sequence",
    "question_id": 47125723,
    "posted_date": "2017-11-05T14:32:09",
    "answers": [
      {
        "answer_id": 57463174,
        "body": "for epoch in range(1, 60):\n    print('epoch', epoch)\n    # Fit the model for 1 epoch on the available training data\n    model.fit(x, y,\n              batch_size=128,\n              epochs=1)\n    # Select a text seed at random\n    start_index = random.randint(0, len(text) - maxlen - 1)\n    generated_text = text[start_index: start_index + maxlen]\n    print('--- Generating with seed: \"' + generated_text + '\"')\n    for temperature in [0.2, 0.5, 1.0, 1.2]:\n        print('------ temperature:', temperature)\n        sys.stdout.write(generated_text)\n        # We generate 400 characters\n        for i in range(400):\n            sampled = np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(generated_text):\n                sampled[0, t, char_indices[char]] = 1.\n            preds = model.predict(sampled, verbose=0)[0]\n            next_index = sample(preds, temperature)\n            next_char = chars[next_index]\n            generated_text += next_char\n            generated_text = generated_text[1:]\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2019-08-12T10:31:31",
        "author": "Guillem"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58657285/how-does-loggings-extra-argument-work",
    "title": "How does logging&#39;s &#39;extra&#39; argument work?",
    "question_id": 58657285,
    "posted_date": "2019-11-01T06:02:11",
    "answers": [
      {
        "answer_id": 75373988,
        "body": "import logging\nimport sys\nclass NewLogger(logging.Logger):\n    # override the makeRecord method\n    def makeRecord(self, *args, **kwargs):\n        rv = super(NewLogger, self).makeRecord(*args, **kwargs)\n        rv.__dict__[\"City\"] = rv.__dict__.get(\"City\", \"Khazad-dum\")\n        return rv\nlog = NewLogger(\"foobar\")\nlog.propagate = False\nhandler = logging.StreamHandler(sys.stdout)\nhandler.setLevel(\"INFO\")\nformatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s | %(City)s')\nhandler.setFormatter(formatter)\nlog.addHandler(handler)\nlog.error(\"you shall not pass\")  # should log the default value\nlog.error(\"fly you foos!\", extra={\"City\": \"Mordor\"})  # should log \"Mordor\"",
        "score": 7,
        "is_accepted": true,
        "creation_date": "2023-02-07T08:22:46",
        "author": "vvvvv"
      },
      {
        "answer_id": 75373988,
        "body": "import logging\nimport sys\nlog = logging.getLogger(\"foobar\")\nlog.propagate = False\nhandler = logging.StreamHandler(sys.stdout)\nhandler.setLevel(\"INFO\")\nformatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s | %(City)s')\nhandler.setFormatter(formatter)\nlog.addHandler(handler)\nold_factory = logging.getLogRecordFactory()\ndef record_factory(*args, **kwargs):\n    record = old_factory(*args, **kwargs)  # get the unmodified record\n    record.City = \"Khazad-dum\"\n    return record\nlogging.setLogRecordFactory(record_factory)\nlog.error(\"you shall not pass\")\nlog.error(\"fly you foos!\", extra={\"City\": \"Mordor\"})",
        "score": 7,
        "is_accepted": true,
        "creation_date": "2023-02-07T08:22:46",
        "author": "vvvvv"
      },
      {
        "answer_id": 75373988,
        "body": "2023-02-07 14:11:19,722 | foobar | ERROR | you shall not pass | Khazad-dum\nTraceback (most recent call last):\n  File \"main.py\", line 82, in <module>\n    log.error(\"fly you foos!\", extra={\"City\": \"Mordor\"})\n  File \"/home/vvvvv/.pyenv/versions/3.8.12/lib/python3.8/logging/__init__.py\", line 1475, in error\n    self._log(ERROR, msg, args, **kwargs)\n  File \"/home/vvvvv/.pyenv/versions/3.8.12/lib/python3.8/logging/__init__.py\", line 1587, in _log\n    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n  File \"/home/vvvvv/.pyenv/versions/3.8.12/lib/python3.8/logging/__init__.py\", line 1561, in makeRecord\n    raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\nKeyError: \"Attempt to overwrite 'City' in LogRecord\"",
        "score": 7,
        "is_accepted": true,
        "creation_date": "2023-02-07T08:22:46",
        "author": "vvvvv"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/7492855/getting-an-embedded-python-runtime-to-use-the-current-active-virtualenv",
    "title": "Getting an embedded Python runtime to use the current active virtualenv",
    "question_id": 7492855,
    "posted_date": "2011-09-20T19:07:52",
    "answers": [
      {
        "answer_id": 28227478,
        "body": "std::vector<std::string> paths;\nstd::string pathEnv = getenv(\"PATH\");\nboost::split(paths, pathEnv, boost::is_any_of(\";:\"));\nfor (std::string path : paths)\n{\n  boost::filesystem::path pythonPath = boost::filesystem::path(path) / \"python\";\n  std::cout << pythonPath << std::endl;\n  if (boost::filesystem::exists(pythonPath))\n  {\n    pythonProgramName_ = pythonPath.string(); // remember path, because Py_SetProgramName doesn't save it anywhere\n    Py_SetProgramName(&pythonProgramName_[0]);\n    break;\n  }\n}\nPy_Initialize();",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2015-01-29T19:54:19",
        "author": "DikobrAz"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/31703037/how-can-i-change-modify-replace-text-in-a-pdf-using-python",
    "title": "How can I change/modify/replace text in a PDF using Python?",
    "question_id": 31703037,
    "posted_date": "2015-07-29T10:13:18",
    "answers": [
      {
        "answer_id": 75574195,
        "body": "#!chapter_007/src/snippet_012.py\nfrom borb.pdf import Document\nfrom borb.pdf import Page\nfrom borb.pdf import PageLayout, SingleColumnLayout\nfrom borb.pdf import Table, FixedColumnWidthTable\nfrom borb.pdf import Paragraph\nfrom borb.pdf import PDF\nfrom decimal import Decimal\ndef main():\n    # create empty Document\n    doc: Document = Document()\n    # add new Page\n    pge: Page = Page()\n    doc.add_page(pge)\n    # set PageLayout\n    lay: PageLayout = SingleColumnLayout(pge)\n    # add Table\n    tab: Table = FixedColumnWidthTable(number_of_columns=2, number_of_rows=3)\n    tab.add(Paragraph(\"Name:\", font=\"Helvetica-Bold\"))\n    tab.add(Paragraph(\"Schellekens\"))\n    tab.add(Paragraph(\"Firstname:\", font=\"Helvetica-Bold\"))\n    tab.add(Paragraph(\"Jots\"))\n    tab.add(Paragraph(\"Title:\", font=\"Helvetica-Bold\"))\n    tab.add(Paragraph(\"CEO borb\"))\n    tab.set_padding_on_all_cells(Decimal(5), Decimal(5), Decimal(5), Decimal(5))\n    lay.add(tab)\n    # store\n    with open(\"output.pdf\", 'wb') as pdf_file_handle:\n        PDF.dumps(pdf_file_handle, doc)\nif __name__ == \"__main__\":\n    main()",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2023-02-26T13:32:53",
        "author": "Joris Schellekens"
      },
      {
        "answer_id": 75574195,
        "body": "#!chapter_007/src/snippet_013.py\nfrom borb.pdf import Document\nfrom borb.pdf import PDF\nfrom borb.toolkit import SimpleFindReplace\nimport typing\ndef main():\n    # attempt to read a PDF\n    doc: typing.Optional[Document] = None\n    with open(\"output.pdf\", \"rb\") as pdf_file_handle:\n        doc = PDF.loads(pdf_file_handle)\n    # check whether we actually read a PDF\n    assert doc is not None\n    # find/replace\n    doc = SimpleFindReplace.sub(\"Jots\", \"Joris\", doc)\n    # store\n    with open(\"output2.pdf\", \"wb\") as pdf_file_handle:\n        PDF.dumps(pdf_file_handle, doc)\nif __name__ == \"__main__\":\n    main()",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2023-02-26T13:32:53",
        "author": "Joris Schellekens"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/15952733/sqlalchemy-logging-of-changes-with-date-and-user",
    "title": "SQLAlchemy logging of changes with date and user",
    "question_id": 15952733,
    "posted_date": "2013-04-11T11:24:24",
    "answers": [
      {
        "answer_id": 58189641,
        "body": "from flask import has_request_context  # How to check if in a Flask session\nfrom sqlalchemy import inspect\nfrom sqlalchemy.orm import class_mapper\nfrom sqlalchemy.orm.attributes import get_history\nfrom sqlalchemy.event import listen\nfrom YOUR_SESSION_MANAGER import get_user  # This would be something in Pyramid\nfrom my_project import models  # Where your models are defined\ndef get_object_changes(obj):\n    \"\"\" Given a model instance, returns dict of pending\n    changes waiting for database flush/commit.\n    e.g. {\n        'some_field': {\n            'before': *SOME-VALUE*,\n            'after': *SOME-VALUE*\n        },\n        ...\n    }\n    \"\"\"\n    inspection = inspect(obj)\n    changes = {}\n    for attr in class_mapper(obj.__class__).column_attrs:\n        if getattr(inspection.attrs, attr.key).history.has_changes():\n            if get_history(obj, attr.key)[2]:\n                before = get_history(obj, attr.key)[2].pop()\n                after = getattr(obj, attr.key)\n                if before != after:\n                    if before or after:\n                        changes[attr.key] = {'before': before, 'after': after}\n    return changes\ndef my_model_change_listener(mapper, connection, target):\n    changes = get_object_changes(target)\n    changes.pop(\"modify_ts\", None)  # remove fields you don't want to track\n    user_id = None\n    if has_request_context():\n        # Call your function to get active user and extract id\n        user_id = getattr(get_user(), 'id', None)\n    if user_id is None:\n        # What do you want to do if user can't be determined\n        pass\n    # You now have the model instance (target), the user_id who is logged in,\n    # and a dictionary of changes.\n    # Either do somthing \"quick\" with it here or call an async task (e.g.\n    # Celery) to do something with the information that may take longer\n    # than you want the request to take.\n# Add the listener\nlisten(models.MyModel, 'after_update', my_model_change_listener)",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2019-10-01T13:24:12",
        "author": "Matt Graham"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/52757556/using-line-profiler-with-multiprocessing",
    "title": "Using line profiler with multiprocessing",
    "question_id": 52757556,
    "posted_date": "2018-10-11T06:14:31",
    "answers": [
      {
        "answer_id": 67969672,
        "body": "import multiprocessing as mp\nimport line_profiler\nclass Worker(mp.Process):\n    def run(self):\n        prof = line_profiler.LineProfiler()\n        # Wrap all functions that you want to be profiled in this process\n        # These can be global functions or any class methods\n        # Make sure to replace instance methods on a class level, not the bound methods self.run2\n        Worker.run2 = prof(Worker.run2)\n        ...\n        # run the main\n        self.run2()\n        # store stats in separate file for each process\n        prof.dump_stats('worker.lprof')\n    def run2(self):\n        # real run method renamed\n        ...",
        "score": 4,
        "is_accepted": false,
        "creation_date": "2021-06-14T07:47:12",
        "author": "Chris"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/68624314/do-asynchronous-context-managers-need-to-protect-their-cleanup-code-from-cancell",
    "title": "Do asynchronous context managers need to protect their cleanup code from cancellation?",
    "question_id": 68624314,
    "posted_date": "2021-08-02T11:32:29",
    "answers": [
      {
        "answer_id": 68635402,
        "body": "async def release_db_connection(conn):\n    \"\"\"\n    Cancellation safe variant of `release_db_connection`\n    Internally protects against cancellation by delaying it until cleanup.\n    \"\"\"\n    # cleanup is run in separate task so that it\n    # cannot be cancelled from the outside.\n    shielded_release = asyncio.create_task(asyncio.sleep(1))\n    # Wait for cleanup completion \u2013 unlike `asyncio.shield`,\n    # delay any cancellation until we are done.\n    try:\n        await shielded_release\n    except asyncio.CancelledError:\n        await shielded_release\n        # propagate cancellation when we are done\n        raise\n    finally:\n        print(\"Released database connection.\")",
        "score": 2,
        "is_accepted": true,
        "creation_date": "2021-08-03T07:42:35",
        "author": "MisterMiyagi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/48702706/why-does-sqlalchemy-not-update-relations-after-object-deletion",
    "title": "Why does SQLAlchemy not update relations after object deletion?",
    "question_id": 48702706,
    "posted_date": "2018-02-09T04:32:41",
    "answers": [
      {
        "answer_id": 69595170,
        "body": "class HideDeletedRelationshipWithoutFlushMixin:\n    def __getattribute__(self, item):\n        value = super().__getattribute__(item)\n        if value is not None and hasattr(value, DEFAULT_STATE_ATTR):\n            state = instance_state(value)\n            if (\n                    state.deleted or                                               # After flush\n                    state.session is not None and state in state.session._deleted  # Before flush\n            ):\n                return None\n        return value\nclass HideDeletedRelationshipAfterFlushMixin:\n    def __getattribute__(self, item):\n        value = super().__getattribute__(item)\n        if value is not None and hasattr(value, DEFAULT_STATE_ATTR) and instance_state(value).deleted:\n            return None\n        return value",
        "score": 3,
        "is_accepted": false,
        "creation_date": "2021-10-16T07:29:13",
        "author": "aaron"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/33983860/hide-chromedriver-console-in-python",
    "title": "hide chromeDriver console in python",
    "question_id": 33983860,
    "posted_date": "2015-11-29T09:23:49",
    "answers": [
      {
        "answer_id": 71093078,
        "body": "from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service as ChromeService # Similar thing for firefox also!\nfrom subprocess import CREATE_NO_WINDOW # This flag will only be available in windows\n# Define your own service object with the `CREATE_NO_WINDOW ` flag\n# If chromedriver.exe is not in PATH, then use:\n# ChromeService('/path/to/chromedriver')\nchrome_service = ChromeService('chromedriver')\n# Use `chrome_service.creationflags` for selenium < 4.6\nchrome_service.creation_flags = CREATE_NO_WINDOW\ndriver = webdriver.Chrome(service=chrome_service)",
        "score": 20,
        "is_accepted": false,
        "creation_date": "2022-02-12T10:10:17",
        "author": "Ali Sajjad Rizavi"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/70641660/how-do-you-get-and-use-a-refresh-token-for-the-dropbox-api-python-3-x",
    "title": "How do you get and use a Refresh Token for the Dropbox API (Python 3.x)",
    "question_id": 70641660,
    "posted_date": "2022-01-09T08:18:12",
    "answers": [
      {
        "answer_id": 74160443,
        "body": "import base64\nimport requests\nimport json\nAPP_KEY = '<APP_KEY>'\nAPP_SECRET = '<APP_SECRET>'\nACCESS_CODE_GENERATED = '<ACCESS_CODE_GENERATED>'\nBASIC_AUTH = base64.b64encode(f'{APP_KEY}:{APP_SECRET}'.encode())\nheaders = {\n    'Authorization': f\"Basic {BASIC_AUTH}\",\n    'Content-Type': 'application/x-www-form-urlencoded',\n}\ndata = f'code={ACCESS_CODE_GENERATED}&grant_type=authorization_code'\nresponse = requests.post('https://api.dropboxapi.com/oauth2/token',\n                         data=data,\n                         auth=(APP_KEY, APP_SECRET))\nprint(json.dumps(json.loads(response.text), indent=2))",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2022-10-21T21:09:19",
        "author": "chjch"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56734576/find-input-shape-from-onnx-file",
    "title": "Find input shape from onnx file",
    "question_id": 56734576,
    "posted_date": "2019-06-24T06:25:20",
    "answers": [
      {
        "answer_id": 57363459,
        "body": "import onnx\nmodel = onnx.load(r\"model.onnx\")\n# The model is represented as a protobuf structure and it can be accessed\n# using the standard python-for-protobuf methods\n# iterate through inputs of the graph\nfor input in model.graph.input:\n    print (input.name, end=\": \")\n    # get type of input tensor\n    tensor_type = input.type.tensor_type\n    # check if it has a shape:\n    if (tensor_type.HasField(\"shape\")):\n        # iterate through dimensions of the shape:\n        for d in tensor_type.shape.dim:\n            # the dimension may have a definite (integer) value or a symbolic identifier or neither:\n            if (d.HasField(\"dim_value\")):\n                print (d.dim_value, end=\", \")  # known dimension\n            elif (d.HasField(\"dim_param\")):\n                print (d.dim_param, end=\", \")  # unknown dimension with symbolic name\n            else:\n                print (\"?\", end=\", \")  # unknown dimension with no name\n    else:\n        print (\"unknown rank\", end=\"\")\n    print()",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2019-08-05T13:31:50",
        "author": "G. Ramalingam"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/55324449/how-to-specify-a-minimum-or-maximum-float-value-with-argparse",
    "title": "How to specify a minimum or maximum float value with argparse",
    "question_id": 55324449,
    "posted_date": "2019-03-24T09:47:01",
    "answers": [
      {
        "answer_id": 55410582,
        "body": "def range_limited_float_type(arg):\n    \"\"\" Type function for argparse - a float within some predefined bounds \"\"\"\n    try:\n        f = float(arg)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"Must be a floating point number\")\n    if f < MIN_VAL or f > MAX_VAL:\n        raise argparse.ArgumentTypeError(\"Argument must be < \" + str(MAX_VAL) + \"and > \" + str(MIN_VAL))\n    return f\nparser.add_argument(\n    '-f',\n    '--float',\n    type=range_limited_float_type,\n    help='Your argument description'\n)",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-03-29T00:37:47",
        "author": "rdas"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57368870/simply-using-parsec-in-python",
    "title": "Simply using parsec in python",
    "question_id": 57368870,
    "posted_date": "2019-08-06T00:18:47",
    "answers": [
      {
        "answer_id": 57473088,
        "body": "from parsec import *\nspaces = regex(r'\\s*', re.MULTILINE)\nname = regex(r'[_a-zA-Z][_a-zA-Z0-9]*')\ntag_start = spaces >> string('<') >> name << string('>') << spaces\ntag_stop = spaces >> string('</') >> name << string('>') << spaces\n@generate\ndef header_kv():\n    key = yield spaces >> name << spaces\n    yield string(':')\n    value = yield spaces >> regex('[^\\n]+')\n    return {key: value}\n@generate\ndef header():\n    tag_name = yield tag_start\n    values = yield sepBy(header_kv, string('\\n'))\n    tag_name_end = yield tag_stop\n    assert tag_name == tag_name_end\n    return {\n        'type': 'tag',\n        'name': tag_name,\n        'values': values\n    }\n@generate\ndef body():\n    tag_name = yield tag_start\n    values = yield sepBy(sepBy1(regex(r'[^\\n<,]+'), string(',')), string('\\n'))\n    tag_name_end = yield tag_stop\n    assert tag_name == tag_name_end\n    return {\n        'type': 'tag',\n        'name': tag_name,\n        'values': values\n    }\nparser = header + body",
        "score": 20,
        "is_accepted": true,
        "creation_date": "2019-08-13T03:31:50",
        "author": "sighingnow"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/69776414/pytzusagewarning-the-zone-attribute-is-specific-to-pytzs-interface-please-mig",
    "title": "PytzUsageWarning: The zone attribute is specific to pytz&#39;s interface; please migrate to a new time zone provider",
    "question_id": 69776414,
    "posted_date": "2021-10-29T22:46:13",
    "answers": [
      {
        "answer_id": 69796567,
        "body": "\"\"\"Basic Flask Example from flask-apscheduler examples, file jobs.py\"\"\"\nfrom flask import Flask\nfrom flask_apscheduler import APScheduler\nclass Config:\n    \"\"\"App configuration.\"\"\"\n    JOBS = [\n        {\n            \"id\": \"job1\",\n            \"func\": \"jobs:job1\",\n            \"args\": (1, 2),\n            \"trigger\": \"interval\",\n            \"seconds\": 10,\n        }\n    ]\n    SCHEDULER_API_ENABLED = True\n    SCHEDULER_TIMEZONE = \"Europe/Berlin\"  # <========== add here\ndef job1(var_one, var_two):\n    print(str(var_one) + \" \" + str(var_two))\nif __name__ == \"__main__\":\n    app = Flask(__name__)\n    app.config.from_object(Config())\n    scheduler = APScheduler()\n    scheduler.init_app(app)\n    scheduler.start()\n    app.run()",
        "score": 22,
        "is_accepted": true,
        "creation_date": "2021-11-01T07:54:50",
        "author": "Alex Poca"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60778279/fastapi-middleware-peeking-into-responses",
    "title": "FastAPI middleware peeking into responses",
    "question_id": 60778279,
    "posted_date": "2020-03-20T12:45:32",
    "answers": [
      {
        "answer_id": 64357530,
        "body": "from starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.requests import Request\nimport json\nfrom .async_iterator_wrapper import async_iterator_wrapper as aiwrap\nclass some_middleware(BaseHTTPMiddleware):\n   async def dispatch(self, request:Request, call_next:RequestResponseEndpoint):\n      # --------------------------\n      # DO WHATEVER YOU TO DO HERE\n      #---------------------------\n\n      response = await call_next(request)\n      # Consuming FastAPI response and grabbing body here\n      resp_body = [section async for section in response.__dict__['body_iterator']]\n      # Repairing FastAPI response\n      response.__setattr__('body_iterator', aiwrap(resp_body)\n      # Formatting response body for logging\n      try:\n         resp_body = json.loads(resp_body[0].decode())\n      except:\n         resp_body = str(resp_body)",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2020-10-14T12:18:24",
        "author": "SteveTheProgrammer"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/12007406/divide-dataframe-by-first-row",
    "title": "Divide DataFrame by first row",
    "question_id": 12007406,
    "posted_date": "2012-08-17T10:08:18",
    "answers": [
      {
        "answer_id": 63781913,
        "body": "In [1]: df\nOut[1]:\n                   SPY      Google        Gold        Xom\nDate\n2008-12-31   90.239998  153.250580   86.519997  79.830002\n2009-01-02   92.959999  160.060059   86.230003  81.639999\n2009-01-05   92.849998  163.412491   84.480003  81.629997\n2009-01-06   93.470001  166.406265   85.129997  80.300003\n2009-01-07   90.669998  160.403763   82.750000  78.250000\n...                ...         ...         ...        ...\n2012-12-24  142.350006  353.425262  160.619995  86.919998\n2012-12-26  141.750000  353.111450  160.779999  87.070000\n2012-12-27  141.559998  351.826263  161.160004  86.860001\n2012-12-28  140.029999  348.697998  160.539993  85.099998\n2012-12-31  142.410004  352.369232  162.020004  86.550003\n[1007 rows x 4 columns]\nIn [2]: df.iloc[0]\nOut[2]:\nSPY        90.239998\nGoogle    153.250580\nGold       86.519997\nXom        79.830002\nName: 2008-12-31 00:00:00, dtype: float64\nIn [3]: df.div(df.iloc[0])\nOut[3]:\n                 SPY    Google      Gold       Xom\nDate\n2008-12-31  1.000000  1.000000  1.000000  1.000000\n2009-01-02  1.030142  1.044434  0.996648  1.022673\n2009-01-05  1.028923  1.066309  0.976422  1.022548\n2009-01-06  1.035793  1.085844  0.983934  1.005888\n2009-01-07  1.004765  1.046676  0.956426  0.980208\n...              ...       ...       ...       ...\n2012-12-24  1.577460  2.306192  1.856449  1.088814\n2012-12-26  1.570811  2.304144  1.858299  1.090693\n2012-12-27  1.568706  2.295758  1.862691  1.088062\n2012-12-28  1.551751  2.275345  1.855525  1.066015\n2012-12-31  1.578125  2.299301  1.872631  1.084179\n[1007 rows x 4 columns]",
        "score": 16,
        "is_accepted": false,
        "creation_date": "2020-09-07T13:28:51",
        "author": "GraphicalDot"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/57596086/final-annotation-and-decorator-in-python3-8",
    "title": "final annotation and decorator in python3.8",
    "question_id": 57596086,
    "posted_date": "2019-08-21T12:48:08",
    "answers": [
      {
        "answer_id": 57596202,
        "body": "$ cat demo.py\nfrom typing import final, Final\n# FOO is marked final, can't assign another value to it\nFOO: Final[int] = 42\nclass Foo:\n    @final\n    def spam(self) -> int:\n        \"\"\"A final method can't be overridden in a subclass\"\"\"\n        return 42\n@final\nclass Bar:\n    \"\"\"A final class can't be subclassed\"\"\"\n# Rule breaking section\nFOO = 81\nclass Spam(Foo, Bar):\n    def spam(self) -> int:\n        return 17\nif __name__ == '__main__':\n    print(\"FOO:\", FOO)\n    print(\"Spam().spam():\", Spam().spam())\n$ python3.8 demo.py   # Python will not throw errors here\nFOO: 81\nSpam().spam(): 17\n$ mypy demo.py        # only a type checker will\ndemo.py:17: error: Cannot assign to final name \"FOO\"\ndemo.py:19: error: Cannot inherit from final class \"Bar\"\ndemo.py:20: error: Cannot override final attribute \"spam\" (previously declared in base class \"Foo\")",
        "score": 33,
        "is_accepted": false,
        "creation_date": "2019-08-21T12:58:41",
        "author": "Martijn Pieters"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56719138/how-can-i-save-a-librosa-spectrogram-plot-as-a-specific-sized-image",
    "title": "How can I save a Librosa spectrogram plot as a specific sized image?",
    "question_id": 56719138,
    "posted_date": "2019-06-22T16:57:19",
    "answers": [
      {
        "answer_id": 57204349,
        "body": "import librosa\nimport numpy\nimport skimage.io\ndef scale_minmax(X, min=0.0, max=1.0):\n    X_std = (X - X.min()) / (X.max() - X.min())\n    X_scaled = X_std * (max - min) + min\n    return X_scaled\ndef spectrogram_image(y, sr, out, hop_length, n_mels):\n    # use log-melspectrogram\n    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n                                            n_fft=hop_length*2, hop_length=hop_length)\n    mels = numpy.log(mels + 1e-9) # add small number to avoid log(0)\n    # min-max scale to fit inside 8-bit range\n    img = scale_minmax(mels, 0, 255).astype(numpy.uint8)\n    img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image\n    img = 255-img # invert. make black==more energy\n    # save as PNG\n    skimage.io.imsave(out, img)\nif __name__ == '__main__':\n    # settings\n    hop_length = 512 # number of samples per time-step in spectrogram\n    n_mels = 128 # number of bins in spectrogram. Height of image\n    time_steps = 384 # number of time-steps. Width of image\n    # load audio. Using example from librosa\n    path = librosa.util.example_audio_file()\n    y, sr = librosa.load(path, offset=1.0, duration=10.0, sr=22050)\n    out = 'out.png'\n    # extract a fixed length window\n    start_sample = 0 # starting at beginning\n    length_samples = time_steps*hop_length\n    window = y[start_sample:start_sample+length_samples]\n\n    # convert to PNG\n    spectrogram_image(window, sr=sr, out=out, hop_length=hop_length, n_mels=n_mels)\n    print('wrote file', out)",
        "score": 32,
        "is_accepted": false,
        "creation_date": "2019-07-25T10:27:26",
        "author": "Jon Nordby"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61451279/how-do-setcolumnstretch-and-setrowstretch-work",
    "title": "How do setColumnStretch and setRowStretch work?",
    "question_id": 61451279,
    "posted_date": "2020-04-26T23:29:46",
    "answers": [
      {
        "answer_id": 61452285,
        "body": "    import random\n    import sys\n\n    from PyQt5 import QtGui, QtWidgets\n\n    if __name__ == \"__main__\":\n        app = QtWidgets.QApplication(sys.argv)\n        w = QtWidgets.QWidget()\n        glay = QtWidgets.QGridLayout(w)\n        elements = (\n            (0, 0, 1, 1),  # Position: 0x0 1 rowspan 1 colspan\n            (1, 0, 1, 1),  # Position: 1x0 1 rowspan 1 colspan\n            (0, 1, 2, 1),  # Position: 0x1 2 rowspan 1 colspan\n            (2, 0, 1, 2),  # Position: 2x0 1 rowspan 2 colspan\n        )\n        for i, (row, col, row_span, col_span) in enumerate(elements):\n            label = QtWidgets.QLabel(\"{}\".format(i))\n            color = QtGui.QColor(*random.sample(range(255), 3))\n            label.setStyleSheet(\"background-color: {}\".format(color.name()))\n            glay.addWidget(label, row, col, row_span, col_span)\n        w.resize(640, 480)\n        w.show()\n        sys.exit(app.exec_())",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2020-04-27T01:31:01",
        "author": "eyllanesc"
      },
      {
        "answer_id": 61452285,
        "body": "    import random\n    import sys\n\n    from PyQt5 import QtGui, QtWidgets\n\n    if __name__ == \"__main__\":\n        app = QtWidgets.QApplication(sys.argv)\n        w = QtWidgets.QWidget()\n        glay = QtWidgets.QGridLayout(w)\n        for i in range(3):\n            for j in range(3):\n                label = QtWidgets.QLabel(\"{}x{}\".format(i, j))\n                color = QtGui.QColor(*random.sample(range(255), 3))\n                label.setStyleSheet(\"background-color: {}\".format(color.name()))\n                glay.addWidget(label, i, j)\n        glay.setRowStretch(0, 1)\n        glay.setRowStretch(1, 2)\n        glay.setRowStretch(2, 3)\n        w.resize(640, 480)\n        w.show()\n        sys.exit(app.exec_())",
        "score": 31,
        "is_accepted": true,
        "creation_date": "2020-04-27T01:31:01",
        "author": "eyllanesc"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/56153726/plot-k-nearest-neighbor-graph-with-8-features",
    "title": "Plot k-Nearest-Neighbor graph with 8 features?",
    "question_id": 56153726,
    "posted_date": "2019-05-15T12:20:14",
    "answers": [
      {
        "answer_id": 56301555,
        "body": "import pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\ndef plot_correlation(data):\n    '''\n    plot correlation's matrix to explore dependency between features\n    '''\n    # init figure size\n    rcParams['figure.figsize'] = 15, 20\n    fig = plt.figure()\n    sns.heatmap(data.corr(), annot=True, fmt=\".2f\")\n    plt.show()\n    fig.savefig('corr.png')\n# load your data\ndata  = pd.read_csv('diabetes.csv')\n# plot correlation & densities\nplot_correlation(data)",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2019-05-24T23:54:03",
        "author": "SuperKogito"
      },
      {
        "answer_id": 56301555,
        "body": "import pandas as pd\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\ndef plot_densities(data):\n    '''\n    Plot features densities depending on the outcome values\n    '''\n    # change fig size to fit all subplots beautifully\n    rcParams['figure.figsize'] = 15, 20\n    # separate data based on outcome values\n    outcome_0 = data[data['Outcome'] == 0]\n    outcome_1 = data[data['Outcome'] == 1]\n\n    # init figure\n    fig, axs = plt.subplots(8, 1)\n    fig.suptitle('Features densities for different outcomes 0/1')\n    plt.subplots_adjust(left = 0.25, right = 0.9, bottom = 0.1, top = 0.95,\n                        wspace = 0.2, hspace = 0.9)\n\n    # plot densities for outcomes\n    for column_name in names[:-1]:\n        ax = axs[names.index(column_name)]\n        #plt.subplot(4, 2, names.index(column_name) + 1)\n        outcome_0[column_name].plot(kind='density', ax=ax, subplots=True,\n                                    sharex=False, color=\"red\", legend=True,\n                                    label=column_name + ' for Outcome = 0')\n        outcome_1[column_name].plot(kind='density', ax=ax, subplots=True,\n                                     sharex=False, color=\"green\", legend=True,\n                                     label=column_name + ' for Outcome = 1')\n        ax.set_xlabel(column_name + ' values')\n        ax.set_title(column_name + ' density')\n        ax.grid('on')\n    plt.show()\n    fig.savefig('densities.png')\n# load your data\ndata  = pd.read_csv('diabetes.csv')\nnames = list(data.columns)\n# plot correlation & densities\nplot_densities(data)",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2019-05-24T23:54:03",
        "author": "SuperKogito"
      },
      {
        "answer_id": 56301555,
        "body": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom sklearn import neighbors\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n# filter warnings\nwarnings.filterwarnings(\"ignore\")\ndef accuracy(k, X_train, y_train, X_test, y_test):\n    '''\n    compute accuracy of the classification based on k values\n    '''\n    # instantiate learning model and fit data\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n\n    # predict the response\n    pred = knn.predict(X_test)\n\n    # evaluate and return  accuracy\n    return accuracy_score(y_test, pred)\ndef classify_and_plot(X, y):\n    '''\n    split data, fit, classify, plot and evaluate results\n    '''\n    # split data into training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 41)\n    # init vars\n    n_neighbors = 5\n    h           = .02  # step size in the mesh\n\n    # Create color maps\n    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n    cmap_bold  = ListedColormap(['#FF0000', '#0000FF'])\n\n    rcParams['figure.figsize'] = 5, 5\n    for weights in ['uniform', 'distance']:\n        # we create an instance of Neighbours Classifier and fit the data.\n        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n        clf.fit(X_train, y_train)\n\n        # Plot the decision boundary. For that, we will assign a color to each\n        # point in the mesh [x_min, x_max]x[y_min, y_max].\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                             np.arange(y_min, y_max, h))\n        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n        # Put the result into a color plot\n        Z = Z.reshape(xx.shape)\n        fig = plt.figure()\n        plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n        # Plot also the training points, x-axis = 'Glucose', y-axis = \"BMI\"\n        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n        plt.xlim(xx.min(), xx.max())\n        plt.ylim(yy.min(), yy.max())\n        plt.title(\"0/1 outcome classification (k = %i, weights = '%s')\" % (n_neighbors, weights))\n        plt.show()\n        fig.savefig(weights +'.png')\n\n        # evaluate\n        y_expected  = y_test\n        y_predicted = clf.predict(X_test)\n\n        # print results\n        print('----------------------------------------------------------------------')\n        print('Classification report')\n        print('----------------------------------------------------------------------')\n        print('\\n', classification_report(y_expected, y_predicted))\n        print('----------------------------------------------------------------------')\n        print('Accuracy = %5s' % round(accuracy(n_neighbors, X_train, y_train, X_test, y_test), 3))\n        print('----------------------------------------------------------------------')\n# load your data\ndata  = pd.read_csv('diabetes.csv')\nnames = list(data.columns)\n# we only take the best two features and prepare them for the KNN classifier\nrows_nbr = 30 # data.shape[0]\nX_prime  = np.array(data.iloc[:rows_nbr, [1,5]])\nX        = X_prime # preprocessing.scale(X_prime)\ny        = np.array(data.iloc[:rows_nbr, 8])\n# classify, evaluate and plot results\nclassify_and_plot(X, y)",
        "score": 25,
        "is_accepted": true,
        "creation_date": "2019-05-24T23:54:03",
        "author": "SuperKogito"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/76038966/type-hinting-pandas-dataframe-content-and-columns",
    "title": "Type hinting Pandas DataFrame content and columns",
    "question_id": 76038966,
    "posted_date": "2023-04-17T16:15:30",
    "answers": [
      {
        "answer_id": 76076231,
        "body": "import pandas as pd\nimport pandera as pa\nfrom pandera.typing import DataFrame\nclass MySchema(pa.DataFrameModel):\n    a: int\n    b: float\n    c: str = pa.Field(nullable=True)  # For example, allow None values\n    d: float    # US dollars\nclass OtherSchema(pa.DataFrameModel):\n    year: int = pa.Field(ge=1900, le=2050)\ndef generate_data() -> DataFrame[MySchema]:\n    df = pd.DataFrame({\n        \"a\": [1, 2, 3],\n        \"b\": [10.0, 20.0, 30.0],\n        \"c\": [\"A\", \"B\", \"C\"],\n        \"d\": [0.1, 0.2, 0.3],\n    })\n    # Runtime verification here, throws on schema mismatch\n    strongly_typed_df = DataFrame[MySchema](df)\n    return strongly_typed_df\ndef transform(input: DataFrame[MySchema]) -> DataFrame[OtherSchema]:\n    # This demonstrates that you can use strongly\n    # typed column names from the schema\n    df = input.filter(items=[MySchema.a]).rename(\n            columns={MySchema.a: OtherSchema.year}\n    )\n    return DataFrame[OtherSchema](df) # This will throw on range validation!\ndf1 = generate_data()\ndf2 = transform(df1)\ntransform(df2)   # mypy prints error here - incompatible type!",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2023-04-21T15:28:37",
        "author": "vvv444"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61711710/runtimeerror-class-not-set-defining-abstractbaseuser-as-class-django-co",
    "title": "RuntimeError: __class__ not set defining &#39;AbstractBaseUser&#39; as &lt;class &#39;django.contrib.auth.base_user.Abstract BaseUser&#39;&gt;. Was __classcell__ propagated",
    "question_id": 61711710,
    "posted_date": "2020-05-10T08:08:18",
    "answers": [
      {
        "answer_id": 65880079,
        "body": "class ModelBase(type):\n    \"\"\"\n    Metaclass for all models.\n    \"\"\"\n    def __new__(cls, name, bases, attrs):\n        super_new = super(ModelBase, cls).__new__\n        # Also ensure initialization is only performed for subclasses of Model\n        # (excluding Model class itself).\n        parents = [b for b in bases if isinstance(b, ModelBase)]\n        if not parents:\n            return super_new(cls, name, bases, attrs)\n        # Create the class.\n        module = attrs.pop('__module__')\n        new_class = super_new(cls, name, bases, {'__module__': module})\n\n        # <========== THE CODE BELLOW SHOULD BE ADDED ONLY ======>>\n        new_attrs = {'__module__': module}\n        classcell = attrs.pop('__classcell__', None)\n        if classcell is not None:\n            new_attrs['__classcell__'] = classcell\n        new_class = super_new(cls, name, bases, new_attrs)\n        # <========== THE CODE ABOVE SHOULD BE ADDED ONLY ======>>\n        # the rest of the class .....",
        "score": 24,
        "is_accepted": false,
        "creation_date": "2021-01-25T01:47:03",
        "author": "Elias Prado"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/61368805/how-to-plot-shaded-error-bands-with-seaborn",
    "title": "How to plot shaded error bands with seaborn?",
    "question_id": 61368805,
    "posted_date": "2020-04-22T11:22:40",
    "answers": [
      {
        "answer_id": 61369662,
        "body": "import matplotlib.pyplot as plt\nimport numpy as np\nmean_1 = np.array([10, 20, 30, 25, 32, 43])\nstd_1 = np.array([2.2, 2.3, 1.2, 2.2, 1.8, 3.5])\nmean_2 = np.array([12, 22, 30, 13, 33, 39])\nstd_2 = np.array([2.4, 1.3, 2.2, 1.2, 1.9, 3.5])\nx = np.arange(len(mean_1))\nplt.plot(x, mean_1, 'b-', label='mean_1')\nplt.fill_between(x, mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.2)\nplt.plot(x, mean_2, 'r-', label='mean_2')\nplt.fill_between(x, mean_2 - std_2, mean_2 + std_2, color='r', alpha=0.2)\nplt.legend()\nplt.show()",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2020-04-22T12:02:53",
        "author": "JohanC"
      },
      {
        "answer_id": 61369662,
        "body": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nsns.set()\nN = 100\nx = np.arange(N)\nmean_1 = 25 + np.random.normal(0.1, 1, N).cumsum()\nstd_1 = 3 + np.random.normal(0, .08, N).cumsum()\nmean_2 = 15 + np.random.normal(0.2, 1, N).cumsum()\nstd_2 = 4 + np.random.normal(0, .1, N).cumsum()\nplt.plot(x, mean_1, 'b-', label='mean_1')\nplt.fill_between(x, mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.2)\nplt.plot(x, mean_2, 'r--', label='mean_2')\nplt.fill_between(x, mean_2 - std_2, mean_2 + std_2, color='r', alpha=0.2)\nplt.legend(title='title')\nplt.show()",
        "score": 30,
        "is_accepted": true,
        "creation_date": "2020-04-22T12:02:53",
        "author": "JohanC"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/37972029/regex-to-match-pep440-compliant-version-strings",
    "title": "Regex to match PEP440 compliant version strings",
    "question_id": 37972029,
    "posted_date": "2016-06-22T11:12:08",
    "answers": [
      {
        "answer_id": 38020327,
        "body": "VERSION_PATTERN = r\"\"\"\n    v?\n    (?:\n        (?:(?P<epoch>[0-9]+)!)?                           # epoch\n        (?P<release>[0-9]+(?:\\.[0-9]+)*)                  # release segment\n        (?P<pre>                                          # pre-release\n            [-_\\.]?\n            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))\n            [-_\\.]?\n            (?P<pre_n>[0-9]+)?\n        )?\n        (?P<post>                                         # post release\n            (?:-(?P<post_n1>[0-9]+))\n            |\n            (?:\n                [-_\\.]?\n                (?P<post_l>post|rev|r)\n                [-_\\.]?\n                (?P<post_n2>[0-9]+)?\n            )\n        )?\n        (?P<dev>                                          # dev release\n            [-_\\.]?\n            (?P<dev_l>dev)\n            [-_\\.]?\n            (?P<dev_n>[0-9]+)?\n        )?\n    )\n    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version\n\"\"\"",
        "score": 19,
        "is_accepted": true,
        "creation_date": "2016-06-24T14:55:28",
        "author": "hornswoggles"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/3044455/sqlalchemy-how-to-group-by-two-fields-and-filter-by-date",
    "title": "SQLAlchemy: How to group by two fields and filter by date",
    "question_id": 3044455,
    "posted_date": "2010-06-15T06:52:54",
    "answers": [
      {
        "answer_id": 3049352,
        "body": "qry = (session.query(\n         table.c.field1,\n         table.c.field2,\n        # #strftime* for year-month works on sqlite;\n\n        # @todo: find proper function for mysql (as in the question)\n        # Also it is not clear if only MONTH part is enough, so that\n        # May-2001 and May-2009 can be joined, or YEAR-MONTH must be used\n        func.strftime('%Y-%m', table.c.datestamp),\n        func.count(),\n    )\n    # optionally check only last 2 month data (could have partial months)\n    .filter(table.c.datestamp < datetime.date.today() - datetime.timedelta(60))\n    .group_by(\n            table.c.field1,\n            table.c.field2,\n            func.strftime('%Y-%m', table.c.datestamp),\n            )\n    # comment this line out to see all the groups\n    .having(func.count()>1)\n  )",
        "score": 28,
        "is_accepted": true,
        "creation_date": "2010-06-15T17:53:58",
        "author": "van"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/60054076/is-dataclass-a-good-fit-to-replace-a-dictionary",
    "title": "Is DataClass a good fit to replace a dictionary?",
    "question_id": 60054076,
    "posted_date": "2020-02-04T04:16:24",
    "answers": [
      {
        "answer_id": 60054907,
        "body": "from typing import ClassVar\n@dataclass\nclass Lamp:\n    valid_sockets: ClassVar[set] = { 'edison_screw', 'bayonet' }\n    valid_min_wattage: ClassVar[int] = 40\n    valid_max_wattage: ClassVar[int] = 200\n    height_cm: int\n    socket: str\n    wattage: int\n\n    def __post_init__(self) -> None:\n        assert self._is_valid_wattage(), f'Lamp requires {self.valid_min_wattage}-{self.valid_max_wattage}W bulb'\n        assert self._is_valid_socket(), f'Bulb must be one of {self.valid_sockets}'\n\n    def _is_valid_socket(self) -> bool:\n        return self.socket.lower() in self.valid_sockets\n    def _is_valid_wattage(self) -> bool:\n        return (self.wattage > self.valid_min_wattage) and ( self.wattage < self.valid_max_wattage)\nIn [27]: l = Lamp(50, 'bayonet', 80)\nIn [28]: print(repr(l))\nLamp(height_cm=50, socket='bayonet', wattage=80)\nIn [29]: l = Lamp(50, 'bayonet', 300)\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In [29], line 1\n----> 1 l = Lamp(50, 'bayonet', 300)\nFile <string>:6, in __init__(self, height_cm, socket, wattage)\nCell In [25], line 11, in Lamp.__post_init__(self)\n     10 def __post_init__(self) -> None:\n---> 11     assert self._is_valid_wattage(), f'Lamp requires {self.valid_min_wattage}-{self.valid_max_wattage}W bulb'\n     12     assert self._is_valid_socket(), f'Bulb must be one of {self.valid_sockets}'\nAssertionError: Lamp requires 40-200W bulb",
        "score": 24,
        "is_accepted": true,
        "creation_date": "2020-02-04T05:01:18",
        "author": "264nm"
      }
    ]
  },
  {
    "url": "https://stackoverflow.com/questions/58061225/read-a-parquet-bytes-object-in-python",
    "title": "Read a parquet bytes object in Python",
    "question_id": 58061225,
    "posted_date": "2019-09-23T07:14:48",
    "answers": [
      {
        "answer_id": 64287485,
        "body": "import io\nimport pandas as pd\npq_bytes = b'PAR1\\x15\\x02\\x19\\x1c5\\x00\\x18\\x06schema\\x15\\x00\\x00\\x16\\x00\\x19\\x1c\\x19\\x0c\\x16\\x00\\x16\\x00&\\x00\\x16\\x00\\x14\\x00\\x00\\x19,\\x18\\x06pandas\\x18\\x8c\\x01{\"index_columns\": [], \"column_indexes\": [], \"columns\": [], \"creator\": {\"library\": \"pyarrow\", \"version\": \"1.0.1\"}, \"pandas_version\": \"1.1.3\"}\\x00\\x18\\x0cARROW:schema\\x18\\xd8\\x02//////gAAAAQAAAAAAAKAA4ABgAFAAgACgAAAAABBAAQAAAAAAAKAAwAAAAEAAgACgAAAMQAAAAEAAAAAQAAAAwAAAAIAAwABAAIAAgAAACcAAAABAAAAIwAAAB7ImluZGV4X2NvbHVtbnMiOiBbXSwgImNvbHVtbl9pbmRleGVzIjogW10sICJjb2x1bW5zIjogW10sICJjcmVhdG9yIjogeyJsaWJyYXJ5IjogInB5YXJyb3ciLCAidmVyc2lvbiI6ICIxLjAuMSJ9LCAicGFuZGFzX3ZlcnNpb24iOiAiMS4xLjMifQAAAAAGAAAAcGFuZGFzAAAAAAAAAAAAAA==\\x00\\x18\"parquet-cpp version 1.5.1-SNAPSHOT\\x19\\x0c\\x00M\\x02\\x00\\x00PAR1'\npq_file = io.BytesIO(pq_bytes)\ndf = pd.read_parquet(pq_file)",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2020-10-09T17:22:48",
        "author": "Asclepius"
      },
      {
        "answer_id": 64287485,
        "body": "import pandas as pd\ndf = pd.DataFrame()\ndf.to_parquet()\nb'PAR1\\x15\\x04\\x15\\x00\\x15\\x02L\\x15\\x00\\x15\\x04\\x12\\x00\\x00\\x00&&\\x1c\\x15\\x02\\x195\\x04\\x00\\x06\\x19\\x18\\x11__index_level_0__\\x15\\x02\\x16\\x00\\x16\\x1c\\x16\\x1e&\\x00&\\x08)\\x1c\\x15\\x04\\x15\\x04\\x15\\x02\\x00\\x00\\x00\\x15\\x02\\x19,5\\x00\\x18\\x06schema\\x15\\x02\\x00\\x15\\x02%\\x02\\x18\\x11__index_level_0__l\\xbc\\x00\\x00\\x00\\x16\\x00\\x19\\x1c\\x19\\x1c&&\\x1c\\x15\\x02\\x195\\x04\\x00\\x06\\x19\\x18\\x11__index_level_0__\\x15\\x02\\x16\\x00\\x16\\x1c\\x16\\x1e&\\x00&\\x08)\\x1c\\x15\\x04\\x15\\x04\\x15\\x02\\x00\\x00\\x00\\x16\\x1e\\x16\\x00&&\\x16\\x1e\\x14\\x00\\x00\\x19,\\x18\\x06pandas\\x18\\xf6\\x02{\"index_columns\": [\"__index_level_0__\"], \"column_indexes\": [{\"name\": null, \"field_name\": null, \"pandas_type\": \"empty\", \"numpy_type\": \"object\", \"metadata\": null}], \"columns\": [{\"name\": null, \"field_name\": \"__index_level_0__\", \"pandas_type\": \"empty\", \"numpy_type\": \"object\", \"metadata\": null}], \"creator\": {\"library\": \"pyarrow\", \"version\": \"3.0.0\"}, \"pandas_version\": \"1.2.3\"}\\x00\\x18\\x0cARROW:schema\\x18\\xec\\x05/////ygCAAAQAAAAAAAKAA4ABgAFAAgACgAAAAABBAAQAAAAAAAKAAwAAAAEAAgACgAAAKwBAAAEAAAAAQAAAAwAAAAIAAwABAAIAAgAAACEAQAABAAAAHYBAAB7ImluZGV4X2NvbHVtbnMiOiBbIl9faW5kZXhfbGV2ZWxfMF9fIl0sICJjb2x1bW5faW5kZXhlcyI6IFt7Im5hbWUiOiBudWxsLCAiZmllbGRfbmFtZSI6IG51bGwsICJwYW5kYXNfdHlwZSI6ICJlbXB0eSIsICJudW1weV90eXBlIjogIm9iamVjdCIsICJtZXRhZGF0YSI6IG51bGx9XSwgImNvbHVtbnMiOiBbeyJuYW1lIjogbnVsbCwgImZpZWxkX25hbWUiOiAiX19pbmRleF9sZXZlbF8wX18iLCAicGFuZGFzX3R5cGUiOiAiZW1wdHkiLCAibnVtcHlfdHlwZSI6ICJvYmplY3QiLCAibWV0YWRhdGEiOiBudWxsfV0sICJjcmVhdG9yIjogeyJsaWJyYXJ5IjogInB5YXJyb3ciLCAidmVyc2lvbiI6ICIzLjAuMCJ9LCAicGFuZGFzX3ZlcnNpb24iOiAiMS4yLjMifQAABgAAAHBhbmRhcwAAAQAAABQAAAAQABQACAAGAAcADAAAABAAEAAAAAAAAQEQAAAAKAAAAAQAAAAAAAAAEQAAAF9faW5kZXhfbGV2ZWxfMF9fAAAABAAEAAQAAAA=\\x00\\x18\"parquet-cpp version 1.5.1-SNAPSHOT\\x19\\x1c\\x1c\\x00\\x00\\x00\\x1f\\x05\\x00\\x00PAR1'",
        "score": 18,
        "is_accepted": false,
        "creation_date": "2020-10-09T17:22:48",
        "author": "Asclepius"
      }
    ]
  }
]